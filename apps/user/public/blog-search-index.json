[{"body":"ローカルテレビって、なんか好きなんですよね。  \n全国テレビ（？）も好きではあるのですが、たまにローカルテレビに切り替えて眺めることがあります。  \n\n## テレビのロケ\n\n放送している番組のロケに、知っている場所が映ると、『あ！あそこだ！』と無駄に親近感が湧いてきます。  \n知っている場所が放送されると、なんだか嬉しい気持ちだったり、また行ってみたいなと思うことがあります。\n\n## テレビCM\n\nテレビCMも結構好きです。  \n有名タレントを起用せずに、社員一同頑張って作った手作り感満載のCMに、なんとなく目が惹かれます。  \nどこの会社のCM？と全く知らないことが多いので、まだまだ地元民になれていないですね。  \n\n## 天気予報\n\n天気予報も好きですね。  \n1都道府県のみの限定した天気予報が放送されることがあります。  \n全国テレビの天気予報だと、近畿地方という広い括りで予報を教えてくれますが、1都道府県のみだと 北部や南部といった分け方や、主要都市ごとの天気も教えてくれたりします。  \n私が現在住んでいる滋賀県だと、北部と南部で結構違うので、助かります。  \n特に雪の有無はかなり違うので、要注意です。\n\n## グルメ\n\n番組で、人気の飲食店を紹介されることがあります。\n地元で有名なクレープ屋さんとか、最近オープンしたカフェ屋さんとかの情報が知れます。  \nそういう情報って、ある程度アンテナを張ってないと届かないので、結構重宝します。  \n地域密着型の生活情報誌が月1に我が家に届くので、それで情報収集してたりもします。  \n\n## おわりに\n\nローカルテレビで起用されているタレントさんやアナウンサーさんを、ほとんど知らないので、勉強しなきゃですね！","publishedAt":"2026-01-30","slug":"20260130","title":"ローカルテレビって、なんか好き"},{"body":"個人サイト（ジブンノート）をリニューアルしました。\n本記事では、個人サイトをリニューアルした際にあった出来事などを振り返りたいと思います。\n\nちなみに、個人サイトは以下のページです。  \nノート風デザインで、ブログ記事が読めるようになりました！🎉\n\nhttps://silverbirder.github.io\n\n## 背景\n\nfequest という プロダクトに機能リクエストサービス(feature request)を作っていました。  \n私自身の個人サイトもプロダクト登録（以下のページ）して、どういう機能が欲しいか 思いつくままに書いていました。  \n\nhttps://fequest.vercel.app/9\n\nすると、直したい・改善したいと思うことがたくさん湧いてきました。  \n執筆環境をよくしたい、画像アップロードを簡単にしたい、リンク表記にリンク先のタイトルにしたい、などが上がりました。\nfequestの開発にひと段落ついたので、**個人サイトをリニューアルしよう！** と思い至りました。\n\n## AI に頑張ってもらうために\n\n私は Codexや GitHub Copilotを普段から使用しています。  \n基本的には、AIにコーディング中心にして貰いつつ、以下に関しては私が調整する というスタンスでした。\n\n- コピーライティング\n- ページ間の動線整備\n- インタラクションの体験調整\n- 見た目の調整\n\n言語化するにも難しい、人間ならではの拘るポイントは、私が引き受けて、機能開発は AI に中心的に作ってもらっています。\n\nAI like にするために、技術スタックとして **公式MCPが公開されているものを 採用しました** 。  \n具体的には、以下の通りです。\n\n- Next.js\n- Chakra\n- Storybook\n- Playwright\n\nMCPを登録しておけば、公式の標準に沿った解決方法を模索してくれるため、そこそこ外れない設計で解決してくれました。\n\n以下の記事は、Playwright MCPを入れてよかった話について、簡単にまとめています。\n\nhttps://zenn.dev/silverbirder/articles/5bba8251cea74a\n\n後は、AGENTS.md を1つ書いたり、コミット前のチェックを厳格にしたりして最低限のガードレールを整えておきました。  \n未使用ファイルの検査やリンター、型チェック、テスト、ビルド を シーケンスに実行してPASSしたら、コミットできるようにしています。  \nテストには、Storybookのa11yのテストも混ぜているので、色のコントラストが低いものは エラーで弾いてくれるため、かなり重宝しました。  \n\nVitest browser mode と Storybook を利用したVRTも導入しているので、 共通コンポーネント修正での影響範囲が画像の差分で出力されるので開発しやすかったです。  \n以下の記事に 情報をまとめていますので、ご参考ください。  \n\nhttps://zenn.dev/silverbirder/articles/7b2795f6b26f98\n\nバイブコーディングすると表記揺れが多発するため、日本語のみの対応でしたが、i18n のライブラリを入れています。  \n直接のテキスト入力をリンターで弾いて、ja.json に集中するようにしていると、AIもja.jsonに書いてくれるため、良い開発体験です。\n\n参考までに、以下のリンクも貼っておきます。\n\nhttps://zenn.dev/silverbirder/articles/4eab857d610dc6\n\n## お膳立てが終わって\n\n上記のお膳立てを諸々整えてたら、後は AI にバリバリ働いて貰いました。  \n作りたいと思う機能を **TODO.md** ファイルとして管理して、そこにひたすら作りたいものをリストアップしていきます。  \n改善したい項目も全部です。  \n例えば、以下のようなざっくりした感じで良いです。\n\n- ブログ記事のメタデータからタグ抽出して、タグ検索したい\n- 執筆環境を用意して、画像アップロードを簡単にしたい\n- リンク入力したら、タイトルとドメインを取得して置き換えたい\n- ブログ記事の本文検索したい\n\n後は、これらの機能を Codex と Copilot を駆使して作らせて、git commit 時の検査をPASSしたら、ﾖｼｯ! としました。  \n\n## AI に任せなかったところ\n\n主に 見た目のところは、一切AI には書かせませんでした。  \n今回は、ノート風デザインを拘りたかったので、以下のポイントを 細部まで拘っています。\n\n- ノートの罫線の上に文字が乗ること\n- 現実世界のあるノートの見た目であること\n  - NOやDATE、メモリ線\n- 落書きアニメーション\n- 写真とセロハンテープ\n\n特に、ノートのメモリ線に関しては苦労しました。  \n以下に、苦労話について書いています。\n\nhttps://zenn.dev/silverbirder/articles/97f026320218f9\n\n記事本文は、mdxファイルとして元々管理していたのですが、より標準的なmdファイルとして扱いたくなったため、mdファイルに戻しました。(markdownlintをPASSさせるのに苦労しました...)  \nmdファイルには、さまざまな記法があるので 罫線の上に ちょうど乗るように スタイルを微調整する作業は大変でした。  \n\nまた、OG画像もノート風デザインにしています。  \nここのデザインも 私が全部書いています。  \nただし、動くまでの機能は AI に作らせています。  \nOG画像のタイトルには、ブログ記事タイトルを設定しています。  \n改行位置が自然になるように、budoux を使っています。  \n以下は、昔書いた OG画像とbudouxの設定方法について記載しています。\n\nhttps://zenn.dev/silverbirder/articles/50ad55007ccdfb\n\n## 終わりに\n\n最後までお読みいただきありがとうございました。  \n殴り書きになってしまいました...。  \n1日1投稿していますので、ぜひ お立ち寄りくださいませ！\n\nhttps://silverbirder.github.io/blog/","publishedAt":"2026-01-29","slug":"20260129","title":"個人サイトリニューアルの振り返り"},{"body":"個人サイトをリニューアルしました！🎉\n\nhttps://silverbirder.github.io\n\nリニューアルは、今回で6回目です。  \n制作期間は、去年の12月27日から今年の1月28日までの約1ヶ月間です。  \n個人的には最速の開発期間でした。AIの力は偉大ですね。  \n\n本記事では、個人サイトのリニューアルでこだわったポイントについて紹介します。\n\n## ノート風という世界観\n\n個人サイトを見て頂くとわかるかと思いますが、ノート風のデザインにしています。  \nデザイン元は、現実世界にあるノートのデザインをそのまま再現しています。\n\n![ノート風デザイン](https://res.cloudinary.com/silverbirder/image/upload/v1769602372/silver-birder.github.io/blog/hvci8nburx07eytjrgx8.png)\n\nたとえば、以下の場所を拘っています。\n\n- 右上の NOやDATEの表示\n- タイトル部分の広い空間\n- タイトル下にある文字のメモリ線\n- 罫線付きの本文\n\n## メモリ線\n\n特にメモリ線は苦労しました。  \n長いメモリ線と短いメモリ線が一定のリズムで表示されています。  \nまた、線の先端を丸くしたりと細部まで拘っています。  \n\n![メモリ線](https://res.cloudinary.com/silverbirder/image/upload/v1769602773/silver-birder.github.io/blog/wwrsts3bmgpjboc3cmpx.png)\n\n最初は 先端を丸くさせなくても良いじゃんと思ったのですが、どうしても諦めきれずに1時間ぐらい格闘していました。笑\n\n## AIデザインレビュー\n\nデザイン案を練る際には v0やfigma make などの AI と壁打ちすることがあります。  \n要素が増える際に、どういう配置にしたら良いか アイデアを貰うために チャットでやりとりしています。  \nAIに対してノート風のデザインを指示すると、ほぼ毎回 左側に縦の線を1本引いたデザインを作ってきます。  \nこれは外国のノートなら有名なのかしれませんが、私はあまり見たことがないため、却下しました。  \n\n![AIからのノート風デザイン案](https://res.cloudinary.com/silverbirder/image/upload/v1769603447/silver-birder.github.io/blog/ig11p8k3wu6kiaef5c1x.png)\n\n## 落書き\n\n現実世界のノートを使う際、落書きすることはよくありました。  \nなので、右下の隅に アニメーション付きの落書きをひっそりと忍ばしています。\n\n![落書き](https://res.cloudinary.com/silverbirder/image/upload/v1769603056/silver-birder.github.io/blog/f2yitoadw7ovc1iwmi5n.png)\n\n## テーマカラーは緑\n\nせっかくなので、好きな色をテーマカラーにしたいです。  \n私は緑が好きなので、全体的に緑色で統一しています。  \n\n青も好きなので、アクセントに青を少しだけ入れようかと悩んでいました。  \n作っている途中に青を入れていくよりも、最後に完成した後に 少しだけ青を付け加えた方が 整うかなと思ったので入れていません。  \n完成したのに、まだ入れていません。笑  \nまた簡単にですが、ダークモードにも対応しています。  \n\n![ダークモード](https://res.cloudinary.com/silverbirder/image/upload/v1769603622/silver-birder.github.io/blog/otq9jgnakpdzhrfgibur.png)\n\n背景が黒、テキストが緑だと、ハッカーっぽくなっちゃいました。\n\n## 付箋\n\nノートには付箋を貼ることがあります。  \n他のページへの移動は、付箋を使って表現しました。  \n\n![付箋](https://res.cloudinary.com/silverbirder/image/upload/v1769603800/silver-birder.github.io/blog/idgrk4bwjrdrwmtj0j2r.png)\n\n開いているページの付箋は前に引っ付いていて、それ以外の付箋は後ろに引っ付いているイメージです。  \n付箋をホバーすると、ほんの少し上に持ち上がります。笑\n\n## 角丸はしていない\n\nノートに貼っている画像などに、角を丸くさせることができます。  \nうまく言語化できていないのですが、記事本文中は 角丸をせずに、直角にしています。\n\n![直感に](https://res.cloudinary.com/silverbirder/image/upload/v1769604187/silver-birder.github.io/blog/%E7%9B%B4%E8%A7%92%E3%81%AB.png)\n\n写真に関しては、マスキングテープやセロハンテープで貼っている感じにしたいなと思っています。（できていません）  \n※ 追記: 簡易ですが入れました。\n\n## 終わりに\n\n拘っているところと、そうでないところがハッキリしています。  \n記事本文は時間をかけていますが、ホームや自己紹介ページはかなり手抜きです。笑\n\n機能リクエストは以下のリンクより受け付けています！\n\nhttps://fequest.vercel.app/9\n\n短期間で拘り抜いて、大満足の1ヶ月間でした！","publishedAt":"2026-01-28","slug":"20260128","title":"個人サイトをリニューアルしました！"},{"body":"たまたま、スーパーで甘納豆が安く販売されていたので購入してみました。プチ甘納豆金時 という商品です。\n以下は、商品のリンクです。\n\nhttps://www.amazon.co.jp/dp/B07635P4CB\n\n1口食べて、ハマりましたね。  \nなぜなら、私は甘いものが好きで、アンコも好きなのです。  \nペースト状のアンコも良いですが、豆の形が残った甘納豆もよいですね。  \n甘納豆の砂糖の甘い味、これは太りそうです。  \n少し調べてみたら、甘納豆は砂糖蜜（砂糖と水！）に豆を漬けるんですね。\nそりゃ甘くなるわけだ。  \n\nちなみに、砂糖漬けの Wiki  があったので 見てみると\n\nhttps://ja.wikipedia.org/wiki/%E7%A0%82%E7%B3%96%E6%BC%AC%E3%81%91\n\n文旦漬け というのもあるのですね。  \n\nhttps://ja.wikipedia.org/wiki/%E6%96%87%E6%97%A6%E6%BC%AC%E3%81%91\n\nあの酸っぱい柑橘の文旦を、砂糖漬けしたものだそうです。  \nこれも美味しそうですね。  \n今度スーパーにあったら、買ってみようかな。  \n\nというか、Wikiの関連項目ってありがたいですね。  \n気になる情報がリンクされていて、今更ながら Wiki に感謝です！","publishedAt":"2026-01-27","slug":"20260127","title":"甘納豆 はじめて食べてみた"},{"body":"完全に私の早とちりです。  \nただの備忘録として、残しておきます...。\n\n## 確定申告間近で、音信不通\n\n去年の11月に税理士さん（Aさん）と記帳代行などの税務業務について業務契約しました。  \nそして、今年の2月には令和7年度の確定申告が始まります。  \n確定申告のスケジュールは、どんな感じなのか 税理士Aさんへ確認のため、メール送信しました。  \n1月9日にメールを送信後、**今日の26日まで返事がありませんでした。**  \n不安が急激に込み上げてきました。  \n\n- メールに記載されている電話番号に電話しても繋がらない\n- 税理士会に登録している電話番号に電話しても繋がらない\n- 11月以降に月一回の書類アップロードしましたメールにいつも返事がない（了解しました も一切ない）\n- 会計ソフトを見ても、 **仕訳登録が一切ない!!!**\n\nあれ、やばくない...？  \n税理士会 に登録されている税理士さんだし、契約書にも記帳代行の業務は明記しているし、大丈夫だと思うんだけど...。  \n\n昔に一度だけ未納付された苦い経験（税とは全く別件）を思い出してしまい、不安がエスカレートしてしまいました。  \n\n## 別の税理士さんへ相談\n\n税理士探しをしていた際にお声がけしていた親切な税理士さん（Bさん）を思い出し、相談無料だったため メールを送りすると、1時間以内に返事がきました。  \n心の底から、ありがとうという気持ちが増しました。  \n\nZoomで、以下についてご相談しました。\n\n- 業界的によくあることなのか\n  - はじめての税理業務の代行なので、肌感が分からない\n- 逃げられるような自体ではないのか\n  - もしそうなら、どうしたら良いのか\n- 代わりに記帳代行をして貰えるか\n  - 間に合うのか\n\nZoom が始まる2分前に、現在契約している税理士Aさんからの返事がちょうどきて、**頭がパニックになりました。**  \n確定申告のスケジュールについて記載されていました。  \n\nそして、税理士BさんとZoomを通して、以下のことのようでした。\n\n- 税理士会に登録されている、業務契約もあるなら、安心してほしい\n  - 逃避は税理士のリスクの方が高いからやらないはず\n- 個人事業主（私）と1人税理士（Aさん）で、仕訳数的にまとめて記帳することは、よくある\n  - 提示して貰ったスケジュール感は、間違っていない\n- ただ、メールのレスポンスが ほとんどない（了解しました などもない）というのは、コミュニケーション的に不安になる気持ちも分かる。\n  - とはいえ、税理士Aさん側の事情もあると思うので、これは相性が悪い\n\nという話を30分ほど相談させて頂き、不安が解消できました。  \n特に何かが解決されたという訳ではなく、私の不安心が消えました。  \nまた、本当に代行業務がなされない場合は連絡ください、とまで仰って頂き、涙が出そうになりました。  \nありがたいお話なので、また次の期は検討しますと、お伝えしました。\n\nただその方だけでなく、地域の税理士さんへ対面して相談を考えようと思いました。1人だけよりも、複数の意見を合わせた方が納得感が違いそうです。  \n\nさて、確定申告の代行はうまくいくのでしょうか...!","publishedAt":"2026-01-26","slug":"20260126","title":"税理士に逃げられたと勘違いした話"},{"body":"半年ぶりぐらいにお家でたこ焼きを作りました。  \nたこ焼きを食べる日は、いつもタコパ（たこ焼きパーティ）と呼んでいます。  \nタコパをする日は、何の具を入れるのか、それを考えるのが楽しいですね。その次に楽しいのは、串でたこ焼きをくるくる回している時間が好きです。隅にある焼きが弱いたこ焼きを中央に引越しするのです。  \n\nたこ焼きの具は、やはりタコが一番ベタで良いと思うのですが、スーパーでタコを買おうとすると、なかなか良いお値段になります。  \nじゃあ、何の具が良いのかな？と悩みます。  \n\nそこで、過去に入れたたこ焼きの具を紹介します！\n\n## ウインナー\n\n定番のウインナーさん。  \nお肉感を味わえ、準備の手間がとても楽、というめんどくさがりな私にはちょうど良いやつです。  \nちょっと焦げたぐらいのウインナーが美味しいですね。  \n\n## チーズ\n\n振りかける系のチーズでいくか、6Pチーズのような固形でいくか。  \n私は後者の方が好きです。  \nチーズがたこ焼きの中でとろけて、甘い感じになります。  \nチーズとマヨネーズの相性が良いですね！\n\n## キムチ\n\n甘い系ではなく、辛い系のキムチがおすすめ。  \nキムチの汁や白菜を、そのままドバーとたこ焼きの中に入れると、生地が赤くなります。  \nたこ焼きの鉄板で、3周目ぐらいに味変としてキムチを食べると、刺激的で良いですね。\n\n## ネギ\n\n青でも白でもお好みのネギを選びます。  \n一口サイズぐらいの少し大きめのサイズでネギを切ります。  \nたこ焼きの中で、ネギが崩れて小さく萎んでしまうので、大きめの方が形が残って良いです。  \nネギだけというのが物足りない人は、天かすや紅生姜を沢山入れましょう。\n\n## もち\n\nお腹に溜まる餅さん。  \nチーズと同じように、たこ焼きの中で餅が溶けていきます。  \n食感が、餅なので 柔らかいモチモチとしていて、意外と美味しいです。  \nこつぶ餅というのがスーパーに販売されています。  \nない場合は、包丁でカットしましょう。  \n\n## こんにゃく\n\n冷蔵庫の中に余ってしまったこんにゃく。  \nたこ焼きの中に、小さめに切ったこんにゃくを入れる。  \n味は質素なのですが、食感がぷにっとするので、そういうのが楽しいですね。\n\n## 牛すじ\n\nスーパーのたこ焼きコーナーの近くに、たまに見かける牛すじさん。  \n牛すじのお肉全てを、贅沢にたこ焼きに入れるのです。  \n牛すじの汁も残さずですよ。  \nご飯が食べたくなる、そんな牛すじです。  \n\n## チョコ\n\n変わり種のチョコさん。\nたこ焼きをデザートとして食べる時に、チョコは良いでしょう。  \nダークチョコのような苦目のチョコを入れる方が、私は好みです。  \nチョコを入れる場合は、最後に食べないと口が一気に食後のデザートなります。\n\n## おわりに\n\n1回のタコパで、大体3つか4つぐらいの種類の具を用意しています。  \n今回は、ウインナー、チーズ、キムチ、ネギの4つです。  \nなんと、スーパーにタコが売り切れていたのです。  \nみんな雪の日は、お家でタコパしてたのかな。","publishedAt":"2026-01-25","slug":"20260125","title":"たこ焼きの具"},{"body":"最近、ヒューマンインターフェース ガイドライン（HIG）という言葉を知りました。\n\n> 「ヒューマンインターフェイスガイドライン」には、どのAppleプラットフォームでも優れた体験を設計できるようにするためのガイドとベストプラクティスが含まれています。\n\nhttps://developer.apple.com/jp/design/human-interface-guidelines/\n\nHIGというのは、かなり昔からあったようなのですね。  \n\nhttps://gihyo.jp/dev/clip/01/orangenews/vol39/0007\n\n\"ヒューマンインターフェース ガイドライン\" で検索すると、以下の記事が検索上位に表示されました。\n\nhttps://www.sociomedia.co.jp/category/shig\n内容については、これから拝見しようと思っています。  \nまだ読めていません。\n\nHIG というのは、UX をよりよくするための UIデザインというのが、私のなんとなくの認識です。UIデザインとUXというのは、個人的にとても興味があります。  \n以下は、読んでいて学びがあった書籍です。\n\nhttps://gihyo.jp/book/2023/978-4-297-13409-9\n\nhttps://www.shoeisha.co.jp/book/detail/9784798177892\n\nhttps://www.oreilly.co.jp/books/9784873116594/\n\nhttps://letter-spacing.mimiguri.co.jp/\n\nhttps://www.shoeisha.co.jp/book/detail/9784798175775\n\nhttps://bow.jp/book/%E3%81%AF%E3%81%98%E3%82%81%E3%81%A6%E3%81%AEux%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E5%9B%B3%E9%91%91/\n\nHIG に関しては、 Apple というビッグカンパニーのUIデザインのガイドラインという めちゃくちゃ興味があります。  \n他にも、おすすめの情報ありましたら、教えてください！","publishedAt":"2026-01-24","slug":"20260124","title":"ヒューマンインターフェース ガイドライン という言葉を知りました。"},{"body":"昨日から滋賀県に雪がたくさん降っています。  20cm以上は雪が積もっています。\n駐車場に雪がたくさん積っているので、雪かきしないと車が出せません。\n\nここで雪対策で購入した、ワークマンのスノーブーツがめっちゃ役に立ちました！\n\nhttps://workman.jp/shop/g/g2300056363059/\n\nこれの良いところは、スノーブーツを履くのが簡単で、スッと足を突っ込んだらちょうどフィットして履けます。その後に、ズボンの裾をブーツの中に収納して、ゴムを引っ張って中に雪が入らようにします。\nこのブーツのおかげで、そのまま雪の中に足を突っ込んでも、濡れないし冷たくない！やった！  \n見た目に作業用っぽさがなくて、そういうところも気に入りました。買ってよかった。\n\n駐車場の雪かきは、コーナンで買った雪かきプッシャーが大活躍しました。あれで、車の前の雪をゴーッと押し出して 一気に雪が取れます。意外と力がいるのですが、昨日今日の雪は柔らかくて軽いので大丈夫でした。\n\n他にも、ワークマンで買った防寒ジャンパーも十分役立っていたし、備えあれば憂いなしですね。\n\n雪がたくさん降っていても、消雪用に細い管から水を噴水して雪を溶かしていたり、排雪するための流雪溝があったり、道路の側面から水が勢いよく噴射していたり、雪国の知恵が大活躍していました。\n\nそれでも、屋根の上にある大雪が落ちてきたり、凍った路面を滑ってしまったりと、普段以上に危険な道路なのは変わりありません。不要な外出は控えて、お家でお鍋でもしましょうね。","publishedAt":"2026-01-23","slug":"20260123","title":"大雪とワークマン"},{"body":"主にWeb関連の個人開発をしている際に心がけていることを書きます。\n\n月末に近づくにつれ、AIの利用上限に達してしまうことがあります。  \nその状況になった時、以下のいずれかの選択肢が私の中では残っています。\n\n- 課金して利用上限を増やす\n- 無料モデルでやり過ごす\n- 何もしない\n\n費用はできれば安く済ませたいので、課金は最終手段です。  \n無料モデルが使えるなら とりあえず無料モデルを使ってやり過ごします。ただ、有料モデルに比べて性能が比較的低いため、期待しないレスポンスにストレスが増えてしまうことがあります。  \nかといって、何もしないと前に進みません。\n\nそこで、利用上限に達した際にやるべきリストを残しておくと良さそう、というのが最近の私の考えです。\n\nAIにやってもらうことと、私がやることを分けています。\n\n## AIにやってもらうこと\n\nAIには、新機能開発を積極的に作って貰い、詳細部分は粗くさせています。  \nただし粗すぎては困るので、最低限守って貰いたいことは AGENTS.md を書いておきます。  \n未使用コードの除去や静的解析・型チェック・テスト・ビルド といったプロセスを厳格にしておけば、そこさえ守らせていけばOK としています。  \n\n## 私がやること\n\n私がやることべきリストは、以下のものを残しています。\n\n- コピー（文章）を丁寧に書き直す\n- インタラクション（動き）を凝る\n- リンク（動線）を整えていく\n- スタイル（見た目）を洗練させていく\n\n主に 人間の目で じっくり見る・考えたいところは残しています。\n\nコピー（文章）は、コピーライティングという職業があるほど 大事なものです。読んでいる状況と、伝えたいことを踏まえた上で文章を練って考えたいです。文章といっても、ボタンのラベルなど文字になるものは全て対象です。  \n\nインタラクション（動き）は、タグをクリックしたら どういう挙動になって欲しいかなど、操作した際に期待する挙動について 凝りたいと思っています。インタラクションに統一性がないと、ユーザーは混乱してしまいます。  \n\nリンク（動線）は、Web上でドキュメント間を繋いで回遊して貰う大事な要素です。行き止まりにならないか、訪問しているページに欲しいリンクが過不足しないか、を考えたいです。\n\nスタイル（見た目）は、デザイントークンやUIライブラリを整えたとしても、余白設計や配色などがごちゃごちゃしていると残念です。世界観を大事にしつつ、自然と読みやすい形を丁寧に作り込んでいきたいです。\n\n## 終わりに\n\nAI の得意とすることには全力で取り組んでもらいつつ、人間が得意とすること は人間が取り組む。  \n分業しておけば、上限が達した際でも私の仕事は残っています。","publishedAt":"2026-01-22","slug":"20260122","title":"AIの利用上限に達した時にすることを残しておく"},{"body":"今更ながらスターバックスのスターを集め始めました。\n\nhttps://www.starbucks.co.jp/rewards/\n\n何年も前から、スターバックスをよく利用させて貰っていたのですが、上記のスターについては全く知りませんでした。  \nうー、もったいないことをしてしまいました。\n\n『もっとずっと前から始めていれば...』という後悔って、色々と味わうことがあるじゃないですか。  \nかといって 何も始めずにもったいない状態になるのも、何か嫌じゃないですか。  \n私は、遅くても良いから登録を始める派です。\n\nスーパーや薬局のポイントカードや、洋服屋のアプリ登録とかもそうでした。  \n最初はいらないかな、また今度にしようかな と避けてしまうことが多いです。\nただその利用したお店を過去に3回以上訪れたら、作るようにしています。  \n最初の1,2回は たまたま利用しただけかもしれませんが、その店舗が気に入って3度目にポイントカードを作ることが多いです。\n\nスターバックスに関しては、スターについて全く知らなくて、お店で順番待ちしていた時に前のお客さんがスターのことを話していたのを聞いて気づきました。  \nありがとう、お客さん...!  \nスターを集めて、スターマグを手に入れるぞ！","publishedAt":"2026-01-21","slug":"20260121","title":"スターバックスのスターを集め始めた"},{"body":"個人サイトをリニューアルをしています。  \nノート風のデザインを目指して、スタイルを調整していました。  \nノートの見た目は、現実にあるノートを再現しようとCSSを書いていました。\n\n現在、以下の画像のようなノートになっています。\n\n![ノート風デザインの見出し](https://res.cloudinary.com/silverbirder/image/upload/v1768908342/silver-birder.github.io/blog/rnxluc4mieymbq1xqxj7.png)\n\n上記の画像の赤枠の箇所について、CSSで書くのに苦労しました。  \nというのも、現実にあるノートのスタイルを再現したく、以下の見た目を作りたかったのです。\n\n1. タイトルの下にある線から、縦の線を下方向に生やしたい\n1. 縦の線は、一定の間隔で繰り返して表示したい\n1. 縦の線は、大きい線と小さい線を分けたい\n1. 縦の線の下側を、丸くしたい\n\n## CSSで書く\n\nそこで、CSS で 以下のようなスタイルを書いて対応していました。\n\n```html\n<div class=\"notebook-heading\">\n  <h1 class=\"notebook-title\">\n    Title Text\n  </h1>\n  <!-- 長い棒（4px / 128px ピッチ） -->\n  <div class=\"notebook-line notebook-line--large\"></div>\n  <!-- 短い棒（2px / 16px ピッチ） -->\n  <div class=\"notebook-line notebook-line--small\"></div>\n</div>\n```\n\n```css\n:root {\n  --border-color: #ccc;\n}\n\n/* 親コンテナ */\n.notebook-heading {\n  position: relative;\n  width: 100%;\n}\n\n/* 見出し */\n.notebook-title {\n  border-bottom: 1px solid var(--border-color);\n}\n\n/* 共通の罫線スタイル */\n.notebook-line {\n  position: absolute;\n  left: 0;\n  width: 100%;\n}\n\n/* 長い棒（4px 高・128px ピッチ） */\n.notebook-line--large {\n  bottom: -4px;\n  height: 4px;\n  background-image: repeating-linear-gradient(\n    to right,\n    var(--border-color) 0 2px,\n    transparent 2px 128px\n  );\n}\n\n/* 短い棒（2px 高・16px ピッチ） */\n.notebook-line--small {\n  bottom: -2px;\n  height: 2px;\n  background-image: repeating-linear-gradient(\n    to right,\n    var(--border-color) 0 2px,\n    transparent 2px 16px\n  );\n}\n```\n\n考えとしては、`.notebook-line` を基準として 高さを2px,4pxで、横幅100% まで広げた領域に対して、背景色を `repeating-linear-gradient` で塗っていく方法です。  \nこの方法だと、実現したい1,2,3はクリアするのですが、4がクリアできないのです。\n\n> 1. 縦の線の下側を、丸くしたい\n\n4について、CSSで解決できる方法があるのかもしれませんが、他の方法がないのかと思案しました。\n\n## SVGで書く\n\n『縦棒の下部分を丸くするというのは、図形を書こうとしている？』と思い、SVGでいけそうだなと考えました。\n\nそこで、以下のような方法で解決できました。  \n実際のコードではなく、イメージのコードです。\n\n```html\n<div class=\"notebook-heading\">\n  <h1 class=\"notebook-title\">Title Text</h1>\n\n  <!-- 長い棒（6px 高 / 128px ピッチ / 下だけ丸い） -->\n  <svg class=\"notebook-svg notebook-svg--large\" aria-hidden=\"true\">\n    <defs>\n      <pattern\n        id=\"dash-bottom-rounded-6\"\n        patternUnits=\"userSpaceOnUse\"\n        width=\"128\"\n        height=\"6\"\n      >\n        <!-- 幅 2px の縦棒。下側だけ円弧で丸める -->\n        <path\n          d=\"\n            M 0 0\n            H 2\n            V 5\n            A 1 1 0 0 1 1 6\n            A 1 1 0 0 1 0 5\n            Z\n          \"\n          class=\"notebook-dash\"\n        />\n      </pattern>\n    </defs>\n\n    <rect width=\"100%\" height=\"100%\" fill=\"url(#dash-bottom-rounded-6)\" />\n  </svg>\n\n  <!-- 短い棒（3px 高 / 16px ピッチ / 下だけ丸い） -->\n  <svg class=\"notebook-svg notebook-svg--small\" aria-hidden=\"true\">\n    <defs>\n      <pattern\n        id=\"dash-bottom-rounded-3\"\n        patternUnits=\"userSpaceOnUse\"\n        width=\"16\"\n        height=\"3\"\n      >\n        <!-- 幅 2px の縦棒。下側だけ円弧で丸める -->\n        <path\n          d=\"\n            M 0 0\n            H 2\n            V 2\n            A 1 1 0 0 1 1 3\n            A 1 1 0 0 1 0 2\n            Z\n          \"\n          class=\"notebook-dash\"\n        />\n      </pattern>\n    </defs>\n\n    <rect width=\"100%\" height=\"100%\" fill=\"url(#dash-bottom-rounded-3)\" />\n  </svg>\n</div>\n```\n\n```css\n:root {\n  --border-color: #ccc;\n}\n\n/* 親コンテナ */\n.notebook-heading {\n  position: relative;\n  width: 100%;\n}\n\n/* 見出し */\n.notebook-title {\n  border-bottom: 1px solid var(--border-color);\n}\n\n/* SVG 下線（共通） */\n.notebook-svg {\n  position: absolute;\n  left: 0;\n  width: 100%;\n  display: block;\n}\n\n/* 長い棒（6px） */\n.notebook-svg--large {\n  bottom: -6px;\n  height: 6px;\n}\n\n/* 短い棒（3px） */\n.notebook-svg--small {\n  bottom: -3px;\n  height: 3px;\n}\n\n/* パターン内の棒の色（CSS 変数で制御） */\n.notebook-dash {\n  fill: var(--border-color);\n}\n```\n\nSVGとして縦棒を表現していて、`.notebook-line` に連続して表示しているみたいです。  \n正直SVGについて理解が浅いため、また今回を機に SVG について興味が湧いてきました。  \nリニューアル後は、SVGについて学んでみたいなと思います。\n\n## 終わりに\n\n図形に関しては、SVGで書いちゃう方が楽でした。  \nCSS 達人のトリックを披露するでも良いのですが、保守性の面では SVG の方が好みです。  \nCSS、SVG それぞれ得意とするもので書いていきたいですね。","publishedAt":"2026-01-20","slug":"20260120","title":"CSSで頑張らなくても、SVGで楽にできるときもある"},{"body":"3ヶ月に1回ぐらいの頻度で 美容室に行っています。  \n前髪が目にかかって邪魔に感じるぐらいになると、そろそろ美容室に行くシーズンです。ただ、なかなか行けません。\n\n私の場合、3年ぐらいの間隔で引越ししているので、今住んでいる地域での行き慣れた美容室というのがありません。そのため、美容室はだいたい初回訪問が多いです。\n\n美容室は、ホットペッパービューティで探すことが多くて、メンズカットできるところで調べています。  \n昔、大阪にいた頃、50代ぐらいのおばさまがカットして下さる美容室に訪問したことがあるのですが、色々と事細かにカットの方向性を伝えないといけなくて、かなり迷惑をかけてしまいました。  \nそれ以降は、メンズカットできる店を探していまして、男性の美容師の方に見て頂いています。\n\n強面な感じの美容師さんが苦手です。  \n美容師さんを指名したことはないのですが、どのような美容師さんがいらっしゃるかネットで確認ぐらいはしています。\n多くの方は、優しそうな印象の方ばかりです。  \nただ、会ってみると違うことが多くて、びっくりしています。\n\n切ってほしい髪型は決まっているので、美容師さんに「ツーブロック、前髪の長さ、後ろ髪の長さ、バリカンの長さ」をお伝えしています。\n\n髪を切って頂いている間の会話なんですが、私の性分的に、静かな雰囲気というのが空気に耐えれないのです。（変ですね）  \nかといって、話したいこともないので「天気・仕事・髪の毛」のいずれかを いつも話しています。  \n美容師さんは そういう話し上手・聞き上手 というか職業的に慣れてらっしゃるので、簡単に話をかけて下さって、自分もそれに受け答えしています。\n\n初回訪問というのが、億劫になる原因なんです。\n純粋に緊張しちゃうんですよね。  \n仕事柄、あまり対面で話すことがないので。  \nまた、自分の身なりに自信がない というのも根っこにありそうです。\n\nそして、近々 美容室を予約するときが来ました。  \n行き慣れた美容室を見つけたい〜〜〜！","publishedAt":"2026-01-19","slug":"20260119","title":"美容室に行くのが億劫"},{"body":"ドラクエが大好きです。  \nシリーズで言うと、1から8までだけですが 全部プレイしました。  \nモンスターズ、ダンジョン、もりもり のゲームもハマりました。  \nどれもこれも面白くて、3周以上は遊んでいましたね。\n\nそんな私は、Googleのレコメンドに スクエニ e-STORE のグッズが流れてきます。  \nもうついつい、タップしちゃうんですよね。\n\nそのレコメンドの1つに、でっかいスライムぬいぐるみ が紹介されて、買っちゃいました。笑\n\nhttps://store.jp.square-enix.com/item/MW60334_11.html\n\n以下は、e-STORE のドラクエシリーズの商品一覧ページです。\n\nhttps://store.jp.square-enix.com/item_list.html#SERIES=1\\&pointercat=SERIES\n\n今から、私が欲しいと持っているものを紹介します。  \n誰か私にください。\n\n## 湯のみ\n\nhttps://store.jp.square-enix.com/item/MW69304.html\n\nデザインが和風でスライム、バブルスライム、ホイミスライム、キングスライムが描かれています。  \nなんて可愛いのかしら。  \nこの湯のみに、ほうじ茶を入れて飲みたい。\n\n## ステンレスカップ\n\nhttps://store.jp.square-enix.com/item/MW69328.html\n\nこっちは、ステンレス製のカップです。  \nダークな黒テイストで、メタルスライムが正面を向いています。  \nなんとかっこよい姿なのでしょうか。  \nメタルスライムの色と縁の色が揃っていて、よい。\n\n## ぬいぐるみ\n\nhttps://store.jp.square-enix.com/item/MW1250_2.html\n\n我が家には、スライムのぬいぐるみが6個ぐらいあります。  \nクッションってなんか好きなんですよね。  \nチョココロネに入っているスライム、スライムコロネ というモンスターだそうです。知りませんでした。  \nこのスライムコロネくん、パンとスライムが分離できちゃうんです。  \nひゃー、遊びたい。\n\n## スープカップ\n\nhttps://store.jp.square-enix.com/item/MW53413.html\n\n淡路島にあるニジゲンノモリに行ったことがあります。  \n淡路島の有名なたまねぎをモチーフとしたたまねぎスライム。  \nこのたまねぎスライムのフォルムのスープカップ。  \nたまねぎスープを入れたくなりますね。  \nコンポタとかも似合いそうだ。\n\n## 貯金箱\n\nhttps://store.jp.square-enix.com/item/MW60685.html\n\nバス乗車用に10円玉を集めています。  \nICカードが使えない、両替機がついていない、そんなバスに乗ることがあるのです。  \nちょうどお金を払わないといけないので、10円玉を集めています。  \nこのメタルスライムくんの貯金箱、かっこよいな〜〜〜。","publishedAt":"2026-01-18","slug":"20260118","title":"スクエニ e-STORE には夢がある"},{"body":"デフォルト効果は、最初に設定されている状態を変更せずにそのまま受け入れやすい心理的効果の1つです。\n\n> デフォルト効果は、認知バイアスのひとつで、予め選択されている意思決定や設定されている値などを変更することなく、そのまま受け入れてしまいやすくなる心理的傾向である。  \n※ [デフォルト効果 - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E5%8A%B9%E6%9E%9C)\n\nデフォルト設定は推奨されている設定であることが多いので、私は多くをデフォルトのままにしています。  \n例えば、以下などがあります。\n\n- スマホやパソコンの設定\n- Webサービスの設定\n- Webフレームワークの設定\n\nこのデフォルト効果を利用したダークパターンもあります。  \nアカウント登録でよくある \"メール配信を希望する\" チェックボックスがデフォルトでチェックされているやつです。  \nこういうのは、推奨されていても拒否しています。\n\n今回、そのデフォルト効果に反することをしてみました。  \nそれは、\"Macbook のテーマカラーを私の好きな緑色に変更\" をしてみました。  \n後で戻そうと思っていたのですが、使ってみるとめちゃくちゃ愛着が湧いてきました。  \nボタンや入力、ウィンドウ、アイコン など よく目にするものの色が、全体的に緑色に置き換わっています。  \nなんというか、気分が上がりました（笑）。\n\n私は、あまりカスタマイズを凝ったりしたことがなくて、多くの人と同じものを選ぶことが多いです。  \nこだわりがないので、無難なものを選びがちです。  \nけれど今回の経験を通して、ちょっとだけ変えてみる、というのは そのもの自体への愛着が強くなって、良さそうだなと感じました。  \nたったの \"テーマカラーを変えただけ\" なのに、思わぬ気づきを得ました。","publishedAt":"2026-01-17","slug":"20260117","title":"デフォルト効果に逆らう"},{"body":"下呂温泉に行こうと思っています。\n\nというのも、来月と再来月が私たち夫婦のそれぞれの誕生月でして、プレゼントされたい品がお互いありません。  \nそこで二人分の誕生日を使って、旅行をしようという結論になりました。\n\n下呂温泉は、学生の頃に青春18きっぷを使って、一人旅で訪れた場所です。  \nその当時は、有名温泉地を巡る旅をしていて、下呂温泉は 橋の下のお風呂ぐらいしか記憶がありません。\n\nなので、夫婦となってもう一度訪れてみたい！となり行くことにしました。\n\n## 調べ方\n\n下呂温泉は有名な観光地だけあってか、観光に関するサイトがたくさんあって役に立ちました。ありがたいことです。\n\n宿は、以下のサイトを見ました。\n\n[下呂駅周辺の旅館・ホテル｜下呂温泉観光協会](https://www.gero-spa.com/shukuhaku/)\n\n色々調べてみると、有名どころの湯之島館か水明館に泊まろうと思っています。  \nどちらも格式高そうで、せっかくなら良いところに泊まってみたいなとなりました。\n\n周辺スポットは、以下のサイトを見ました。\n\n[全カテゴリ - 全エリア｜観る・あそぶ｜下呂温泉観光協会](https://www.gero-spa.com/spot/)\n\n合掌村 というのも行ってみたいですね。  \n岐阜県では合掌造りで有名な白川郷がありますが、こちらの合掌村にも合掌造りの民家があるらしく、一度見てみたいなと思います。\n\n[下呂温泉 合掌村 公式ホームページ](https://www.gero-gassho.jp/)\n\nグルメは、以下のサイトをみました。\n\n[下呂温泉ぐるめ案内 - げろぐる｜下呂商工会](https://www.gerogle.jp/index.html)\n\n湯島庵さんの肉寿司でも食べてみたいなと思います。  \n下呂松葉さんの飛騨牛も食べたいなと思うのですが、今回の旅行は食より宿を優先したいので、おそらく食べに行かない気がします。テンションが上がって食べに行くかもしれません。","publishedAt":"2026-01-16","slug":"20260116","title":"下呂温泉"},{"body":"普段使っている Macbook の macOS を Tahoe 26 にアップデートしてみました。  \nLiquid Glass というガラスっぽいデザインに刷新されていました。  \nまだ使用して2日目ぐらいですけど、比較的気に入っています。\n\nどこか気に入っているのかと言われると、自然な透過感が良いですね。  \n機能が良い悪いというより、違和感なく滑らかに ガラスっぽさが浸透している感じです。\n\nたとえば、Finder を開くと、背景の色に合わせて左メニューのガラスの色が少し変わります。\n\n![Finder](https://res.cloudinary.com/silverbirder/image/upload/v1768479536/silver-birder.github.io/blog/wy3sexzv8fxmgejyw2om.png)\n\n上記画像は Finder のスクリーンショットを撮ったのですが、なぜか背景色が反映されたガラス色が写りませんでした。 🤔\n\n他には、アプリアイコン の縁が少しキラキラしていて、いいねぇと思います。\n\n![Figma](https://res.cloudinary.com/silverbirder/image/upload/v1768480355/silver-birder.github.io/blog/vki8cjiu8dl5r0vjwfjy.png)\n\nあと、入力補助の表示で、グネッとした感があって 不思議でしたね。\n\n![入力](https://res.cloudinary.com/silverbirder/image/upload/v1768480791/silver-birder.github.io/blog/k8mted8hqqjflutj8yuk.png)\n\nもうひとつ、全体的に角が丸っぽくなっている気がしますが、これは気のせい？\n\nま、Liquid Glass 気に入りました！","publishedAt":"2026-01-15","slug":"20260115","title":"Mac を Liquid Glass にしてみた"},{"body":"私のアカウントは↓です。よければ相互フォローさせてくださいな。\n\nhttps://bsky.app/profile/silverbirder.bsky.social\n\nTwitter から X に変わっても、なんとなくXを使い続けていました。  \nあーだこーだと騒がれても、結局はXに残っちゃっていました。  \n私のスマホに、BlueskyとかThreadsのアプリを入れたまま放置していました。\n\nあまり深い理由はないのですが、Blueskyをメインとして使ってみようかなと思います。  \nBlueskyの好きなところは、UIが気に入っています。  \n落ち着いた色合いと、線や円が美しく整っていて、結構好きなんですよね。  \nスマホのBlueskyアプリだと、スクロールしたときにスクロールボタンとアバターボタンが重なるのが気に入っています笑。  \nPDSという仕組みも興味はありますが、、、。\n\nとりあえず、スマホの一番下にある一軍スペースの一番左に、Blueskyを置きました。準備万端です。\n\nBlueskyの主な用途は、ネットサーフィンと適当なコメント書き込みぐらいです。  \nただXで気に入っている用途もありまして。\nそれはサービス障害発生とか地震発生でのユーザーの声が早いところです。  \nBluesky はどうなんでしょう？  \n少し話が逸れますが、以前のCloudflare の障害では Bluesky は正常だったんですよね。\n\nXとBlueskyを併用する考えだと、あまり今と変わらないと思うので、Blueskyをメインに使います。  \nはてなブログ投稿時のX共有は便利なので、そういうのは使い続けるかもしれません。  \nいつまで続くのか分かりませんが、とりあえず行ってきます！","publishedAt":"2026-01-14","slug":"20260114","title":"メインのSNSを、XからBlueskyへ"},{"body":"平日の今日、いつも通り在宅ワークをしていました。  \n午前中の仕事でひと段落ついたので、休憩の取ろうとリビングに戻ったら妻がソファで横になっていました。  \n妻は今日仕事が休みなので、寝ているのかなと思ったのですが、小さい声で『頭が痛い...』と震えてました。  \n\n頭が痛いのはたまに聞くのですが、なんかいつもと様子がおかしいなと思ったので、近寄って色々聞くと、頭痛と吐き気がすごいみたいです。\n\nすごく心配になったので、在宅ワークは仕事先の人へ連絡してストップし、すぐに妻の元に戻ると、トイレで吐いていました。  \n背中をさすって声をかけて、落ち着かせた後、内科の病院やってるかなと調べたら、ちょうど営業時間外でした...。\n\n## ドラッグストア\n\n病院が再開する16時まで待つのは悪化しちゃうし、つらそうだなと思ったので、家で頭痛薬と胃腸薬を探しました。  \nけど、良さそうなものがなかったので、近くのドラッグストア（ドラッグユタカ）に行きました。\n\n5分ぐらい薬の棚で『どれが良いのか...』と悩み果てていると、店員さんに声かけて頂いきました。  \n事情を伝えて、頭痛を何度も訴えていたので、胃の負担が軽い頭痛薬を紹介してもらい、購入して帰宅しました。  \n店員さん、ありがとう...！\n\n## お薬と昼食\n\n空腹時にお薬はよくないので、フルグラを少し食べてもらった後にお薬を飲んでもらい、ソファじゃなくてお布団に運びました。  \n『吐いちゃうけど食べれるなら、栄養つけて元気になるかな』と思って、パパっと（妻が好きな）卵入りの雑炊を作ってお布団でお昼ご飯を食べてもらいました。  \nけど、やっぱり吐いちゃいました...。\n\n## 寝て元気に\n\n症状に合うお薬が分からないし、食べるのも難しそうだし、16時までまだまだだし、お布団で横になってても苦しそうだったので、せめてと思い、一緒にお布団で横になってました。  \nご飯もお風呂も寝る時もいつも一緒なので、落ち着くかなと思ったので、とりあえず1時間ほど天井を眺めながら、妻をサスサスしていました。  \n妻も私も寝てしまい、さらに1時間ぐらい経過しました。  \nどうやら、元気になったらしく、頭痛と吐き気が落ち着いたみたいです。  \n一安心。\n\n原因を聞くのはいまじゃないので、とりあえず妻には寝てもらって、私は仕事に戻りました。  \n夜の8時ぐらいに仕事が終わったのですが、妻は元気な姿に戻っていました。  \nめでたしめでたし。\n\n原因は、また明日にでも考えてみます。  \nまた悪くなるなら、内科に行こう。","publishedAt":"2026-01-13","slug":"20260113","title":"妻の体調不良と看病"},{"body":"昨夜、雪がかなり降っていたので、今朝 外を見ると、雪が積もっていました。  \n前回降っていた量よりも多くて、足で雪を踏んでも地面は見えないぐらいの量です。まだまだ序の口かもしれません。  \n\n今日は外出する予定があったので、午前頃、外に出てみると、私の駐車エリアに、ご近所の子供たちが雪だるまを作っていました。  \n微笑ましくて、ついついゆっくりしたかったのですが、移動しなきゃなので、買った雪かき道具でせっせと雪を降ろしました。\n\nフロントガラスの下に溜まる雪って、どうやったら良いんですかね？  \n前回も下に溜めてしまって、素手で雪をどかしていたのですが、工夫が足りないのかな。\n\n今日の雪は、素手で触った感じだと、さらさらふわふわの雪で水分が多くない感じです。  \n何か そういうかき氷ってあったなぁとか思っちゃいました。  \n\n車で雪道を移動していると、屋根や信号機から雪が落ちたりしていて、少し怖いですね。  \nまだ少量なので、受けても大丈夫そうだったのですが、多くなったら 被さって怪我しそうです。\n\n目的地に到着後、妻と一緒に雪景色の写真を撮りにウロウロしていました。  \n成人式の日に、雪景色の写真撮影。  \n親族に雪景色が見てみたいと言われていたので、それっぽいものをパシャパシャと撮って送信しておきました。  \n国道は除雪車が通っていたし、観光地は地面から水が出ていて雪を溶かしていたので、歩行者側の雪だけが溜まっている感じでした。\n\n目的を達成できたので、帰りにスーパーに寄ったのですが、従業員さんがせっせと、大きな雪かきプッシャー で雪をかき集めていました。  \n1つの大きな雪山が何個もできていました、お疲れ様です...。  \n掃除用品を購入後、即帰宅しました。\n\n夕方ごろに、また外出したのですが、地面にあった雪がすっかり溶けて無くなっていました。  \n雪山とか鉢植えにある雪はのこっていましたが、大体の雪が溶けて無くなっていました。（早い...!）  \n午前中に 雪遊びしていた子供たちはナイスタイミングだったのですね！ 👍\n\n良い1日を満喫できました。お疲れ様でした。","publishedAt":"2026-01-12","slug":"20260112","title":"また雪がきた！"},{"body":"みなさんご存知の TikTok。\n\n私は普段、気に入った動画をブックマークして、後から見返すことがあります。  \nただ、都合により、動画ファイルそのものが必要になる場面があります。  \nそのため、右クリックのコンテキストメニューから動画を保存する、公式で提供されている方法を利用しています。\n\n## 手作業の負担\n\n保存したい動画の数が増えてくると、この作業を手動で繰り返すことが、次第に負担になってきました。  \n抜け漏れ重複があったり、つまらない作業で違う操作をしてしまったりします。  \nそこで、もう少し楽にできないかと考えたことが、今回の取り組みの発端です。\n\n## API は提供されていない\n\nTikTok では、ログインユーザーがブックマークした動画の一覧取得や、動画ダウンロードを行う公式 API は提供されていません。  \n非公式 API はいくつか存在するようですが、公式側の仕様変更とのいたちごっこになりやすく、安定した運用は難しそうでした。  \nまた、そもそも非公式 API を利用すること自体、適切とは言えません。\n\n## Chrome 拡張機能\n\nそこで私は、Chrome 拡張機能を使って、自分が普段行っている操作そのものを自動化する方法を選びました。  \nこの拡張機能は個人利用のために作成したもので、公開はしていません。  \nコードはかなりぐちゃぐちゃしていますが、動けばﾖｼｯとしています。\n\n近年は AI の支援もあり、このようなニッチな自動化も比較的簡単に実現できるようになったと感じています。  \n以前であれば、環境構築や Chrome 拡張特有の API の使い方を思い出すだけでも、かなりの時間を要していました。\n\n## 実際の自動化フロー\n\nChrome 拡張機能を利用すると、TikTok に事前にログインした状態を保ったまま、Chrome 上の操作をそのまま再現できます。\n\n具体的には、次のような流れです。\n\n1. 自分のプロフィールページを開く  \n1. ブックマークアイコンをクリックし、保存済みの動画一覧を表示する  \n1. 動画を右クリックして保存する  \n1. 次の動画へ移動するボタンをクリックする  \n1. 3 に戻る  \n\nこの一連の流れは、実際に私が手動で行っていた操作です。  \nそのため、Chrome 拡張機能でも、同じ手順をそのまま機能として実装できました。\n\n## 運用上の工夫\n\nブックマーク自体は解除せず、コレクション機能を使って、最後に保存した動画をチェックポイントとして記録しています。  \n次回の収集では、その動画より前までを対象にすることで、重複を避けた運用ができています。\n\n## TikTok の仕様を前提に\n\nTikTok は、スクレイパー対策が非常に徹底されている印象があります。  \n動画ファイルのリンクを直接取得し、別タブで保存するといった方法は、可能ではあるものの手間がかかり、構造変更の影響も受けやすいです。\n\nその点、公式が提供している機能を前提に自動化することで、安定した運用ができています。  \n現時点では、この方法で半年ほど継続して利用できています。","publishedAt":"2026-01-11","slug":"20260111","title":"TikTokの動画を集める自動化"},{"body":"Web のフロントエンド実装において、次のようなミスによってデザイン崩れを起こしてしまったことはありませんか。\n\n- `flex-shrink` の指定を忘れて、要素が押しつぶされてしまった\n- `z-index` の指定を間違えて、要素が意図せず前面（または背面）に表示されてしまった\n- `object-fit` の指定を間違えて、画像の一部が欠損してしまった\n\nこれらのデザイン崩れは、実装中に気づくこともあれば、リリース後に初めて気づいてしまうこともあります。  \n本記事では、このようなデザイン崩れについて、テストコードによって発生しないことを担保できないかと考え、その可能性を整理します。  \nなお、本記事にはサンプルコードは含まれていません。\n\n## デザイン崩れをチェックするアドオン\n\nデータ増減によるデザイン崩れを発見しやすくするため、私は次の Storybook アドオンを開発しました。\n\nhttps://www.npmjs.com/package/storybook-addon-range-controls\n\nこのアドオンを使うことで、数値や配列などの Props に対して、スライダー UI を用いて簡単にデータを増減させることができます。  \nコンポーネントに対して、想定より多い・少ないデータを与えながら表示を確認できる点で、便利なツールです。\n\n一方で、この確認作業は最終的に人の目によるチェックに依存しており、「デザインが崩れていないこと」を仕組みとして保証できているわけではありません。\n\n## CSS Layout Testing\n\nこうしたデザイン崩れに対して、テストコードを書くことで問題を防げないかと考えました。  \nそこで、次のような方法で、レイアウトに関するテスト、CSS Layout Testing を構築できるのではないかと思います。\n\n1. Vitest Browser Mode を利用し、Playwright 上でテストを書く\n    - JSDOM のような仮想 DOM ではなく、実際のブラウザ上で動かすことが重要です\n1. テストコード内で Web API を使い、レイアウトが崩れていないかを検証する\n    - `getBoundingClientRect`: 要素の表示位置や横幅・縦幅を取得できる\n    - `elementFromPoint`: 指定した位置において、最前面に描画されている要素を取得できる\n    - そのほか、必要に応じた API\n\n例えば、「`flex-shrink`の指定を忘れて、要素が押しつぶされてしまった」というケースであれば、\n対象となる要素の横幅や縦幅を `getBoundingClientRect` で取得し、一定以上のサイズを保っていることを検証する、といったテストが考えられます。\n\nまた、「`z-index`の指定を間違えて、要素が意図せず前面（または背面）に表示されてしまった」というケースでは、該当箇所まで移動した上で、特定の X 軸・Y 軸に対して`elementFromPoint` を実行し、取得された要素が意図する要素であることを検証する、といったテストが書けそうです。\n\nこれらの問題は、CSS Lint の設定によって防げる場合もありますし、Visual Regression Testing（VRT）によって検出できる場合もあります。ただし、Lint ではすべてのデザイン崩れを拾えるわけではありませんし、VRT についても、画像ファイルの管理や実行時間の増加などの制約があります。\n\n## おわりに\n\nサンプルコードを用意しようかと思ったのですが、都合により準備することができませんでした。時間があれば、試してみたいと思います。","publishedAt":"2026-01-10","slug":"20260110","title":"CSS Layout Testing  というテスト手法の提案"},{"body":"AIの進化によって、プロダクションコードに対するテストコードは、以前と比べて格段に書きやすくなったと感じています。\n\n単体テストに関する基本的なお作法については、以前に以下の記事で整理しました。  \n興味があれば、参考として読んでもらえると嬉しいです。\n\nhttps://zenn.dev/silverbirder/articles/e62ad1be9cdb40\n\n保守や運用の観点で見ると、プロダクションコードを修正した際に、既存のテストが壊れ、そのテストを修理しながら既存機能を担保していく、という点で、単体テストは有効に機能します。\n\n一方で、テストカバレッジ100%のように、すべての分岐や条件を網羅するテストを書くことについては、費用対効果の面で疑問を感じることもあります。  \nどこかで「おおよそ75%程度を目安にすればよい」という話を聞いた記憶もあり、現実的な落とし所を探る必要があるように思います。\n\nAIの力によって、さまざまなパターンのテストを比較的簡単に書けるようになった今だからこそ、どこまでテストを書くべきか、という点で迷いが生まれています。\n\n## 単体テストを書いていなかった頃の開発体験\n\n今から10年ほど前、SIerとして業務システムの新規開発に携わっていた頃、単体テストコードを書かずに開発を進めた経験があります。  \n当時はPHPを用いてWebサービスを構築しており、開発プロセスとしてはV字モデルを採用していました。\n\n実装した機能は、画面を手動で操作して期待通りに動作することを確認し、その後Subversionに登録して次の機能実装へ進みます。  \nすべての機能実装が終わった段階で、Excelにまとめられたテスト仕様書をもとに、自分が実装していない画面に対して、ひたすら手動で確認作業を行っていました。\n\nテスト中に不具合が見つかれば修正を行い、再び同じテストをやり直します。  \nこのサイクルを繰り返し、ようやく納期に間に合わせて成果物を完成させ、本番環境へ反映し、最終的に発注元に操作してもらう、という流れでした。\n\n手動テストは人が行う以上、どうしても見落としが発生します。  \nまた、修正のたびに同じ操作を繰り返す必要があり、規模が大きくなるほど確認項目も増え、負担が大きくなっていきました。私が携わったプロジェクトでは、プロジェクトの関係のないメンバーを何十名もかき集めて、20人近くで みんなで手動テストしていたこともあります。\n\n## テストコードを書く理由の根っこ\n\nこのような経験から、手動テストを自動化したいという思いが、自分の中でテストコードを書く動機として根付いています。\n\nテストと一口に言っても、いわゆるテストピラミッドの考え方のように、単体テスト、統合テスト、E2Eテストなど、役割は分かれます。  \nそれでも、根底にある目的は昔から変わっていないと感じています。\n\n- 手動テストにかかる時間を減らすこと  \n- 人による確認ミスを減らすこと\n\n## どこまでテストを書くかという判断\n\n単体テストですべてのパターンを網羅することよりも、もし手動で確認するとしたら、どのような操作を行うかを意識しながらテストを書く方が、自分の好みに合っています。\n\n数値のバリデーションのように、境界で挙動が変わるものについては、境界値を意識したテストを書きたくなりますし、プロパティベーステストのような手法を取り入れるのも自然だと思います。  \nまた、複数の状態の組み合わせによって出力が変わるロジックについては、パラメタライズドテストが有効だと感じています。\n\n個人的には、循環的複雑度が高そうなロジックについては、意図的にテストケースを厚めに書きます。  \n一方で、単純な処理については、代表的な1パターンを確認できれば十分と考え、その時点でテストを終えることも少なくありません。\n\nサンプルコードを示さず、考え方だけを書き連ねましたが、今の自分のテストに対するスタンスは、このようなものです。最後までお読みいただきありがとうございました。","publishedAt":"2026-01-09","slug":"20260109","title":"単体テストを全通り書くんじゃない！"},{"body":"## Qiita\n\n新卒の頃、もう10年ほど前になるが、Qiita にはとてもお世話になっていた。  \nソフトウェアエンジニアとして初学者だった当時は、Google 検索でエラーメッセージの文字列をそのまま入力し、Qiita の記事にたどり着くことが多かった。\n\n解放されていない Port を終了させるコマンドや、Docker のホストとコンテナ間でボリュームをマウントする方法など、自分が困っていることに対する解決策が整理されて書かれていて、読んでは納得し、助けられる場面が何度もあった。\n\nただ、いつ頃からかははっきりしないが、Qiita の記事を以前ほど読まなくなった。  \n言葉を選ぶのが難しいが、読みたいと感じる記事よりも、そうではない記事の割合が増えたように感じている。  \n怪文書のようなものや、転職話、スクールの宣伝と受け取れる内容を目にする機会も増えた。\n\n記事そのものとの相性だけでなく、自分の技術レベルが少しずつ上がり、読みたい内容の水準や関心の向きが変わってきたことも影響している。  \n選り好みをするようになった結果、読む記事の数が減った、という感覚も近い。\n\nその結果として、自然と Qiita を読む頻度が下がっていったのだと思う。\n\n## Zenn\n\nどこかのタイミングで Zenn というサービスが登場し、記事が集まり始めた。  \n自分の調べたいキーワードで検索すると、検索結果に Zenn の記事が表示される割合が、徐々に高くなっていった。\n\n自分の関心や感覚に合う内容が多く、読んでいて引っかかるものがあったのだと思う。  \nWeb 界隈で、JavaScript や TypeScript を中心に仕事をしていることもあり、  \nそれらに関する少しマニアックな話題や、仕組みを掘り下げた記事から学ぶことが多かった。  \nブラウザのレンダリングエンジンの仕組みや、TypeScript の型パズルのような内容は、特に好みだった。\n\nただ、最近は Zenn の記事も、以前ほど読むことが少なくなってしまった。  \n理由として一番思い当たるのは、AI を使って書かれたように感じる記事が増えたことかもしれない。  \n体重が乗っていないというか、熱が伝わってこないというか、そんな印象を受けることが増えた。\n\nもちろん、めっちゃよい記事も多く存在している。  \nそれでも、目に入る AI 関連の記事の雰囲気が似通って感じられる場面が増えたし、「AI すごい」という記事などに、自分が少し疲れてしまったのかもしれない。\n\nその結果として、自分が知りたい内容との距離を感じる場面が増え、またしても、読む機会が減っていったのだろう...。\n\n## 記事の性質と距離感\n\nサービスとして提供されているメディアには、投稿ガイドラインやルールが存在する。  \nその枠組みの中で、一定の自由度をもって記事が投稿されている、という前提がある。\n\n怪文書のように感じられるものや、個人的な自慢話に近い記事に対して、批判的な気持ちを強く持っているわけではない。  \nプラットフォームに対して特別な愛着や正義感があるわけでもないため、記事の良し悪しを断定的に判断する立場でもないと思っている。\n\n一方で、サービスを大切にしたいという気持ちから、投稿内容について声を上げる人の考えには、共感できる部分もある。  \n書かれた記事の扱いや整理については、プラットフォーム側に引き続き工夫や対応を期待したいところではある。\n\nそうした記事を目にする機会が増えたと感じた結果、そういう傾向が強いと感じるサービスとは、自然と距離が離れていったのかもしれない。\n\n## 個人サイトという置き場所\n\n自分は昔から個人サイトを持っていて、記事はすべて Markdown ファイルとして残している。\n\nhttps://silverbirder.github.io\n\n自分の書いた記事を、人の目に触れやすい場所に置きたい、という気持ちがある。  \n個人サイトは有名なものではないため、届けたいと思っても、なかなか届かないと感じることがあるからだ。  \nそのため、これまでは人の目が集まりやすい場所として、Qiita や Zenn などにも記事を投稿してきた。\n\n今後、新しい技術記事プラットフォームが誕生したら、そこに記事を移すかもしれないし、  \nあらためて、自由になんでも書ける個人サイトに重心を戻すこともあると思う。\n\n最近は、二か月以上、ほぼ毎日記事を書き続けている。  \n内容も技術に限らず、日常生活のことを書くことが増え、書くこと自体を楽しめていると感じている。\n\n## 個人サイトキュレーション\n\n個人サイトを集めたキュレーションサイトを作るのも、面白いかもしれない。  \n誰でも、自分が検索したときによくヒットする個人サイトを登録して皆も目に入る、という雑イメージ。  \n最初は、泥臭い登録作業を黙々とやっていく。\n\n個人サイトに RSS フィードがあれば、そのリンクを掲載し、気になったサイトの更新情報を追いかけられるようにする。  \n実際、自分自身も、いくつかの個人サイトの RSS フィードを購読している。\n\nそうした形で、個人サイト同士をゆるくつなぐ場があってもよいのではないかと思っている。  \n過去に作成し、使われないままになっている「個人サイトへありがとうを伝える」個人開発アプリもあるので、それらを組み合わせることができたら、気持ちのよい場になるのかもしれない。","publishedAt":"2026-01-08","slug":"20260108","title":"QiitaかZennか個人サイトか"},{"body":"学生の頃から、私は訪れた場所について Google Map に口コミを書いています。  \n後から振り返るための記録として残したい、というのが主な理由です。  \n口コミの内容は、写真と一緒に、その場所で印象に残った出来事や感想を書くことが多くなっています。\n\n## 口コミを読む\n\n口コミを書く一方で、読むこともよくあります。  \nどこかに出かける際は、ほぼ必ず事前に口コミを確認してから行き先を決めています。  \n口コミの件数や、気になる写真が投稿されているかどうかを基準に判断することが多いです。\n\n## 病院の口コミ\n\n数ある口コミの中でも、病院に関するものは、目にするたびに表現が強いと感じることがあります。  \n例えば、次のような内容です。\n\n- 電話対応が悪い  \n- 受付の態度が冷たい  \n- 医師の愛想がよくない  \n\n※ まだ優しいものです。\n\n仮に実際にそうした対応を受けたとしても、Google Map のように誰でも閲覧できる場所に書かれる言葉としては、少し居心地の悪さを感じます。  \n本人には伝えず、陰で悪口を話しているように見えてしまうからかもしれません。  \nもっとも、書き手にとっては、それだけ強い不満が残ったのだとも思います。\n\n## 口コミと実体験\n\n一方で、実際に病院を訪れた際の私の印象は、口コミとは大きく異なることがほとんどです。  \n電話応対は丁寧で、受付の方の対応も落ち着いています。  \n医師の問診についても、こちらの話をきちんと聞こうとする姿勢を感じることが多いです。\n\nこれはあくまで私自身の経験に基づく話であり、他のケースについては分かりません。  \nそれでも、病院を訪れるたびに、同じような印象を受けています。\n\n## 口コミが激しくなりやすい理由\n\n病院という場所は、そもそも前向きな目的で訪れることが少ない場所です。  \n体調不良や不安を抱えた状態で足を運ぶため、気持ちに余裕がないまま体験を受け取ってしまうこともあるのだと思います。  \nその結果として、感情の振れ幅が大きい口コミが残りやすくなるのではないかと感じています。\n\nこの考え方を当てはめると、前向きになりにくい場所の口コミは、全体的に厳しくなりやすいのかもしれません。  \n反対に、結婚式場のように前向きな感情が集まりやすい場所では、肯定的な口コミが多くなるのではないかとも思います。\n\n## 激しめの口コミとの距離感\n\n私は病院の口コミをあまり気にしないようにしました。  \n実際に電話をかけてみて、そのときの応対や雰囲気から判断するほうが、自分には合っていると感じています。","publishedAt":"2026-01-07","slug":"20260107","title":"病院の口コミには闇が潜む"},{"body":"半年ぶりくらいに体重計に乗りました。  \n思っていた体重より、4kg増えていました。\n\nお正月に、もつ鍋を何度か食べたり、お餅もたくさん食べたりして、「こういうときだしいいよね！」と、つい食べすぎてしまいました...。  \nそれが原因かな、と思っています。\n\nなんとかして、体重を落としたい！\n\n## 今までの筋トレなど\n\n去年の10月ごろから継続して、夕方ごろに腹筋・腕立て・背筋・スクワットを、それぞれ20回 × 3セット行ってきました。\n筋トレを始めた目的は、基礎代謝を上げて、体重を落としやすい体になりたかったからです。  \n（なのに、太ってしまった...！）\n\n個人開発で使った、こつこつ記録するWebアプリが役立っています。\n\nhttps://kotsu-kotsu.vercel.app\n\n記録フォーマットが自由なので、腹筋・腕立て・背筋・スクワットの回数を記録しています。\n\n![筋トレ記録](https://res.cloudinary.com/silverbirder/image/upload/v1767702817/silver-birder.github.io/blog/kvhobyrxvytivyegxiaf.png)\n\nただ、有酸素運動については、去年の8月ごろに滋賀に引っ越してから、する機会がめっきり減りました。\n\n移動は車が中心で、近距離でも車を使うことがありますし、車を使わない場合でも電動自転車を選ぶことが多いです。  \n毎朝の散歩も、いつの間にか電動自転車でのサイクリングになっていました。\n\n歩く有酸素運動をほとんどしなくなっていたことに今になって気づきました...。\n\n## 有酸素運動\n\nまずは、毎朝の散歩を復活させます。  \nまた、お昼休憩などで外出する際も、時間が許せば徒歩で移動するようにします。\n\n本当は、  \n\n1. 軽い有酸素運動\n1. 筋トレなどの無酸素運動\n1. 仕上げにやや長めの有酸素運動\n\nという流れを作りたいところです。  \nただ、現実的には、そこまでまとまった時間を確保するのは難しそうなので、  \n今は無理をせず、できる範囲で続けることにします。\n\nまた、個人開発で作った散歩コース生成くんを使う時がきました。\n\nhttps://my-walker.vercel.app\n\n![散歩コース生成](https://res.cloudinary.com/silverbirder/image/upload/v1767703322/silver-birder.github.io/blog/btfooljvnxgtec2fgffo.png)\n\n## 漢方\n\n医療の力を借りられないかと思い、  \n「薬で何か良いものはないかな」と調べてみました。\n\nそこで知ったのが、「防風通聖散錠」という漢方です。  \n名前がちょっと防御魔法っぽいです。\n\n漢方の一種で、脂肪の分解・燃焼・排出を促進する効果があるそうです。  \n最近、皮下脂肪が増えてきた気がするので、  \nこうしたものを頼ってみるのもアリかな、と思っています。\n\n## おわりに\n\n継続する力だけはわりと得意なので、まずは4kg減量を目標に、コツコツ頑張ってみます。  \n応援してください！","publishedAt":"2026-01-06","slug":"20260106","title":"正月太りと防風通聖散錠"},{"body":"https://honeylab.hatenablog.jp/entry/2026/01/01/135619\n\nこちらの「タイミーおじさん」の記事を読んだのですが、\n過酷な環境下で家族を守る、一人の父としての働きがカッコ良すぎました。\n\n自分も同じ IT 業界で働く身ではありますが、\n一本のメインとなる仕事に加えて、タイミーによる隙間時間のサブの仕事、\n2 人のお子さんの送迎などの面倒、体調が芳しくない奥様へのサポート、\nさらに親戚から預かった大型犬の面倒まで...（なんでやねん！）\n\nとてもじゃないけれど、自分ならできる気がしません。\n\nIT 畑で在宅ワークだと、体力的にきついだろうなと思いますし、\nご家族への諸々のケアを担う精神的な負荷も、相当なものだと思います。\nやらない、という選択肢もある中で、あえて「やる」という選択をしている。\nそのタフネスには、もう尊敬しかありません。\n\n自分がその立場だったらどうなるだろう、と想像するとゾッとします。\n家族は自分で支えたいので、最初はガッと頑張れるかもしれませんが、\nどこかで体力か精神か、ポキッと折れてしまいそうな気がします。\n\n親戚を頼る、という選択も浮かびますが、\n親戚が高齢だったり、そうでなくても頼りにくい事情があったりと、\n現実的には簡単ではないケースも少なくなさそうです。\n\n役所に相談する、という選択であればまだハードルは低そうですが、\n資産を売却してお金を生むことや、生活保護を受けて生活することは、\n物理的な変化だけでなく、精神的にもかなりキツくなりそうだと感じました。\n\nいやー、路頭に迷いそうだ...本当にすごすぎる。\n\nタイミーおじさんには強い尊敬の念がある一方で、\nやはり一家の大黒柱が折れてしまうと、\n総崩れになる怖さも感じました。\nだからこそ、何かしらの「保険」をかけておきたいとも思います。\n\nまた、自分の今の環境がどれほど恵まれているのか、\nないものねだりをしていないか、と\n改めて自分自身の立ち位置を考えるきっかけにもなりました。\n\n将来、自分（31 歳）がタイミーおじさんと同じくらいの年齢（43 歳）になったとき、\n同じような道を歩むのかは分かりません。\n自分にはそこまでのタフネスがないので、\n保険や貯蓄は十分に備えておこうと思います。\n万が一のときに頼れる人間関係を大切にすることも重要ですが、\n自分は友人関係がかなり薄いので、そこは正直な悩みどころです。\n\n...とはいえ、\nタイミー、ちょっとやってみたくなりました（笑）。","publishedAt":"2026-01-05","slug":"20260105","title":"タイミーおじさん"},{"body":"最近、AI エージェントに Playwright MCP を設定した状態で、CSS の調整作業を行っていました。  \nデザイン上どうしても原因を特定できず、修正に行き詰まっていたスタイルがあったのですが、Playwright MCP を使って調査を進めたことで解決に至りました。  \n本記事では、そのときの経緯と、CSS の修正がどのように進めやすくなったかを振り返ります。\n\n## 罫線付きノート風レイアウトの調整\n\n今回対象としていたのは、次のページのような罫線付きノート風のレイアウトです。  \nブログサイトのリニューアル作業中のページになります。\n\nhttps://silverbirder.github.io/blog/contents/20251226/\n\nこのレイアウトでは、横罫線の上に文字が自然に配置されることを前提としてデザインしています。  \n一見すると単純な構造ですが、文字と罫線の位置関係がわずかに崩れるだけでも、ノートとしての印象が損なわれてしまいます。\n\nこの横罫線と文字配置の調整を進める中で、Playwright MCP が CSS 修正の手助けになる場面がありました。\n\n## 技術的な構成\n\n記事本文は Markdown で記述し、Next.js の Markdown パーサを使って HTML に変換しています。  \n変換後のコンテンツは、Chakra UI の Prose コンポーネントを利用して表示しています。\n\nhttps://nextjs.org/docs/app/guides/mdx  \nhttps://chakra-ui.com/docs/components/prose\n\nMarkdown を使うことで記述自体は簡潔になりますが、表示上は複数の要素が混在する構成になります。\n\n## 罫線デザインと Markdown\n\n罫線の上に文字を載せるためには、罫線の間隔、文字サイズ、行の高さが適切に対応している必要があります。  \nテキストのみで構成されている場合であれば、line-height や margin、padding を罫線間隔の倍数に揃えることで、比較的整った見た目になります。\n\n一方で、Markdown にはテキスト以外にも、画像、テーブル、コードブロックなど、さまざまな要素が含まれます。  \nこれらを含んだ状態でも、罫線が途切れず、文字の位置がずれないことを目標に実装を進めていました。\n\n## 罫線と文字のズレに気づく\n\n実装を進める中で、特定の要素を境に罫線と文字の位置が合わなくなる箇所があることに気づきました。\n\n- テーブルの直下から罫線の位置がずれる  \n- 画像の下から罫線の位置がずれる  \n- コードブロックの下から罫線の位置がずれる  \n\n上下方向の余白や行の高さに影響する CSS プロパティについては、すべて罫線間隔の倍数になるように調整していました。  \nそれにもかかわらず、特定の箇所から整合性が崩れ、原因を特定できない状態が続いていました。\n\n## Playwright MCP による調査\n\n調整に行き詰まったため、次のような内容で AI に相談しました。\n\n- 「http://localhost:3000/blog/contents/xxx の本文途中から、罫線の上に文字が載らなくなる。原因が分からない」\n\nすると、Playwright MCP が起動し、ブラウザが立ち上がって該当ページへアクセスし始めました。  \nスナップショットの取得や DOM 要素の確認などを行いながら、表示状態を段階的に確認していく様子が見られました。\n\nこれまでは、記述した CSS の内容や JSX の構造をコンテキストに渡し、それを前提に調査してもらうことがほとんどでした。  \n一方で Playwright MCP を使った今回の調査では、実際の描画結果を起点として、画面上の状態を確認しながら原因を追っていく流れになっていた点が印象的でした。\n\n## 判明した原因と修正\n\n調査の結果、コードブロック内で使用している Mono フォントと、本文で使用しているフォントが異なっていることが分かりました。  \nフォントの字面の違いにより、同じ line-height を指定していても、実際の表示高さが揃っていませんでした。（たぶん）\n\nその差分が積み重なり、コードブロック以降で罫線と文字の位置がずれて見える状態になっていました。  \nコードブロックのフォント指定を本文と揃えることで、罫線の上に文字が自然に配置されるようになりました。\n\nMono フォントの使用を検討していましたが、今回は調整が難しかったため見送っています。\n\n## 技術スタックと MCP\n\n現在の開発では、公式に MCP が提供されている次のライブラリやフレームワークを利用しています。\n\n- Next.js  \n  https://nextjs.org/docs/app/guides/mcp\n- Playwright  \n  https://github.com/microsoft/playwright-mcp\n- Storybook  \n  https://storybook.js.org/addons/@storybook/addon-mcp\n- Chakra UI  \n  https://chakra-ui.com/docs/get-started/ai/mcp-server\n\nCSS の修正で行き詰まった際に、実際の画面を確認しながら原因を一緒に探れる点は、開発を進める上でとても助かりました。  \n既存の知識に加えて、MCP による補助を受けながら作業できる体験は、安心感のある開発体験につながっていると感じています。","publishedAt":"2026-01-04","slug":"20260104","title":"Playwright MCPでCSSの修正が楽になった"},{"body":"雪が降る地域に引っ越してから、おふとんが寒くて寒くて仕方がなかったです。  \n暖房は、寝るときはつけないようにしています。\n\nそのため、夜に布団へ入ったときの寒さが、以前より気になるようになりました。\n\n## これまで使っていた寝具\n\n寝具は、新卒で一人暮らしをしていたときに買ったものを、8年ほど使い続けています。  \n大きく買い替えることはせず、まずは布団カバーと敷布団カバーを見直すことにしました。\n\n## Nウォームのカバーに替えてみる\n\n布団カバーと敷布団カバーを、ニトリのNウォームシリーズのものに取り替えました。\n\nhttps://www.nitori-net.jp/ec/product/2115100077819s/\n\nhttps://www.nitori-net.jp/ec/product/2115100078335s/\n\n肌触りがすべすべしていて気持ちよく、お布団に入るのが楽しみになっています。  \n上も下もNウォームで揃えたことで、布団の中がしっかりと暖かく感じられます。  \n熱が逃げている感じが少なく、布団の中の温かさが続いている印象です。\n\n## 朝を寝過ごす\n\nお正月という時期もありますが、これまで8時30分ぐらいに起きていたところを、11時までずっと寝ていました...。  \nこれは、なんとかしないといけないぞ。\n\n## 終わりに\n\n毎日使うものへの投資は大事ですね。\n毎晩のお布団が楽しみですよ。","publishedAt":"2026-01-03","slug":"20260103","title":"ニトリNウォームの布団カバー、もふもふ暖かくて寝過ごした"},{"body":"[お題「ベーカリー（パン屋）で必ず買ってしまうパン」](https://blog.hatena.ne.jp/-/odai/820878482968691474:title=お題「ベーカリー（パン屋）で必ず買ってしまうパン」)\n\n私がベーカリーで必ず買ってしまうのは、塩パンですね！\n\nバターの風味をしっかり感じられる生地に、ほどよい塩味が加わることで、甘さがより引き立つところが好きです。\n\n値段もお手頃なことが多く、気づくと2〜3個まとめて買ってしまうこともあります(笑)。\n材料や工程が比較的シンプルなので、ほかのパンよりも安価になりやすい印象があります。\n\n家に帰って、焼きたての場合はそのまま食べますが、少し冷めているときはトースターで1分ほど温めて食べることが多いです。\nそうすると、バターの香りが立って、よりおいしく感じられます...！\n\n塩パン以外だと、以下のパンもよく買いますね。\n\n- スイートブール\n  - ふっくら、もっちもちなのがよい\n- クロワッサン\n  - サクサクしていて、ポロポロする感じがよい\n- チョココロネ\n  - 極限までチョコが詰まっているのがよい\n\n食感が好きなのと、チョコが大好きなので、だいたい同じようなパンばかり買っています。\n書いていたら、急に食べたくなってきました...笑","publishedAt":"2026-01-02","slug":"20260102","title":"ベーカリー（パン屋）で必ず買ってしまうパンは、塩パン"},{"body":"諸事情により、久しぶりにバスを利用しました。  \n自宅から駅までの移動手段としてバスを選んだのですが、利用経験は人生で2、3回ほどしかなく、今回は「どの順序で利用すればよいのか」を決める段階でかなり苦戦しました。\n\nここでは、その一連の体験を簡単に振り返ります。\n\n## バス停を探す\n\n最初に必要だったのは、乗車するバス停を見つけることでした。  \nGoogle Mapで「バス停」と検索し、自宅周辺を調べました。\n\nただし、地図上には表示されないバス停も存在していました。  \n利用者が少ないためなのか、新設されたばかりなのか、その理由は分かりません。  \nバス停は事業者が管理し、地図サービスにも登録されているものだと考えていたため、この点は少し意外でした。\n\n最終的に、徒歩圏内に1か所バス停が見つかったため、そこから乗車することにしました。\n\n## ルートを決める\n\n次に行ったのは、どのルートのバスに乗るかを決めることでした。  \n循環バスや方面別の路線など、同じバス停を通る系統が複数存在します。\n\nGoogle Mapでは、すべての経路が網羅されているわけではなく、他の経路検索アプリでも情報に抜けがあるように感じました。  \nそのため、最終的にはバス事業者が提供しているWebサイトや路線図を確認する必要がありました。\n\nWebサイトはやや使いにくかったため、今回は路線図を参照することにしました。  \n路線図を見ながら、乗車予定のバス停と目的地である駅が同じ路線上でつながっているかを確認し、該当するルートを探しました。\n\n## 乗車時間を決める\n\nルートが決まったあとは、乗車する時間を決めました。  \n今回は、駅に到着しなければならない時刻が事前に決まっていました。\n\nそのため、到着時刻から逆算し、バスの発車時刻を確認しました。  \nしかし、対象の路線はおよそ40分に1本という運行間隔でした。\n\n最初に選んだバス停では、都合の合う便が見つからず、別のバス停を検討し直すことになりました。  \nどのバス停から、どのルートで、どの時間帯に乗車するかを整理する作業は、想像以上に手間がかかりました。\n\n## 遅延を前提にした待ち時間\n\nバスは交通状況の影響を受けるため、多少の遅れは避けられません。  \nその点は理解していたため、10分程度の遅延はあらかじめ想定していました。\n\nそれでも、なかなかバスが到着しない時間が続くと、本当に来るのか不安になる場面もありました。  \n日常的に利用している人であれば気にならないのかもしれませんが、慣れていない立場ではソワソワしてしまいました。\n\n## 年末年始という特殊な条件\n\n今回は、12月31日と1月1日にバスを利用するという特殊な状況でした。  \nそのため、時刻表は土日祝ダイヤとなり、運行本数も少なくなっているようでした。\n\nそもそも運行しているかどうか自体を確認する必要があり、この点も判断を難しくする要因のひとつでした。\n\n## おわりに\n\nとはいえ、目的地まで安全に運んでくださる運転手の方々には、感謝の気持ちとしてお礼を言いましょう。\n\n今回は、運賃の支払いが現金のみで、両替機もなかったため少し慌てましたが、たまたま小銭を持っていたおかげで事なきを得ました。","publishedAt":"2026-01-01","slug":"20260101","title":"バスって難しい"},{"body":"年末年始は、実家の大阪に帰省しています。  \n今年はその滞在中に、地元の銭湯へ足を運び、久しぶりにゆっくりと湯に浸かってきました。  \n\nその銭湯は家族経営で、昔から地域に根付いている場所です。  \n正確な年数はわかりませんが、少なくとも30年以上は続いているように感じます。  \n子どもの頃にも何度か訪れた記憶があり、お風呂上がりにビー玉入りのラムネ瓶を飲んでいました。  \n\n受付には、いつも店主の方が座っています。  \n普段は下を向いてゲームをしている姿をよく見かけるのですが、今日は少し様子が違っていました。  \n年末ということもあってか、訪れる客一人ひとりに丁寧に挨拶をされていました。ナイスです。  \n\n浴場には、ジェット湯や電気風呂、熱湯と冷水の二つの蛇口がある洗い場など、昔ながらの設備のままです。  \n加えて、水風呂とサウナも併設されています。  \n\nただ、最近サウナで起きた痛ましい出来事が頭に残っており、サウナに入ることには少し抵抗がありました。  \nそこで、出入り口が押し戸であることや非常ベルの位置を事前に確認しました。  \nそれでも一人で入るのは不安だったため、ほかの人が入るタイミングに合わせて中に入ることにしました。（笑）  \n\nこういう意識って、忘れるまでずっとこんな感じになっちゃうのでしょうか。  \n慣れてしまうべきなのか、注意すべきなのか、戸惑いますね。","publishedAt":"2025-12-31","slug":"20251231","title":"年末帰省、銭湯のサウナに震える"},{"body":"冬の夜、20時ごろ。  \n少し遠出した帰り道を、車で自宅へ帰路の途中。\n\n助手席には妻。  \nSpotifyのお気に入りリストを流しながら、時速50kmほどでゆるやかに。\n\nその日は晴れていて、夜は真っ暗。  \n街灯の明かりを頼りに進み、たまにコンビニの灯りが視界に入ったり。  \n見覚えのある場所を見るたびに、もう少し？と思ったり。\n\n対向車は少なく、前方を走る車もほとんどいない。  \n舗装された道路を淡々と進み、途中には小さな山越えも。\n\n夕食はすでに済ませていて、ほどよく満腹。  \n買いたいものも買えて、気持ちは満足。  \nそんな夜の景色です。\n\n運転中の私は前を向いていて、  \n妻と会話を交わしていました。\n\nその日にあった出来事や、昔話。  \n次はどこいこうか、誕生日プレゼントは何がいいか。  \n職場の愚痴をこぼしたり、  \n二人のお気に入りの RADWIMPS の曲を一緒に口ずさんだり。\n\n特別な話ではないけれど、  \nただただ、時間がゆっくりと流れていきます。\n\nあまり話したがらない話題も、なぜか自然と口に出てきて、  \nほんの少し前に進めた気がしたのもよかったな。\n\nまた、あの時間を味わいたいな。","publishedAt":"2025-12-30","slug":"20251230","title":"夜のドライブって、なんかいいな"},{"body":"最近、雪が降り、うっすらと積もりました。\nこれまで雪が積もる地域で生活したことがなかったので、初めて積雪を見ました。\nちょっとわくわくしました。\n\n地元の人にとっては日常的な出来事であっても、引っ越してきたばかりの自分にとっては新鮮な体験でした。足跡をつけて、バックトラックしちゃいました。\n\n## ワイパーを立てる\n\n雪が降る前日、周囲の車を見るとワイパーが立てられていました。  \n理由が気になり調べてみると、ワイパーが雪に埋もれた状態で凍結し、そのまま作動させると故障につながる可能性があるようです。（知らんけど）\n\n念の為に、自分も周囲の対応に合わせてワイパーを立てておきました。\n色々な車のワイパーが立ってて、ちょっと昆虫っぽくて可愛かったです。\n\n## 雪の中で運転\n\n積雪があったその日、急に車を運転する用事ができました。\n地面の雪かきスコップは用意していましたが、フロントガラスやサイドガラスの雪を落とす道具は持っていませんでした。\n\nどうしようもないので、手で雪を取り除きながら車内から視界を確保できるようにしました。雪が氷っぽく固まっているところもあったので、少し痛かったです...。\n\n## 走行こわい\n\n雪を取り除いたあと、道路は一面白くなっていましたが、走行自体はできそうな状態でした。事前にスタッドレスタイヤに交換していたものの、慎重に運転するために、速度を落としてエンジンブレーキで止まるようにしました。\n\n走行中は、雨ではなく雪が断続的に降り続き、ワイパーを動かしても視界が白くなる場面がありました。目の前がかなり真っ白の中で、運転するのって 心理的に不安が高まりました...。\n\nあれは、多分自分には慣れないなと思いました...。","publishedAt":"2025-12-29","slug":"20251229","title":"雪と車と私"},{"body":"個人開発として、機能リクエスト投稿サービスを作成しました。  \nサービス名は Fequest で、Feature Request の略です。\n\nFequest は、プロダクトに対して「この機能を追加してほしい」「ここを改善してほしい」といった要望を、公開された形で投稿できるサービスです。  \n投稿されたリクエストには、Slack のリアクションに近い形式で、絵文字による反応を付けられるようにしています。\n\nhttps://fequest.vercel.app/8\n\n![fequest](https://res.cloudinary.com/silverbirder/image/upload/v1766889740/silver-birder.github.io/blog/idaphhsxs71l0cc8iceg.png)\n\n## Fequest の使い方\n\nFequest では、プロダクトごとに機能リクエスト専用のページを用意します。\n\n- https://fequest.vercel.app/8\n\n各プロダクトのフッターなどに「機能リクエスト」というテキストとともに、この専用ページへのリンクを設置することを想定しています。  \nこの構成により、ユーザーは利用中のプロダクトから、自然な流れで機能リクエストを投稿できます。\n\n## プロダクト登録と管理画面\n\nプロダクトを登録するために、管理画面も用意しました。\n\nhttps://fequest-admin.vercel.app/\n\n管理画面では、登録したプロダクトの一覧を確認できます。  \nあわせて、各プロダクトに対して投稿された機能リクエストの内容を確認し、対応完了として扱うためのステータス管理も行えるようにしています。\n\n## 作成に至った経緯\n\nこれまで、個人開発として複数の Web サービスを作ってきました。  \nいずれのサービスも、自分自身が必要だと感じたものを形にしたものです。\n\n開発や運用を続ける中で、「この機能があれば便利だ」「ここを改善したい」と感じる点が、次第に増えていきました。  \n一方で、改善予定やロードマップを整理するためのページを、各サービスごとに用意することには手間を感じていました。\n\n## 従来の対応方法と課題\n\n改善に関するメモやタスクは、GitHub Projects を使って管理しています。  \nただし、この情報は開発者向けのものであり、ユーザーにそのまま公開することはできません。\n\nまた、ユーザーから要望を受け取る手段としては、Google フォームによるお問い合わせ対応が中心でした。  \nこの方法では、同じ要望がどれくらい存在するのかをユーザー自身が把握しづらく、ユーザー同士で内容を共有することもできません。\n\n## 機能リクエストを切り出した理由\n\n機能リクエストについては、他のユーザーも同じ要望を持っている可能性が高いと感じていました。  \nそのため、個別の問い合わせとして扱うのではなく、公開された形で集約できる仕組みを用意したいと考えました。\n\nそこで、機能リクエストを一元的に扱うサービスとして Fequest を作成しました。  \n各プロダクトに対応する機能リクエストページを用意し、そのリンクをプロダクト側に設置する構成としています。\n\n## おわりに\n\n既存のプロダクトや、今後作成していくプロダクトについても、Fequest の機能リクエストページへのリンクを設置していく予定です。  \n開発者とユーザーの間で要望を共有しやすくする仕組みとして、運用を通じて改善を重ねていきたいと考えています。","publishedAt":"2025-12-28","slug":"20251228","title":"機能リクエスト投稿サービスを作った"},{"body":"## はじめに\n\nWebの配色設計では、ベースカラー・メインカラー・アクセントカラーの3つを軸に考えることが多くあります。\nサービスのコンセプトや性質に応じて、どのような色を採用するかを検討していきます。\n\n本記事では、色の基本的な構成要素を整理したうえで、CSS の oklch を用いた配色設計と、その運用例について紹介します。\n\n## 色の三属性\n\n色は主に、色相・明度・彩度の3要素で構成されています。\n\n色相は赤や青といった色味の違いを表し、明度は色の明るさを示します。\n彩度は色の鮮やかさを表し、数値が高いほど視認性が高くなります。\n\nこれらの要素をどのように組み合わせるかによって、画面全体の印象が決まります。\n\n## 同系色による配色\n\n色相を同じ、もしくは近い値に揃えた配色は、同系色配色と呼ばれます。\nこの配色では、全体に統一感が生まれ、落ち着いた印象を与えやすくなります。\n\n色同士が過度に主張し合わないため、視覚的なノイズが抑えられ、配色設計に慣れていない場合でも扱いやすい点が特徴です。\n\n## 色調（トーン）という考え方\n\n色相ではなく、明度や彩度を揃える設計もあります。\nこの考え方は「色調（トーン）」と呼ばれ、以下の資料で詳しく解説されています。\n\nhttps://zokeifile.musabi.ac.jp/%E8%89%B2%E8%AA%BF/\n\n例えば、彩度を最も高く揃えたビビッドトーンの配色があります。\nビビッドトーンは鮮やかさが強く、活気のある印象を与えます。\n\nhttps://tee-room.info/color/tone-v.html\n\n一方で、彩度を抑え、明度を高くしたペールトーンという配色もあります。\nペールトーンは淡い色合いとなり、柔らかく穏やかな印象を持ちます。\n\nhttps://tee-room.info/color/tone-p.html\n\nこれらの配色体系については、「PCCS 日本色研配色体系」で調べると、体系的に学ぶことができます。\n\n## OKLCH による配色定義\n\nCSS では、明度・彩度・色相を明示的に指定できる oklch カラーモデルを利用できます。\nこのモデルを用いることで、配色の意図を数値として保持したまま設計できます。\n\nhttps://developer.mozilla.org/ja/docs/Web/CSS/Reference/Values/color_value/oklch\n\n以下は、色相を1つに限定した同系色配色の例です。\nまず、色相・明度・彩度を変数として定義します。\n\n```css\n:root {\n  /* 色相は1つだけ */\n  --hue-base: 238deg;\n\n  /* 明度はいくつか用意する */\n  --lightness-95: 0.95;\n  --lightness-92: 0.92;\n  --lightness-90: 0.9;\n\n  /* 彩度もいくつか用意する */\n  --chroma-20: 0.017;\n  --chroma-10: 0.01;\n  --chroma-0: 0.006;\n}\n```\n\nこれらの変数を組み合わせて色を定義します。\n以下は、背景色に適用した例です。\n\n```css\n:root {\n  --background: oklch(var(--lightness-95) var(--chroma-0) var(--hue-base));\n}\n```\n\n## 色相の変更によるテーマ切り替え\n\n上記の同系色配色を、個人開発の Web サービスに取り入れています。\n\nhttps://fequest.vercel.app\n\nFequest（Feature Request の略）は、機能リクエストを送信できるサービスです。\nこのサイトでは、ログイン後の設定ページから色相を変更できるようにしています。\n\n色相を切り替えることで、選択した色味に応じてページ全体の配色が変化します。\n同系色配色を採用しているため、どの色相を選んでも落ち着いた印象を保てます。\n\n## 色のコントラストと可読性\n\n配色設計では、見た目だけでなく可読性の確保も重要です。\nStorybook の a11y アドオンを有効にすると、各 Story に対して色コントラストの検証を行えます。\n\nhttps://storybook.js.org/docs/writing-tests/accessibility-testing\n\nこのチェックを前提として開発を進めることで、最低限の色コントラストを継続的に維持できます。\n\n## おわりに\n\noklch を用いた配色設計は、色の意図を数値として管理しやすく、テーマ展開やアクセシビリティ対応とも相性の良い方法です。\n色を感覚だけで扱うのではなく、構造として整理できる点が、この手法の特徴だと考えています。","publishedAt":"2025-12-27","slug":"20251227","title":"Web配色とoklch設計"},{"body":"## はじめに\n\nPlaywright で E2E テストを書く際、`playwright codegen` や、近年では Playwright MCP を利用して、テストコードの雛形を作成することが多いと思います。\n\nただし、生成したテストコードが正しく動作するかどうかは、実際に E2E テストを実行するまで確認できません。\n\nE2E テストは、単体テストなどと比べて、実行環境の準備が重く、実行時間が長くなりやすい傾向があります。また、実行環境の影響を受けやすく、テストが不安定になる場合もあります。\n\nそのため、テストコードを書いてから動作確認を行うまでの往復に、想像以上の時間がかかることがあります。\n\n## Storybook を使った事前検証という考え方\n\nこの課題に対して、私は Playwright のテストコードを、最初から実アプリケーションに向けて実行するのではなく、Storybook をテスト対象として利用する方法を取っています。\n\nStorybook では、ページ単位のコンポーネントを描画対象とします。\nそのページ単位のコンポーネントの近くにPage Object Model（POM）を配置し、まずは Storybook 上で POM の動作確認を行います。\n\nこの段階の目的は、E2E テストを書くことではありません。\nPOM が意図した要素を取得できるか、想定した操作が成立するかを、軽量な環境で確認することにあります。\n\n### 本記事で扱う実例について\n\n本記事で紹介しているテスト構成は、個人で開発している Web サービス、Fequestの実装をもとにしています。\n\nhttps://fequest.vercel.app\n\nFequest は Feature Request の略で、 プロダクトに対して機能リクエストを送れるサービスです。\n\n> ほしいとつくるを共有するプラットフォーム  \nユーザーがほしい機能をリクエストし、開発者がそれをつくるにつなげる、  \nみんなでプロダクトを育てる場所です。\n\nFequest 自体にも機能リクエストが送れます。プロダクト登録も誰でもできます。\n\nhttps://fequest.vercel.app/8\n\nこのプロダクトでは、今回紹介する Storybook と Playwright を組み合わせた POM の検証方法や、Cucumber と Testcontainers を用いた E2E テスト構成を実際に採用しています。\n\nソースコードは公開しており、テスト周りの実装も含めて確認できます。\n\nhttps://github.com/silverbirder/fequest\n\n## フォルダ構成の例\n\nこの構成を前提としたフォルダ構成は、以下のようになります。\n\n```txt\nsrc/\n├─ components/\n│  ├─ Product.tsx\n│  └─ Product.stories.tsx\n├─ e2e/\n│  ├─ product.page.ts\n│  └─ product.page.spec.ts\n├─ features/\n│  ├─ product.feature.md\n│  └─ product.steps.ts\n├─ playwright.config.ts\n├─ cucumber.config.js\n└─ package.json\n```\n\n## ページ単位コンポーネントの例\n\n以下は、管理画面のプロダクトページを想定した、ページ単位コンポーネントの例です。\n\n```tsx\n// src/components/Product.tsx\ntype Props = {\n  product: {\n    name: string;\n    description?: string;\n    features: { id: number; title: string }[];\n  };\n  onDelete?: () => void;\n};\n\nexport function Product({ product, onDelete }: Props) {\n  return (\n    <div>\n      <h1>プロダクトの管理</h1>\n\n      <section>\n        <h2>{product.name}</h2>\n        {product.description && <p>{product.description}</p>}\n      </section>\n\n      <ul>\n        {product.features.length === 0 ? (\n          <li>リクエストはまだありません</li>\n        ) : (\n          product.features.map((feature) => (\n            <li key={feature.id}>{feature.title}</li>\n          ))\n        )}\n      </ul>\n\n      <button onClick={onDelete}>\n        プロダクトを削除\n      </button>\n    </div>\n  );\n}\n```\n\n## Storybook の用意\n\n上記のコンポーネントに対して、表示と操作確認に必要な最小限の Storybook を用意します。\n\n```tsx\n// src/components/Product.stories.tsx\nimport type { Meta, StoryObj } from \"@storybook/nextjs-vite\";\nimport { Product } from \"./Product\";\n\nconst meta = {\n  title: \"Feature/Product\",\n  component: Product,\n  args: {\n    product: {\n      id: 1,\n      name: \"サンプルプロダクト\",\n      description: \"ユーザーからの要望を集めるプロダクトです。\",\n      features: [\n        { id: 1, title: \"プロフィール画像アップロード\" },\n        { id: 2, title: \"管理画面のフィルタ機能\" },\n      ],\n    },\n    onDelete: async () => {\n      console.log(\"delete product\");\n    },\n  },\n} satisfies Meta<typeof Product>;\n\nexport default meta;\ntype Story = StoryObj<typeof meta>;\nexport const Default: Story = {};\n```\n\n## Page Object Model の実装\n\nページ単位コンポーネントに対応する POM を実装します。\n以下は、表示確認と基本操作のみを持つ簡易的な例です。\n\n```ts\n// src/e2e/product.page.ts\nimport { expect, type Page } from \"@playwright/test\";\n\nexport class ProductPage {\n  constructor(private page: Page) {}\n\n  async goto(url: string) {\n    await this.page.goto(url, { waitUntil: \"networkidle\" });\n  }\n\n  async expectVisible() {\n    await expect(\n      this.page.getByRole(\"heading\", { name: \"プロダクトの管理\" }),\n    ).toBeVisible();\n  }\n\n  async deleteProduct() {\n    await this.page.getByRole(\"button\", { name: \"プロダクトを削除\" }).click();\n    await this.page.waitForLoadState(\"networkidle\");\n  }\n}\n```\n\nこの POM は、Storybook と実アプリケーションのどちらのテストからも再利用できます。\n\n## Storybook を対象とした Playwright テスト\n\nまずは Storybook を対象に、POM の動作確認を行います。\n\n```ts\n// src/e2e/product.page.spec.ts\nimport { test } from \"@playwright/test\";\nimport { ProductPage } from \"./product.page\";\n\ntest(\"product page (storybook)\", async ({ page }) => {\n  const productPage = new ProductPage(page);\n\n  await productPage.goto(\n    \"/iframe.html?id=feature-product--default\",\n  );\n\n  await productPage.expectVisible();\n});\n```\n\n## Playwright と Storybook の設定\n\nStorybook を起動した状態で、Playwright のテストを実行するための設定例です。\n\n```json\n{\n  \"scripts\": {\n    \"storybook:e2e\": \"STORYBOOK_PORT=6000 playwright test\"\n  },\n  \"devDependencies\": {\n    \"@playwright/test\": \"~1.57.0\",\n    \"playwright\": \"~1.57.0\",\n    \"@storybook/nextjs-vite\": \"^10.1.10\"\n  }\n}\n```\n\n```ts\n// playwright.config.ts\nimport { defineConfig } from \"@playwright/test\";\n\nconst port = Number(process.env.STORYBOOK_PORT ?? 6000);\n\nexport default defineConfig({\n  testDir: \"./src/e2e\",\n  use: {\n    baseURL: `http://localhost:${port}`,\n    viewport: { width: 1280, height: 720 },\n  },\n  webServer: {\n    command: `storybook dev -p ${port}`,\n    port,\n    reuseExistingServer: true,\n    timeout: 120_000,\n  },\n});\n```\n\n## E2E テストへの展開\n\nStorybook 上で POM の動作確認ができたら、次に実アプリケーションを対象としたE2E テストを記述します。\n\n私は、受け入れ駆動と使い捨てE2E環境が好みなので、Cucumber と Testcontainers を組み合わせています。\n\n```markdown\nシナリオ: プロダクト管理画面を表示できる\n  前提 管理画面が起動している\n  もし プロダクト管理画面を開く\n  ならば プロダクト管理画面が表示される\n```\n\n```ts\n// src/features/product.steps.ts\nimport { Given, When, Then } from \"@cucumber/cucumber\";\nimport { ProductPage } from \"../e2e/product.page\";\n\nlet productPage: ProductPage;\n\nGiven(\"管理画面が起動している\", async function () {\n  // Testcontainers で adminUrl, page が用意済み\n  productPage = new ProductPage(this.page);\n});\n\nWhen(\"プロダクト管理画面を開く\", async function () {\n  await productPage.goto(\n    `${this.adminUrl}/products/${this.productId}`,\n  );\n});\n\nThen(\"プロダクト管理画面が表示される\", async function () {\n  await productPage.expectVisible();\n});\n```\n\n## おわりに\n\nこの構成では、POM の検証と E2E テストの記述を分離できます。\n\nStorybook を中間地点として利用することで、E2E テストに進む前の不確実性を抑えた状態で、テストコードを書くことができます。\nぜひ、参考にしてみてください。","publishedAt":"2025-12-26","slug":"20251226","title":"Playwright の POM を Storybook 上で確認してから E2E テストを書く"},{"body":"今年の年始から年末まで、業務委託という形で、週4日・在宅ワークの働き方を続けました。  \n業界はIT分野で、業務内容はPC作業が中心です。そのため、日中は自宅の仕事部屋にあるデスクで作業をしています。\n\nこの働き方を1年間継続してみて、私生活と仕事を明確に区別しやすくなり、それぞれに集中できた点がよかったと感じています。\n\n本記事では、今年の働き方を振り返り、主に良かった点を中心にまとめます。\n\n## 週4勤務という選択\n\n稼働日は月・火・木・金とし、水曜日を平日の休みに設定しました。  \n週の途中に休みを入れることで、気持ちの切り替えがしやすくなり、平日の過ごし方全体が安定したと感じています。\n\n## 平日のリズムと休みの配置\n\n稼働日と休日の並びは、次のような流れになります。\n\n- 月曜日  \n  - 週の始まりとして仕事に向き合う日\n- 火曜日  \n  - 翌日に休みが控えているため、集中しやすい日\n- 水曜日  \n  - 休日\n- 木曜日  \n  - 休み明けで気持ちを切り替えやすい日\n- 金曜日  \n  - 週の区切りとして仕事を締める日\n- 土曜日  \n  - 休日\n- 日曜日  \n  - 休日\n\n働く日の前後に休みが挟まることで、疲れが蓄積する前に一度立ち止まることができます。  \n年齢を重ねるにつれて疲労が抜けにくくなっている実感があり、この配置は体調管理の面で助けになっています。\n\nまた、水曜日や週末は業務そのものは行いませんが、仕事について前向きに考える時間を自然と持てています。  \n課題に直面している場合でも、一度距離を置くことで考えが整理され、解決の糸口が見えることがあります。  \n一日休むことで、次の稼働日に安定した状態で仕事に向かいやすくなっていると感じています。\n\n## 在宅ワークにおける切り替えの工夫\n\n在宅で週4日働いていると、仕事と私生活の境界が曖昧になりやすくなります。  \nそのため、自分の中で意識的に切り替えの習慣を作るようにしました。\n\n毎朝、必ず外に出る時間を設けています。  \n散歩という形で外出し、用事があればそれを済ませ、特に目的がない場合でも一定時間歩いてから帰宅します。  \n天候に関わらず、この流れは継続しています。\n\n外出後に仕事部屋へ入ることで、通勤したような感覚を作り、仕事に向かう意識へ切り替えています。  \n外気に触れることで体が自然に環境へ順応し、落ち着いた状態で作業に入れる点も良い影響を与えています。\n\n## 瞑想による思考の整理\n\n外出後、仕事を始める前に、10分ほどの瞑想を取り入れていました。  \n現在は引越しの都合により行っていませんが、実践していた期間は一定の効果を感じていました。\n\n特別なテーマを設けず、思考が浮かんだらそれに気づき、再び何も考えない状態に戻る、という単純な内容です。  \nこの「考え始めていることに気づく」という行為が、日常生活でも役立っていました。\n\n自分の思考状態を客観的に捉えやすくなり、感情や考えに引きずられにくくなったと感じています。  \n結果として、仕事に取りかかる際の頭の状態が整い、落ち着いた気持ちで作業を始められるようになりました。\n\n## 体を動かす時間を取り入れる\n\n在宅での仕事は、どうしても体を動かす量が少なくなります。  \n業務では頭を使いますが、身体的な負荷はほとんどありません。\n\n以前はジムに通っていましたが、結婚後の生活の変化により通わなくなりました。  \nその代わり、仕事終わりに一度家の外へ出て、軽いランニングを行うようにしました。  \n引越し後は内容を変え、現在は自宅での筋力トレーニングを中心にしています。\n\n仕事部屋を出て運動することで、その日の業務が終わったという区切りを作れています。  \n体を動かしたあとは適度な疲労感があり、夜の睡眠も安定しやすくなりました。\n\n## 自分にとっての適性\n\n週4日の在宅ワークが自分に合うかどうかは、始める前は分かりませんでした。  \nしかし実際に続けてみると、生活のリズム、体調管理、仕事と私生活の切り分けの面で、無理のない形だと感じています。\n\nそれぞれの時間に集中しやすくなり、日々の過ごし方に納得感を持てるようになりました。  \n今の自分にとって、この働き方は自然で継続しやすい選択肢の一つだと思っています。\n\n## 改善点として感じていること\n\n一方で、人との交流が減った点は課題として感じています。  \n行動範囲が自宅中心になり、誰かと直接話す機会が少なくなりました。\n\n日常的な会話はビデオ通話が中心になり、外出先で偶発的に人と会話する機会はほとんどありません。  \nお酒を飲まないこともあり、外で人と集まる場に出向くことも少なくなっています。\n\n特に新しい行動を起こしていないため、人と話す機会の少なさを実感する場面があります。  \n今後は、この点について少しずつ工夫していく余地があると感じていますが、人見知りの性格のため そのままになるかもしれません。","publishedAt":"2025-12-25","slug":"20251225","title":"2025年仕事の思い出：1年間、週4在宅ワークやってみた"},{"body":"賃貸物件で生活しています。  \nある日、お手洗いの換気扇が動かなくなりました。  \n電源ボタン自体は反応しているものの、換気扇は回らない状態でした。\n\nこの物件では ruum というサービスを利用しているため、そちらから換気扇について問い合わせをしました。\n\nhttps://www.ruum.me/shop/default.aspx\n\nすると翌日にチャットで返信があり、さらにその翌日には工事の方が来てくださいました。\n\n点検の結果、モーターが弱っている可能性が高いとのことでした。  \n換気扇の羽根を押さえている部品を外し、手で少し補助すると回り始めたためです。  \nモーターには当たり外れがあり、長持ちするものとそうでないものがあるようです。\n\nそのまま新しい換気扇に交換してもらいました。  \n換気扇を外すと、室内の空気を外へ逃がすための円形の穴があり、外まで貫通していました。  \n換気扇はその穴に差し込む構造で、ネジで固定されています。  \n古い換気扇を外し、新しいものを差し込み、ネジで留めて作業は完了しました。\n\nこれまで使っていた換気扇は、今思えばそれなりに音がしていたようです。  \nただ、住み始めた頃からその音だったため、特に気にしていませんでした。  \n新品の換気扇はとても静かで、違いがはっきりと分かりました。\n\n問い合わせから対応、工事までがスムーズで、よい体験だったと感じました。\n\n## その他の思い出1：水道管の破損\n\n以前、祖父母から譲ってもらった古民家の一軒家に住んでいたことがあります。  \nその家では、排水管が屋外に露出した状態で設置されており、カバーは付いていましたが、駐輪スペースの近くにありました。\n\nあるとき、自転車を取り出そうとした際に、ペダルが排水管に当たってしまい、管が破裂しました。  \n水が勢いよく噴き出し、夏だったこともあり、とても冷たくて気持ちよかったです。\n突然の出来事で数分ほど慌てましたが、水栓を止めればよいと気づき、落ち着きました。\n\nその日のうちに水道業者を呼び、修理してもらい、水道は使えるようになりました。  \nただ、その配管はかなり古かったようで、翌年になって漏水していることが分かりました。\n\n水道業者が定期点検の際に、水道メーターの数値が異常に増えていることを理由に、漏水の可能性を知らせる用紙をポストに入れてくれていました。  \n当初は半信半疑でしたが、家中の水を止めてもメーターが動き続けていたため、実際に漏水していることが分かりました。\n\n確認のために地面を少し掘ってもらうと、配管から水が噴き出し、周囲がかなり濡れていました。  \n修理方法はいくつかあるようでしたが、完全に直すには大規模な工事が必要になるため、その時点では配管周辺のみを修復してもらいました。\n\n将来的には、別の場所でも漏水が起こる可能性があるとのことで、いずれは全面的な修繕や建て替えが必要になると言われました。  \n結果的には、その前に引っ越すことになりました。\n\n## その他の思い出2：団地での火災\n\nUR団地に住んでいた頃、同じ棟の1つ上の階の左上の部屋で火災が発生したことがあります。  \n土日の昼頃だったと思いますが、火災警報が鳴り、すぐに建物の外へ避難しました。\n\n消防車が駆けつけ、火は比較的早く鎮火されました。  \nその後、自室に戻ると、少し雨漏りのような状態になっていました。  \n消火活動の関係か、もしくは火災の関係か、水が下の階に漏れてきたのだと思います。\n\n水が落ちてきたのはキッチン側で、大きな被害にはなりませんでしたが、念のためブルーシートを敷いて水を受け止めていました。  \n幸い、けが人はいなかったようで、その点は安心しました。\n\n## おわりに\n\n生活をしていると、住まいの老朽化に伴い、さまざまなトラブルが起こります。  \nまた、近隣の方との関わりの中でも、大小を問わず問題が発生することがあります。\n\nその場で慌ててしまうのは、自然なことだと思います。  \nそんなときは、一人で抱え込まず、誰かに助けを求めるようにしています。\n\n換気扇や水道管、火災の件についても、私は近くの人や関係先に相談し、自分一人で解決しようとはしませんでした。  \n自分で対応できる範囲は対応しますが、一人の視点よりも、複数の視点がある方が状況を冷静に捉えやすいと感じています。\n\n困ったときは、誰かに声をかけて、解決につながる人を探すことも大切だと思います。","publishedAt":"2025-12-24","slug":"20251224","title":"換気扇が壊れた"},{"body":"私は、どちらかというとケチな性格です。\nできる限り安いものを選びたいので、コンビニよりもスーパーを選ぶことが多く、多少時間がかかっても安さを優先します。\n\nこの考え方は、日用品に限らず、買い物全般に当てはまります。\nショッピングに出かけた際も、「本当に必要だろうか」「この値段に納得できるだろうか」と考えすぎてしまい、購入の一歩を踏み出せないことがあります。\nその結果、何も買わずに帰宅し、あとから後悔した経験を何度もありました。\n\n## 買い物に関する自分ルール\n\nそうした経験を通して、買い物に関する自分なりのルールを作りました。\nそれは『さいしょに小さなお金を払う』ことです。\n\nもちろん不要なものは買いませんが、飲み物や軽い食べ物、百円ショップの商品など、迷わず支払える金額のものを選びます。\n最初に一度お金を使うと、その後に気になっていた商品を 素直に買えるようになりました。\n余計なケチ精神が外れている感じです。\nこの方法って、心理学でいうフット・イン・ザ・ドア効果に近いのかもしれませんね（？）。\n\nただし、無制限にお金を使うわけではありません。\n衝動的に支払ってよい金額の上限は、常に意識の片隅に置いています。\n\n## 機会が限られている場面での支出\n\n一方で、旅行先のように、次に訪れる機会がほとんどないと感じる場面では、判断の軸が少し変わります。\nその場合は、金額そのものよりも、体験や記憶として残るかどうかを重視しています。\n\n入場料や、その土地ならではの食事、写真代、体験型のサービスなどについては、迷わず選ぶことが多いです。\nその時間や空間でしか得られないものだと考えると、支出に対する抵抗はほとんどありません。\n\n## 記念写真という形で残るもの\n\n旅行先では、記念写真を撮影し、その写真を購入することが多いです。  \nほぼ毎回購入していると言ってもよいかもしれません。\n\nその結果、玄関や廊下、リビング、仕事部屋など、家のさまざまな場所に写真を飾っています。\nどこにいても写真が目に入り、そのときの出来事や空気感を思い出せて、幸せな気分になります。\n\n後から振り返れる形で残るものについては、支払った金額以上の価値を感じています。  \n\n## おわりに\n\nお金は使える時に、使っていきましょう！\nその一方で貯金もしましょうね！","publishedAt":"2025-12-23","slug":"20251223","title":"さいしょに小さなお金を払う"},{"body":"多言語対応を予定していない場合でも、i18n ライブラリを導入し、文言をメッセージファイルで管理しておく方法があります。  \nこの方法を取ると、表記揺れに気づきやすくなるという利点があります。\n\nこの記事では主にフロントエンドの文脈で話を進めますが、考え方自体は特定の領域に限定されるものではありません。その点を踏まえて読んでいただければと思います。\n\n## 表記揺れという課題\n\n私は個人開発で Web アプリを作っており、次のようなサービスを公開しています。\n\n- Fequest  \n  - https://fequest.vercel.app\n- Fequest 管理画面  \n  - https://fequest-admin.vercel.app\n\nこのサービスは、プロダクトに対する改善要望や新機能のリクエストを投稿でき、開発者はそれを参考に開発を進めていくものです。ユーザーと開発者の双方でプロダクトを育てていくことを目的としています。\n\nFequest 自体へのリクエストを集めるページも用意しています。\n\nhttps://fequest.vercel.app/8\n\n実際に開発を進めていくと、表示する文言が気になる場面が増えてきます。\n\nたとえば、次のようなケースです。\n\n- 「プロダクト」と書くか、「サービス」と書くか\n  - ドメイン用語が定まっていないことによる違い\n- 「申し込み」と書くか、「申込み」と書くか  \n  - 日本語特有の表記の違い\n\nこのような表記揺れがページごとに存在すると、複数ページを横断して読むユーザーに、違和感や混乱を与える可能性があります。\n\n## AI 利用による影響\n\n近年は、AI を使ってコード生成を行う、いわゆるバイブコーディングの流れが広がっています。私自身も、その方法を取り入れています。\n\n一方で、十分にコンテキストを共有しないまま AI に実装を任せると、文言の表現が少しずつ異なるコードが生成されることがあります。開発を進めるほど、その差分が蓄積されていく傾向があります。\n\n## メッセージファイルでの管理\n\nこうした状況への対応策の一つとして、メッセージファイルを用意する方法があります。  \n多言語対応を行わない場合でも、next-intl などの i18n ライブラリを利用して文言を集約する選択肢があります。自作の仕組みでも問題ありません。\n\n日本語の文言を一つのファイルにまとめておくと、全体を俯瞰しやすくなり、表記揺れに気づきやすくなります。\n\n以下は、メッセージファイルの例です。\n\n```json\n{\n  \"top\": {\n    \"tagline\": \"ほしいとつくるを共有するプラットフォーム\",\n    \"description\": \"ユーザーがほしい機能をリクエストし、開発者がそれをつくるにつなげる、みんなでプロダクトを育てる場所です。\"\n  },\n\n  \"request\": {\n    \"empty\": \"リクエストはまだありません。\",\n    \"loginToPost\": \"ログインするとリクエストを投稿できます。\",\n    \"newAriaLabel\": \"新しいリクエスト\"\n  },\n\n  \"requestEdit\": {\n    \"title\": \"リクエストの編集\",\n    \"description\": \"{productName} へのリクエスト「{requestTitle}」を更新します。\",\n    \"form\": {\n      \"titleLabel\": \"タイトル\",\n      \"contentLabel\": \"内容\",\n      \"contentPlaceholder\": \"改善内容や背景を入力してください\"\n    },\n    \"buttons\": {\n      \"save\": \"保存する\",\n      \"cancel\": \"キャンセル\",\n      \"delete\": \"削除する\"\n    }\n  },\n\n  \"toast\": {\n    \"save\": {\n      \"loading\": \"保存中...\",\n      \"success\": \"保存しました\",\n      \"error\": \"保存に失敗しました\"\n    },\n    \"delete\": {\n      \"loading\": \"削除中...\",\n      \"success\": \"削除しました\",\n      \"error\": \"削除に失敗しました\"\n    }\n  },\n\n  \"error\": {\n    \"required\": \"必須項目です\",\n    \"unexpected\": \"予期しないエラーが発生しました\"\n  }\n}\n````\n\nこの例では一つのファイルにまとめていますが、単語帳と文章を役割ごとに分ける設計も考えられます。\n\n## 直接記述を避ける工夫\n\nさらに、静的解析を利用し、コード中に直接文字列を書くことを検知するルールを設ける方法もあります。\nこの仕組みを用いると、AI が生成したコードであっても、文言の直接記述に気づきやすくなります。\n\n結果として、文言は自然とメッセージファイルへ集約されていきます。\n\n## 導入の進め方\n\nメッセージファイルの構造は、最初から厳密に設計する必要はありません。\n初期段階では、ページ単位で愚直に定義していく方法も考えられます。\n\n構造化されたデータであれば、後から機械的に整理することが可能です。\n必要に応じて、少しずつ整えていく進め方も選択肢の一つです。\n\n## その他\n\n別の方法として、textlint のような、テキストに対して静的解析を行うツールを利用し、問題を検知するという選択肢もあります。","publishedAt":"2025-12-22","slug":"20251222","title":"多言語対応しなくても i18n を入れる理由は、表記揺れをなくすため"},{"body":"本日、初めて利用したふるさと納税の返礼品として、福岡県大野城市から「もつ 1000g」が届きました。\n\nhttps://www.satofull.jp/products/detail.php?product_id=1213874\n\n返礼品は冷凍された状態で届き、箱の中には大野城市を紹介する小冊子と、もつ鍋の簡単なレシピが同封されていました。\n\n同封されていた手順に沿って調理したところ、もつは程よい歯応えがあり、美味しくいただくことができました。  \nまだ 800g ほど残っているため、今後の夕食でも楽しめそうです。\n\n### 鶏ぼっかけ\n\n今回の返礼品をきっかけに、福岡県大野城市について簡単に調べてみました。  \n普段、旅行先について調べる際には、観光名所や美味しいものに目を向けることが多いため、今回は食に関する情報を中心に確認しました。\n\n調べていく中で、大野城市には「鶏ぼっかけ」と呼ばれる郷土料理があることを知りました。\n\n> 大野城市では親睦の場のシメの料理や家庭料理として、鶏の吸物の汁をご飯にぶっかけた「ぼっかけめし」と呼ばれる郷土料理が親しまれてきました。これに改良を重ね、開発されたのが「大野城 鶏ぼっかけ」です。文化庁令和4年（2023年）度「100年フード」にも認定されたふるさと大野城の味を、大野城心のふるさと館などでぜひ味わってください。\n\n※ https://www.crossroadfukuoka.jp/areaguide/onojo-shi より引用\n\n紹介されている内容によると、鶏ぼっかけは家庭料理としても親しまれてきた料理のようです。\n\n作り方は以下の通りで、比較的簡単な手順となっています。\n\n> 1. 鶏がらスープに鶏肉を入れる  \n>\n>\n> 1. ご飯に盛り付ける  \n>\n>\n> 1. 野菜を添える  \n\n※ https://www.city.onojo.fukuoka.jp/s071/020/010/110/060/20231011140420.html より引用\n\n使用する食材は鶏がらスープと鶏肉が中心となるため、特別な準備は必要なさそうです。  \n自宅にある材料で作れそうなので、機会を見て試してみたいと思います。\n\n### うちの郷土料理\n\nさらに調べていく中で、農林水産省のウェブサイトに「うちの郷土料理」というページがあることを知りました。\n\nhttps://www.maff.go.jp/j/keikaku/syokubunka/k_ryouri/index.html\n\nこのページでは、日本各地の郷土料理について、由来や特徴、レシピなどが地域ごとに紹介されています。\n\n試しに大阪府の項目を確認したところ、「きつねうどん」や「桜餅」も郷土料理として掲載されていました。  \n普段から身近にある料理であっても、地域の食文化として位置づけられていることを改めて知る機会となりました。","publishedAt":"2025-12-21","slug":"20251221","title":"福岡県大野城市と郷土料理"},{"body":"もう今年も残り11日となりました。年々、1年の経過が早く感じます。  \n今年も、例年どおり振り返りを書いてみたいと思います。\n\n過去の振り返りは、以下のリンクにまとめています。\n\n- 2020年: https://silverbirder.github.io/blog/contents/2020_furikaeri/\n- 2021年: https://silverbirder.github.io/blog/contents/2021_furikaeri/\n- 2022年: https://silverbirder.github.io/blog/contents/2022_furikaeri/\n- 2023年: https://silverbirder.github.io/blog/contents/2023_furikaeri/\n- 2024年: https://silverbirder.github.io/blog/contents/2024_furikaeri/\n\n## 滋賀へ引越し\n\n今年の7月ごろ、滋賀県へ引っ越しました。\n\n理由はいくつかありますが、大きなポイントは、（妻の実家がある）静岡県と、（私の実家がある）大阪府のどちらにも行きやすい距離に住みたかった、という点です。\n\nここ数年、家族を取り巻く環境にも少しずつ変化があり、将来のことや両親のことを考える機会が増えました。\nできるだけ無理のない距離感で、必要なときには静岡県にも大阪府にも行き来できる場所に住めたら、という思いがありました。\n\n一方で、住む場所は簡単に決められるものでもありませんでした。\n家族それぞれの考えや事情があり、何度も話し合いを重ねる中で、祖父母の年齢や家族構成、嫁ぎ先での立場、妻のご家族の状況など、考慮すべきことが多く、思っていた以上に引っ越し先を決めきれずにいました。\n話し合いの過程では、気持ちが沈む出来事も何度もあり、少し距離を置きたいと感じることもありました。\nまた純粋に物理的な理由として、当時住んでいた家と私の実家までの距離が徒歩10歩ほどと非常に近く、日常的に顔を合わせる環境でもありました。\n\n最終的には、静岡にも大阪にも無理なく行けて、今後の生活を落ち着いて続けられそうな場所として、滋賀県を選びました。\n物理的な距離だけでなく、気持ちの距離感としても、ちょうどよい場所なのではないかと、今は感じています。\n\n引っ越してからしばらく経ち、環境が変わったことで、家族間の距離感や依存の度合いも、ほどよく緩やかになってきたように思います。\nこの選択が正解だったかどうかは、きっとこれから分かっていくのだと思います。\n\n## 毎日ブログ投稿\n\n今年の10月27日から、つい最近ではありますが、毎日ブログを投稿するようにしました。\nその理由や背景については、以下の記事で触れています。\n\nhttps://silverbirder.github.io/blog/contents/20251207/\n\n今のところ、55日連続で投稿できています。\n\nときには、何を書くかネタが思い浮かばない日や、仕事で疲れていて書く気力が湧かない日、帰省中でまとまった時間が取れない日もありました。\nそれでも、なんとか毎日書き続けています。\n\n書いていて良かったと感じるのは、1日1日の出来事に自然と目を向けるようになったことです。\n何気なく過ごしていると、昨日の景色や出来事はすぐに忘れてしまいますが、毎日ブログを書くようになってからは、\n「今日は何があったか」「何を考えていたか」「どんな会話をしたか」といった、その日のスナップショットを文章として残せるようになりました。\n結果として、1日をより鮮明に過ごしている感覚があります。\n\n私は、何かを振り返ってしっぽりする時間が好きです。\nGoogle Photo や Google Map、そして過去のブログ記事などを眺めながら、コーヒー片手に振り返る時間は、私にとって至福のひとときです。\n\n文章を書くこと自体は、正直あまり得意ではありません。\nとりあえず思いの丈を一気に書き出し、それを AI に推敲してもらい、書き直してはまた推敲する、という工程をだいたい5回ほど繰り返しています。\nそうして、ようやく「いい感じだな」と思えるところに着地したものを投稿しています。\n\nそのおかげもあってか、技術ブログのPV数も少しずつ増えてきました。\n途中から、技術ブログは Zenn、日常ブログは Hatena に分けて投稿するようにしています。\nたまにバズることもあり、30代の睡眠時間について書いた記事を X に投稿したところ、Xの表示回数が約60万PV、記事自体も約8,000PVと、\nこれまであまり見たことのない数字を見ることができて、思わずにやにやしてしまいました。\n（正直、なぜこれが伸びたのかはよく分かっていませんが…）\n\n## お仕事や趣味\n\n現在、業務委託としてお仕事させていただいている職場では、気づけば2年ほどが経過しました。\n新規事業として立ち上がった Web サービスの開発を、目まぐるしく変化する状況の中で進めながら、\nほどよい熱量を保ちつつ、継続的にフロントエンドの仕事に携わらせてもらっています。\n\nCSS に関しては、十分にスキルが身についたという実感があります。\nまた、UI・UX を意識した提案や実装も、少しずつ自然にできるようになってきたと感じています。\nWeb において重要だと考えている「リンク・コピー・インタラクション」という3つのコアな要素を、\nユーザーに自然な形で届けるために、画面の動線を整えたり、文章の分かりやすさを調整したり、\n直感的に操作できる感覚を丁寧に作り込んできました。\n\n今後は、より一層ユーザーへの理解を深めながら、\nさらに洗練された UI・UX を構築していきたいと考えています。\n\nCSS に関しては、「苦手意識がある」という声をよく聞いていたこともあり、\nその当時にベターだと思っていた考え方や知識を、以下の記事にまとめています。\n\nhttps://silverbirder.github.io/blog/contents/learn-layout/\n\n個人開発では、以下のようなものを作ってきました。\n\n- かったものリスト\n  - https://my-buy-items.vercel.app\n- Storybook のデザイン崩れを確認できるアドオン\n  - https://www.npmjs.com/package/storybook-addon-range-controls\n- DuckDB WASM を使った Google Activity の可視化\n  - https://actviz.vercel.app\n- Tauri で作った VLog アプリ\n  - https://github.com/silverbirder/vlog\n- 現在開発中の、プロダクトへのリクエスト管理サービス「Fequest」\n  - https://fequest.vercel.app\n\nどれも、それぞれでチャレンジしたいことに取り組めており、\n個人的にはとても満足しています。","publishedAt":"2025-12-20","slug":"2025_furikaeri","title":"2025年の振り返り。滋賀とブログと私"},{"body":"## TL;DR\n\n執筆時点では、Next.js v15（15.5.9）において、`opengraph-image.tsx` から CSS（SCSS を含む）を import すると、本番ビルド後の環境で CSS が `script` として扱われ、`SyntaxError` が発生し、スタイルが適用されないことがあります。  \nNext.js v16（16.1.0）では、この問題は解消されています。  \nv15 を使い続ける場合は、`opengraph-image.tsx` から CSS を直接・間接的に読み込まないようにしましょう。\n\n関連 Issue  \nhttps://github.com/vercel/next.js/issues/72480  \n\n再現リポジトリ（Next.js v15）  \nhttps://github.com/silverbirder/nextjs-15-opengraph-image-scss\n\n## はじめに\n\nNext.js v15.5.9 を使用したアプリケーションにおいて、本番ビルド後に一部のスタイルが適用されなくなる問題に遭遇しました。\n\nこの問題には、次のような特徴がありました。\n\n- `next dev` では再現しない  \n- `next build` → `next start` した本番環境でのみ発生する  \n- 再現性が低く、常に発生するわけではない  \n\nそのため、原因の特定が難しく、調査にかなり時間がかかりました。\n\n調査当初は、挙動からブラウザキャッシュや CDN キャッシュの問題を疑いましたが、いずれも原因ではありませんでした。  \nまた、Next.js のページ数が多い状態では再現性が著しく低く、不安定になります。一方で、発生している 1 ページのみに絞って検証すると、再現性が格段に高まることが分かりました。\n\n切り分けを進めた結果、`opengraph-image.tsx` から CSS（SCSS）を読み込んでいることが原因であると判明しました。  \n本記事では、その調査過程と原因、再現方法、そして回避策についてまとめます。\n\n## 発生していた問題\n\n本番環境（`next build && next start`）において、次のような問題が発生しました。  \n\n- ボタンなどのコンポーネントにスタイルが適用されない  \n- `Uncaught SyntaxError: Unexpected token '.'` という JavaScript エラーが発生する  \n\n一方で、`next dev` では問題なく表示されるため、開発中には気づきにくい点が特徴でした。  \n\n## 調査の過程と関連 Issue\n\n切り分けを進める中で、次の Next.js の Issue とほぼ同じ事象であることが分かりました。  \n\nhttps://github.com/vercel/next.js/issues/72480  \n\nこの Issue でも、`opengraph-image.tsx` から SCSS ファイルを import している場合に問題が発生することが報告されています。  \n\n## 原因：opengraph-image からの CSS 読み込み\n\n### 何が起きているか\n\n`opengraph-image.tsx` から CSS（SCSS）を読み込むと、ビルド後の挙動が不正になります。  \n\n具体的には、CSS ファイルが JavaScript の `script` として扱われ、次のような `script` タグが出力されます。  \n\n`<script src=\"/_next/static/css/f2515c4387c9bb9d.css\" async=\"\"></script>`  \n\nその結果、CSS ファイルが JavaScript として解釈され、`Uncaught SyntaxError: Unexpected token '.'` が発生します。  \n\n### build-manifest.json に現れる異変\n\nビルド後に生成される `build-manifest.json` を確認すると、`rootMainFiles` に本来含まれるべきでない CSS ファイルが含まれていることが分かります。  \nこのプロパティの正確な用途は把握できていませんが、正常に動作している場合は JavaScript ファイルのみが含まれている、というのがこれまでの経験則です。  \n\nこの状態になると、今回のスタイル未適用の問題が発生しやすくなります。  \nそのため、CI などで `build-manifest.json` を確認し、`rootMainFiles` に CSS ファイルが含まれていないかを検査する方法も有効です。  \n\n## 再現コード\n\n最小構成で再現するリポジトリを用意しています。  \n\n### Next.js v15（問題が発生する）\n\nhttps://github.com/silverbirder/nextjs-15-opengraph-image-scss  \n\n以下を実行すると、CSS のスタイルが適用されない状態になります。  \n\n1. `npm run build`  \n1. `npm run start`  \n\n### Next.js v16（問題が解消される）\n\nhttps://github.com/silverbirder/nextjs-16-opengraph-image-scss  \n\n同じ構成でも、Next.js v16 では問題が発生しませんでした。  \n\n## 対処方法・回避策\n\n### Next.js v16 にアップデートできる場合\n\n可能であれば、Next.js v16 にアップデートするのが最もシンプルな解決策です。  \n今回の問題は、v16 では再現しませんでした。  \n\n### v15 を使い続ける場合の注意点\n\nNext.js v15 を継続して使う場合は、次の点に注意する必要があります。  \n\n- `opengraph-image.tsx` から CSS / SCSS を import しない  \n- import しているファイルの中で、間接的に CSS を読み込んでいないかを確認する  \n\n特に、Nx や Turborepo などのモノレポ構成では、CSS を読み込むコンポーネントを export しているライブラリを import しただけで、問題が発生するケースがあります。  \n\n## まとめ\n\n- Next.js v15 では、`opengraph-image.tsx` からの CSS import に注意が必要です  \n- 本番ビルドのみで発生し、再現性が低いため発見しづらい問題です  \n- `build-manifest.json` の `rootMainFiles` に CSS が含まれていた場合は注意が必要です  \n- v16 にアップデートできるのであれば、それが安全な解決策です  \n\n同じように、本番環境のみで CSS が適用されない問題に遭遇した場合の参考になれば幸いです。","publishedAt":"2025-12-19","slug":"20251219","title":"Next.js v15でopengraph-imageにCSS Modulesを読み込むと、ページでスタイルが適用されない"},{"body":"という会話を、妻とドライブ中になんとなく話していました。\n\n## パソコンを使う仕事なら\n\n私の場合、パソコン関係の仕事であれば、これまで培ってきたハードスキルをある程度活かせそうだなと思います。\n\n昔、学習塾の先生のアルバイトを4年間、掛け持ちでいろいろ経験しました。\nこどもたちの苦手意識を一緒に整理し、少しずつ克服するためのサポートをする。\nそうした役割は、とても自分の性分に合っていたように感じます。\n\nその延長線上として、パソコン教室のような仕事は面白そうだなと、5年ほど前から考えていました。\n今では学校にタブレットやPCが普及し、プログラミングの授業も行われているでしょう。\n需要も高そうですし、やってみたい気持ちは今もあります。\n\n高齢者向けのMicrosoft Officeの使い方講座でも、子ども向けのローコード・ノーコードで学ぶプログラミング教室でも、どちらも楽しそうだなと思います。\n\n## パソコンから少し離れるとしたら\n\n一方で、もしパソコンから少し離れるとしたら、よく利用する無印良品やミスタードーナツの従業員、という選択肢も浮かびます。\n利用者としては好きですが、実際に働いてみるとどうなんでしょう。\n\nミスタードーナツは学生の頃にアルバイトをしていました。\nフードコート内の店舗で、無料のコーヒーが必要かどうかをお客さんに尋ねる仕事があり、あの仕事は意外と好きでした。\n\n## 自分の性格をあらためて考える\n\n性格的には、継続力はある方で、そこそこ潔癖症なところがあります。\n日常的に掃除をするタイプです。\n\n人見知りだと自分では思っていますが、他者からは「人懐っこい」と言われることがよくあります。\n一方で、高いところや狭いところは苦手です。\n\n## 「2つ目の業界」を考える\n\nそういえば、ユーキャンなどで資格を取得して新しい仕事に就く、という道もあります。\n働きながら保育士の資格を取り、転職されたという話も聞いたことがあります。\n\nこれまでのキャリアで培った経験を活かしつつ、まったく別の業界で活躍している人を、私はこれまで何人も見てきました。\n\nもし自分が「2つ目の業界」を目指すとしたら、何が向いているだろう。","publishedAt":"2025-12-18","slug":"20251218","title":"もし今と違う職業を選ぶとしたら？"},{"body":"ネガティブな発言をする人がいるとします。  \nその言葉に対して、こちらもマイナスな感情を抱いてしまうことがあります。\n\nたとえば、こんな発言です。\n\n- 「なんでこんなところにゴミ置いてるんだ（怒り）」\n- 「私って、ほんと何もできないや（悲しみ）」\n\n## ネガティブで返してしまうと\n\nけれど、その発言に対して、こちらもネガティブな言葉で返してしまうと、気づかないうちに悪循環に陥ってしまいます。\n\n- 「なんでこんなところにゴミ置いてるんだ（怒り）」\n  - →「知らないよ、私に言わないでよ！」\n- 「 私って、ほんと何もできないや（悲しみ）」\n  - →「わかったよ。だから何もしないで！」\n\n## 無理にポジティブにならなくていい\n\nそうならないように、ネガティブな発言があったとしても、ぐっとこらえて、ネガティブではない言葉を返してみましょう。  \n無理にポジティブになる必要はありません。  \n淡々とした、ノーマルな言葉で十分です。\n\n- 「なんでこんなところにゴミ置いてるんだ（怒り）」\n  - →「何か急ぎの用事があったのかな？ ゴミは運んでおくよ」\n- 「私って、ほんと何もできないや（悲しみ）」\n  - →「そんなことないよ。大丈夫だよ」\n\n## 空気は少しずつ変わっていく\n\nそれだけで、下へ向かっていた空気が、ほんの少しずつ、上へと向きを変えていくはずです。\n\n相手は自由に感情を出していて、こちらがこらえる立場になると、もやもやしてしまうこともあるかもしれません。\n\nただ、ネガティブなやり取りをさらに膨らませて、結果的に自分まで嫌な気分になるくらいなら、少しでもポジティブに、あるいは笑って終われる着地のほうが、後味はずっと良いのではないかと思います。\n\nby みつを","publishedAt":"2025-12-17","slug":"20251217","title":"ネガティブにネガティブを返さない"},{"body":"たまたま、親戚からジェフグルメカードを1万円分もらいました。\n\nhttps://www.jfcard.co.jp/\n\nジェフグルメカードは、全国の飲食店加盟店で使えるお食事券です。\n500円単位で利用でき、現金のように使えてお釣りが出るのが特徴です。\n\n## 夕食を作るのが面倒な日\n\n私たちは普段、毎日妻と一緒に夕食を作っています。\n1品メインを決めて、ご飯とお味噌汁を用意し、余裕があればもう一品できているものを添える、という流れです。\nただ、献立がなかなか決まらなかったり、次のように感じる日もあります。\n\n- 今日は何を作ろうか決めきれない（レパートリーが尽きる）。\n- 正直、作るのが面倒（気分じゃない）。\n- 仕事終わりで疲れている（もう寝たい）。\n\nそんな日は、冷凍うどんで肉うどんにしたり、冷凍餃子やパスタなどで済ませることが多いです。\n\n## ジェフグルメカードで外食してみた\n\n本日、その面倒だなぁと感じたタイミングだったので、ジェフグルメカードを使って夕食を外で食べに行きました。\nお手頃なファミレスです。\n作る手間がかからないのはもちろん、飲食店へ行く手間は多少あるものの、次の点は思っていた以上に良かったです。\n\n- いつもと違った美味しいものが食べられる。\n- 支払いの負担がほとんどない。\n- 外食でメニューを見てわいわいできたり、ちょっと寄り道して遊べる\n- 加盟店が限られている分、行く店への迷いが少ない。\n\n貰い物が前提ではありますが、夕食準備に疲れたときや、少し飽きてきたときに、お食事券で気分転換するのは良い経験でした。\n\n## 株主優待を連想した\n\nこのジェフグルメカードを見ていて、なんとなく株主優待というものを連想しました。\n\nこれまで私は、FXによるキャピタルゲイン、いわゆる値上がり益を狙った取引は経験がありますが、株を保有して得られるインカムゲイン、配当や優待についてはやったことがありません。\n\n株主優待といえば、個人的には夜更かしの桐谷さんが真っ先に思い浮かびます。\nなんとなくネットサーフィンをしていたところ、次の記事を見つけました。\n\nhttps://froggy.smbcnikko.co.jp/19416/\n\n800銘柄もの優待株を保有しているそうです。\n3桁という数字を見て、いったいいくらするんだろう、と素直に思いました。\n\n## 株を始めてみようかな\n\n最近になって、自分も株をやってみようかな、と思い始めました。\n株を始めるには証券口座が必要ですが、幸いSBI証券の口座はすでに持っているので、やろうと思えばすぐに始められそうです。\n自分が応援したい企業の株を選び、次の点を見つつ進めていきたいと考えています。\n\n- どんな優待があるのか。\n- 配当利回りはどれくらいか。\n\n用語や仕組みをざっと理解しながら、少しずつ試してみようかな。\n知識だけ読んでいても、なかなか実感は湧かないので、つまらないです。\nなので、まずは安くて体験しやすい銘柄から、小さく試してみようかなと思います。（するとは言っていない）","publishedAt":"2025-12-16","slug":"20251216","title":"ジェフグルメカードと株主優待"},{"body":"今月に入ってから、陶器のコップを割ったり、お味噌汁を入れたお椀を落としたりしました。\n理由は特に深いものではなく、ただただ不注意です。\n\n## お気に入りのコップを割ってしまった\n\nコップを割ったのは、キッチン台に置いてある食器乾燥機から取り出したときのことです。コップの持ち手をつかんで取り出そうとした瞬間、手元が滑り、コップはそのまま床へ。\n\nパリン。\n\n結構お気に入りのコップだったので、かなりショックでした...。  \nごめんよ、痛かったろうに。  \n一応、瞬間接着剤で手当てしました...。\n\n## お味噌汁が宙を舞う\n\nもうひとつは、お味噌汁を入れたお椀の件です。\n\nお味噌汁をよそったお椀を手に持ち、リビングのローテーブルに置こうと腰を下ろした、その瞬間。\n手からお椀がスルッと滑ってしまいました...。\n\nその結果、中身は宙を舞い、ローテーブル、カーテン、クッション、毛布へと降り注ぐことに。\n\nやってしまいました...。\n\nすぐに全部洗濯し直し、お味噌汁の匂いはなんとか取れました。  \nそれでも、「こんなミスをするなんて......」と、しばらく落ち込みました。\n\n## 昔の記憶までよみがえる\n\nそういえば昔、熱々のお味噌汁をお椀に入れて運んでいたとき、指がお味噌汁に触れてしまい、あまりの熱さに耐えきれず、お椀ごと投げてしまったことがありました...。\n\n書いていて、だんだん情けなくなってきます。  \n熱いのを我慢して運べばいいだけなのに、なんで投げてるんだ...。\n\n## 最近の悩み\n\nここ最近、「手から物がスルッと滑る」ことが多い気がします。  \nハンドクリームでも塗った方がいいのだろうか...。","publishedAt":"2025-12-15","slug":"20251215","title":"最近、ものをよく落とす"},{"body":"今週の木曜から昨日まで、妻の帰省にあわせて静岡県へ行っていました。\n\n静岡県へ向かう途中、高速道路のサービスエリアで「バリ勝男クン。」というキャラクターを見かけました。\n\n![バリ勝男クン。](https://res.cloudinary.com/silverbirder/image/upload/v1765713592/silver-birder.github.io/blog/t9qkwmx7yqwb5sy1h5uw.jpg)\n\n※ https://www.sealuck.co.jp/product/katsuo.html より「スマートフォン用壁紙」\n\nバリ勝男クンは、静岡県焼津のゆるキャラで、鰹の「勝男クン。」と書くそうです。\n手書き風のイラストで、子どもが描いたような素朴で可愛らしい雰囲気があります。\n\n関西在住の私にとっては、「なんだこれは？」というのが正直な感想でしたが、静岡出身の妻はよく知っているようでした。\n\n## 頭から離れない、あのCMソング\n\nバリ勝男クンのCMが、静岡県では流れていたようです。  \nYouTube に動画もありました。\n\nhttps://www.youtube.com/watch?v=4E1J1un37Rw\n\nCMで流れる音楽のフレーズが独特というか、妙にクセがあって、しっかり頭に残ってしまいました（笑）。\n\n```text\nででんででんでん バリカツオ  \nででんででんでん バリカツオ  \n\nバーリカーツオ でんでんでん\n```\n\n### 静岡とかつおの関係\n\nちなみに静岡県は、かつおの水揚げ量が全国1位とのことです。\n\nhttps://www.pref.shizuoka.jp/sangyoshigoto/nogyo/gakkotaiiku/1027662.html\n\nやるじゃん。\n\n## 鰹の出汁の素、うまいやん\n\nスーパーに行くと、静岡県産のかつおを使った出汁の素が販売されていて、妻の母からひとつ頂きました。\n\n我が家では毎晩お味噌汁を飲んでいて、普段はあごだしを使っています。  \n今日、その出汁をかつおのものに替えてみたところ、最初に出た感想は、\n\n「香り、めっっっちゃええやん」\n\nでした。\n\n味ももちろん美味しかったのですが、何より香りが良く、かつおの風味が部屋中に広がります。  \n人からもらったものですし、「美味しいよ」と聞いていたので先入観があるのは否定できませんが、それを差し引いても「これは美味しいな」と素直に思いました。\n\n## 静岡土産の定番が、またひとつ増えた\n\n静岡県へ帰省するときは、いつも「わさびドレッシング」と「JA の掛川茶」を買って帰るのですが、これからは出汁の素も定番になりそうです。\n\n## バリ勝男クンは、おつまみに良い\n\nそして、バリ勝男クンも購入しました。\n\nカツオを乾燥させた、バリバリ・サクサクとしたスナックのようなお菓子で、おつまみにちょうどいい感じです。  \nほかにもさまざまなアレンジ商品があるようなので、次にサービスエリアで見かけたら、また買ってみようかなと思います。","publishedAt":"2025-12-14","slug":"20251214","title":"ででんででんでん バリカツオ"},{"body":"睡眠時間を削って何かをするのは、20代ぐらいまでだなと感じます。\n30代になると、きちんと睡眠を取らないと翌日の集中力が落ちてしまっている気がします。\n\n## 自分なりの睡眠リズム\n\n私の場合、24時を過ぎたら寝て、翌朝8時ごろに起きる生活を心がけています。\nこの24時の就寝が1時間ほどずれて、仕事柄 翌朝8時ごろに起床すると、頭が少しぼーっとしている感覚になります。\n\nまた、24時に寝たとしても、夜中にトイレなどで目が覚めてしまうことがあります。\nいったん脳が起きてしまうと、再び「眠る状態」に戻るまでに時間がかかっている気がします。\nそういう日は、翌日の頭もやはり少し冴えません。\n\nぼーっとしているときはカフェインで目を覚ますのですが、1日が勿体無いなと思ってしまいます。\n\n## 昔はできていたこと\n\n学生の頃は、そこまで睡眠を意識していませんでした。\n社会人になりたての頃は、徹夜もそれなりに楽しくできていた気がします。\nエナジードリンクを飲みながら、ゲームをしたり、アニメを見たりしていました。\n眠さよりも情熱が勝っていて、夜中の時間が結構楽しかったなと思います。\n\n## のび太くんになるために\n\n平日は仕事のパフォーマンスを最大限発揮したいので。できるだけ夜にしっかり眠れるよう工夫しています。\n\n具体的には、筋トレで汗をかくことを続けています。\n初めの頃は15分ほどの軽い有酸素運動のランニングをしていました。\n引越しに伴って、今年の10月ぐらいから毎日 筋トレをしています。(実は ほぼ毎日...!)\n\nまた、夕食の時間を19時ごろで一定にしています。\n夕食後は、カフェインを摂らないように意識しています。\nお風呂上がり後は、暖かい格好で体を暖かく保っています。\n\n平時なら、24時にスッと寝れる、のび太くんスタイルになりました。\n\n## 寝溜めができない\n\n一方で、いわゆる「寝溜め」もできなくなってきました。\n8時間ほど眠ると、自然と目が覚めます。\nそれ以上は、あまり寝られません。\n\n休日でも同じです。\n8時間寝たらすっと起きて、いつも通り8時ごろに起床します。\nトイレ掃除をしたり、部屋に掃除機をかけたりします。\n日課を淡々とこなしています。\n\n## だらっとする時間を大切に\n\nとはいえ、1日を有意義に使えている感覚があります。\nなので、これはこれで悪くないと思っています。\nただ、だらーっとする時間も私にとっては大切なので、14時ごろにお昼寝タイムをとっています。\nあえて、何もしない時間をつくることもあります（笑）。\n\n## 40代、50代\n\nもっと歳を重ねると、どうなるのでしょうか。\n今度は睡眠時間自体が短くなる、とよく聞きます。\n7時、あるいは6時起きが当たり前になっていくのでしょうか。\n心配ということはないですが、なんだか不思議な感覚です。","publishedAt":"2025-12-13","slug":"20251213","title":"30代の睡眠時間と体調"},{"body":"個人開発をしていると、「これを作りたい！」という強い熱が湧いてくるときがあります。\n\n作り始める前に、似たアプリがすでに存在しないか調べることもあるでしょう。そして、似たアプリを見つけて、「これで課題は解決できそうだし、自分が作らなくてもいいかも」と思うこともあります。私はそれで何度か諦めたことがあります。\n\nそれでも、**作りたいという熱があるなら、作ってしまっていい**と思います。なぜなら、その熱は自分だけのものであり、それを満たしてあげられるのも自分だけだからです。\n\nそもそも、その「似たアプリ」は、本当に自分が作りたいアプリと同じでしょうか？自分が想像している体験と、完全に一致していますか？\n\nきっと、どこかに自分だけのオリジナルな部分があるはずです。その一点だけはブレずに作りきれば、きっと満足できるものになると思います。\n\n作る目的は人それぞれですが、私の場合は、第一に「自分が困っていることを解決したい、より良くしたい」という気持ち。\n第二に、技術や挑戦したいことに打ち込むことです。マネタイズや FIRE も、できるならしてみたいですが、自分には向いていないので、そこは狙っていません。\n\n自分だけのために、最高のアプリを作る。**自己満足のための開発**を、思いきりエンジョイしましょう。","publishedAt":"2025-12-12","slug":"20251212","title":"似たアプリがあったとしても、作ってしまえ！"},{"body":"半年に一度くらい、静岡県へ行く機会があります。妻の実家が静岡にあるため、ほとんどは帰省が目的です。\n\n高速道路で静岡県に入ると、あの有名なハンバーグの看板がちらほら見えてきて、「帰ってきたな」と感じます。\n\n## さわやかハンバーグの思い出\n\n静岡に帰省したら、ほぼ必ず夕食はさわやかのハンバーグを食べています。ネット予約はなく、お店で整理券を受け取って順番を待ちます。\n\n土日・平日を問わず、訪れるたびに30分以上は並びます。初めて行ったときは、妻と妻の仲良し2人の友達と車に同乗して向かい、車内で1時間以上待って、21時前のラストオーダーぎりぎりに入店しました。\n\n「なんでこんなに待つんだ…」「ハンバーグなんてどこで食べても同じだろ」そんな気持ちを抱えながら入ったのですが、その考えは良い意味で裏切られました。\n\n牛肉100%のげんこつハンバーグは圧巻の旨さ。店員さんが目の前でハンバーグを半分に切り、鉄板に押し付けて焼いてくれる演出も楽しい。オニオンソースとデミグラスソースのどちらも試しましたが、私は断然オニオンソース派。そこに白米も足して最高。\n\nそして、食後のはっか飴。口の中がスッとさわやかにリセットされて、満腹でも気持ちが整います。\n\n毎回「今回は行かなくてもいいかな…」と思うのに、結局行ってしまう それが、さわやかです。\n\n## 杏林堂の思い出\n\n緑と黄色の派手な配色が印象的なドラッグストア杏林堂。あれを見ると、「静岡に帰ってきたなぁ」と実感します。\n\n滋賀県だとユタカ、大阪府だとキリン堂というドラッグストアがありますが、知っていますか？\n\n杏林堂に行くときは、たいてい妻の（杏林堂で働いている）母に連れていってもらい、朝食用のパンを買ってもらっています。\n特別な出来事があるわけではないのに、どこか懐かしい気持ちになります。\n\nそのあと、しずてつストアや近くの魚屋で海鮮をたっぷり買い込み、夕食にするのが定番。安くて分厚いマグロの刺身が最高にうまい。本当にうまい。","publishedAt":"2025-12-11","slug":"20251211","title":"さわやかハンバーグ、杏林堂"},{"body":"学生の頃はあまり衣服に興味がなかったのですが、最近は服屋さんに行くと、カッコ良い服や触り心地の良い生地、ちょっとオシャレな服を見つけて、購入してお家で着替える時に気分が上がります。前日の夜から「明日は何を着ようかな」とワクワクしてしまう日もあります。\n\nといっても、ハイブランドにこだわっているわけではありません。値段に関係なく、「良いな」と思えば買うようになりました。在宅ワークで毎日同じような服装を続けてきて、少し飽きてきたのかもしれませんね……笑。\n\n夏はシャツとズボンでシンプルな服装になりがちですが、冬は重ね着ができたり、温かみのある素材を楽しめたりするので、どちらかというと冬服の方が好きです。\n\nどこのお店で買った服か聞かれると、ほとんど覚えていません。ショッピングモールの服屋さんで買うことが多いのですが、店名を読めなかったり、そもそも看板より服そのものばかり見ているので、気づくと店名をまったく覚えていないんです。\nそのくせ、レジで「アプリありますか？クーポン使えますよ」と言われて、あ、持ってた……と思い出す、ということがよくあります。\n\n好きな服の傾向としては、\n\n- 肌触りが良い\n- 落ち着いたトーンの色味\n- シンプルなデザイン（派手な柄はあまり入れたくない）\n  - ただし、ワンポイントだけある控えめなデザインは好き\n\n学生の頃は兄のおさがりをよく着ていて、大学生になってからもユニクロやGUでなるべく安く済ませていた記憶があります。社会人になってからは、スーツの職場を経て私服の会社に移り、とりあえず“変じゃなくて目立たない服”を必死に探して（家用の服はさすがにダサかったので）買っていました。笑\n\nまさか今になって、こんなふうに服をちゃんと選んで買うようになるとは思いませんでした。笑","publishedAt":"2025-12-10","slug":"20251210","title":"お気に入りの服を着ると気分がアガる"},{"body":"2025年12月8日午後11時15分ごろ、青森県東方沖を震源とする震度6強の地震が発生しました。今のところ、死者や行方不明者は出ていないようです。ひとまず安心しました。\n\nhttps://www.jiji.com/jc/article?k=2025120801065\n\nhttps://www.jishin.go.jp/regional_seismicity/rs_tohoku/p02_aomori/\n\nこうしたニュースがあるたびに、自分が住んでいるのは地震大国で、島国でもあるという事実をあらためて感じます。ただ、自分ごととして捉えるのは難しく、発生時は考えるものの、日々の生活の中ですぐ忘れてしまいます。そこで、自分が今どんな備えをしているのか、何ができていないのかを書き留めておくことにします。\n\n## ハザードマップ\n\n今住んでいる地域は、車で20分ほどで湖がありますが、海ではないので津波の心配はないと思っています。以前住んでいた地域では、津波よりも河川氾濫のほうがリスクが高く、水害への備えとしてハザードマップを確認していました。\n\n一方で、今の地域のハザードマップはまだ確認できていません。引っ越したばかりではありますが、近所の学校や体育館が避難場所として使えそうなことは分かっています。平地が多い地域で、高低差も大きくなさそうです。それでも家族と一緒にハザードマップを見て、避難先を共有しておきたいと感じています。\n\n水害の心配は少なそうですが、地震に備える必要はあります。周囲に大きな建物はなく、倒壊による二次災害の可能性は低そうです。\n\n雪による災害についてはどうでしょうか。今住んでいる地域は雪が多く積もると聞いており、スコップや長靴、スタッドレスタイヤなどは準備しています。周囲に山はなく田んぼが広がっているので雪崩の心配は少ないと思いますが、除雪時の事故や路面凍結による交通事故は起こり得ます。\n\n## 地震への備え\n\n地震への備えとして、玄関に防災カバンを家族分用意しています。以前の住まいでは枕元に置いていましたが、今は事情があって玄関に置いています。\n\n防災カバンには非常食、防寒具、エチケット用品、ライトやラジオなど一通り揃えています。年に一度、乾パンやカロリーメイトなど賞味期限のあるものを入れ替えています。\n\n地震発生時はこれを持って避難所へ向かうつもりです。もちろん周囲を確認したうえで行動します。\n\n## 保険について\n\n災害によって家財や車が被害を受けた場合の保険も気になります。車の保険は加入していますが、地震や津波が対象外だった記憶があります。\n\n賃貸住宅では火災保険に加入していますが、これは家庭内の火災が対象で、自然災害による火災は含まれません。地震保険という選択肢もあります。住んでいる地域の特徴を考えると、水害よりも地震や雪に関する保険を検討したほうが良さそうです。\n\n## 怪我や入院への備え\n\n災害時に怪我をして仕事ができなくなった場合の備えも必要です。個人事業主として収入が止まると困ってしまうので、こうしたリスクに備える保険を考えてもよいのかもしれません。これは災害とは関係なく、日常的にも必要な備えだと思います。\n\n避難生活では、怪我の治療だけでなく気持ちの面でのケアも大切です。被災していなくても、地震のニュースばかりを見ると気が滅入ることがあります。避難所でも少しでも心が落ち着くよう、普段から使っているものや、好きな音楽や漫画、慣れた味の食べ物などがあると良いのかもしれません。","publishedAt":"2025-12-09","slug":"20251209","title":"自然災害の備え"},{"body":"正社員からフリーランスになって 1年以上が経ちました。  \nこの期間に実際に取り組んだことを、備忘録としてまとめておきます。\n\n## 国民年金・国民健康保険の切り替え\n\n正社員の頃は、厚生年金と健康保険組合（協会けんぽなど）に加入しています。  \nフリーランスになると、これらが 国民年金・国民健康保険へ切り替わります。\n\n退職（失業扱い）時は、国民年金に免除制度があります。  \n私は一時的に全額免除を受けました。  \n免除中は将来の年金額が半分になりますが、受給資格は維持されます。\n\nhttps://www.nenkin.go.jp/service/kokunen/menjo/20150428.html\n\nまた、免除した期間は「追納（追加で納めること）」が可能です。  \nただし追納できる期限があるため、早めに市役所で確認しておくのがおすすめです。\n\n国民健康保険にも自治体によっては減免制度がありますが、私は利用しませんでした。\n\n## プリンターの用意\n\nフリーランスになると書類の取り扱いが増えます。  \nコンビニ印刷も便利ですが、自宅にプリンターがあると印刷だけでなく、書類のPDF化もできて捗ります。\n\n## 開業届と青色申告の準備\n\nフリーランスとして働くなら、まずは開業届を税務署へ提出します。  \n提出しなくても罰則はありませんが、後から各種手続きで必要になる場面がありますので、提出しておく方が安心です。  \nまた、開業届の控えも取っておくこと良いです。  \nいつ開業したかとか後々必要になるからです。  \n（私は控えを取っておらず、少し困りました…）\n\n提出時には、青色申告承認申請書も同時に提出しましょう。  \n青色申告を利用すると最大 **65万円の控除** を受けられ、所得税を大きく減らせます。\n\n所得税を減らすメリットは大きく、というのも **住民税は前年の所得で決まる** からです。  \n住民税の金額には、毎回ゾッとします...。\n\n### e-Taxについての注意\n\n確定申告で e-Tax を使う場合、Web版は機能が限定的です。  \nフル機能を使えるのは Windows のソフト版のみ（私が調べた当時）。  \nMacユーザーはここが少し不便かもしれません。\n\n## 貯金・将来資金の準備\n\n厚生年金と比べて、国民年金だけだと老後がやや不安です。  \nそこで、私は以下の複数の方法を組み合わせて将来資金を準備しています。\n\n### 銀行貯金\n\n定期預金などもありますが、我が家は手動でコツコツ貯めるスタイル。\n\n### iDeCo\n\n- 国民年金保険料を免除されている期間は加入不可\n- 引き出しは60歳以降\n- 掛金は年に1度変更可能\n- 受け取りは一括 or 有期年金（終身ではない）\n- **掛金は全額所得控除**\n\n### 国民年金基金\n\n- iDeCoと同様、免除期間は加入不可\n  - iDeCoとの比較：https://www.zenkoku-kikin.or.jp/kanyu/ideco/\n- 1口目は掛金変更不可。2口目以降は変更可能\n- 受給は原則65歳〜\n- **終身年金**\n- iDeCoと合わせた上限は月68,000円\n- **掛金は全額所得控除**\n\n### NISA\n\n私はウェルスナビを利用。  \n掛金の控除はありませんが、運用益が非課税になるのが魅力です。\n\n## 健康診断を受ける場所を確保する\n\nフリーランスは自分で健康診断を手配する必要があります。  \n地域の病院を探すか、福利厚生として健康診断が付いてくる団体へ加入するのも手です。  \n体が資本なので、年1回の受診は必須と感じています。\n\n## 退職金の代わりに積み立てをする\n\n個人事業主には退職金がありません。  \nその代わりとしておすすめなのが小規模企業共済です。\n\n- 毎月1,000円〜積み立て可能\n- 掛金は全額所得控除\n- 将来の退職金代わりになる制度\n\n加入しておいて損はないかと思います。\n\n## 税理士を雇う\n\n年収が1,000万円を超えると、2年後から **課税事業者（消費税の納付義務あり）** になります。  \n税金まわりは本当に複雑なので、私は税理士さんに相談しました。\n\n（何が必要かわからなくて不安だったので）オールインワンの会計ソフト（freee）を契約し、仕訳・確定申告などをお願いしています。  \n家賃の按分、本の購入、サブスク費なども経費として処理していただき、とても助かっています。\n\n税理士を雇う際に調べた内容は以下の記事にまとめています。\n\nhttps://silverbirder.github.io/blog/contents/20251027/\n\n## その他やったこと\n\n### ふるさと納税\n\n寄付額 - 2,000円 が控除されます。  \n応援したい自治体に寄付できる点も気に入っています。  \nふるさと納税ポータルサイトを比較した結果、私は **さとふる** を利用しています。\n\n### 生命保険（死亡保険）\n\n生命保険料控除が受けられるので加入しました。\n\n## おわりに\n\n以上、正社員からフリーランスになってから実際に行ったことをまとめました。  \nこれからフリーランスを目指す方の参考になれば嬉しいです。","publishedAt":"2025-12-08","slug":"20251208","title":"フリーランスになってやったこと"},{"body":"今週のお題「今年読んでよかったブログ」\n\n今年読んで良かったブログは、あやめしさんの **7年間、毎日ブログ投稿を継続した** という記事です。\n\nhttps://www.e-aidem.com/ch/listen/entry/2025/10/22/103000\n\n著者の方はライターとして活動されていますが、子どものころは文章を書くのが苦手だったそうです。  \nさらに、激務で心身ともに疲弊し休職されていた時期にブログを始めたとのこと。  \nそんな状態からスタートしながらも、7年間一度も途切れずに投稿を続けてきたという歩みに、強く惹かれました。\n\n## 惹かれた理由は「共通点」\n\n実は私も、小学生の頃から国語が得意ではありませんでした。  \n文章を読むのも書くのも苦手で、テストの点数はいつも平均以下。  \n「国語が苦手だから理系へ進む」というタイプです。\n\nそして私自身も、かつて仕事で疲弊し、正社員を辞めて心身が弱っていた時期があります。  \nあのころの自分を振り返ると、**新しいことへ一歩踏み出す勇気**なんて、とても持てなかったはずです。  \nだからこそ、著者の方が困難な状況の中でも投稿を続けてきた事実に、素直に「すごい」と感じました。\n\n著者の方は、結婚・転勤・出産・引っ越しといった大きなライフイベントがある時期でさえ投稿を止めず、その継続が自信となり、現在のライターという仕事へつながっていったそうです。\n\nもし私が同じ立場だったら、たとえ最初の一歩を踏み出せても、ネガティブ思考に押されて途中でやめてしまうかもしれません。  \nだからこそ、継続の力で道をひらいていった姿には、共感と尊敬の気持ちが湧きました。そして、私も一歩踏み出したくなりました。\n\n## 記事に影響され、私も始めたこと\n\n私もブログを書いていますが、これまでは月に一度投稿するかどうか、というペースでした。\n\nhttps://silverbirder.github.io/\n\nブログを書く理由は、主に知識を整理しアウトプットするためです。  \nその意味では、ブログを書くための環境や習慣は、自分の中にあります。\n\nそして私は **「振り返り」がとても好き** です。  \nカレンダーや写真を見返しながら「あの時こんなことがあったな」と思い返す、あの静かな時間が本当に好きです。\n\nそんな自分の性格を考えたとき、ふと気づきました。\n\n> 「これをブログにも活かせるのでは？」\n\n毎日投稿すれば、振り返りの材料が自然と積み重なっていく。  \nそう考え、**2025年10月27日から毎日投稿を続けています**。\n\n文章を書くことはまだ得意ではありませんが、毎日書くことで、 **「実は1日の中にはいろいろな小さな出来事がある」** ということに気づかされました。  \n\nただ、そうした小さなイベントは、1日経つとすぐに忘れてしまいがちです。  \nだからこそ、ブログとして書き起こし、記録として残しておくことで、数ヶ月後に振り返る時に、より深く、より楽しい時間になるはずだと感じています。\n\n## おわりに\n\n最後まで読んでいただき、ありがとうございました。","publishedAt":"2025-12-07","slug":"20251207","title":"今年読んでよかったブログ：7年間 毎日ブログ投稿を継続された話"},{"body":"毎年恒例、妻とのクリスマスプレゼント交換。  \n今年は私がリクエストした **チョコドリンクメーカー** が今日ついに我が家へ届きました。  \n結論から言うと、甘党の私にはめっちゃめっちゃ刺さった！ 最高でした。\n\n今回買ってもらったのは、レコルトの 「ホットチョコ＆ミルクフォーマー」です。\n\nhttps://recolte-jp.com/products/rmt-3/\n\n型番はRMT-3で、なんと発売日は先月の11月26日だったようです(10日前ぐらい？)。めっちゃ最近。\n\nhttps://news.kakaku.com/prdnews/cd=kaden/ctcd=2113/id=153164/\n\nちなみに 1 つ前の RMT-2 は、明治とコラボ（？）していたらしく、あの板チョコでホットチョコドリンクが作れるとのこと。\n\nhttps://www.meiji.co.jp/learned/choco-drink/drink-maker/\n\n箱の中にはレシピブックも入っていて、せっかくなので明治の板チョコを使った基本のホットチョコレートを作ってみました。\n\n![レシピ](https://res.cloudinary.com/silverbirder/image/upload/v1765025812/silver-birder.github.io/blog/wynf7d7eugjkmlnbuckn.jpg)\n\n作り方は簡単です。\n\n1. チョコと牛乳を、測り付き容器に入れる\n1. 「ホットチョコ」メニューをタップ\n1. スタートをタップ\n\n動き出すと、静音で“フローサー”という円形パーツが静かにぐるぐる回り、5 分ほどで完成しました。\n\n以下は、スタート直後に撮った写真です。\n\n![動いている様子](https://res.cloudinary.com/silverbirder/image/upload/v1765026426/silver-birder.github.io/blog/recolte-drink-3.jpg)\n\nそして肝心のお味ですが、**チョコの味がめちゃくちゃ濃くて甘いです**。  \n「ほどよく」ではなく、**しっかり濃厚です**。  \nチョコのコクと牛乳のまろやかさが混ざり合って、ムラなくとても良い仕上がりです。  \n甘党の私にはドンピシャでした...！（写真を撮るのを忘れてました...）\n\n容器は口が広く、フローサーも取り外せるので洗いやすい点も良いですね。\n\n唯一ちょっと手間だと感じたのは、「チョコを 3〜4g のサイズに割って入れる」必要があること。  \n明治の板チョコならマス目 1 つ分が目安なのですが、細かく割るのは正直少し面倒でした。  \n今回は初回なので丁寧にやりましたが、次からはもう少し大雑把でいこうかなと思います。\n\nでも、明治の板チョコと牛乳だけで作れるので、材料の入手はとても簡単。スーパーで手軽に買えるのは良いですよ！\n\nはぁ〜〜〜！ 最高のプレゼントだった！本当にありがとう！\n\n## P.S\n\n届いた商品の箱がとても可愛かったので、思わず写真を撮りました。\n\n![箱表](https://res.cloudinary.com/silverbirder/image/upload/v1765025808/silver-birder.github.io/blog/bheynzow9jffzlaa3yvr.jpg)\n\n![箱裏](https://res.cloudinary.com/silverbirder/image/upload/v1765025809/silver-birder.github.io/blog/gbisul8jl7pyw6kgkj2i.jpg)","publishedAt":"2025-12-06","slug":"20251206","title":"レコルトのチョコドリンクメーカー、最高じゃん"},{"body":"LG の縦型ディスプレイを使い始めて、2 年 7 ヶ月が経ちました。\n\nhttps://www.lg.com/jp/monitors/fhd-qhd/28mq780-b/\n\nそれ以前は一般的な横型ディスプレイを使っていましたが、  \nVSCode などのエディターを最大化すると 右端に広い“空白エリア”が残ることが多く、  \nどうにもスペースを使い切れていない感覚がありました。\n\n縦型ディスプレイに変えてみると、その悩みは解消されました。  \n私は VSCode を 画面下半分の横幅いっぱいに配置して使っているのですが、  \nちょうど良い密度で、無駄な空間がほとんどありません。  \n\nさらに、上半分にはブラウザ（Chrome）を全幅で配置して、  \nWeb アプリ開発中に “どこが変わったか” を上下に視線移動しながら確認できるのがとても快適です。  \n横長ディスプレイのときは左右に視線を振る必要があり、少し疲れやすかった記憶があります。\n\n唯一の欠点は、Zoom などで画面共有するとき。  \n縦型ディスプレイ派は少数派なので、画面全体を共有すると相手には細長く表示されてしまい、  \n見づらくなりがちという点です。\n\nそれでも、日々の仕事効率は良くなったかと思います。  \n縦型ディスプレイ、いいぞ。","publishedAt":"2025-12-05","slug":"20251205","title":"縦型ディスプレイはいいぞ"},{"body":"買ったけれど、今は全く使っていない商品たちを紹介します。  \nせめてもの罪滅ぼしとして、ここで懺悔しておきます……。\n\n前提として、商品自体はどれも悪くありません。\n\nただ、用途を考えず勢いで買ってしまった私が悪いのです。\n\n## BALMUDA The Lantern\n\nhttps://www.balmuda.com/jp/lantern\n\nBALMUDA って、なんだかカッコいいじゃないですか？  \nあの温かみのある光、シンプルで可愛い見た目、私の中の「ランタンといえばこれ」というイメージにドンピシャで、気づいたら購入していました。\n使い道は特に決めていませんでした。\n\n「夜中にトイレへ行く時に足元を照らせるかな？」  \nそれくらいの、ふわっとしたイメージだけで買っちゃいました☆\n\nそして、買って1年ほど経過して使った回数は、数回程度。\n\n最近では、お風呂場の電球が切れたとき、光源の代わりとして働いてくれました。\nありがとう、ランタン……。\n\n## ラノー ヨーグルトメーカー\n\nhttps://shop.daywear.jp/view/item/000000000113\n\nこれは、ネスカフェ ドルチェ グストのポイント交換でもらったものです。  \n使い切れるポイント数だったので、なんとなく選びました。\n\n牛乳パックをそのままセットして、8 時間ほど待てばヨーグルトが完成！というお手軽さが売り。\n\n実際に作ってみたのですが、そこで気づいてしまったのです...。\n\n『無糖ヨーグルトそんなに好きじゃない...。』\n\n砂糖やジャムを入れて食べることもできますが、「健康的にいきたい」という言い訳をして、そのまま使わなくなりました。  \nさらに、牛乳 1 本の値段と市販ヨーグルトの価格を比べると「まあ買ったほうが早いよね」という結論にも至り……。\n\n## スキレット\n\nキャンプでよく使うスキレットを買ったことがあります。  \nおそらく「ゆるキャン△」の影響です。（キャンプしないのに）\n\nスキレットは手入れが大変なことで有名で、好きな人はその工程すら楽しむのですが……私はダメでした。\n\n使った後に火にかけて乾かし、油を塗って、また火にかけて……。  \n最初は頑張っていたものの、段々と面倒になり、数回、目玉焼きを焼いて「フライパンでいいや」と悟りました。\n\n## Meta Quest 2\n\nhttps://www.meta.com/jp/quest/products/quest-2\n\n買ったきっかけは、職場の同僚が持っていて、自分も一緒に遊んでみたかったからです。  \n\n当時はコロナ禍で、バーチャル空間でコミュニケーションを取ることに興味がありました。\n\n買ってすぐは職場の人と遊んだり、いくつかのゲームを楽しんだりして、VR の面白さにどっぷりハマりました。\n\nところが、転職や引越しなどの環境変化で VR を使う機会が減り、今では押入れの中にあります。\n\nまた、PC の作業をバーチャルディスプレイで拡大して行うことにもハマっていたのですが、\n\n- ヘッドセットの重さで首がつらい  \n- 視力的にも長時間はきつい  \n\nという理由で使わなくなりました。\n\n## トラベラーギター\n\nギター、カッコつけたかったんです。\n\nhttps://www.amazon.co.jp/dp/B000OQI2CI\n\n何も目標を決めずに買ってしまったのが良くなかった……。\n\n買ってすぐは好きなアーティストの楽譜を買って練習していました。  \nFコードにも苦戦しながら、スピッツの「チェリー」がなんとか弾けるようになった記憶だけはあります。\n\nしかしその後、特に続ける理由も見つからず、そっとケースに戻し、今では埃をかぶっています。","publishedAt":"2025-12-04","slug":"20251204","title":"使っていない、買ったもの2025"},{"body":"Storybook の Story オブジェクトを Vitest の Browser Mode だけで、Visual Regression Test（VRT）ができるようになりました。\n\n本記事では、その導入手順をコンパクトに紹介します。\n\n## 前提\n\n以下のセットアップが完了していることを前提に進めます。\n\n- Storybook のセットアップ\n  - 👉 https://storybook.js.org/docs/get-started/setup\n- Vitest Browser Mode のセットアップ\n  - 👉 https://vitest.dev/guide/browser\n\nまた、以下 2 つの Storybook フレームワークで動作確認済みです。\n\n- https://www.npmjs.com/package/@storybook/nextjs-vite\n  - ※併せて以下のセットアップが必要\n    - https://www.npmjs.com/package/vite-plugin-storybook-nextjs\n- https://www.npmjs.com/package/@storybook/react-vite\n\n加えて、この記事も参考になります。\n\nhttps://storybook.js.org/docs/api/portable-stories/portable-stories-vitest\n\n## Vitestの設定\n\nまず、Vitest で Browser Mode を有効にします。\n\n```js\n// vitest.config.js\nimport react from \"@vitejs/plugin-react\";\n// import nextjs from \"vite-plugin-storybook-nextjs\"; // nextjs-vite を使う場合\nimport { playwright } from \"@vitest/browser-playwright\";\nimport { defineConfig } from \"vitest/config\";\n\n/*\n * @type {import(\"vitest/config\").ViteUserConfigExport}\n */\nconst baseConfig = {\n  plugins: [\n    react(),\n    // nextjs(),\n  ],\n  test: {\n    include: [\"src/**/*.test.{ts,tsx}\", \"src/**/*.spec.{ts,tsx}\"],\n    setupFiles: [\"./vitest.setup.js\"],\n    browser: {  // 👈 Browser Mode の設定\n      enabled: true,\n      provider: playwright(),\n      headless: true,\n      instances: [{ browser: \"chromium\" }],\n    },\n  },\n};\n\nexport default defineConfig(baseConfig);\n```\n\nVitest Browser Mode 向けのセットアップも追加します。\n\n```js\n// vitest.setup.js\nimport \"vitest-browser-react\";\n```\n\n## Story を VRT する\n\nでは、サンプルコンポーネントと Story、テストコードを作成していきます。\n\n### コンポーネント\n\n```ts\n// ./bubble-text.tsx\ntype Props = {\n  text: string;\n};\n\nexport const BubbleText = ({ text }: Props) => {\n  return (\n    <div>{text}</div>\n  );\n};\n```\n\n### Storyファイル\n\n```ts\n// ./bubble-text.stories.tsx\nimport type { Meta, StoryObj } from \"@storybook/react-vite\";\n// or\n// import type { Meta, StoryObj } from \"@storybook/nextjs-vite\";\n\nimport { BubbleText } from \"./bubble-text\";\n\nconst meta = {\n  args: {\n    text: \"Hello, World\",\n  },\n  component: BubbleText,\n} satisfies Meta<typeof BubbleText>;\n\nexport default meta;\ntype Story = StoryObj<typeof meta>;\n\nexport const Default: Story = {};\n```\n\n### VRT のテストコード\n\n#### 1. `@storybook/nextjs-vite` を使用する場合\n\n`composeStories` で Story オブジェクトをまとめて取得し、\n`Story.run()` → `toMatchScreenshot()` の流れで VRT できます。\n\n```ts\n// ./bubble-text.spec.tsx\nimport { composeStories } from \"@storybook/nextjs-vite\";\nimport { describe, expect, it } from \"vitest\";\nimport * as stories from \"./bubble-text.stories\";\n\nconst Stories = composeStories(stories);\n\ndescribe(\"BubbleText\", () => {\n  it.each(Object.entries(Stories))(\"should %s snapshot\", async (_, Story) => {\n    // Act\n    await Story.run();\n\n    // Assert\n    await expect(document.body).toMatchScreenshot();\n  });\n});\n```\n\n#### 2. `@storybook/react-vite` を使用する場合\n\n`@storybook/nextjs-vite` と同様に、`composeStories` で Story オブジェクトをまとめて取得し、 `render` → `toMatchScreenshot()` の流れで VRT できます。\n\n```ts\nimport { composeStories } from \"@storybook/react-vite\";\nimport { describe, expect, it } from \"vitest\";\nimport { render } from \"vitest-browser-react\";\nimport * as stories from \"./bubble-text.stories\";\n\nconst Stories = composeStories(stories);\n\ndescribe(\"BubbleText\", () => {\n  it.each(Object.entries(Stories))(\"should %s snapshot\", async (_, Story) => {\n    // Act\n    const { getByTestId } = await render(\n      <div data-testid=\"test\">\n        <Story />\n      </div>,\n    );\n\n    await expect(getByTestId(\"test\")).toMatchScreenshot();\n  });\n});\n```\n\nこれにより、Storybook と Vitest だけで完結する VRT 環境が構築できました！🎉\n\n## 備考\n\nhttps://zenn.dev/silverbirder/articles/7b2795f6b26f98","publishedAt":"2025-12-03","slug":"20251203","title":"Storybook の Story を Vitest Browser Mode with Playwright で VRT"},{"body":"仕事でも生活でも、何かを決めないといけない場面ってありますよね。  \nそれは、大きなことでも、小さなことでも同じです。\n\nたとえば、車を買うという大きな決断から、トイレ掃除をするという日常の小さな決断まで、さまざまです。  \n自分から進んで決めたことであれば、多少疲れることがあっても前向きに取り組めます。\n\nでも一方で、\n\n- 「誰もやらないから、自分がやるしかない」  \n- 「ほんとは嫌だけど、結局やるのは自分だ」  \n- 「お願いされっぱなしで、自分ばかりだ」\n\nといった、“他の理由から始まる決断” のときは、どうしてもネガティブな気持ちが生まれます。\n\n「なんで自分がやってるんだろう…」  \nそんなふうに思う瞬間、私にもあります。\n\nただ最近は、こう考えるようにしました。\n\n- 「とはいえ、選んだのは自分なんだよね」  \n- 「選ばないという道もあったのに、選ぶ決断をしたんだよ」\n\n面倒なことやネガティブな決断ほど、人のせいにしたくなったり、逃げたくなったりします。  \nだからこそ、そういうときに自分へ\n\n## 「選ばないという道もあったけれど、選ぶほうを選んだ自分は偉い」\n\nと声をかけるようにしています。\n\n些細な決断でも、積み重なればストレスになります。  \nだからこそ自分へ、\n\n「最終的に決断したのは自分。よくやった」\n\nと伝えて、少し前向きに過ごすようにしています。","publishedAt":"2025-12-02","slug":"20251202","title":"最終的な決断は自分自身"},{"body":"ベストバイを紹介するシーズンがやってきましたね。  \n今日は、これまで買って「本当に良かった！」と思えたものを紹介します。\n\nここで紹介するのは、あくまで私個人の感想であり、それ以下でも以上でもありません！（ステマじゃないよ）  \n選んだ基準は、その商品がもし故障したら **同じもの、または類似品を必ず買い直すかどうか** です。\n\n## 炭酸水メーカー: Drinkmate\n\n炭酸水メーカーの Drinkmate を使い始めて数年たちますが、いまだ現役です。\n\nhttps://www.drinkmate.jp/products.php\n\n特に夏は喉が乾きやすく、毎朝の炭酸水が欠かせません。  \nリモートワークで一日中家にいるため、お昼や夕方にも 2〜3 回は飲んでいます。\n\nシュワっとした爽快感と、ほどよい満腹感で仕事に集中しやすいんですよね...。  \n基本は無味の炭酸水ですが、たまに買った飲み物を炭酸割りにして楽しむこともありました。\n\nなお、コーヒーやお茶の炭酸割りは…個人的にはおいしくなかったです。\n\n## 浄水器: ブリタ タンク型浄水器\n\nまた飲み物ですが、ブリタのタンク型浄水器は毎日使っています。\n\nhttps://www.brita.co.jp/%E8%A3%BD%E5%93%81%E4%B8%80%E8%A6%A7/%E3%83%9D%E3%83%83%E3%83%88%E5%9E%8B%E6%B5%84%E6%B0%B4%E5%99%A8/%E3%83%95%E3%83%AD%E3%83%BC\n\nタンク型の良いところは、**上から蛇口の水をそのまま注げて、たくさん入ること**。\n\nキッチンに置いておけば、伸びる蛇口でジャーっと注ぐだけでOKです。  \n冬は常温で室内に置き、夏は冷蔵庫に入れて冷やしています。  \n（タンクを冷蔵庫に運ぶのは少し手間ですが…）\n\n## 買い物かご: 無印良品\n\n車を買ってから週一でまとめ買いをするようになり、買い物かごは必需品になりました。\n\nhttps://www.muji.com/jp/ja/store/cmdty/detail/4550512865797\n\n無印の買い物かごは 5,000 円分くらいの食品を全部まとめて入れられて、そのまま車へ積めて便利です。  \nスーパーによっては、店員さんが私の買い物かごへ直接詰めてくれるところもあって助かっています。\n\n買い物かごがなかった頃は、エコバッグ 2 つに詰めて自転車で持ち帰っていたので、洗濯の手間もありました。  \n今はそのストレスがありません。  \nただ無印良品の買い物かごは、取手が弱くて千切れそうです...。\n\n## TVチューナー: Xit\n\n私は家のどこでもテレビを見たくなってしまうタイプで、特にお風呂で見たい派です。\n\nそんな時に便利なのが Xit の TV チューナー。\n\nhttps://www.pixela.co.jp/products/xit/\n\nテレビ線と Wi-Fi につないでおけば、iPad などのタブレットでアプリ経由でテレビが見られます。  \nお風呂ではタブレットスタンドと防水カバーを使って視聴しています。\n\nもう何年も続けている習慣で、これは手放せません。\n\n## アイマスク: MYTREX\n\n寝るときは真っ暗派です。  \nただ、部屋の都合で光が少し入るので、以前は RADWIMPS グッズのタオルを顔にかけて寝ていました。\n\nhttps://mytrex.jp/eye-air/\n\nLoft で見かけて買った MYTREX のアイマスクがすごく良くて、いまは毎日これです。\n\n- 軽い\n- 肌触りが良い\n- 光をしっかり遮ってくれる\n- 締め付けは強すぎず、寝返りしてもズレにくい\n\n使い始めてから明らかにぐっすり眠れるようになりました。  \n愛用しています。\n\n## ハンガー: ニトリ キャッチ式ハンガー\n\n洗濯物を干すとき、ニトリの「キャッチ式ハンガー」を必ず使っています。\n\nhttps://www.nitori-net.jp/ec/product/8500505s/\n\n晴れの日は外干しですが、雨の日は室内干しに切り替えます。  \nこのとき、キャッチ式ハンガーが本当に便利。\n\n竿だけでなく、**室内の “ちょっとした出っ張り” に引っかけられる**のが良きです。  \n風の通り道に干せるので乾きやすい。\n\nただし、場所によっては出っ張りを傷つけるので注意は必要です。\n\n## コップ: スライム ゆらゆらコップ\n\n完全に趣味の領域ですが、1 年以上ずっと使っています。\n\nhttps://store.jp.square-enix.com/item/MW60297_4.html\n\nドラクエが好きでスライムが好きなので、このコップは見るだけでも楽しい。  \n水や炭酸水を入れると “ゆらゆら” します。\n\n夏は山盛りの氷＋炭酸水で、コップが揺れて音が鳴るのが最高です。  \n色シロップでスライムを変身させるのも楽しい。\n\n## テーブルクッション: リラフィット\n\n休日の大半はソファの上にいます。  \nパソコンを使いたいときは、リラフィットのテーブルクッションを膝の上に置いてパソコン作業をしています。\n\nhttps://livheart.jp/shopdetail/000000000904/\n\nクッション部分は柔らかく、テーブル部分は適度に硬い。  \nタブレットやスマホ用のくぼみもありますが、私はシンプルに「膝上テーブル」として使っています。\n柔らかさと大きさが、自分にはちょうど良いみたいです。\n\n## プリンター: キャノン\n\nフリーランスになってから書類を用意する機会が増え、コンビニプリントが面倒になったため購入しました。\n\nhttps://personal.canon.jp/product/printer/pixus/lineup/ts3730\n\n「そんなに使わないかな？」と思っていたのですが、意外と出番があります。  \n月に 1 回は何か印刷している気がします。\n\n特に多いのが、書類のスキャン。  \nPDF にして保存できるのが便利で、買って大正解でした。\n\n## 車: 日産 DAYZ\n\n車種にはそこまでこだわりがなかったのですが、たまたま安かった DAYZ を購入しました。\n\nhttps://www3.nissan.co.jp/vehicles/new/dayz.html\n\n結果、これが生活の質を爆上げしてくれました。\n\n車を買う前は電車移動が中心でしたが、今は車でしか行けない場所にもどんどん行けます。  \n休日はほぼ毎日ドライブして、美味しいものを食べたり観光したりするのが楽しみになりました。\n\n免許を取ってすぐ買っておけばよかった…と思うほど。  \nペーパードライバーからの復帰は怖かったけど、今は買って本当によかったです。\n\n## 終わりに\n\n以上、私が「買ってよかった！」と思えるものでした！  \n来年も、これらは使っているかな？","publishedAt":"2025-12-01","slug":"20251201","title":"今日まで買ってよかったもの2025"},{"body":"Tailwind CSS v4.0 から、色指定に OKLCH が標準採用されました。\n\n> oklch() 関数記法は、指定された色を Oklch 色空間で表現するものです。これは oklab() と同じ L 軸を持っていますが、極座標系の C （彩度）と H （色相）を使用します。\n> — [oklch() - CSS | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/Reference/Values/color_value/oklch)\n>\n>\n> - 明度（Lightness）: 色の明るさをコントロール。0から1の値、または0%から100%の範囲に設定します。\n>\n> - 彩度（Chroma）: 色の強度をコントロール。彩度（Saturation）に似ています。\n>\n> - 色相（Hue）: 色相をコントロール。0から360までの度数で設定します。\n> — [コリス: OKLCHカラーについて理解を深めよう](https://coliss.com/articles/build-websites/operation/design/about-oklch-color.html)\n\nOKLCH は明度・彩度・色相を独立して扱えるため、配色をより論理的に設計できるのが良いところです。  \nWeb UI では「ベースカラー・メインカラー・アクセント」などの配色が有名です。  \n色相を固定し、明度と彩度のみで変化をつけることで、落ち着いた統一感のある配色が作れるのでは？と感じました。\n\nこの記事では、私が試している OKLCHとトークン設計の方法をまとめます。\n\n## 1. 明度・彩度・色相をトークン化する\n\nまずは OKLCH の構成要素をそのままトークンにします。  \nここでは「素材」としての値だけを定義します。\n\n```css\n:root {\n  /* ---- 色相（Hue）---- */\n  --hue-base: 120;\n\n  /* ---- 明度（Lightness）---- */\n  --tone-100: 1;\n  --tone-90: 0.9;\n  --tone-80: 0.8;\n  --tone-70: 0.7;\n  --tone-60: 0.6;\n  --tone-50: 0.5;\n  --tone-40: 0.4;\n  --tone-30: 0.3;\n  --tone-20: 0.2;\n  --tone-10: 0.1;\n  --tone-0: 0;\n\n  /* ---- 彩度（Chroma）---- */\n  --chroma-100: 1;\n  --chroma-90: 0.6;\n  --chroma-80: 0.36;\n  --chroma-70: 0.216;\n  --chroma-60: 0.13;\n  --chroma-50: 0.078;\n  --chroma-40: 0.047;\n  --chroma-30: 0.028;\n  --chroma-20: 0.017;\n  --chroma-10: 0.01;\n  --chroma-0: 0.006;\n}\n```\n\n## 2. トークンに「役割」を与える\n\n次に、UI の文脈に沿って「どこで使うか」という役割を与えます。\n\n### 明度の意味付け\n\n```css\n:root {\n  /* ---- 背景・面（Surface） ---- */\n  --light-bg: var(--tone-100);\n  --light-surface: var(--tone-60);\n  --light-popover: var(--tone-100);\n\n  /* ---- Primary（ブランド色） ---- */\n  --light-primary: var(--tone-60);\n  --light-primary-fg: var(--tone-100);\n}\n```\n\n### 彩度の意味付け\n\n```css\n:root {\n  /* ---- 無彩色〜弱彩度 ---- */\n  --chroma-none: var(--chroma-0);\n  --chroma-muted: var(--chroma-40);\n  --chroma-low: var(--chroma-30);\n  --chroma-medium: var(--chroma-70);\n  --chroma-strong: var(--chroma-100);\n\n  /* ---- Primary ---- */\n  --chroma-primary: var(--chroma-100);\n  --chroma-primary-fg: var(--chroma-20);\n}\n```\n\nこの段階で、はじめて UI の役割と数値トークンが結びつきます。\n\n## 3. Tailwind のカラーとして OKLCH を組み立てる\n\n最後に、トークンを OKLCH の形式にまとめて Tailwind に流し込みます。\n\n```css\n:root {\n  /* ---- Primary ---- */\n  --primary: oklch(\n    var(--light-primary)\n    var(--chroma-primary)\n    var(--hue-base)\n  );\n\n  --primary-foreground: oklch(\n    var(--light-primary-fg)\n    var(--chroma-primary-fg)\n    var(--hue-base)\n  );\n}\n\n@theme inline {\n  --color-primary: var(--primary);\n  --color-primary-foreground: var(--primary-foreground);\n}\n```\n\n## まとめ：三段階で配色をコントロールする\n\nこの手法では、色が\n\n1. 数値トークン（明度・彩度・色相）\n1. 意味付けトークン（背景・Primary など）\n1. 最終カラー（OKLCH 値）\n\nという三層に分かれます。\n\nこの設計により、UI 全体で色の一貫性を保てるうえ、後からの調整も容易になります。  \nたとえば「Primary をもう少し淡くしたい」場合でも、使用するトークンを変えるだけになります。\n\n## 終わりに\n\n配色は「カラー配色図鑑」などから直感で選ぶ方法も楽しいですが、  \n今回紹介したような OKLCHとトークン設計 による“理論的アプローチ”も試してみると良いかもしれません。","publishedAt":"2025-11-30","slug":"20251130","title":"oklchとトークン設計"},{"body":"Web フロントエンドの UI 開発では、私の中では Storybook は、ほぼ必須なツールです。  \nUI カタログとして使うだけでなく、**ビジュアルリグレッションテスト（VRT）** にも活用したいと常々思っています。\n\nVRT が必要になる場面としては、たとえば次のようなケースがあります。\n\n- 共通コンポーネントのデザイン修正後、依存コンポーネントの崩れを検知したい\n- デザイントークンやテーマ変更の影響範囲を確認したい\n- ライブラリアップデート時にデザイン差分を確認したい\n\nStorybook の以下のドキュメントでは、Visual Tests は Chromatic の利用が紹介されています。\n\n- [Visual tests | Storybook docs](https://storybook.js.org/docs/writing-tests/visual-testing)\n\nただ、さまざまな理由から Chromatic に依存したくないこともあります。\n\n## Vitest の Browser Mode と toMatchScreenshot\n\nここで役に立つのが、Vitest に追加された Browser Mode です。  \nヘッドレスブラウザ（Chromium など）上での UI テストが可能になりました。\n\n- [Browser Mode | Guide | Vitest](https://vitest.dev/guide/browser)\n\nさらに、 `toMatchScreenshot` により、スクリーンショットを比較する VRT ができるようになりました。\n\n- [Visual Regression Testing | Vitest](https://vitest.dev/guide/browser/visual-regression-testing.html)\n\n## Storybook の composeStory と組み合わせる\n\nStorybook には `composeStory`（および `composeStories`）というAPIがあり、  \nStorybook の Story オブジェクトをテストコード内で利用できます。\n\n- [Stories in unit tests | Storybook docs](https://storybook.js.org/docs/writing-tests/integrations/stories-in-unit-tests)\n\nこれを使うことで、\n\n- Storybook に定義した UI 状態（Story）\n- Vitest のスクリーンショット比較（toMatchScreenshot）\n\nをそのままつなげて、Chromatic なしで Storybook の Story を VRT できるようになります。\n\n## 実際に対応したコミット\n\n実際にこの方法を試したコミットはこちらです。\n\n- https://github.com/silverbirder/fequest/commit/13a331b029a406781d500f1ce88a26cf924b3918\n\n上記コミットには、Vitest 側の不具合修正を早めに取り込みたかったため、patch を当てています。\n\n- 参考: https://github.com/vitest-dev/vitest/issues/8853\n\n使用した環境は次のとおりです。\n\n- `@storybook/react-vite`\n- `vitest-browser-react`\n\n当初は `@storybook/nextjs-vite` で試していたものの、Next.js の `next/navigation` 周りの mock エラーに苦戦し、一旦断念しました。  \n再挑戦すれ解決できる可能性はありますが、今回は `@storybook/react-vite` を使用しています。\n\n## サンプルコンポーネント\n\n```tsx\n// my-input.tsx\nimport { Input } from \"<path to shadcn input component>\";\nimport { ComponentProps } from \"react\";\n\ntype Props = ComponentProps<typeof Input>;\n\nexport const MyInput = ({ ...rest }: Props) => {\n  return <Input {...rest} />;\n};\n```\n\n## Storybook 側のファイル\n\n```tsx\n// my-input.stories.tsx\nimport type { Meta, StoryObj } from \"@storybook/react-vite\";\n\nimport { MyInput } from \"./my-input\";\n\nconst meta = {\n  component: MyInput,\n} satisfies Meta<typeof MyInput>;\n\nexport default meta;\ntype Story = StoryObj<typeof meta>;\n\nexport const Default: Story = {};\n```\n\n## Vitest の VRT テストコード\n\n```tsx\n// my-input.spec.tsx\nimport { composeStories } from \"@storybook/react-vite\";\nimport { describe, expect, it } from \"vitest\";\nimport { render } from \"vitest-browser-react\";\n\nimport * as stories from \"./my-input.stories\";\n\nconst { Default } = composeStories(stories);\n\ndescribe(\"MyInput\", () => {\n  it(\"matches Default story screenshot\", async () => {\n    const { getByTestId } = await render(\n      <div data-testid=\"test\">\n        <Default />\n      </div>,\n    );\n\n    await expect(getByTestId(\"test\")).toMatchScreenshot();\n  });\n});\n```\n\nこのテストを実行すると、Default Story のスクリーンショットが保存され、  \n次回以降はその差分が検知されるようになります。\n\n## これで Storybook の Story を全部 VRT できる\n\n`composeStories` と `toMatchScreenshot` を組み合わせることで、\n\n- Storybook の Story をそのままテストに読み込む\n- Story 全パターンに対してスクリーンショット比較を行う\n- Chromatic なしで VRT ができる\n\nという、シンプルな構成で VRT ができそうです。  \nStorybook と Vitest という、どちらもメジャーな OSS だけで実現できるため、外部依存を減らせる点も魅力的です。\n\n## 追記\n\n`@storybook/nextjs-vite` でもスクリーンショット VRT が動作することを確認できました。\nポイントは、以下で紹介されている `vite-plugin-storybook-nextjs` を導入する必要があったことです。\n\n- [Portable stories in Vitest | Storybook docs](https://storybook.js.org/docs/api/portable-stories/portable-stories-vitest)\n\n私の環境では monorepo を採用しているため、`vite.config.ts` に次のような設定を追加しました。\n\n```ts\n// vite.config.ts\nimport nextjs from \"vite-plugin-storybook-nextjs\";\n\nexport default defineConfig({\n  plugins: [nextjs({dir: \"../../apps/user\"})],\n});\n```\n\nテストの書き方ですが、上記の紹介した形式だと、以下のエラーが発生しました。\n\n> SB_FRAMEWORK_NEXTJS_0002 (NextjsRouterMocksNotAvailable): Tried to access router mocks from \"next/router\" but they were not created yet. You might be running code in an unsupported environment.\n\nそこで、以下のようなテストの書き方に変更したら動作しました。\n\n```tsx\n// my-input.spec.tsx\nimport { composeStories } from \"@storybook/react-vite\";\nimport { describe, expect, it } from \"vitest\";\nimport { render } from \"vitest-browser-react\";\n\nimport * as stories from \"./my-input.stories\";\n\nconst { Default } = composeStories(stories);\n\ndescribe(\"MyInput\", () => {\n  it(\"matches Default story screenshot\", async () => {\n    await Default.run();\n\n    await expect(document.body).toMatchScreenshot();\n  });\n});\n```\n\n修正したコミットは以下になります。\n\n- https://github.com/silverbirder/fequest/commit/d8ef4ddbb52ab78d954f1db2d95b727d6f46d81c","publishedAt":"2025-11-29","slug":"20251129","title":"StorybookのcomposeStoryとVitestのtoMatchScreenshotを組み合わせたVRT"},{"body":"Web のフロントエンド開発や、Figma でデザインを議論するときに、  \nよく「ここにテキストが入ります」といったモックデータを配置して進めることがあります。\n\nしかし、**想像力を高めて気づきを得る** という意味では、  \nそこに「実際に入りそうな具体的なデータ」を置いて会話した方が、  \n議論の精度もスピードも上がりやすいと感じています。\n\n## なぜ具体的なデータを使うべきか\n\nたとえば、管理画面のブログ記事一覧ページを設計するとします。\n\n- ブログタイトル\n- PV 数\n- 公開日\n- 著者情報\n\nといった項目が並ぶ典型的な一覧画面です。  \nこのとき、タイトルに\n\n- 「ここはタイトルが入ります」\n- 「サンプルタイトルです」\n\nPV 数に\n\n- 「9999」\n\nのような架空データを入れるよりも、\n\n- タイトル: 「CSS の技術 Tips 集」\n- PV 数: 652\n\nといった “実際にありそうな数値や文言” を入れた方が、  \n画面のリアリティが一気に高まり、議論が自然と深まりやすいと感じています。\n\n具体的なデータを使うことで得られるメリットは次のとおりです。\n\n- **議論のベースラインが揃う**\n  - 参加者全員のイメージが自然と一致しやすい。\n- **会話が発散しにくい**\n  - 特定データに縛られすぎないことは前提としても、方向性が定まりやすい。\n- **ユーザー体験のイメージが明確になる**\n  - 不要な要素を削ぎ落としやすく、文言や動線の妥当性にも気づきやすい。\n\nもちろんデザインでは最大・最小サイズなどのケースを考慮する必要がありますが、  \nUX や仕様の議論では「具体的なデータ」の方が向いているかと思います。\n\n## 時系列も一緒に考えると、より深い設計になる\n\nさらに、データそのものだけでなく、時系列（過去・現在・未来）を想定して会話すると、  \n設計の精度は格段に上がります。\n\n- 「初期はデータが少ないけれど、将来的に増える可能性は？」\n  - → 並び順や表示件数、ページングの必要性が見える。\n- 「セミナーなどを申し込んだ後、画面はどう変化する？」\n  - → 状態遷移やステータス表示の設計が明確になる。\n- 「処理中にキャンセルをしたい場合は？」\n  - → 戻り動作やエラーハンドリングの検討につながる。\n\nまた、どのロールのユーザーがどのような状況で使うのかも合わせて考えると、  \n仕様の抜け漏れが減り、議論の解像度も高まります。\n\n可能なら、自分がその画面のユーザーであるかのように想像して話すと、  \nさらに現実的な議論がしやすくなると思います。\n\n## 終わりに\n\n私はこの考え方で、プランニングやデザインの議論を進めていました。  \nぜひ、皆さんも試してみてください。","publishedAt":"2025-11-28","slug":"20251128","title":"具体的なデータで議論しよう"},{"body":"CSS の色に関する Tip を 2 つ紹介します。\n\n- 1つの文字色から、薄い背景色を決める\n- 1つの背景色から、文字色を決める\n\nAPIなどで色が1つ決まっている際に、文字色や背景色を決めるのに便利なテクニックです。\n\n## 1つの文字色から、薄い背景色を決める\n\nCSS の `color-mix()` を使うと、1つの色をベースにして  \n自動で **ちょっと薄い背景色** を作ることができます。\n\nたとえば、青色の10%を混ぜた背景色にする例です。\n\n```html\n<div>薄い背景色</div>\n<style>\ndiv {\n  display: inline-block;\n  padding: 8px 12px;\n\n  color: blue;\n  background-color: color-mix(in srgb, blue 10%, transparent);\n}\n</style>\n```\n\n`color-mix()` が使える環境なら、淡い背景を作るときにとても便利です。\n\n<div style={{display: 'inline-block', height: \"3rem\", padding: \"8px 12px\", color: \"blue\", backgroundColor: \"color-mix(in srgb, blue 10%, transparent)\"}}>薄い背景色</div>\n\n## 1つの背景色から、文字色を決める\n\n背景色だけ指定して、自動的に読みやすい文字色に調整したい場合は、`invert + grayscale + contrast` を使う方法があります。\n\n以下の記事が参考になりました。\n\n- [CSSのfilterを使って、背景色に合わせた文字色を自動的に設定する - Blanktar](https://blanktar.jp/blog/2020/11/css-automate-foreground-text-color)\n\n```html\n<div>\n  <span>読みやすい文字色</span>\n</div>\n<style>\ndiv {\n  display: inline-block;\n  padding: 8px 12px;\n  background-color: blue;\n}\nspan {\n  color: inherit;\n  filter: invert(100%) grayscale(100%) contrast(100%);\n}\n</style>\n```\n\n背景色が濃くても薄くても、適度に読みやすい文字色になります。\n\n<div style={{display: 'inline-block', height: \"3rem\", padding: \"8px 12px\", backgroundColor: \"blue\"}}>\n  <span style={{color: \"inherit\", filter: \"invert(100%) grayscale(100%) contrast(100%)\"}}>読みやすい文字色</span>\n</div>\n\n## 終わりに\n\n以上、CSS だけで、1つの色から他の色を決める方法を紹介しました。","publishedAt":"2025-11-27","slug":"20251127","title":"CSSで任意の色から、背景色・文字色を決める方法"},{"body":"今、個人開発で **Fequest** という「ユーザー画面」と「管理画面」の 2 つの Web アプリを実装しています。  \nこの 2 つを跨いだ E2E テストを、Testcontainers と Cucumber（Gherkin Markdown）、そして Playwright を組み合わせて書いています。\n\n今回、**管理画面でデータを登録し、その内容がユーザー画面で正しく表示される** という一連の E2E テストが GitHub Actions 上で動作するようになったので、その方法をまとめておきます。\n\n## Fequest とは\n\n**Fequest（feature request）** は、ユーザーが新機能や改善要望を投稿できるサービスです。\n\n- 管理画面で「プロダクト名」を登録\n- ユーザー画面にそのプロダクトページが生成\n- ユーザーが機能リクエストを投稿\n\nユーザーと開発者が、「つくってほしいもの」「つくる予定のもの」を相互に伝え合える場を作るのが目的です。\n\n## 前提構成\n\nFequest の構成は以下のとおりです。  \nTestcontainers は Docker 上で動作できることが必須なので、それ以外はなんでも構いません。\n\n- モノレポ（Turborepo）\n  - ユーザー画面：Next.js\n  - 管理画面：Next.js\n- DB：PostgreSQL\n- ORM：Drizzle\n- 認証：管理画面は Google 認証必須、セッションは DB に保存\n- ブラウザ操作：Playwright\n\n## 全体の流れ\n\n実際に行う処理は次のような流れです。\n\n1. Testcontainers が **PostgreSQL コンテナ**を起動する\n1. 同じネットワーク内で、以下の Docker を Testcontainers から起動する（ユーザーアプリ、管理アプリ）\n1. DB にセッションデータを事前登録して、認証済み状態を作る\n1. Playwright のブラウザコンテキストに、そのセッション Cookie をセットする\n1. 認証済みユーザーとして管理画面にアクセスし、データを登録する\n1. 同じ DB を参照するユーザー画面で、登録済みデータが表示されることを確認する\n\nこの一連の流れは **ローカルだけで完結** します。  \nGitHub Actions 上でも完全に同じ構成で動作します。  \nステージング環境が不要になるのが大きなメリットです。\n\n## 実装例\n\nソースコードはすべて公開しています。\n\n- https://github.com/silverbirder/fequest/blob/main/apps/e2e/src/features/product-detail/product-detail.feature.md\n\n以下は、その中から抜粋したサンプルです。\n\n### 3. DB フェーズ：session を挿入する\n\n管理画面ログイン済み状態を作るため、DB にユーザーとセッションを直接挿入します。\n\n```ts\nconst userId = `e2e-user-${randomUUID()}`;\n\nawait db.insert(users).values(buildUserRecord(userId));\n\nconst sessionToken = `e2e-session-${randomUUID()}`;\n\nawait db.insert(sessions).values({\n  expires: new Date(Date.now() + 1000 * 60 * 60),\n  sessionToken,\n  userId,\n});\n```\n\n### 4. Playwright に Cookie を注入する\n\nPlaywright のブラウザコンテキストに Cookie を追加し、管理画面にアクセスした瞬間からログイン済み状態にします。\n\n```ts\nawait adminBrowser.context.addCookies([\n  {\n    domain: new URL(adminBaseUrl).hostname,\n    httpOnly: true,\n    name: \"authjs.session-token\",\n    path: \"/\",\n    sameSite: \"Lax\",\n    secure: false,\n    value: sessionToken,\n  },\n]);\n```\n\n### テストの流れ\n\n1. `adminBrowser` で管理画面にアクセス\n1. UI 操作でプロダクトを登録\n1. ユーザー画面で、そのプロダクトが表示されていることを確認\n\n管理画面とユーザー画面が **同じ DB を参照している** ため、  \n管理側で登録した内容がユーザー側ですぐ反映されます。\n\nUI ベースで「実運用に近い E2E テスト」を構築できるのが非常に快適です。\n\n## 終わりに\n\n以上、Testcontainers 芸人でした。\n\n## 関連記事\n\nTestcontainers については、以下の記事も参考にしてください。\n\n- [Testcontainersで実現する、使い捨て結合テスト環境構築とテスト実施 - zenn](https://zenn.dev/silverbirder/articles/0a54533cb7ee9b)\n- [Testcontainersを用いたNext.jsとDBの結合テスト - zenn](https://zenn.dev/silverbirder/articles/bcf9ae9b496a15)","publishedAt":"2025-11-26","slug":"20251126","title":"Testcontainers で管理・ユーザー画面の一気通貫 E2Eテスト"},{"body":"歩くことでゲームが進む **ピクミンブルーム（Pikmin Bloom）** を普段から使っています。  \n「外を歩くかどうか」が、ピクミンを成長させるための動機にもなり、日常の行動に良い影響を与えてくれるアプリです。  \n「今日1万歩歩かないとバッジがもらえないから、今日は歩こう」といった具合に、気分を前向きにしてくれます。\n\nもう一つは、睡眠することでゲームが進む **ポケモンスリープ（Pokémon Sleep）**。  \nこのおかげで、寝る時間がいつも深夜0時半を過ぎることはなくなりました。  \n遅く寝るとゲーム内で損をしてしまうため、自然と就寝リズムが整ってきています。\n\n**歩く・寝る**のように、日常の「必ず行う習慣」とゲームがリンクしていると、生活が少しずつ改善される感覚があります。  \nそこで、同じように **日常をちょっと良くしてくれる“生活 × ゲーム”アプリ** を他にも探しています。\n\nたとえば「食事」がゲームとして成り立つアプリはないかな？と思い出したのが、（ゲームではありませんが）以前使っていた **あすけん**。  \n食べたものを写真で記録し、カロリーや栄養素を確認できるアプリです。  \nいつの間にか使わなくなってしまいましたが、これも確かに生活改善には役立っていました。\n\n他にも、**健康的な習慣づくりや生活の改善につながるゲーム性のあるアプリ**で、おすすめがあればぜひ知りたいです。","publishedAt":"2025-11-25","slug":"20251125","title":"健康になれるスマホゲーム"},{"body":"私の住む地域では、毎年 1 月中旬ごろに雪がかなり降るそうです。  \n美容室のお兄さんに過去の冬の写真を見せてもらったところ、車がすっぽり隠れるほどの大雪で驚きました。\n\n私はこれまで雪が積もる地域に住んだことがありません。  \n最初は「ちょっと楽しそう」と思っていたのですが、話を聞くうちにだんだん不安のほうが大きくなってきました。\n\n## 車の準備\n\nまず、車はスタッドレスタイヤに替えることにしました。  \nタイヤ交換が初めてだったため、今回はタイヤ選びから交換まですべてディーラーと相談しながら進めました。  \n費用は 10 万円ほど。\n\nこの地域に長く住むなら、来年以降は交換方法を自分で調べてやってみても良いかもしれません。  \nあるいは、ディーラーではなく自分でタイヤを選んで（今回はもう買ったけれど）タイヤ専門店で交換してもらう方法もあります。  \nただ、初めての今回は安心を優先して、全部お任せしました。\n\nまた、運転時の注意点として「減速するときはブレーキではなく、エンジンブレーキを使ってください」とディーラーの担当者の方に教えてもらいました。  \n急ブレーキでタイヤがロックされると、雪道では特に滑りやすくなるとのこと。  \n雪が降ってからいきなり運転の仕方を変えるのは難しいので、今のうちから少しずつ意識しておこうと思います。\n\n## 雪かき道具の準備\n\n次に、雪かき道具です。  \n早朝は、夜の雪が溶けて凍り、雪がカチコチになることが多いそうです。  \nもし早朝に車を出す必要がある場合は、しっかり雪をどかさないと動けません。\n\nそんなときに使うのが **剣先スコップ**。これを 1 つ購入しました。  \nまた、広い面を押して雪をどかす **プッシャー** も用意しました。  \n車の上の雪を落とす専用の道具もあるそうですが、私は手かプラスチックのプッシャーで対応する予定です。\n\nほかにも、車に積んでおく雪かき道具があると便利だと聞きましたが、まずは上記の 2 つを使いながら様子を見ようと思います。  \n（雪かきに使った道具を、そのまま車に積むイメージです）\n\n## 足元の準備\n\n雪の日は、普通の靴では滑ったり濡れたりしてしまいます。  \n滑りにくく、靴裏のグリップがしっかりした **長靴** は必須とのこと。  \nこれはまだ買っていないので、近いうちに選ぶつもりです。\n\n## 雪かきは誰がするのか\n\n大通りは通勤時間帯に除雪車が入るようですが、それ以外の時間帯は雪が残っていたり固まっていたりするとのこと。  \n住宅街の細い道は、基本的に **住民が雪かきする** ことになります。\n\n私の住むアパートでは、私の駐車場所がもっとも奥側（道路から離れた場所）にあるため、  \n車を出すときの雪かきは自分でやらないといけないそうです。  \n道路に近いところに車を停めている人は、誰かが雪かきした道を使えるので、少し楽だと聞きました。\n\n## 人に聞く\n\n雪国の生活はわからないことだらけなので、気になることは人に聞くようにしています。  \n美容室のときもそうですし、ホームセンターのスタッフの方に尋ねたり、妻が職場の人から教えてもらったりと、いろいろなところで情報を集めています。\n\nたとえば、\n\n- 「いつごろ雪が降り始めるのか」\n- 「どれくらいの期間続くのか」\n- 「降る頻度はどれくらいか」\n- 「バスや電車は動いているのか」\n\nこうした話は、やっぱり地元の人に聞くのがいちばん確かです。  \n季節の感覚や“だいたいこの時期はこうなる”という実感は、住んでいる人にしかわからないものですね。\n\n教えてもらった情報のおかげで、帰省の時期をずらす判断もできたので、とても助かりました。\n\n## 最後に\n\n雪がある日は無理に外出しないほうが良いのは確かですが、  \nどうしても出ないといけない日もあるはず。  \n\nそのときに慌てないよう、今のうちにできる準備だけはしておこうと思います。","publishedAt":"2025-11-24","slug":"20251124","title":"雪への備え"},{"body":"Google Map の約7年分のタイムラインデータが消えてしまいました。  \n悲しすぎる。\n\n原因は、スマホ（Google Pixel）のストレージ整理中に、  \nGoogle Map のストレージを誤って削除してしまったこと。\n\nバックアップ自体は ON にしていたのですが、昨日ストレージを削除したことで、  \n空っぽの状態が夜間バックアップで上書きされてしまった模様です。\n\n右上のクラウドアイコンから  \nバックアップ → 端末 → インポート  \nと進んでも、戻ってくるのは たった1日分のデータだけでした。\n\nあ〜...やらかしました。本当に悲しい。\n\nタイムラインの保存先がクラウドからデバイスへと仕様変更がありましたよね。  \n知ってましたが忘れてました..。  \n自動削除の設定はOFFにしていたけど、空データで上書きバックアップって...。\n\n数ヶ月前に一度だけ、タイムラインをエクスポートしたJSONファイルがあったのですが、  \nどうやら そのJSONファイルを Google Map へ再インポートする手段はないようです。\n\nさらに、Web版のタイムラインも既に提供終了しており、  \n強引な復元方法もなさそう...。\n\nエクスポートしたデータを見ると、2018年からの記録が残っていました。  \n**約7年分のタイムラインが消失**。","publishedAt":"2025-11-23","slug":"20251123","title":"Google Map の7年分のタイムラインデータが消えた"},{"body":"![メタセコイア並木](https://res.cloudinary.com/silverbirder/image/upload/v1763814987/silver-birder.github.io/blog/l6tazuodfzjuzavzq54j.jpg)\n\n今日は 11 月 22 日、いい夫婦の日。  \nそして、私たちの **5 年目の結婚記念日**です。\n\n今年は滋賀県に引っ越したこともあり、高島市マキノ町にある **メタセコイア並木**へ行ってきました。  \n滋賀県ではとても有名な景勝地で、メタセコイアの紅葉が見事に色づき、まっすぐ伸びる並木と秋空のコントラストが美しい場所です。\n\nはじめて訪れたのですが、想像以上の渋滞に驚きました。  \n並木から車で 10 分ほど手前の地点からすでに渋滞が始まっていて、「こんなに人気なんだ…！」とびっくり。\n\n並木道には老若男女、そして海外の観光客まで、いろんな人たちが写真を撮りながらゆっくり歩いていて、  \n本当に賑やかで活気ある雰囲気でした。\n\n私たちは南側の駐車場に車を停め、そこから北側の駐車場まで歩き、途中のカフェに寄って休憩しながら散策。  \nそのあと南側まで戻って、並木を抜けた先の少し離れたカフェまでまた歩いて行き、最終的に南側へ帰ってくる、という感じでかなりしっかり歩きました。\n\n歩いている間、見上げれば黄色やオレンジに染まった紅葉、そして頭上には雲ひとつない青空。  \nさらに西側の山々を見ると、赤・オレンジ・茶色が混ざり合った綺麗な景色が広がっていました。\n\n![山の景色](https://res.cloudinary.com/silverbirder/image/upload/v1763815409/silver-birder.github.io/blog/kmryvhuua4yxpvbsj3kn.jpg)\n\nカフェはどこも混んでいて、10～20 分ほど並ぶことが多かったです。  \n並木の近くには乗馬している人もいて、「こんなところで馬が見られるのか！」とちょっと驚きました。\n\n道路上で車が途切れた瞬間を狙って、並木のど真ん中で写真を撮っている人もいて、少し危ないな…とは思いつつ、  \nみんな同じ景色に心を動かされて来ているんだよなぁ、とも感じました。\n\n![メタセコイア並木](https://res.cloudinary.com/silverbirder/image/upload/v1763815408/silver-birder.github.io/blog/fnjten82ixpjbdhxeail.jpg)\n\n---\n\n毎年、結婚記念日には “これまでしたことがないこと” や “少し贅沢なこと” を選んで過ごしています。  \n3 ヶ月ほど前から「今年はどこに行こうか」と話しながら、その日を楽しみに待つのが恒例です。\n\n妻のテンションが上がると、普段よりよくしゃべり、前を歩いて「あれもこれも」と興味の赴くままに動き回ります。  \nその姿を見ると、「来た甲斐あったな」と心から思います。\n\n記念日だけでなく、なんでもない休日でも、こうした“共有できる経験”をもっと増やしていきたい——  \nそんな気持ちが強くなった一日でした。","publishedAt":"2025-11-22","slug":"20251122","title":"5年目の結婚記念日"},{"body":"先日発生した Cloudflare の障害について、以下の公式ブログにレポートが公開されていました。\n\n- https://blog.cloudflare.com/ja-jp/18-november-2025-outage\n\n内容としては、ボット対策用のフィーチャーファイルが誤って肥大化し、  \nプロキシがクラッシュしたことで Cloudflare 全体に影響が広がった、というものでした。\n\n## 障害レポートの上にあった UI\n\nこのレポートページを読んでいて気づいたのが、**スクロール量に応じて上部の細いバーが伸びていく UI** です。\n\n![進捗バー](https://res.cloudinary.com/silverbirder/image/upload/v1763727078/silver-birder.github.io/blog/d5q03u9ljzj8anmlgbkz.png)\n\n昔からたまに見る UI ですが、読み物系の記事との相性が本当に良いですね。  \n**「自分がどこまで読んだのか」** がひと目でわかるので、ブログにも付けたくなりました。\n\n## サンプルコード\n\n必要なのは、進捗バー用の要素を 1 つ置くだけです。\n\n```html\n<div class=\"progress\"></div>\n```\n\nCSS はこれだけ。\n\n```css\n.progress {\n  position: fixed;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 3px;\n  background: #3f434f;\n\n  transform-origin: 0 0;\n  animation: progress linear;\n  animation-timeline: scroll();\n}\n\n@keyframes progress {\n  from { scale: 0 1; }\n  to   { scale: 1 1; }\n}\n```\n\nたった数行ですが、Cloudflare のレポートページのような  \n**スクロール量に連動して伸びる進捗バー** が簡単に作れます。\n\n`animation-timeline`、想像以上に便利ですね。\n\n### 対応ブラウザについて\n\nただし現状、`animation-timeline` は **Firefox が未対応** のようです。\n\n- https://caniuse.com/?search=animation-timeline\n\nChrome・Safari・Edge では動作するので、必要に応じて採用判断すると良さそうです。\n\n## 終わりに\n\nいつもお世話になっている Cloudflare、これからも応援しています！","publishedAt":"2025-11-21","slug":"20251121","title":"Cloudflareの障害レポートの上"},{"body":"私が住んでいる市では、ごみの分別がとても細かい。  \n市指定のごみ袋を使わないと回収されず、分類ルールも厳密だ。\n\n以前住んでいた UR 団地では、住んでいる棟1階近くにある収集場所に  \n分類用の箱が置かれていて、瓶・段ボール・缶をそこへ分けて入れるだけでよかった。  \nまた別の地域では、家の前の電柱付近にごみ袋を置くだけの運用で、  \nプラごみの分別すら不要という大雑把なところもあった。\n\n今住んでいる自治体はその真逆で、  \nごみの種類を検索できる「ごみ分別辞典アプリ」まで公開しているほど熱心だ。  \n可燃ごみとプラごみにはだいぶ慣れたものの、  \n不燃ごみや資源ごみは、今でもアプリ片手に一つずつ調べている。\n\nたとえば、 **飲み薬用の薬瓶は「資源ごみ」** だが、  \n**飲み薬以外の薬瓶は「不燃ごみ」** 扱いになる。\n\n## 資源ごみと不燃ごみの違い\n\n**資源ごみ**とは、ペットボトル、缶、びん、紙類（新聞・段ボール・雑誌など）、  \nプラスチック製容器包装、古布など、再資源化できるものの総称だ。  \n回収後は、新しい製品の原料やエネルギー源としてリサイクルされる。\n\n一方、**不燃ごみ**は焼却施設で燃やせないごみで、  \n金属、陶磁器、ガラス製品、小型家電、乾電池、ライターなどが該当する。  \nただし、細かいルールは自治体ごとに異なるため、地域のガイドに従う必要がある。\n\n飲み薬用の薬瓶が資源ごみになるのは、洗浄すれば安全に再利用できるからだろう。  \n逆に薬品が付着していた可能性のある薬瓶は、安全性の観点から不燃ごみになるのだと思う。\n\n金属がついたベルトは不燃ごみで、金属のない布製ベルトは可燃ごみ、というような細かな違いもある。\n\n## 日常の分別あれこれ\n\n牛乳パック、発泡スチロール、段ボール、ペットボトル、缶などは、  \nよく行くスーパーに設置されている回収コーナーへ持って行っている。これらは資源ごみだ。\n\n乾電池は家電量販店で回収していると思っていたが置いておらず、  \n結局は自治体の回収ボックスへ持参することになった。これも資源ごみに分類される。\n\nスプレー缶は、穴を開けてから資源ごみへ出す。リサイクルのための手順だ。  \nこれは昔からしていたよ。\n\n## プラスチックごみは特に複雑\n\n資源ごみの中でも、**プラスチック製容器包装**は特にややこしい。  \n汚れが落とせないものはリサイクルできないため可燃ごみ、  \nバケツや油容器など、分解しづらい硬いプラスチックは不燃ごみになるようだ。\n\n## ごみ分別で変わったこと\n\n今の地域で暮らしてから、「これはどのごみになるんだ？」と考えることが大幅に増えた。  \nその影響で、自然と“捨てやすい素材”の製品を選ぶようになった。\n\nというのも、今住んでいるマンションでは**可燃ごみとプラスチックごみだけが敷地内で捨てられる**。  \nそれ以外の資源ごみや不燃ごみは、徒歩10分ほど離れた自治体の回収所まで朝 8:30 までに持って行く必要がある。  \nしかも現地では回収担当のおじいさんが、種類を間違えていないか一つずつ確認してくれる。\n\nこの一連の手間がなかなか大きく、結果として、  \nできるだけ可燃ごみかプラごみとして捨てられる製品を選ぶようになってきた。","publishedAt":"2025-11-20","slug":"20251120","title":"不燃ごみと資源ごみ"},{"body":"昔、引越し先を探していたとき、気になる賃貸物件を6件ほど見つけ、不動産会社へ問い合わせをしました。  \n希望している設備や周辺環境を満たした物件ばかりで、あとは細かな条件次第という状況でした。\n\n問い合わせ自体はメールで完結します。  \n住宅情報サービスから問い合わせると、不動産会社から\n\n> 「◯◯物件のお問い合わせありがとうございます。内覧をご希望の場合は候補日をお知らせください」\n\nといった返信が届きます。\n\nですが、私は現住所から引越し先までの距離がかなり遠かったため、内覧は1日に3件ほどに絞りたく、慎重に進めていました。  \nそこで、内覧前に「洗濯機やエアコンの設置面積を知りたい」と質問していたのですが、\n\n- まだ入居中で確認できない\n- 内覧時に見てほしい\n- オーナーに聞かないとわからない\n\nといった回答が多く、判断材料が不足していました。\n\nそんなとき、ある不動産会社からこんな返事が届きました。\n\n> 「今から物件を見てきますので、後ほど写真と寸法をお送りしますね」\n\n空室だったこともあり、その方はすぐに現地へ向かい、  \n洗濯機置き場・エアコン設置場所の写真、手書きの寸法、ホースの取り回しの注意点まで丁寧に送ってくれました。\n\nもともと条件はどこも大きく変わらず、決め手に迷っていたのですが、  \n\n## この一件で心が決まりました\n\n心理学でいう「返報性の原理」に近いのかもしれませんが、  \nそれ以上に “相手の親切さや熱量” を感じて、そこに動かされたのだと思います。\n\n---\n\n好きなものについて情熱を持って語る人の言葉は、不思議とすっと心に入ってきます。  \nただ情報を並べるだけではなく、その人の「熱」が伝わってくるからです。\n\n逆に、自分が誰かに動いてほしいときも同じだと思います。  \n理由や背景を整理し、なぜそうしたいのか、自分の「熱」を込めて伝える。  \nそのほうが、きっと相手の心に届くはずです。","publishedAt":"2025-11-19","slug":"20251119","title":"結局は、人の熱に動かされる"},{"body":"以前、Andreas Kutschmann 氏が書いた「Design Token-Based UI Architecture」を読んだことがあります。  \n最近ふとその内容を思い出したので、あらためて自分の UI 設計の考え方と重ね合わせて整理してみました。\n\n## Design Token-Based UI Architecture とは\n\n原著では、UI を次の 3 種類のトークンで構築する考え方が紹介されています。\n\n1. Option Tokens  \n  — UI で利用可能なスタイルの選択肢そのものを定義するトークン\n1. Decision Tokens  \n  — Option Tokens の中から「文脈に応じてどのスタイルを使うか」を決めるトークン\n1. Component Tokens  \n  — Decision Tokens を参照し、「どのコンポーネントのどこにスタイルを適用するか」を定義するトークン\n\nデザイントークンをベースとして、コンポーネントのPropsもトークンで設計する感じです。\n例えば、Buttonだとvariantとして\"primary\"や\"secondary\"のようなインターフェースにする感じです。\n\n## 私なりの考え方：3 層構造で UI を整理する\n\n原著の考え方はとても理解しやすいのですが、実際のプロダクト開発で扱いやすい形に落とし込むと、  \n私は UI を以下の3層構造で整理するのが現実的だと感じています。\n\n1. デザイントークン層（最小単位の値）\n1. アトミックコンポーネント層（唯一トークンを直接参照する層）\n1. ドメインコンポーネント層（アプリ固有 UI）\n\n## 1. デザイントークン層\n\nUI の「最小単位の値」を定義する層です。\n\n- 色（プリミティブ / セマンティック）\n- スペーシング\n- 角丸（radius）\n- タイポグラフィ\n- 影・エレベーション\n\nこれらは **Figma のバリアブルを Single Source of Truth** として扱います。\n\nTokens Studio を使うと、\n\n- トークンを JSON として抽出\n- GitHub に PR を自動生成\n- フロント側では CSS 変数として利用\n\nというワークフローを組むこともできるはずです。（昔作った記憶あるけど忘れました）\n\n## 2. アトミックコンポーネント層（Component Tokens に相当）\n\nデザイントークンを **唯一直接参照する UI コンポーネント層** です。\n\n例：\n\n- Button / TextField / Select\n- Heading / Text\n- Flex / Grid / Box / Container\n\n使用側は生のトークン値に触れず、抽象化された API で UI を構築します。\n\n```tsx\n// OK（抽象化された API を利用）\n<Button size=\"md\" variant=\"primary\" />\n<Flex gap=\"sm\" bg=\"primary\" />\n\n// NG（トークンの生値を直接使用している）\n<Button padding=\"16px\" bg=\"#0070f3\" />\n<Flex gap=\"4px\" bg=\"#0070f3\" />\n```\n\n### なぜ抽象化するのか\n\n- `\"16px\"` のような生値ではなく、`sm / md / lg` のような意味単位で扱える\n- トークン変更時の影響範囲を **この層に閉じ込める** ことができる\n- Figma の Variant と揃えやすく、MCP との連携も自然\n- 利用側が「どの値を使うべきか」を迷わなくなる\n\n**内部はトークン、外部は抽象化された API** という設計が理想です。\n\n## 3. ドメインコンポーネント層（アプリ固有 UI）\n\nアトミックコンポーネントを組み合わせて構築する、プロダクト固有の UI 層です。\n\n例：\n\n- ShopItemCard  \n- UserProfile  \n- CheckoutForm  \n\n特徴は **デザイントークンに直接アクセスしない** という点で、これをルールとして強制します。\n\n## この構造がもたらすメリット\n\n3 層に分けることで、UI のトークンのデータフローは一方向になります。\n\n```text\nFigma → デザイントークン → アトミックコンポーネント → ドメインコンポーネント\n```\n\nこの構造により、\n\n- トークン変更の影響範囲が予測しやすい\n- VRT / Playwright で UI 差分を検出しやすい\n- UI の一貫性が自然と保たれる\n- デザイナーとエンジニアの連携が取りやすい\n\nというメリットが得られます。\n\n## 私ならどう構築するか（現実的な選択肢）\n\n## 案 A: Chakra UI に 1〜2 層を任せる\n\n- Variant ベースの設計が強力\n- ただし emotion 採用が気になる場合は注意\n\n## 案 B: tailwind + shadcn + 自作アトミックコンポーネント\n\n- emotion を使わずに済む構成\n- Layout / Typography などの基礎部分だけ自作する運用が現実的\n\n## 終わりに\n\nこの記事を書こうと思った理由は、個人開発で tailwind + shadcn を使って UI を作っているうちに、  \n**className で直接ユーティリティを大量に書けてしまう環境** によって、  \n「どのスタイルを使うべきか」という一貫性が少しずつ失われている気がしたためです。  \nそこで、上記の考え方を試験的に試してます。","publishedAt":"2025-11-18","slug":"20251118","title":"Design Token-Based UI Architecture"},{"body":"Gherkin（ガーキン）は、自然言語に近い構文でシステムの振る舞いを記述できる言語です。  \n主にビヘイビア駆動開発（BDD）のテストを書く際に使用され、Cucumber などのフレームワークと組み合わせて利用されます。\n\n本記事では、Cucumber における Gherkin の特徴と、Markdown で Gherkin を書く方法について紹介します。\n\nまずは、Gherkin の `.feature` ファイルで書かれた例を見てみましょう。\n\n```feature\nFeature: Staying alive\n  This feature describes how to stay alive,\n  not the Bee Gees song.\n\n  Rule: Eating keeps you alive\n    @important @essential\n    Scenario Outline: Eating cucumbers\n      Given I have <start> cucumbers\n      When I eat <eat> cucumbers\n      Then I should have <left> cucumbers left\n\n      Examples:\n        | start | eat | left |\n        |   12  |  5  |   7  |\n        |   20  |  5  |  15  |\n```\n\nこのシナリオを動かすステップ定義は、Cucumber を使うと次のように書けます。\n\n```js\nconst assert = require('assert')\nconst { Given, When, Then } = require('@cucumber/cucumber')\n\nGiven('I have {int} cucumbers', function (start) {\n  this.cucumbers = start\n})\n\nWhen('I eat {int} cucumbers', function (eat) {\n  this.cucumbers -= eat\n})\n\nThen('I should have {int} cucumbers left', function (expectedLeft) {\n  assert.strictEqual(this.cucumbers, expectedLeft)\n})\n```\n\nCucumber の Gherkin は **70 を超える自然言語をサポート**しており、次のリンクから確認できます。\n\n- https://cucumber.io/docs/gherkin/reference/#spoken-languages\n- https://github.com/cucumber/gherkin/blob/main/objective-c/GherkinLanguages/gherkin-languages.json\n\nそのため、プログラマ以外のメンバー、例えばプロダクトオーナーや QA でも、Gherkin のシナリオを仕様として読み取れるという利点があります。\n\nE2E テストを BDD として扱い、ユーザー目線の「フィーチャー」として表現できるほか、  \n受け入れテスト駆動開発（ATDD）にも利用でき、プロダクトオーナーとプログラマの合意形成に役立ちます。\n\n仕様を Gherkin で統一して書くことで、**仕様がそのままテストコードとして管理できる**点も魅力です。\n\n## Markdown でも Gherkin が書ける\n\n通常、Gherkin は `.feature` ファイルに記述しますが、実は **Markdown でも Gherkin を書くことができます**。\n\n- https://github.com/cucumber/gherkin/blob/main/MARKDOWN_WITH_GHERKIN.md\n\nMarkdown で Gherkin を書くメリットは次のとおりです。\n\n- 画像・リンクなど、Markdown の装飾が利用できる\n- ドキュメントやナレッジツールに統合しやすい\n- 表示が美しく読みやすい\n- 仕様書とテスト仕様を一体として扱いやすい\n\n以下は、先ほどの `.feature` ファイルを Markdown Gherkin に書き換えた例です。\n\n```markdown\n## Feature: Staying alive\n\nThis feature describes how to stay alive,\nnot the Bee Gees song.\n\n## Rule: Eating keeps you alive\n\n`@important` `@essential`\n### Scenario Outline: Eating cucumbers\n\n* Given I have <start> cucumbers\n* When I eat <eat> cucumbers\n* Then I should have <left> cucumbers left\n\n#### Examples\n\n  | start | eat | left |\n  | ----- | --- | ---- |\n  |   12  |  5  |   7  |\n  |   20  |  5  |  15  |\n```\n\nMarkdown で書くと、**Feature セクションに画像を追加したり、補足リンクを挿入したりといった拡張が簡単です**。\n\nまた、日本語でも同じように記述できます。\n\n```markdown\n## フィーチャー: 生き延びる\n\n実際に「生き延びる」ための方法について説明します。\nBee Gees の曲の話ではありません。\n\n## ルール: 食べないと生きられない\n\n`@important` `@essential`\n### シナリオアウトライン: きゅうりを食べる\n\n* 前提 きゅうりを <start> 本持っている\n* もし <eat> 本食べた\n* ならば <left> 本残っているはず\n\n#### 例\n\n  | start | eat | left |\n  | ----- | --- | ---- |\n  |   12  |  5  |   7  |\n  |   20  |  5  |  15  |\n```\n\nこのように、Markdown でも読みやすく自然な形で Gherkin を記述できるため、  \n仕様書・設計資料としても扱いやすくなります。\n\n## 終わりに\n\nCucumber を利用しているプロジェクトはそこまで多くないかもしれませんが、  \nGherkin を Markdown で書けるというのは非常に便利な仕組みです。  \n仕様とテストを一体として管理したい場合には特に役立つため、ぜひ参考にしてみてください。","publishedAt":"2025-11-17","slug":"20251117","title":"GherkinにMarkdownがサポートされている"},{"body":"久々に Google Drive のフォルダを整理していたところ、学生時代に作った Web アプリの資料が見つかりました。  \n開発したのは **2016年、今から9年前**。  \n当時の自分の技術スタックや開発の進め方を思い出しながら、ちょっと懐かしく振り返ってみます。\n\n## 当時作っていた Web アプリ\n\n私が作っていたのは、**動画をアップロードしてコマ画像を抽出し、好きなコマを選んで並び替え Gif 画像に変換するアプリ** です。  \n生成した Gif は掲示板に投稿でき、コメントもつけられるという、シンプルながら機能が詰まったサービスでした。\n\n![トップページ](https://res.cloudinary.com/silverbirder/image/upload/v1763296187/silver-birder.github.io/blog/em59va9jelbttvtq8soo.png)\n\n![Gif画像掲示板](https://res.cloudinary.com/silverbirder/image/upload/v1763296188/silver-birder.github.io/blog/s1spgaj8xmfazjl2aih7.png)\n\nGif 作成まわりのフローはこんな感じでした。\n\n![Gif作成 - 動画アップロード中](https://res.cloudinary.com/silverbirder/image/upload/v1763296189/silver-birder.github.io/blog/kcblm9rzxfecmlmn2fz5.png)\n\n![Gif作成 - 動画から画像を抽出](https://res.cloudinary.com/silverbirder/image/upload/v1763296190/silver-birder.github.io/blog/bercvw7wjr1llzcmdlwt.png)\n\n![Gif作成 - 画像を並び替えてGifに変換](https://res.cloudinary.com/silverbirder/image/upload/v1763296190/silver-birder.github.io/blog/des0a3rvohgf4sxzgrbg.png)\n\n当時はもちろん Figma も触っておらず、Web デザインはすべて手書きの HTML と CSS。  \nインタラクティブな部分は jQuery、ビューは EJS を使っていました。\n\n## 使用していた技術\n\n- サーバサイド: Node.js + Express v3.5.1\n- ビュー: EJS\n- フロント: jQuery\n- データベース: MongoDB\n- ストレージ: Dropbox\n- 動画 → Gif 変換: ffmpeg\n- 一時ファイル削除: cron\n\nS3 を使う発想はなく、Dropbox に動画や分割した画像を保存していました。\n抽出した画像を ffmpeg で Gif に変換するフローは、いま思えばよく組めていたなと感じます。\n\n## 学生時代の開発環境\n\n当時の開発環境もなかなか味わい深いものでした。\n\n- サーバー: さくらのレンタルサーバ\n- バージョン管理: Git なし（フォルダにそのまま保存）\n- コードアップロード: WinSCP\n- SSH 接続: たぶん TeraTerm\n- デプロイ: SSH 接続 → `npm install` → `express start`\n- アクセス: IP アドレス + Express のデフォルトポートに直アクセス\n\nいまのように AWS や Vercel が当たり前の時代ではなかったので、この運用でも特に疑問を持たず使っていました。\n\n## 資料（2016年当時の画面設計・構成図など）\n\n画面構成やシステム構成は、Microsoft Visio を使って作成していました。  \nUI デザインツールを持っていなかったので、Visio の図形を組み合わせてポンチ絵を作っていた記憶があります。\n\n![画面構成](https://res.cloudinary.com/silverbirder/image/upload/v1763296185/silver-birder.github.io/blog/axypr0poguogwqgjn4uw.jpg)\n\n![システム構成](https://res.cloudinary.com/silverbirder/image/upload/v1763296186/silver-birder.github.io/blog/dwcfevei1zdn9i6kr186.jpg)\n\n## 当時読んでいた本\n\n当時の私は、大学では C 言語や Java を学んでおり、Web 系の開発経験はほぼゼロでした。  \n友人に「今は Node.js が流行っているらしい」と聞き、手探りで買ったのがこの本でした。  \nなんとなく、やってみたい!という気持ちだけで購入した記憶があります。\n\n- [はじめてのNode.js - サーバーサイドJavaScriptでWebアプリを開発する](https://www.amazon.co.jp/dp/4797370904)\n\n当時の知識は IT パスポート程度で、\n\n- ターミナル操作は初めて\n- Node.js や Express のバージョンが書籍と手元で違うことを理解していない\n- HTML/CSS を写経したことがある程度\n- サーバ、データベース、ストレージの概念がほぼゼロ\n\nという状態でした。\n\nそれでも本を何度も読み返し、エラーに何度もつまずきながら、少しずつ動く形に近づけていきました。  \n気づけば、表紙が擦り切れるほど読み込んでいた気がします。（たぶん1年以上）\n\n## 終わりに\n\n今では、AI に任せれば、それっぽい Web アプリが簡単に作れる時代です。  \nGit Push するだけで、自動的にデプロイまで完了させることもできます。\n\nそれでも、学生時代に身につけた **「エラーが起きたときに原因を探る洞察力」** や  \n**「分からない領域を少しずつ自分の理解に置き換えていく地道な作業」** は、今の自分にとって確かな財産になっています。","publishedAt":"2025-11-16","slug":"20251116","title":"9年前の学生の自分が作ったWebアプリを懐かしむ"},{"body":"きょう、はじめて行く大型ショッピングモールへ行ってきました。  \nかなり前から家の中で話題になっていた場所だったので、  \nお昼の14時過ぎにモールへ到着したときには気分は最高潮（笑）。\n\nその勢いのまま、**どこに車を停めたかをまったく覚えないまま**、一目散にモールへ入ってしまいました。\n\n店内では3階建てのモール内をくまなく巡り、服を買ったり、カバンを買ったり、美味しいご飯を食べたり。  \n満腹感と幸福感に包まれながら買い物を楽しんでいるうちに20時を過ぎ、そろそろ閉店時間。  \n帰宅しようとしたそのとき――問題が発生。\n\n## 「あれ……どこに車を停めたっけ？」\n\nはじめて来た場所。モールの外にはとにかく広い駐車場。  \n時間は20時過ぎで外は真っ暗。  \n満腹＋歩きすぎで足はもう疲れている。  \nたしかに1階に停めた記憶はあるものの、  \n\n## どの出入り口から出れば車の近くなのか、完全に思い出せない\n\n「入るとき何を見たっけ？」と必死に記憶をたどり、  \n消去法で出入り口を1つに絞り込み、  \nよし、この出口だ……！ とモールを出て車探しを開始。\n\nところが、駐車場には外灯がなく、車の影がまったく見えない。  \nそこで、鍵の開閉ボタンを押して、**ピカッと光る反応**を頼りに探す作戦に変更。  \n端から端まで歩きながら、ひたすらボタンを連打しているうちに、体感15分が経過。\n\nそして最終的には、ほぼしらみつぶしで探し続け、ようやく車を発見しました……。\n\nいや〜、これはなんとかしたい。  \n普段は停めた場所の写真を撮っていたり、行きつけなら “いつもの場所” があるので迷わないのですが、  \n\n## 初めての場所の駐車場、それも立体駐車場は本当に迷子になる\n\n平面でも、区画があちこちに分かれていると急に難易度が上がる。  \n階を間違えたり、出口を間違えたりしたら、まじで見つからない。\n\nみんな、こういうときどうしてるんだろう……？","publishedAt":"2025-11-15","slug":"20251115","title":"帰りの駐車場で、車が見つからない"},{"body":"AI に 10 分ほどで雑に作らせたのですが、金曜ロードショーで「どの月にどんな映画が多く放送されているか」を可視化してみました。\n\nhttps://friday-road-show.vercel.app\n\n## 月ごとに見える“傾向”\n\nいくつか面白い偏りがありました。\n\n- 7月\n  - 『となりのトトロ』『魔女の宅急便』が各 8 回\n  - 夏休みだから？\n- 8月\n  - 『火垂るの墓』が 11 回\n  - 終戦の日だから？\n- 11月\n  - 『アナと雪の女王』が 3 回\n- 12月\n  - 『ホーム・アローン』が 5 回\n  - 『ホーム・アローン2』が 2 回\n  - クリスマス映画の代表作だから？\n\nこの感じだと、今年も近いうちに『アナと雪の女王』や『ホーム・アローン』が放送されるかも？\n個人的には「千と千尋の神隠し」や「天空の城ラピュタ」が圧倒的に多いのかと思っていたのですが、実際に可視化してみると意外とそうでもなかったのが面白かったです。","publishedAt":"2025-11-14","slug":"20251114","title":"金曜ロードショー月別「よく放送される作品」ランキング"},{"body":"我が家では、日用品や食品が切れたとき、  \n冷蔵庫に貼っているホワイトボードにメモを残す習慣があります。\n\n一人暮らしの頃は Amazon の定期便を使っていたため、在庫管理は比較的ラクでした。  \nしかし、妻と二人暮らしになってからは、次の理由で定期便をやめました。\n\n- 消費ペースのばらつきが大きい  \n- Amazon 定期便よりスーパーの方が安い商品が多い  \n- スーパーで新しい商品に出会える楽しさがある  \n\n現在は、歯磨き粉や生姜などがなくなったタイミングでホワイトボードにメモを書き、  \n買い物前にそれをスマホで撮影して、  \nスーパーではその写真を見ながら買い物をしています。  \nお店を回る順番も、この写真をもとに考えることが多いです。\n\nただ、この「写真を撮る」という作業が、だんだん面倒になってきました。  \n買い物メモを覚えるのは脳トレとして悪くありませんが、  \n今日の歯磨きに使う歯磨き粉を買い忘れるのは致命的なので、できれば避けたいところです。\n\nもっとラクに、そしてコスパよく解決したいのですが、  \n冷蔵庫を“中身が見えるタイプ”に買い替えるのは現実的ではありません。\n\n思いついた案としては、次の3つです。\n\n## 1つ目：タブレットをホワイトボード代わりにする方法\n\niPad などのタブレットを冷蔵庫に取り付け、Wi-Fi 接続した状態でペン入力し、  \nそのメモをスマホから閲覧できるようにすれば、写真を撮る必要がなくなります。  \n個人的には、これを推しています。\n\n## 2つ目：ホワイトボードを小型カメラで常時撮影する方法\n\nホワイトボードを映す小型カメラを設置し、  \n外出先から映像を確認できるようにすることで、写真を撮る手間をなくします。  \nただ、文字がカメラ越しで読めるのか怪しいです。\n\n## 3つ目：生活動線の中にホワイトボードを組み込む方法\n\n現在は、車の鍵を自分のカバンに収納していますが、  \nこれをあえてホワイトボードの近くに置くようにします。  \n今住んでいる地域では買い物はほぼ車移動なので、  \n鍵を取るタイミングでホワイトボードが目に入り、  \nその場でメモ内容を覚えよう！というものです。\n\nこのほかに、もっと良いアイデアがあれば知りたいです。","publishedAt":"2025-11-13","slug":"20251113","title":"冷蔵庫に貼っているホワイトボードをやめたい"},{"body":"2023年に新車を購入してから、もう2年ほど経ちました。  \n購入当時のエピソードは、[2023年の振り返り。家と車と私](https://silverbirder.github.io/blog/contents/2023_furikaeri/) にも書いています。\n\n今日、車を運転していて、駐車場に着いたときのことです。  \n\nパーキングブレーキをかけ、  \nシフトレバーを「P」に入れて停車したあと、  \n\n電源を切るためにブレーキペダルとエンジンスタートボタンを押そうとしたのですが、  \n間違えて**アクセルを踏んでしまいました**。  \n\nヒヤっとしました...。  \nニュースでよく見るあのパターンですよね、アクセルとブレーキを踏み間違える..。  \n本当に気を引き締めないと、と思いました。\n\nこの2年間で、2つほどヒヤッとしたことがありました。  \n忘れないように、ここに書き留めておきます。\n\n- ショッピングセンターに左折で入ろうとしたとき、左側から勢いよく自転車が飛び出してきて、あわてて急ブレーキを踏んだ。\n- 左車線に変更しようとしたとき、左後方近くに車がいて、危うく接触しそうになった。\n\nこうして振り返ると、自分の運転の未熟さを痛感します。  \nこれからも、より慎重に、安全運転を心がけていきたいと思います。","publishedAt":"2025-11-12","slug":"20251112","title":"車のヒヤリハット"},{"body":"なんでやねん！\n\nAIに指摘をしたとき、なんかモヤっとする。  \n「するどい指摘です！」とか言われると、褒められてるようでいて、どこかズレてる感じ。  \n反論しても不毛なので、冷静に淡々と指示を出そう。  \n「いい気づきです！」みたいな返しもあるけれど……ぬぬぬ。  \n\n最近よく見る文末がこれ。  \n\n> 「ご希望があれば、XXの方向やYYの方向で修正できます。どちらの方向に整えましょうか？」\n\nこれ、9割以上は希望していない方向が多い印象。  \nそういうときも、やっぱり冷静に淡々と指示を続けるのが吉。\n\nGitHub のプルリクエストで AI からのレビューコメントを見ていると、  \n\n> 「このコードは XX という点で問題があります。修正を推奨します。」\n\nといったコメントが出てくることがある。  \nでも実際は、問題ではないケースのほうが多い。  \nむしろ、提案された修正を適用するとバグることすらある。  \nなので、これらのコメントは“気持ち程度”に見るぐらいがちょうどいい。  \n（たまにドキッとするやつもありますが）","publishedAt":"2025-11-11","slug":"20251111","title":"AIに間違いを指摘したら「するどい指摘です！」と言われたときー"},{"body":"機能リクエスト投票サービス **fequest**（*feature request* の造語）を開発しています。  \nユーザー向けと管理者向けの 2 つの Web アプリを構築中です。\n開発中のコードは、以下のGitHubリポジトリで公開しています。\n\n- https://github.com/silverbirder/fequest\n\n## 開発方針\n\nこれまでは慣れたツールセットでスピード重視の開発を行っていましたが、今回は久しぶりに「試してみたい技術」を積極的に取り入れています。\n\n以前はツール導入に全力を注ぎすぎて、肝心のアプリが完成しないこともありました。  \nですが今は、AI のサポートによってセットアップが驚くほど簡単になったので、コーヒー片手に気楽に新しい技術を試しています。\n\n## フォルダ構成\n\n- apps\n  - user: ユーザー向け画面\n  - admin: 管理者向け画面\n- packages\n  - db: Drizzle で DB 管理\n  - eslint-config: ESLint 設定\n  - schema: Valibot スキーマ定義\n  - storybook: Storybook 設定\n  - typescript-config: TypeScript 設定\n  - ui: 共通 UI コンポーネント\n  - user-feature-xxx: ユーザー向けフィーチャー\n  - admin-feature-xxx: 管理者向けフィーチャー\n  - vitest-config: Vitest 設定\n\nモノリポ構成を採用し、モノレポツールには **turborepo** を利用しています。  \nさらに、UI コンポーネントやフィーチャーコードを自動生成するために `turborepo` のコード生成機能 **turbo gen** を使用しました。\n\n- [Generating code | Turborepo](https://turborepo.com/docs/guides/generating-code)\n\n## アプリケーションフレームワーク\n\nアプリケーションフレームワークは **Next.js 16** を採用しています。  \n巨人の肩には、もう少し乗っておきたいところです。\n\n- [Next.js 16 | Next.js](https://nextjs.org/blog/next-16)\n\nキャッシュコンポーネントはまだ使用していませんが、今後試してみたいと考えています。  \n「キャッシュ」という言葉には、どうしても少し抵抗があるんですよね……。\n\nNext.js の設定には、以下の 2 点を追加しています。\n\n1. **typedRoutes**\n    - `Link` の URL を型安全に扱える。\n    - 動的ルーティングでは `pathpida` が必要になるかもしれません。\n1. **reactCompiler**\n    - `useMemo` や `useCallback` を省略できる。\n    - 安定版として使えるようになっているようです(?)。\n\nまた、`PageProps` インターフェースが自動生成され、`params` や `searchParams` に型安全にアクセスできるようになっています。\n\n## API 通信\n\nAPI 通信には、慣れ親しんだ **tRPC** を採用しました。  \n本来は `packages/trpc` として切り出す予定でしたが、DB や認証との依存関係が複雑だったため、現在は `apps` 内に配置しています。\n\n- [tRPC | tRPC](https://trpc.io/docs/)\n\n## Lint / TypeScript 設定\n\n`eslint-config` と `typescript-config` は、`turborepo` の `create-turbo` テンプレート由来で、そのまま利用しています。\n\n- [Next.js | Turborepo](https://turborepo.com/docs/guides/frameworks/nextjs)\n\n## Schema\n\nバリデーションスキーマには **Valibot** を採用しました。  \n普段は **Zod** を使っていますが、Valibot は後発のスキーマバリデーションライブラリなので、試しに導入してみました。  \n軽量だと言われていますが、実際のところは未確認です。\n\n## Storybook\n\n**Storybook v10** を使用し、フレームワークには `@storybook/nextjs-vite` を採用しています。  \n現時点では CSF 3 形式を継続使用中です。\n\nv8.5 で Story にタグを付けてフィルタリングできる機能が追加され、v10 ではさらに「除外」もサポートされました。  \nこれまでタグ機能をあまり意識していなかったので、今回知る良いきっかけになりました。\n\n- [Storybook 10](https://storybook.js.org/blog/storybook-10/)\n\n## Vitest と VRT\n\n**Vitest v4** を導入し、Storybook と連携したスナップショットテストを実行しています。  \n`Story` の `play` 関数にテストを書くのは少し抵抗があるため、現在は描画確認レベルのシンプルなテストにとどめています。\n\n- [Vitest 4.0 is out! | Vitest](https://vitest.dev/blog/vitest-4)\n\nさらに、`@storycap-testrun/browser` を導入し、Storybook のテストランナー実行時に各 `Story` の **VRT (Visual Regression Test)** を自動実行するようにしました。  \n当初は Vitest や Storybook の公式機能で対応を試みましたが、うまく動作しなかったため、以下のアドオンを使わさせて貰いました。\n\n- [@storycap-testrun/browser | Storybook integrations](https://storybook.js.org/addons/@storycap-testrun/browser)\n\n`vitest-config` では **Browser Mode** の設定を行い、`jsdom` ではなく **Playwright** を利用した実 DOM テストを可能にしています。\n\n- [Browser Mode | Guide | Vitest](https://vitest.dev/guide/browser/)\n\nこれにより、`await expect.element(el).toMatchScreenshot();` のような要素単位の VRT も実行できます。  \n現状では Story 単位の VRT で十分ですが、テストケースによっては使い分けも検討しています。\n\n## UI 構成\n\n`ui` パッケージでは **Tailwind CSS** をデザイントークンとして使用し、**shadcn/ui** をベースに共通 UI コンポーネントを構築しています。\n\nレイアウトコンポーネントは **Chakra UI** の思想を参考に自作しました。  \n以下のようなレイアウト系コンポーネントを用意しています。\n\n- `Box`\n- `Center`\n- `Container`\n- `VStack`\n- `HStack`\n- `Flex`\n- `Grid`\n\nまた、テキスト用の `Text` コンポーネントや、見出し用の `Heading` コンポーネントも定義しています。\n\nCSS を書くのは好きなのですが、Tailwind を採用している以上、トークンベースで統一した方が保守性が高いため、スタイルはすべて Tailwind で管理しています。\n\nこのように、  \n\n## デザイントークン → 共通コンポーネント／レイアウト → ドメインレベルのコンポーネント\n\nという階層構造で UI を組み立てています。\n\nデザイントークンをベースに、共通コンポーネントやレイアウトを使用しているため、基本的に `tailwind` の `className` はこのレイヤーまでで完結します。\n\nドメインレベルのコンポーネントでは、共通コンポーネントやレイアウトの `variant` を利用してスタイルを調整するため、直接 `className` を指定することは原則ありません。\n\n全体としては、**Design Token-Based UI Architecture** の考え方を意識し、**Option tokens → Decision tokens → Component tokens** の三層構成でデザインを整理しています。\n\n- [Design Token-Based UI Architecture](https://martinfowler.com/articles/design-token-based-ui-architecture.html)","publishedAt":"2025-11-10","slug":"20251110","title":"モダンな(?)フロントエンド技術セット"},{"body":"個人開発アプリのWebデザインを考える際に、Figma Makeを使って壁打ちしてみました。  \nこれまではVercelのv0を利用していましたが、無料プランの利用制限に引っかかってしまったため、代わりとなるAIデザインツールを探していました。\n\n最初に思い出したのはGoogle LabsのStitchでしたが、レスポンス速度やデザイン精度、調整の自由度が今ひとつだったため見送りました。  \nそこで、以前少し触ったことのあるFigma Makeを再び試してみることにしました。\n\nFigma Makeは、Figmaプラットフォーム上のツールだけあって、Figmaとの相性がとても良いです。  \nテキスト指示によるデザイン生成に加え、shadcnベースのコード生成や、Figmaデータのエクスポートにも対応しています。  \nさらに、既存のFigmaデータをインポートして活用できる点も魅力的です。\n\n特に良かったのは、Figma Makeで生成したデザインをFigmaにエクスポートし、気になる箇所だけをコピーして再度Figma Makeに貼り付けることで、部分的な改善提案を得られることです。  \nデザイン全体を作り直すことなく、ピンポイントで修正できるのは便利でした。\n\nv0とFigma Makeはいずれも、デザイン修正依頼やコンテキストの注入といった点で似ていますが、**「Figmaとの連携」という明確な差別化ポイント**がFigma Makeの魅力だと思います。\n\nただし注意点として、FigmaのStarterプランでは利用できる機能がかなり限られます。  \n途中で行き詰まることもあるため、継続的に使う場合はProfessionalプランなどの課金を検討したほうが良いでしょう。","publishedAt":"2025-11-09","slug":"20251109","title":"Figma Make を使ってみた"},{"body":"Thoughtworks の **Technology Radar Vol. 33** が公開されました。  \n\n- [Technology Radar | Guide to technology landscape | Thoughtworks](https://www.thoughtworks.com/radar)\n\n今回は、流し読みして気になったトピックについての感想をまとめます。  \n\n### AI 関連の話題が多い\n\n今回の Radar では、AI に関するテーマが多く取り上げられていました。\n「仕様駆動開発」や「AI によるブラウザ操作（playwright-mcp）」、「AGENT.md による AI コーディングエージェントへの指示フォーマット」などがありました。  \n\n### spec-driven development\n\n- [spec-driven development | Technology Radar | Thoughtworks](https://www.thoughtworks.com/radar/techniques/spec-driven-development)\n\nレガシーシステムのモダナイゼーションにおいて、仕様駆動開発は相性が良いのかもしれません。  \n既存システムの仕様を再整理し、その仕様をもとに再構築を行うというアプローチです。  \nリバースエンジニアリングのあとに、フォワードエンジニアリング（はじめて知りました）を行う流れですね。  \n\n仕様駆動開発は、UI・UX の設計では難しいのかな？という所感です。  \n一方で、バックエンド寄りのシステマチックな領域では、比較的取り入れやすいのかもしれません。  \n\n以前、VS Code で GitHub Copilot の新機能として「Plan モード」が発表されていました。  \n\n- [VS Code、Copilot が仕様作成を支援する「Plan モード」が追加 － Publickey](https://www.publickey1.jp/blog/25/vs_codecopilotplan.html)\n\n[spec-kit](https://github.com/github/spec-kit) を試してみたことがあるのですが、使いこなせませんでした。  \n今度こそ、もう少し丁寧に触ってみようかなと思います。  \n\n### Complacency with AI-generated code\n\n- [Complacency with AI-generated code | Technology Radar | Thoughtworks](https://www.thoughtworks.com/radar/techniques/complacency-with-ai-generated-code)\n\n「AI にコードを書かせて満足してしまう」という指摘。\nこれは非常によくわかります。\nAI コーディングエージェントを使っていると、たくさんのコードが生まれていきます。\n追加・削除・変更といったコードチャーンが多いと、レビューする側が大変になりますね。\nしかも重複コードが増えたり、リファクタリングが必要になったりと、苦労した経験があります。  \n\n### AI-accelerated shadow IT\n\n- [AI-accelerated shadow IT | Technology Radar | Thoughtworks](https://www.thoughtworks.com/radar/techniques/ai-accelerated-shadow-it)\n\n「シャドー IT」という言葉を今回初めて知りました。\n企業が正式に許可していない IT ツールやアプリを、従業員が独自に利用することを指すようです。  \n\nノーコードやバイブコーディングが普及したことで、エンジニアでなくてもアプリを作れる時代になりました。\nその結果、簡単な社内アプリが次々に生まれ、統制が効かないシステムが増えるリスクも高まっているようです。  \n\n### TCR (Test && Commit || Revert)\n\n- [TCR (Test && Commit || Revert) | Technology Radar | Thoughtworks](https://www.thoughtworks.com/radar/techniques/tcr-test-commit-revert)\n- [test && commit || revert | Medium (Kent Beck)](https://medium.com/@kentbeck_7670/test-commit-revert-870bbd756864)\n\nテスト駆動開発の文脈で、テストが成功するたびにコミットし、失敗した場合はリバートするというアイデアです。  \n常にテストが成功している状態を維持しながら、小さく確実にコミットを積み重ねる開発スタイルのようです。  \n\n現代のモダンな開発現場であれば、CI/CD が整備されており、テストが失敗すればマージされない仕組みが一般的です。\nTCR のアプローチは、途中経過のコミットもきれいに保てる点が魅力的だと思いました。\n私自身も、基本的にこのスタイルに近い形で開発しています。  \n\n### oRPC\n\n- [oRPC | Technology Radar | Thoughtworks](https://www.thoughtworks.com/radar/tools/orpc)\n\n普段 tRPC をよく使っていますが、oRPC はその後発のようです。\nより洗練された記法を採用しており、**OpenAPI との統合を公式サポート**している点が特徴的です。  \n\n現時点では tRPC で十分と感じていますが、  \n将来的に OpenAPI との連携が必要になった際には、検討してみたいと思いました。","publishedAt":"2025-11-08","slug":"20251108","title":"Technology Radar Vol. 33 所感"},{"body":"仕事で依頼されたことを期日どおりに対応するのは、プロとして当然のことです。  \nただ、そこに少しだけプラスの工夫を加えると、相手にぐっと喜んでもらえることがあります。  \n私は、依頼された内容に「+α」を添えることを意識しています。\n\nたとえばプログラムの実装なら、仕様どおりに仕上げたあとで、軽くリファクタリングしたり、小さなUX改善を加えたりすると、期待以上の反応をもらえることがあります。\n\n資料を集める仕事でも同じです。  \n単に資料をそろえるだけでなく、CSVならファイル名を規則的に整えたり、補足情報をメモにまとめたりするだけでも、相手の手間を減らせます。\n\nこうした「ちょっとしたプラス」は、すぐに成果として見えにくいものの、一緒に働く仲間との**信頼貯金**を少しずつ増やしてくれるものです。\n\n依頼された内容に、もうひとつプラスを。  \nその小さな工夫が、仕事をもっと気持ちのいいものにしてくれます。","publishedAt":"2025-11-07","slug":"20251107","title":"仕事にちょっとプラスすると良い感じ"},{"body":"AIが生成するコードは、必ずレビューしましょう。  \nこの記事では、**AIが生成したCSSをレビューする際の7つのポイント**を紹介します。  \nCSSのレビューをする際に参考にしてください。\n\n## 1. 不要なプロパティが含まれていないか\n\n生成されたCSSには、必要のないプロパティが追加されることがあります。  \nよくあるのが `box-sizing: border-box` です。  \nこれらは多くの場合、**グローバルCSS** などで定義済みです。\n\nNG例\n\n```css\n.card {\n  box-sizing: border-box; /* グローバルで定義済み */\n  padding: 16px;\n  border-radius: 8px;\n}\n```\n\nOK例\n\n```css\n.card {\n  padding: var(--space-md);\n  border-radius: var(--radius-md);\n}\n```\n\n意味を理解せずに残してしまうと、**冗長で保守性の低いCSS** になります。  \n削除してもデザインが崩れないなら、思い切って消しましょう。  \n意図がある場合は、そのまま残しても構いません。\n\n## 2. セレクタ名が適切か\n\nTailwind CSS を使っていれば気にしなくてよい部分ですが、AIがCSSファイルを生成する場合、**セレクタ名** も確認しましょう。\n\n- プロジェクト内の命名規則に沿っているか？\n- 意味が曖昧な名前（例: `.main-style`）になっていないか？\n\nNG例\n\n```css\n.productCardHighlight { ... } /* ドメインに依存しすぎ */\n```\n\nOK例\n\n```css\n.card { ... } /* 見た目の特徴を表す */\n```\n\nドメイン固有の語（例: “product”, “user”）を混ぜると、将来的に仕様変更が入った際、セレクタ名の修正が必要になります。  \nデザイン的な特徴を表した名前にしましょう。\n\n## 3. データ可変・レスポンシブ対応を確認しよう\n\nAIは「静的な状態」を前提にコードを出力します。  \nしかし実際のWebページでは、**テキスト量や要素数が変化**します。\n\n- タイトルが2行になったら崩れないか？\n- リストアイテムが10個になってもレイアウトが保てるか？\n\nNG例\n\n```css\n.list {\n  display: flex;\n  gap: 8px;\n  width: 400px; /* 固定長は危険 */\n}\n```\n\nOK例\n\n```css\n.list {\n  display: flex;\n  flex-wrap: wrap;\n  gap: var(--space-sm);\n  max-width: 100%;\n}\n```\n\nStorybook を使っている場合は、以下のアドオンを使って動的にデータ数を変更しながら、デザイン崩れしていないか簡単に確認できるのでおすすめです。\n\n- [storybook-addon-range-controls](https://github.com/silverbirder/storybook-addon-range-controls)\n\n**4デバイス（モバイル / タブレット / ラップトップ / デスクトップ）** で最低限の表示確認を行いましょう。\n\n## 4. デザイントークンを使っているか\n\nAIは数値を直接書きがちです。  \n`2px` や `16px` のような値が並んでいたら要注意です。\n\nNG例\n\n```css\n.button {\n  padding: 8px 16px;\n  font-size: 14px;\n}\n```\n\nOK例\n\n```css\n.button {\n  padding: var(--space-sm) var(--space-md);\n  font-size: var(--font-size-sm);\n}\n```\n\nトークンを使うことで、**一貫したデザイン** を保ちましょう。\n\n## 5. flexbox と grid の使い分け\n\nAIが生成するレイアウトコードは、たいてい **flexbox 一辺倒** です。  \nしかし、構造によっては **grid** のほうが適しています。\n\nどちらが適しているかは、以下の記事を参考にしてください。\n\n- [苦手なCSSを克服しよう | silverbirder](https://silverbirder.github.io/blog/contents/learn-layout/)\n\nNG例\n\n```css\n.gallery {\n  display: flex;\n  flex-wrap: wrap;\n}\n.gallery img {\n  flex: 1 0 33%;\n}\n```\n\nOK例\n\n```css\n.gallery {\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n  gap: var(--space-md);\n}\n```\n\nまた、`flex-grow` を指定したら `flex-shrink` も忘れずに設定しましょう。  \n圧縮時の崩れを防ぎます。\n\n## 6. CSSの詳細度を意識する\n\nAIは複雑なセレクタを生成しがちです。  \n詳細度が高すぎると、後から上書きが難しくなります。\n\nNG例\n\n```css\n.main .card > h2.title { ... }\n```\n\nOK例\n\n```css\n:where(.card:has(.title)) {\n  background-color: var(--surface-accent);\n}\n```\n\n`:where()` は詳細度を0にできる便利な疑似クラスです。  \n他にも `:is()` や `:has()` など擬似クラスを活用して、柔軟なスタイル指定をしましょう。\n\n## 7. カスタムプロパティで値を共通化しよう\n\n同じ意味の値を複数箇所で使っている場合は、**カスタムプロパティ**で共通化しましょう。\n\nNG例\n\n```css\n.box {\n  margin-left: -4px;\n  margin-right: -4px;\n  width: calc(100% + 8px);\n}\n```\n\nOK例\n\n```css\n.box {\n  --gutter: 4px;\n  margin-inline: calc(-1 * var(--gutter));\n  width: calc(100% + var(--gutter) * 2);\n}\n```\n\nまた、`@property` を使えば型や初期値を厳密に定義できます。\n\n```css\n@property --gutter {\n  syntax: '<length>';\n  inherits: false;\n  initial-value: 4px;\n}\n```\n\n## まとめ\n\nAIが生成したCSSのレビューで、スルーされることが多いので、ぜひレビュー時のチェックポイントとして活用してください。  \nもしくは、プロンプトチューニングの参考にしてみてください。","publishedAt":"2025-11-06","slug":"20251106","title":"AIが生成したCSSをレビューしよう"},{"body":"ライブカメラ映像を見るのが好きです。  \n道頓堀のような人が多い場所では、絶えず動きがあって見ていて飽きません。\n\n- [大阪 道頓堀 - YouTube](https://www.youtube.com/watch?v=Nbs_WkWTD7M)\n- [渋谷スクランブル交差点 - YouTube](https://www.youtube.com/watch?v=tujkoXI8rWM)\n- [東京 新宿 歌舞伎町 - YouTube](https://www.youtube.com/watch?app=desktop&v=gFRtAAmiFbE)\n\n神社や山など、自然の風景を映すカメラもあり、家にいながらちょっとした旅行気分を味わえますし、リフレッシュにもなります。  \n私は [カメ探](https://www.cametan.com/) というサイトでよく探しています。\n\n「Atmoph Window」という、世界の風景を“窓”のように映して楽しむガジェットもありますが、買い切りやサブスクで料金がかかります。  \n一方で、ライブカメラ映像は無料で楽しめるのが魅力です。  \nまた、それぞれ映像の品質や雰囲気が異なり、そこに独特の味わいがあります。\n\n調べてみると、YouTubeだけでなく国土交通省も全国各地にライブカメラを設置しており、道路状況などをリアルタイムで配信しています。\n\n- [道路：各地方整備局の取組 全国のライブカメラ - 国土交通省](https://www.mlit.go.jp/road/bosai/LIVEcamera.html)\n\n自宅では、防犯目的で Google Nest カメラを玄関に設置しています。  \nNest Hub から映像を確認したり、Google Home アプリでスマホから見たりもできます。  \nこの映像も、たま〜に眺めています。\n\niPadにライブカメラ映像を流しっぱなしにして、ふとしたときに画面を見て「ふ〜っ」と一息つく。  \nそんな時間が好きです。\n\nこの映像を使って、何か役に立つものを作れたら面白いのですが、なかなかアイデアが浮かびません。ユーリカ！と叫びたいのに。\n\nリフレッシュ用途で使えそうなアイデア、何かあるでしょうか？\n\n- ランダムにライブカメラを切り替える？\n- カテゴリ別に映像を流し続ける？\n- 複数の映像を同時に表示する？\n\nもしありましたら、ぜひ教えてください。\n何か作ってみたいと考えています。","publishedAt":"2025-11-05","slug":"20251105","title":"ライブカメラ"},{"body":"誰かに親切をするとき、見返りを求めてはいけないと思っています。  \n見返りを前提にした親切は、どこか詐欺めいたものに感じるからです。\n\nたとえば、電車の中で見ず知らずの年配の方に席を譲る場合、  \nその後に会うことはほとんどありません。  \nたとえ再び会うことがあったとしても、そのときには予期していなかったはずです。  \nだからこそ、その行為は純粋な善意のままです。\n\n一方で、友人など今後も関係が続く相手に親切をする場合、  \n「これこれ手伝ったので、あれあれやってほしいな」といった見返りを期待してしまうと、関係が歪んでしまいます。  \n契約もないのに一方的に助けておいて、後から見返りを求めるのはフェアではありません。  \nそれは相手からすれば、困惑しかありません。\n\n誰かを助けるなら、**「徳を積む」** という意識で行えばよいと思います。  \nそうでなければ、助けられた側は「結局、自分のためだったのか」と感じてしまうでしょう。\n\n逆に、相手から親切にしてもらう立場のときも、  \nできる限り自分でやる努力をして、本当に困ったときに助けを借りるのがよいのかもしれません。  \nそうすれば、お互いに健全な距離感で親切を受け渡すことができます。\n\n仕事でもプライベートでも、誰かを助けたり助けられたりする場面は多いものです。  \nそのとき、もし助けた側だったなら、「徳を積んだ」と思い、その瞬間で完結させましょう。  \n相手から「お礼をさせて」と言われたときは、お気持ちだけ受け取るのがベターです。  \nもし金銭などを受け取ってしまえば、せっかく積んだ**徳は帳消し**になるかもしれません。\n\n逆に、助けられた側になった場合は、まず感謝の気持ちをしっかり伝えましょう。  \nそして、お返ししたい気持ちが芽生えたときは、  \n相手が困っていることを自然な形で助けるのがよいと思います。\n\n**「タダより高いものはない」** と言われます。  \n助けてもらったときこそ、その言葉を思い出して、気をつけたいものです。","publishedAt":"2025-11-04","slug":"20251104","title":"見返りを求める善意"},{"body":"「さざなみ街道」は、琵琶湖の東岸を南北に走る道路の愛称です。  \n琵琶湖を一周する「ビワイチ」ルートの一部としても知られており、自転車やバイク、車でのツーリングを楽しむ人が多くいます。\n\n- [琵琶湖さざなみ街道・中山道](https://www.kkr.mlit.go.jp/road/kaidou/list/map/biwakonakayama.html)\n\n今日、用事があってさざなみ街道を車で走っていたのですが、夕日が沈む時間帯になると、  \n空と湖面がオレンジ色に染まり、草木の影がゆっくりと伸びていきました。  \nその瞬間の景色は、本当にエモいです。\n\n![車内から撮影した、さざなみ街道の夕景](https://res.cloudinary.com/silverbirder/image/upload/v1762169391/silver-birder.github.io/blog/jjqg3uj9tyltbnuzvjv9.jpg)\n\n風が吹くと、湖面にさざ波が立ち、夕日の光がキラキラと反射します。  \n海のように大きな波はありませんが、静かに揺れる湖面がとても美しく、見ているだけで心が落ち着きました。\n\n写真の場所とは別ですが、木々が揺れ、落ち葉がふわりと舞い上がる光景にも出会いました。  \nまるで映画のワンシーンのようで、思わずシャッターを切りました。\n\nドライブ中にこの景色がふと視界に広がると、心がじんわりと温かくなります。  \n何気ない一瞬なのに、「来てよかった」と心から思える場所です。\n\nまた、今度は夕焼け前の晴れた日に、ツーリングで訪れたいと思います。","publishedAt":"2025-11-03","slug":"20251103","title":"さざなみ街道はエモい"},{"body":"以下の記事を読みました。\n\n- [三日坊主だった私が見つけた習慣化のコツ　毎日ブログ更新を7年間継続できた「小さなルール」 - りっすん by イーアイデム](https://www.e-aidem.com/ch/listen/entry/2025/10/22/103000)\n\n「毎日ブログを投稿する」は本当にすごい。  \nネタは尽きないのだろうか、とつい思います。私自身、月1本書けたら良いほうでした。\n\n私がブログを書く最大の目的は**知識の整理**です。  \n「書こう！」という熱は、たいてい技術を学んだり、これから学ぼうとする時に生まれます。  \n学んだことを言語化すると曖昧な点が浮き彫りになり、調べ直して理解が深まる。  \n一方で、書き終える頃には熱がすっと引くこともしばしばです。\n\n最近はCSSに触れる機会が多く、見えてきたベストプラクティスを言語化しています。  \nブラウザごとの描画の差に疑問を持ち、小さなプロトタイプで仕組みを検証して記事にしたこともあります。  \nReact や GraphQL の歴史整理、簡単な技術 Tips、「やってみた」の初歩的な内容も書きます。  \n誰もが知っていそうでも、自分の言葉で残すことで、知らなかった誰かの助けになることがあります。\n\n人は忘れます。だから、未来の自分への備忘としてもブログは役立ちます。  \n過去記事のおかげで「あの時は何に悩んでいたか」を思い出せるのはうれしいし、毎年の振り返りも楽しみです。\n\nとはいえ、毎日書くのは難しい。技術ネタだけでは続きません。  \nそれでも**投稿頻度が低い**のはもったいない。日々の気づきや学びを残せば、日常はもっと充実するはずです。  \nそこで、**毎日投稿**に挑戦します。まずは**短くても毎日書く**ことから始めます。\n\n毎日書くには、日常で**ネタを探す意識**を持つことが大切だと、上記の記事でも語られていました。  \nこの1週間はその意識で過ごし、小さな発見があちこちに転がっていると実感しました。  \n思いついたらすぐに Google Keep にメモしています。  \n最近のメモは「ぬいぐるみを作る方法」「賃貸の最終的な決め手」「マルチプラットフォーム開発のネタ」など。  \n以前の私なら気づいても忘れていたはずのことが、今は残せています。  \nネタから記事にすれば、1つの資産として形が残るので、将来の自分にも役立つでしょう（たぶん）。\n\n投稿先は、note や はてなブログのように流入が見込める場所も考えました。  \nコミュニティに属してモチベーション維持につながる可能性もあります。  \nただ、以前は複数媒体に分散した記事を最終的に自分のサイトへ集約しました。  \n今回も、自分のブログで続けることにします。","publishedAt":"2025-11-02","slug":"20251102","title":"毎日ブログを投稿する"},{"body":"## はじめに\n\n久しぶりにWebアプリを開発します。  \nこれまでの成果物は、以下にまとめています。\n\n- [silverbirder's services](https://sites.google.com/view/silverbirders-services)\n\n今回のテーマは、「機能リクエストを投稿・閲覧できるWebアプリ」です。\n\n## なぜ作るのか\n\n個人開発では、MVPとして小さく作り、少しずつ機能を追加していくことが多いです。  \nしかし、開発後に「やり残した機能」がそのまま放置されることもあります。\n\nユーザーからすると、「この機能は今後追加されるのか？」「それとも実装予定がないのか？」がわかりません。  \nそこで、ユーザーが直接リクエストを投稿でき、開発者やユーザーが一覧で確認できる仕組みを作ろうと思いました。\n\n## 技術構成\n\n今回は、**管理画面とユーザー画面の2面構成**に挑戦します。  \n仕事ではよく使う構成ですが、個人開発ではまだ試したことがなかったので挑戦してみます。\n\n技術スタックは、使ってみたいものを優先して選びました。\n\n- **Next.js 16**\n- **Turborepo** によるモノレポ構成\n- **Vitest Browser Mode** のテスト構成\n- **Testcontainers** と **Cucumber** によるE2Eテスト\n- **tRPC** と **Drizzle ORM** のAPI通信\n  - いつも使っているお気に入り\n\n新しい環境でセットアップしていくと、「知らなかった機能や設定」に出会えるのが楽しいですね。  \nこのプロセス自体が勉強になります。\n\n## プロジェクト概要\n\nリポジトリは以下に公開しています。\n\n- [https://github.com/silverbirder/fequest](https://github.com/silverbirder/fequest)\n\nサービス名は **Fequest（フィークエスト）**。  \nこれは「Feature Request」をもとにした造語です。\n\n## 個人開発への思い\n\n最近はSNSなどで「個人開発×マネタイズ」や「どう広めるか」が注目されがちです。  \nでも、私の場合は少し違います。\n\n私の個人開発は、**「作りたいから作る」** が100%。  \n「新しい技術に挑戦したい」「不便を解決したい」、それが動機です。  \n利益よりも、作ること自体が目的であり楽しみです。\n\n## おわりに\n\nもしこのプロジェクトに興味を持ってくださった方は、  \nGitHubリポジトリを **Watch** してもらえると嬉しいです。","publishedAt":"2025-11-01","slug":"20251101","title":"Fequestを作る — 機能リクエストを見える化するサービス"},{"body":"今朝、2年ぶりに健康診断に行ってきました。\n\n会社員の頃は、会社から定期的に案内があり、面倒に思いながらも受診していました。  \nしかし、**個人事業主になってからは、自分で予約しないといけません。**\n\n私は現在32歳です。以前住んでいた自治体では、私の年齢で受けられる生活習慣病健診がなく、  \n最も近い対象は40歳以上を対象とした「特定健康診査（生活習慣病検診）」でした。  \nそのため、健康診断を受けたい場合は自分で病院やクリニックに電話して、  \n「個人でも受けられるか」を確認し、予約を取る必要がありました。\n\nネットで調べながら何件か電話しましたが、  \n多くの医療機関は「雇入時の健康診断」にしか対応しておらず、  \n個人事業主向けの健康診断は実施していませんでした。  \n\n## 結局そのときは、受診をあきらめることにしました\n\nところが、引っ越し後の今の自治体では、  \n「19〜39歳の市民で、職場や学校で健康診断を受けられない方」を対象に  \n生活習慣病健診を実施しており、今回は無事に受診できました。  \n**「ようやく健康診断を受けられる！」** という気持ちになりました。\n\n人間ドックも検討したのですが、  \n「35歳を過ぎると検査項目が増えるから、そのタイミングで受けよう」  \nという自分への言い訳をして、今回は生活習慣病健診にしました。  \n次こそは人間ドックを受けてみようと思います。\n\n健診の前日までに、問診票を記入しておきました。  \nその中に、気になっていることを簡単に書き添えておきます。  \n問診の際に、先生がその内容を見て頂けるはずです。\n\nそして当日。定番の検査を終えたあと、問診の時間がありました。\n\n最近の一番の悩みは「お手洗いが近いこと」です。  \n尿意の頻度や水分摂取量などを伝えると、  \n泌尿器科での受診を勧められました。  \n治るものなのか不安もあるので、専門の先生に診てもらう予定です。  \n健康診断を受けて、本当によかったと思いました。\n\nちなみに、今回の健診では身長が約1cm伸びていました。  \nこの年齢で伸びるとは思わず、びっくりです。  \nBMIは正常値でしたが、もう少しで肥満の範囲に入りそうとのこと。  \n今月から始めた筋トレ、**続けよう...！**","publishedAt":"2025-10-31","slug":"20251031","title":"能動的に健康診断に行こう"},{"body":"以前は、某Mのマークの家計簿アプリを使って、自動で家計簿をつけていました。  \n銀行口座やクレジットカードを連携すると、支出や収入を自動で取得して、きれいにグラフ化してくれます。  \nとても便利だったのですが、「自動でやってくれるから、あとで見ればいいや」と思ってしまい、次第に見なくなっていきました。  \n結果として、家計簿を「つけている実感」が薄れていったのです。\n\nそこで2年ほど前から、**あえて手動で家計簿をつけるようにしました。**  \n目的は、家計簿をつけている実感を取り戻し、お金の流れを自分の感覚でつかむことです。  \nシステム開発も、まずは手動で仕組みを理解してから自動化しますよね。\n\n### やっていること\n\n買い物の際は必ずレシートをもらい、月末にそれを見ながら（Mではない）家計簿アプリに1件ずつ入力しています。  \nカテゴリ、日付、金額を記録し、年金・保険料・税金などの支出も漏れなく入力します。  \nもちろん、お給料などの収入も同様です。\n\n銀行口座の引き落としやクレジットカードの明細も確認します。  \nまとまった引き落としがある場合は、携帯料金などのように各サービスのマイページへログインし、内訳をチェックします。  \nわかりにくい支出があれば、その都度調べて記録します。\n\n### 続けてわかった3つの良さ\n\n## 1. 支出を振り返る時間が生まれる\n\n1件ずつ入力していると、「あのお店のレシートだ、美味しかったな」と思い出す瞬間があります。  \nただの記録作業ではなく、思い出を振り返るちょっとした時間になります。  \nその過程で「そういえば行けなかったあのお店、今度行こうかな」と、新しい行動のきっかけが生まれることもあります。\n\n## 2. 不明な支出に気づける\n\n明細を見ていると、ときどき「これ何だっけ？」という支出があります。  \n思い出せるものもあれば、不要なサブスクが見つかることもあります。  \n「初月無料、2ヶ月目から課金」など、うっかり解約を忘れていたサービスに気づくこともありました。  \nどうしても思い出せない支出は、引き落とし元に問い合わせたこともあります。\n\nこうした経験から、支払い手段を絞るようになりました。  \nクレジットカードは1枚、電子決済も1種類に統一し、その電子決済に紐づけるカードも同じにしています。  \n公共料金などの口座引き落としも同じ銀行に揃え、支出の流れをシンプルにしました。\n\n## 3. お金を使った実感が残る\n\n手動入力は確かに手間ですが、その分「今月は外食が多かったな」「服に使いすぎたな」といった感覚が残ります。  \n電子決済が主流の今、レシートを見ながら入力することで“使った実感”を取り戻せます。  \n\n一時期は「来月は支出を抑えよう」と意識したこともありましたが、今はあまり制限しません。  \n楽しみを削ってまで節約しても、長続きしないからです。  \n大切なのは、お金の使い方を「自分で把握できている」状態だと思っています。\n\n### おわりに\n\n手動入力は時間がかかります。  \n月末にレシートを整理して入力するのは、正直少し面倒です。  \nそれでも、自分のお金の動きを肌感覚で理解できるのは大きな収穫です。  \nこれからも私は、手間を楽しみながら手動で家計簿をつけていこうと思います。","publishedAt":"2025-10-30","slug":"20251030","title":"家計簿を手動でつけている"},{"body":"サイゼリヤの注文画面は、私の体験としては「悪くなっていない」と感じている。\n\n私は現在社会人だが、学生の頃からサイゼリヤには何度も通ってきた。  \n注文画面が導入される前は、メニュー表に書かれた商品番号を紙に記入し、店員さんを呼んで最終確認をしてから注文していた。  \n注文後はお冷を取りに行き、席で「間違い探し」をしながら料理を待つ——そんな流れが定番だった。\n\nこの流れに慣れている私からすると、**今の注文画面は従来の体験を壊さず、自然に馴染んでいるように思う。**  \n注文番号を入力し、表示された商品名を確認してカートに入れる。食べたいものをすべて選んだら、そのまま注文するだけ。  \nUIはとてもシンプルで、特に改善点を感じるわけでも、違和感を覚えるわけでもない。  \n**体験としては、紙に書いていた頃とほとんど変わっていない**。\n\n当たり前だが、導入する側にとってはメリットは大きい。  \nオペレーションの変更は最小限で済み、紙や鉛筆といった資源の削減、店員による確認作業の軽減にもつながる。  \nそうした意味で、良い方向への進化だと思う。\n\n個人的に、飲食店でメニューを眺める時間が好きだ。  \n大きなメニュー表を広げ、美味しそうな写真や手書き文字を見ながら「どれにしようか」と悩む——その時間にワクワクする。  \n一方で、すべてがタブレット端末で完結する店では、どこかそのワクワク感が薄れてしまう。  \n魅せ方や体験設計に工夫がないまま、紙をそのままデジタルに置き換えてしまうと、どうしても味気なく感じてしまう。\n\nその点、サイゼリヤの注文体験は絶妙だ。  \n\n## メニュー表は従来どおり残し、注文の部分だけをデジタル化している\n\nもしメニュー表も含めてすべてを刷新するような「新しいUX」を追求する方向もあるだろうが、\n堅実にいくなら、今の形がもっともバランスが取れているのかもしれない。\n\nつまり、私にとってサイゼリヤの注文画面は、UXとして「良くも悪くも変わっていない」。  \nしかし、紙資源の削減やスタッフの負担軽減といった観点では、確実に前進した改善だと思う。\n\nでは、新規のお客さんにとってはどうだろう？","publishedAt":"2025-10-29","slug":"20251029-2","title":"サイゼリヤの注文画面"},{"body":"「内弁慶」という言葉があるように、家の中と外で性格が違う人は多いと思います。\n環境によって性格が変わることは、よくあることです。\n\n私自身も、仕事中の自分と家にいる自分とでは少し性格が違います。\n仕事の時は、比較的社交的にコミュニケーションを取りますが、\n家では、わざわざ社交的である必要もなく、マイペースに過ごしています。\nまた、法事などで親戚に会うときの自分は、普段よりもゆったりとしたトーンで話すことが多いです。\n他には、友人に会う時は砕けたノリで話しますが、初対面の人に会う時は、意識的に明るく話すことが多いです。\n\n環境の違いは、人と会うときだけではありません。\n自分ひとりのときでも、状況によって性格が変わることがあります。\nたとえば、何かうまくいかなかった日に出かけると、つい他責的になってしまいます。\n逆に物事が順調な日は、見知らぬ相手の失敗にも寛容になれたりします。\nそんな自分の変化を感じることがあります。\n\nこのように、環境によって性格が変わるのは自然なことだと思います。\nけれど、そうした「場によって変わる自分」をうまく受け入れられない人もいるかもしれません。\n私自身はそこまで悩むことはありませんが、それでも「外の自分は作っているな」と感じる時があります。\n\nこうした「環境や状況によって変わる自分」こそが、分人主義の考え方に近いのだと私は解釈しました。\n\n> 「分人」は、対人関係ごと、環境ごとに分化した、異なる人格のことです。  \n> 中心に一つだけ「本当の自分」を認めるのではなく、  \n> それら複数の人格すべてを「本当の自分」だと捉えます。  \n> この考え方を「分人主義」と呼びます。  \n\n[「分人主義」公式サイト｜複数の自分を生きる](https://dividualism.k-hirano.com/) より引用\n\nこの考え方は「自分を肯定する」ための助けになるのかなと思います。\n\n心地よい性格のときもあれば、意地悪な性格が出るときもある。\nどちらも自分であり、良い悪いで分ける必要はない。\n\n結局のところ、それがどうというわけではないのですが、\n**自分の性格が変化していると気づけること** 自体が、\n**性格を平常に戻す手がかり** になるのではないかと思いました。","publishedAt":"2025-10-29","slug":"20251029","title":"分人主義という考え方"},{"body":"滋賀県には、発祥の地でもある『飛び出し坊や』という交通安全の看板が数多くあります。\n\n[![飛び出し坊や - Wikipedia](https://res.cloudinary.com/silverbirder/image/upload/v1761653387/silver-birder.github.io/blog/k8uis9wbnjsj8pwriobb.jpg)](https://ja.wikipedia.org/wiki/飛び出し坊や)\n\n各地を巡ると、その**土地らしいアレンジがされた飛び出し坊や**に出会います。  \n名産品を食べていたり、歴史上の人物の格好をしていたり。中には、年月を経て絵がすっかり崩れてしまったものもあります。\n\nこういう看板を見つけると、つい写真を撮りたくなるのですが、運転中に撮影するのはもちろん危険です。  \nどうにかして「走行中でも安全に飛び出し坊やを撮れないか」と考えたとき、思い出したのが**ドライブレコーダー**でした。\n\n- [ドライブレコーダー HDR965GW | COMTEC 株式会社コムテック](https://www.e-comtec.co.jp/0_recorder/hdr965gw.html)\n\nドライブレコーダーなんて、車を購入して以来ほとんど触ったことがありません。  \n「事故のときにSDカードを抜く」くらいの知識しかありませんでした。\n\nそこで、久しぶりにドライブレコーダーのSDカードを取り出し、以下のアダプタを使って、Macで読み込んでみることに。\n\n- [Anker USB-C 2-in-1 カードリーダー｜アダプタの製品情報 | Anker Japan 公式オンラインストア](https://www.ankerjapan.com/products/a83700a2)\n\n中には、**フロント（前）** と **リア（後ろ）** の映像がそれぞれ保存されていました。  \n[説明書](https://www.e-comtec.co.jp/manual/drive_recorder/hdr965gw.pdf)を読むと、「常時録画」と「イベント録画」の2種類があるようです。\n\n- **常時録画**：走行中ずっと録画される映像\n- **イベント録画**：衝撃を検出したときに自動で保存される映像\n\n常時録画は、走行中ずっと録画している映像で、イベント録画は、何か音が鳴ったときに録画される映像のようです。\nファイル名に AG_ と書いているとイベント録画、 A__ と書いていると常時録画のようです。\n\nまた、地理情報も記録されているようなのですが、専用のビューワソフトは**Windows専用**でした。\n\n- [ビューワソフトのダウンロード](https://www.e-comtec.co.jp/0_recorder/viewer/HDRviewerW2/viewer.html)\n\n「地理情報があるなら、どこの飛び出し坊やか分かるじゃん！」と思ったのですが、Macでは動かず断念。  \n残念ながら、映像データの再生と目視確認にとどまりました。\n\n録画データは古いものから自動で上書きされていくため、最近の映像しか残っていません。  \nもし飛び出し坊やを見つけたなら、その日のうちにSDカードを抜いて確認するのが良さそうです。  \nまた、常時録画とイベント録画は保存領域が別なので、イベント録画をうまく使う手もあるかもしれません（※危険です）。\n\n対応容量は128GBまでだったので、今回はAmazonで新しいSDカードを購入しました。\n\n- [EXCERIA microSDメモリカード | KIOXIA - Japan (日本語)](https://www.kioxia.com/ja-jp/personal/micro-sd/exceria.html)\n\n次に飛び出し坊やを見かけたら、ドライブレコーダー覗いてみよっと！","publishedAt":"2025-10-28","slug":"20251028","title":"飛び出し坊やを撮りたい、ドラレコを漁る"},{"body":"毎月末になると、freeeで会計処理をしています。  \n青色申告の65万円控除を受けるためです。  \nただ、自分で仕訳をしていると、本当に正しいのか不安になることがありました。\n\nそこで、税理士にお願いしてみようと思いました。  \nfreeeを使っているので、まずは [freeeの税理士コーディネーター](https://www.freee.co.jp/zeirishi-shokai) に相談しました。  \n費用の仕組みやサポート内容をざっくりと教えてもらいました。\n\n大まかには次の3つのサービスがあるようです。\n\n- **顧問契約**：専門家にいつでも相談できる\n- **記帳代行**：会計ソフトへの入力を代行してもらう\n- **申告代行**：確定申告を任せられる\n\n費用は事務所によってさまざまとのことです。  \nそこで、引越し業者を探すような感覚で、複数の税理士事務所を比較することにしました。\n\n- [freee 税理士検索](https://search-advisors.freee.co.jp/)\n\n以下の条件で検索しました。\n\n- リモート対応可能\n- 確定申告・記帳代行に対応\n- 個人事業主の実績あり\n- IT業界に強い\n- 私の業種・サービスにマッチしている\n- 費用が明示されていて予算内\n- 人柄が合いそう\n\nこれらの条件で20件以上に絞り込み、各事務所のサイトを見ながら、メッセージや雰囲気を確認しました。\n\n最終的に、4つの事務所とオンライン面談を実施しました。  \nどの事務所も丁寧で、資料を用意してくださったり、圧迫感なくスムーズに質問に答えてくださったりと、  \nそれぞれの良さがありました。  \n従業員の規模、他士業の在籍有無、税理士本人の年代など、事務所ごとに個性もさまざまでした。  \n\n最終的には、**費用・人柄（誠実さ）・IT業界への理解度**を重視して、1つの事務所に決定しました。  \n今後はその事務所に依頼し、確定申告や記帳代行を進めていく予定です。  \n\n経費の明細や控除の証明書類を整理しながら、次の申告に備えようと思います。  \n\nおつかれさま！","publishedAt":"2025-10-27","slug":"20251027","title":"税理士に頼ることにした"},{"body":"こんにちは! [@silverbirder](https://github.com/silverbirder) です。\n今回、私が心掛けている単体テストコードを書く上でのお作法について共有します。\n読者の皆さんが、より良い単体テストコードを書く一助になれば幸いです。\n\n## 本記事の前提\n\n- 例では テストフレームワークとして Vitest を使用しますが、考え方は他の技術にも活かせると思います。\n  - 言語は、TypeScriptを使用しています。\n- 本文ではアプリ本体を「プロダクションコード」、検証用のコードを「テストコード」と呼びます。\n\n### 単体テストとは\n\n単体テストは、関数やクラス、コンポーネントなど最小単位の振る舞いが仕様どおりかを確かめるテストです。\n内部の実装を踏まえて分岐やパスを確認する、ホワイトボックステストが基本になります。\n\n## テストを書く目的\n\nテストを書く目的は次の3つだと私は考えています。\n\n- 手動確認を減らして開発効率を高める\n- バグの再混入を防いで品質を守る\n- 振る舞いを言語化して仕様をはっきりさせる\n\n単体テストコードを書くことで、自動化された検証が増え、手動での確認作業が減ります。\nまた、テストがあることでリファクタリングや機能追加の際に既存機能が壊れていないかを素早くチェックでき、品質を保ちやすくなります。\nさらに、テストコードは仕様を言語化したドキュメントの役割も果たし、実装の意図を明確にします。\n\n## 読みやすさを最優先にする\n\nプロダクションコードはユーザー体験そのものを左右するため、パフォーマンスや使いやすさを最適化する設計が求められます。\n\n対してテストコードは開発者が読むためのドキュメントです。\n機能が想定どおりに振る舞うかを確認する手段であり、実装理解を助ける説明書でもあります。\n複雑な抽象化や過剰な最適化よりも、仕様がそのまま読める構造が大切です。\n\nだからこそ、**テストコードでは「読みやすさ」を最優先にします。**\nここからは、読みやすさを保つ具体的な工夫を紹介します。\n\n## 今回のサンプルコード\n\nここからは、EC サイトによくある、カートの合計金額を求める関数 \"calculateCartTotal\" を題材にします。\nクーポン割引と消費税を加味して合計を返すシンプルなロジックです。\n細かいロジックを読んで頂く必要はなく、コメントで補足していますので、全体の流れをざっくり把握できれば十分です。\n\n```ts\n// カートアイテム\ntype CartItem = {\n  id: string;\n  // 商品名\n  name: string;\n  // 単価\n  price: number;\n  // 数量\n  quantity: number;\n};\n\n// クーポン\ntype Coupon = {\n  // 割引タイプ(今回は%固定のみ)\n  type: \"percent\";\n  // 割引値（%）\n  value: number;\n  // 適用条件: 最小購入金額\n  minAmount?: number;\n  // 適用期限\n  expiresAt?: Date;\n};\n\n// 消費税（軽減税率）\nconst TAX_RATE = 0.8;\n\n/** カート全体の合計 */\nexport const calculateCartTotal = (\n  items: CartItem[],\n  coupon?: Coupon\n): number => {\n  // 小計を計算\n  const subtotal = calculateSubtotal(items);\n  let discountedSubtotal = subtotal;\n\n  // クーポンが存在し、適用可能な場合のみ適用\n  if (coupon && isCouponApplicable(subtotal, coupon)) {\n    discountedSubtotal = applyCoupon(subtotal, coupon);\n  }\n\n  // 税込み価格を計算して返す\n  return calculateTotalWithTax(discountedSubtotal);\n};\n\n/** 小計を計算 */\nconst calculateSubtotal = (items: CartItem[]): number =>\n  items.reduce((sum, item) => sum + item.price * item.quantity, 0);\n\n/** クーポンが適用可能かを判定する */\nconst isCouponApplicable = (subtotal: number, coupon: Coupon): boolean => {\n  const now = new Date();\n\n  // 期限切れや最小購入金額未満の場合は適用不可\n  if (coupon.expiresAt && coupon.expiresAt < now) return false;\n  if (coupon.minAmount && subtotal < coupon.minAmount) return false;\n\n  return true;\n};\n\n/** クーポンを適用 */\nconst applyCoupon = (subtotal: number, coupon?: Coupon): number => {\n  if (!coupon) return subtotal;\n  return subtotal * (1 - coupon.value / 100);\n};\n\n/** 税込み価格を計算 */\nconst calculateTotalWithTax = (subtotal: number): number =>\n  Math.round(subtotal * (1 + TAX_RATE));\n```\n\n## テストコードの作法\n\n### 共通準備: モックデータを整える\n\nまずはテスト対象を呼び出すためのデータを揃えます。\n今回の題材ならモックのアイテムとクーポンを生成する関数を持っておくと便利です。\n\n```ts\nconst generateItem = (override: Partial<CartItem> = {}): CartItem => ({\n  id: \"item-001\",\n  name: \"Wireless Mouse\",\n  price: 4980,\n  quantity: 1,\n  ...override,\n});\n\nconst generateCoupon = (override: Partial<Coupon> = {}): Coupon => ({\n  type: \"percent\",\n  value: 15,\n  minAmount: 5000,\n  expiresAt: new Date(\"2025-12-31T23:59:59Z\"),\n  ...override,\n});\n```\n\nモックデータの値は、できるだけ本番に近しいデータを用意しましょう。\nその方が、具体的なシナリオがイメージしやすくなります。\n\n### Arrange-Act-Assert を徹底する\n\nテストは概ね「Arrange→Act→Assert」（AAA）の順で進みます。\n\n1. Arrange: 前提データやモックを用意する\n1. Act: テスト対象に対して操作を実行する\n1. Assert: 結果が期待どおりか検証する\n\n**このサイクルは1ケースにつき1回に絞るのが鉄則**です。\nAssert 後に別の Act→Assert を足すと、ケースの目的が増え、読解コストが一気に跳ね上がります。\n\n以下は、AAAパターンを守った例です。\n\n```ts\nit(\"should calculate total with tax when no coupon\", () => {\n  // Arrange\n  const items = [\n    generateItem({ price: 2000, quantity: 2 }),\n    generateItem({ price: 5000 }),\n  ];\n\n  const subtotal = 2000 * 2 + 5000;\n  const expectedTotal = subtotal * (1 + TAX_RATE);\n\n  // Act\n  const total = calculateCartTotal(items);\n\n  // Assert\n  expect(total).toBe(expectedTotal);\n});\n```\n\n逆に、AAAパターンを崩した例です。\n\n```ts\nit(\"should calculate total with tax when coupon is applied\", () => {\n  // Arrange\n  const items = [\n    generateItem({ price: 2000, quantity: 2 }),\n    generateItem({ price: 5000 }),\n  ];\n  const coupon = generateCoupon({ value: 10 });\n\n  const subtotal = 2000 * 2 + 5000;\n  const discountedSubtotal = subtotal * (1 - coupon.value / 100);\n  const expectedTotal = discountedSubtotal * (1 + TAX_RATE);\n\n  // Act\n  const total = calculateCartTotal(items, coupon);\n\n  // Assert\n  expect(total).toBe(expectedTotal);\n\n  // Act (NG)\n  const totalWithoutCoupon = calculateCartTotal(items);\n\n  // Assert (NG)\n  expect(totalWithoutCoupon).toBe(subtotal * (1 + TAX_RATE));\n});\n```\n\n### ロジックを畳まず愚直に書く\n\nループや条件分岐は一見スマートでも、読む側には余計な追跡コストがかかります。\nテストでは可読性を優先し、ロジックを畳まずそのまま書き下ろす方が好みです。\n\n```ts\n// NG\nconst items = [];\nfor (let i = 0; i < 3; i++) {\n  items.push(generateItem({ price: 1000 * (i + 1), quantity: i + 1 }));\n}\n```\n\n```ts\n// OK\nconst items = [\n  generateItem({ price: 1000, quantity: 1 }),\n  generateItem({ price: 2000, quantity: 2 }),\n  generateItem({ price: 3000, quantity: 3 }),\n];\n```\n\n大量のデータを用意する必要がある場合は、件数を指定したモック生成関数を用意すると良いでしょう。\n\n加えて、**期待値を算出する際に本番コードと同じ計算手順を複製するのは避けます**。\n本番側にバグがあってもテストが同じ計算をしていれば検知できないためです。\n\n```ts\n// NG\nconst expectedTotal = items.reduce((sum, item) => sum + item.price * item.quantity, 0) * (1 + TAX_RATE);\n```\n\n```ts\n// OK\nconst expectedTotal = 14000 * (1 + TAX_RATE);\n```\n\nまた変数を定義する際は、抽象的な名前よりも具体的な名前を付けると意図が伝わりやすくなります。\n\n```ts\n// NG\nconst value = 14000 * (1 + TAX_RATE);\n```\n\n```ts\n// OK\nconst expectedTotal = 14000 * (1 + TAX_RATE);\n```\n\n### テストケース名とマッチャーを自然文にする\n\nテストケースの説明文が曖昧だと、コードを追わないと意図がつかめません。\n自然な文章にして、読むだけで狙いが伝わるように整えます。\nまた、抽象的な語を避けて、状況と期待結果まで書き切りましょう。\n\n```ts\n// NG\nit('should work correctly', () => {\n  // ...\n})\n\n// OK\nit('should calculate total with tax when no coupon', () => {\n  // ...\n})\n```\n\n私の場合は \"it should ... when ...\" の骨格に揃え、条件や期待結果を自然文で並べています。\n\nマッチャーも同じです。\"expect ... to ...\" が文として読めるものを選ぶと、コード全体が平叙文になります。\n\n```ts\n// NG\n// Arrange\nconst list = ['A', 'B', 'C'];\n\n// Assert\nexpect(list.includes('A')).toBe(true)\n```\n\n```ts\n// OK\n// Arrange\nconst list = ['A', 'B', 'C'];\n\n// Assert\nexpect(list).toContain('A')\n```\n\nさらに、否定形より肯定形で表現した方が読みやすくなります。\n\n```ts\n// NG\n// Arrange\nconst isDisabled = false;\n\n// Assert\nexpect(isDisabled).not.toBe(true);\n```\n\n```ts\n// OK\n// Arrange\nconst isEnabled = true;\n\n// Assert\nexpect(isEnabled).toBe(true);\n```\n\n### テストケース単位で完結させる\n\nテストを書いていると共通化したくなる処理が自然と出てきます。\n関数化するのは良いのですが、テストケース名から離れた場所を行き来しないと中身が分からない構成は避けたいところです。\n**できるだけテストケース内で見通せる形に保ちます**。\n\n```ts\n// NG\nconst generateItems = () => [\n  generateItem({ price: 2000, quantity: 2 }),\n  generateItem({ price: 5000 }),\n];\n\nit(\"should calculate total with tax when no coupon\", () => {\n  const items = generateItems(); // NG\n\n  const subtotal = 2000 * 2 + 5000;\n  const expectedTotal = subtotal * (1 + TAX_RATE);\n\n  const total = calculateCartTotal(items);\n\n  expect(total).toBe(expectedTotal);\n});\n```\n\n```ts\n// OK\nconst generateItem = (override: Partial<CartItem> = {}): CartItem => ({\n  id: \"item-001\",\n  name: \"Wireless Mouse\",\n  price: 4980,\n  quantity: 1,\n  ...override,\n});\n\nit(\"should calculate total with tax when no coupon\", () => {\n  // Arrange\n  const items = [\n    generateItem({ price: 2000, quantity: 2 }),\n    generateItem({ price: 5000 }),\n  ];\n\n  const subtotal = 2000 * 2 + 5000;\n  const expectedTotal = subtotal * (1 + TAX_RATE);\n\n  // Act\n  const total = calculateCartTotal(items);\n\n  // Assert\n  expect(total).toBe(expectedTotal);\n});\n```\n\nどちらも共通化のテクニックですが、前者はモックの中身を知るために \"generateItems\" を読み解く必要があります。\n後者は \"generateItem(\\{ price: 2000, quantity: 2 \\})\" のようにテスト内で値を指定しているため、その場で意図が分かります。\n共通化は便利でも、テストケースから離れた依存が増えるほど読解コストが跳ね上がります。\nテストケース内で、見通しの良い形に保ちましょう。\n\n### グルーピングのネストを浅く保つ\n\nテストケースが増えると共通の前提でグルーピングしたくなりますが、入れ子を重ねすぎると文脈をたどる手間が増えます。\n例えば次のようにグループを3階層にすると、最深部のケースを読む際に上位の条件を逐一思い出さなければなりません。\n\n```ts\n// 1階層\ndescribe(\"calculateCartTotal\", () => {\n  // 2階層\n  describe(\"when coupon is applied\", () => {\n    // 3階層\n    describe(\"and coupon is valid\", () => {\n      it(\"should calculate total with tax after discount\", () => {\n        // ...\n      });\n    });\n    // 3階層\n    describe(\"and coupon is expired\", () => {\n      it(\"should calculate total with tax without discount\", () => {\n        // ...\n      });\n    });\n  });\n});\n```\n\nネストが深いほど読み手の負荷が高まるため、基本的には避けたいところです。\nただし、共通の前提で整理したくなる場面もあるはずです。\nその場合でも階層は 2 までにとどめ、テストケース名に状況を織り込んでフラットに並べるのがおすすめです。\n\n```ts\n// 1階層\ndescribe(\"calculateCartTotal\", () => {\n  it(\"should calculate total with tax after discount when coupon is valid\", () => {\n    // ...\n  });\n\n  it(\"should calculate total with tax without discount when coupon is expired\", () => {\n    // ...\n  });\n});\n```\n\n### 未実装機能をテストで記録する\n\n開発を進めていると「仕様は決まっているが、実装は後回し」というケースがよくあります。\nまずは未実装のプロダクトコードに TODO が残っている一例です。\n\n```ts\n// 将来対応予定\nconst applyCoupon = (subtotal: number, coupon?: Coupon): number => {\n  // TODO: Implement coupon application logic\n  return subtotal;\n};\n```\n\n仕様が固まっているなら、先にテストで期待値を記録しておくと実装忘れを防げます。\nVitest なら「今は失敗していてよい」ことを表現できる \"it.fails\" が便利です。\n\n```ts\nit.fails(\"should apply coupon when coupon is valid\", () => {\n  // Arrange\n  const subtotal = 1000;\n  const coupon = generateCoupon({ value: 10 });\n  const expectedTotal = 900;\n\n  // Act\n  const total = applyCoupon(subtotal, coupon);\n\n  // Assert\n  expect(total).toBe(expectedTotal);\n});\n```\n\nテストをまだ書けない場合は \"it.skip\" や \"it.todo\" で意図だけ残す方法もあります。\n\n```ts\nit.todo(\"should apply coupon when coupon is valid\");\n```\n\n未完了のテストを一覧したいときはタグで印を付け、\"--testNamePattern\" で絞り込むと追跡しやすくなります。\n\n```ts\nit.todo(\"should apply coupon when coupon is valid @coupon\");\n```\n\nテスト実行時は次のように検索します。\n\n```bash\nvitest --testNamePattern=\"@coupon\"\n```\n\nフィーチャーが完成したら、\"fails\" や \"todo\" が出力に残っていないことを確認し、未実装記録を順次解消していきます。\n\n### 並び順で意図を伝える\n\nテストの並びには（個人的には）意味を持たせたくないものの、私は「正常系→準異常系→異常系」の順に並べることが多いです。\n最初に Happy Path を示すと、続くケースが何を守るためのガードなのか読み手が掴みやすくなります。\n\n例えば、以下のような順番です。\n\n```ts\n// 正常系\nit(\"should calculate total with tax when no coupon\", () => {\n  // ...\n});\nit(\"should calculate total with tax when coupon is applied\", () => {\n  // ...\n});\n// 準異常系\nit(\"should calculate total with tax when coupon is expired\", () => {\n  // ...\n});\n// 異常系\nit('should throw error when coupon type is unknown', () => {\n  // ...\n});\n```\n\n### アサートは細かく明示する\n\nテストは「何を確認したのか」を明確に残す必要があります。\n特に戻り値がオブジェクトや複数行テキストのとき、**ざっくりとしたアサートだとバグをすり抜けさせがちです**。\n値だけでなく、呼び出し回数や引数まで丁寧に検証しましょう。\n\n```ts\n// NG\nconst summary = formatOrderSummary(order);\n// summary が存在することだけを確認\nexpect(summary).toBeTruthy();\n\n// OK\nexpect(summary).toEqual({\n  total: 14000,\n  itemCount: 3,\n  hasDiscount: true,\n});\n```\n\nフロントエンドでは HTML の検証も同様です。\n要素が存在するだけでなく、どこにどんなテキストが描画されているかまで確認します。\n\n```ts\n// Arrange & Act\nconst html = `\n  <section>\n    <h2>Cart total</h2>\n    <p data-testid=\"cart-total\">-</p>\n    <p data-testid=\"contact\">Call us: 03-1234-5678</p>\n  </section>\n`;\n\n// Assert\n// NG\nexpect(html.includes(\"-\")).toBe(true);\n\n// OK\nconst dom = new DOMParser().parseFromString(html, \"text/html\");\nconst total = dom.querySelector('[data-testid=\"cart-total\"]');\nexpect(total?.textContent).toContain(\"-\");\n\n// NOTE: 実際は @testing-library/react の screen.getByRole などを用いますが、\n// ここではライブラリに依存しない例として DOMParser を使っています。\n```\n\n同様に、モック関数は呼び出し回数と引数を合わせて検証します。\n\n```ts\n// Arrange\nconst logger = vi.fn();\n\n// Act\nnotifyMissingCoupon(logger);\n\n// Assert\nexpect(logger).toHaveBeenCalledTimes(1);\nexpect(logger).toHaveBeenCalledWith({\n  level: \"warn\",\n  message: \"Coupon is missing\",\n});\n```\n\n検証対象が大きすぎるときは \"expect.objectContaining\" などを使い、必要な部分だけを確実に見るようにします。\n\n```ts\n// Arrange\nconst logger = vi.fn();\n\n// Act\nnotifyMissingCoupon(logger);\n\n// Assert\nexpect(logger).toHaveBeenCalledWith(\n  expect.objectContaining({\n    level: \"warn\",\n    message: \"Coupon is missing\",\n  })\n);\n```\n\n### パラメータの網羅性を確保する\n\n期待結果が入力パラメータに左右されるときは、境界値や同値分割を意識して網羅的に押さえます。\n列挙が増えそうならパラメタライズドテストを使い、ON/OFF のような二択も迷うくらいなら両方書いてしまった方が早いです。\n\n例えば、クーポン適用の有無の関数 \"isCouponApplicable\" の場合、以下のようにテストケースを分けます。\n\n```ts\nit.each`\n  subtotal | minAmount    | expected\n  ${1000}  | ${undefined} | ${true}\n  ${1000}  | ${1001}      | ${true}\n  ${1000}  | ${1000}      | ${true}\n  ${1000}  | ${999}       | ${false}\n`(\"should return $expected when subtotal=$subtotal and minAmount=$minAmount\", ({ subtotal, minAmount, expected }) => {\n  // Arrange\n  const coupon = { type: \"percent\", value: 10, minAmount };\n\n  // Act\n  const result = isCouponApplicable(subtotal, coupon);\n\n  // Assert\n  expect(result).toBe(expected);\n});\n```\n\n### 状態遷移はケースを分割する\n\n状態遷移を伴うオブジェクトをテストするとき、**1ケースで一連の流れをなぞると途中で失敗した時点で残りの検証が実行されません**。\n遷移ごとにテストを分けて、どの状態で落ちたのかを明確にすると安心です。\n\n例えば、以下のような簡易のカートクラスを考えます。\nこのクラスは、カートの状態を管理し、アイテムの追加やチェックアウトを行います。\n\n```ts\nexport enum CartState {\n  Empty = \"Empty\",\n  Active = \"Active\",\n  CheckedOut = \"CheckedOut\",\n}\n\nexport class Cart {\n  private total = 0;\n  private state = CartState.Empty;\n\n  add(price: number) {\n    if (this.state === CartState.CheckedOut) throw new Error(\"Already checked out\");\n    this.total += price;\n    this.state = CartState.Active;\n  }\n\n  checkout() {\n    if (this.state !== CartState.Active) throw new Error(\"Cannot checkout\");\n    this.total = 0;\n    this.state = CartState.CheckedOut;\n  }\n\n  getState() {\n    return this.state;\n  }\n\n  getTotal() {\n    return this.total;\n  }\n}\n```\n\nこのカートを例に、状態ごとにケースを切り分けてみます。  \n以下は、1ケースで状態遷移を追う例です。\n\n```ts\n// NG\nit(\"should be Empty state when initialized, Active state after adding an item, and CheckedOut state after checkout\", () => {\n  // Act\n  const cart = new Cart();\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.Empty);\n\n  // Act\n  cart.add(1000);\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.Active);\n\n  // Act\n  cart.checkout();\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.CheckedOut);\n});\n```\n\n以下は、状態ごとにケースを分けた例です。\n\n```ts\n// OK\nit(\"should be Empty state when initialized\", () => {\n  // Act\n  const cart = new Cart();\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.Empty);\n});\nit(\"should be Active state after adding an item\", () => {\n  // Arrange\n  const cart = new Cart();\n\n  // Act\n  cart.add(1000);\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.Active);\n});\nit(\"should be CheckedOut state after checkout\", () => {\n  // Arrange\n  const cart = new Cart();\n  cart.add(1000);\n\n  // Act\n  cart.checkout();\n\n  // Assert\n  expect(cart.getState()).toBe(CartState.CheckedOut);\n});\n```\n\n### 責務ごとにテストの深さを調整する\n\n単体テストでも結合テストでも、対象の責務に合わせて深さを決めます。\n1つの関数で他のモジュールを呼ぶ場合、呼び出し先の詳細まで二重にテストする必要はありません。\n例としてバリデーション関数とそれを利用する送信関数を考えます。\n\n```ts\n// バリデーション関数\nexport const isValidEmail = (email: string): boolean => {\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n  return emailRegex.test(email);\n};\n\n// それを使用した関数\nexport const sendEmail = (email: string): boolean => {\n  if (!isValidEmail(email)) {\n    throw new Error(\"Invalid email\");\n  }\n  // メール送信処理\n  return true;\n};\n```\n\nこのとき \"sendEmail\" のテストで \"isValidEmail\" の全パターンを再度検証する必要はありません。\n\"sendEmail\" では「有効なら送る」「無効ならエラーを投げる」ことを確認し、\"isValidEmail\" の細かい条件は別のテストで保証します。\n\n```ts\n// sendEmail のテストコード\nit(\"should send email when email is valid\", () => {\n  // Arrange\n  const validEmail = \"test@example.com\";\n\n  // Act\n  const result = sendEmail(validEmail);\n\n  // Assert\n  expect(result).toBe(true);\n});\n\nit(\"should throw error when email is invalid\", () => {\n  // Arrange\n  const invalidEmail = \"invalid-email\";\n\n  // Act & Assert\n  expect(() => sendEmail(invalidEmail)).toThrow(\"Invalid email\");\n});\n```\n\n```ts\n// isValidEmail のテストコード\nit.each`\n  email                 | expected\n  ${\"test@example.com\"} | ${true}\n  ${\"invalid-email\"}    | ${false}\n`(\"should return $expected for email: $email\", ({ email, expected }) => {\n  // Act\n  const result = isValidEmail(email);\n  // Assert\n  expect(result).toBe(expected);\n});\n```\n\n### テスト警告を潰す習慣を持つ\n\nテスト実行時に流れる警告は放っておかないでください。\n原因によっては環境によって落ちるフレークテストの兆候です。\nログに黄色い行が残ったら、まず警告の出所を突き止めて解消する習慣を付けましょう。\n\n## 終わりに\n\nテストコードは「読み手に何を伝えたいか」を意識すると自然と整っていきます。\nAAA で流れを揃え、愚直に書き、言葉とアサートを丁寧にするだけで再読性はぐっと上がります。\n明日以降の自分やチームが迷わないよう、今回紹介した工夫を少しずつ取り入れてみてください。","publishedAt":"2025-10-20","slug":"unit-test-writing-guidelines","title":"単体テストコードのお作法"},{"body":"最近、Mac 向けに画面と自分の姿を同時に記録する VLog アプリを Tauri で作りました。\n開発の背景やつまずき、乗り越えた工夫を振り返ります。\nソースコードと署名なしの `.dmg` は GitHub に置いています。\n\nhttps://github.com/silverbirder/vlog\n\nアプリの雰囲気が伝わるように、スクリーンショットを 2 枚載せておきます。\n\n![VLog アプリのホーム画面](https://res.cloudinary.com/silverbirder/image/upload/v1759582696/silver-birder.github.io/blog/vlog-intro-1.png)\n\n起動直後のホーム画面です。保存先や自動停止時間などをここで設定できます。\n\n![録画中の VLog アプリと PiP 表示](https://res.cloudinary.com/silverbirder/image/upload/v1759582703/silver-birder.github.io/blog/vlog-intro-2.png)\n\n録画中はこのように ピクチャ・イン・ピクチャ (PiP) でカメラ映像を前面に固定しながら、画面全体をキャプチャします。\n\n## 背景\n\nYouTube や TikTok を見て、日常を短い動画で残す VLog 文化があることを知りました。\n私は自分で書いたブログ記事を読み返したり、自分が歩いた記録が残る Google マップのタイムラインや撮りためた Google フォトのアルバムを眺めたりして、**過去を振り返る時間が好きです**。\n「動画でも記録しておけたら面白そうだな」と思ったのが、今回の起点でした。\n\n日々の大半は自宅で過ごし、パソコン作業の時間が長いです。\nそれなら **Mac の画面と自分の姿を同時に録画できるデスクトップアプリを自作しよう** と決めました。\n\n## 技術選定の迷いと Tauri 採用\n\n当初は経験のある Electron を使うつもりでした。\nしかし、公式の React テンプレートが無かったり、Electron Fiddle がうまく動かなかったり、`npm install electron` が通らなかったりと、序盤からストレスが溜まり始めました。\n過去にも同じような壁に当たった記憶があったので、Electron で進む気持ちは一気にしぼみました。\n\nそこで思い出したのが、以前にメジャーアップデートのニュースで見かけた Tauri です。\nモバイル対応は検討していませんでしたが、デスクトップアプリを作れるし、React テンプレートも整備されています。\nクイックスタートをなぞるだけで数分後には開発環境が整い、`.dmg` ビルドまで一気に到達できました。\n「これなら作り切れそうだ」と実感し、Tauri 採用を決めました。\n\n## 動画保存まわりの試行錯誤\n\n録画には Web API の `MediaDevices.getDisplayMedia()` と `MediaDevices.getUserMedia()` を使いました。\n`getDisplayMedia` が画面キャプチャ、`getUserMedia` がカメラ映像の取得を担当します。\n\n最初は、取得した映像チャンクをフロントエンドで蓄積し、録画停止時にまとめて Rust 側へ送る構成を採用しました。\n保存するのはスクリーン録画 (mp4)、カメラ映像 (mp4)、マイク音声 (m4a) の 3 ファイルです。\nAI Agent に下書きしてもらったコードがそのまま動いたので、早速録画してみました。\nところが、完成した動画は冒頭の数分だけが動き、その後は静止画になっていました。\nチャンク処理をフロントエンドで抱えきれず、途中で詰まってしまったようです。\n\n次に、Rust 側で直接キャプチャする方法を調査しました。\nただしネイティブ API に踏み込む必要があり、理解コストが高そうだったので見送りました。\n\nそこで **フロントエンドでチャンクを保持せず、取得したデータを即座に Rust 側へ送り、ファイルに追記する** 方式へ切り替えました。\n結果として、録画が途中で止まる問題は解消され、停止ボタンを押すだけで保存が完了するようになりました。\n\n## 欲しかった機能を揃える\n\n使い続けるうちに、次のような要望が浮かびました。\n\n- 一定時間で自動停止したい\n  - ずっと録画し続けるのではなく、15 分や 30 分で区切りたい\n- 停止に気づける通知が欲しい\n  - 集中していると録画状態を忘れるので、自動停止時に気づきたい\n- カメラやマイクを切り替えたい\n  - 外付けデバイスを接続したときに選択したい\n- 停止後にすぐ再開したい\n  - 録画停止と開始を繰り返す操作を簡単にしたい\n\nこれらを一つずつ実装し、特に使っていなかったマイク録音は機能ごと削除しました。\n余計な設定が消えて、アプリ全体の使い心地が軽くなった感覚があります。\n\n## PiP をどう実現したか\n\nスクリーンとカメラを別々に保存していると、見返すときに視線が忙しく感じました。\nそこで PiP のような、スクリーン上にカメラの映像を重ねて録画する方法を探りました。\n\nまずはフロントエンドでスクリーンとカメラの映像を合成し、単一の動画として保存する方式を試しました。\nところが処理が重く、FPS が落ちてカクつきが目立ったため断念しました。\n次に、録画後に ffmpeg で合成する案も検討しましたが、15 分の動画でも処理時間が長く、運用したい気持ちになれませんでした。\n\n最終的にたどり着いたのは、**録画中にカメラ映像を常に前面表示し、そのままスクリーン録画に写し込む** というシンプルな方法です。\nリアルタイム合成も後処理も不要で、狙い通りの PiP 動画が撮れるようになりました。\n唯一の課題は、VS Code などをフルスクリーン表示すると PiP ウィンドウを最前面に固定できないことです。\n今はフルスクリーンを控えることで運用しています。\n\n## おわりに\n\nReact の “Learn Once, Write Anywhere” というスローガンがありますが、Tauri でも同じ感覚でデスクトップアプリを作れたのが嬉しいポイントでした。\n今回は Rust 側の実装を最小限に抑え、フロントエンドの改善に注力したことで、迷子にならずにリリースまでたどり着けました。\n\nTauri はデスクトップやモバイル、Web までを React の知識でカバーできる仕組みがすでに整っています。\nひと昔前なら Electron と React Native、さらに React Native for Web を組み合わせていた場面が、一つの選択肢にまとまるイメージです。\n今後も Tauri を使って、日常を記録するためのツールを少しずつ育てていきたいと思います。","publishedAt":"2025-10-04","slug":"tauri-vlog-app-development","title":"Tauri でつくる自分用 VLog アプリ開発記"},{"body":"Google マイアクティビティの履歴をブラウザだけで分析したくて、DuckDB WASMとOrigin Private File System (OPFS) を組み合わせた Web アプリを作りました。\nこの記事ではアプリの紹介は軽めに、ブラウザ完結のデータ基盤をどう構成したのかを中心に振り返ります。\n開発したアプリとソースコードは、以下になります。\n\n- https://actviz.vercel.app\n- https://github.com/silverbirder/google-myactivity-visualization\n\n## アプリのざっくり紹介\n\n[Google Takeout](https://takeout.google.com/settings/takeout) からエクスポートしたマイアクティビティの ZIPファイル をアプリにアップロードすると、ブラウザ内で以下の可視化を眺められます。\n\n- 検索キーワードのワードクラウド\n- 月別のアクティビティヒートマップ\n- 時間帯ごとの行動パターン\n- 位置情報ベースのマップ表示\n\nサーバーへは何も送らず、データは手元のブラウザに閉じたまま。  \nGoogle が保持している元データは [My Activity](https://myactivity.google.com/myactivity) で確認できます。\n\n## DuckDB WASMを選んだ理由\n\n6年前に Chrome の検索履歴でワードクラウドを作ったときは、ブラウザの何かしらのStorageに入れていました。\n\n- https://github.com/silverbirder/google-word-cloud\n- https://github.com/silverbirder/searchWordCloud\n\n当時の実装はもう覚えていませんが（笑）、いまならブラウザだけでどこまでやれるのか試したくなりました。\nブラウザにDBを持つという[素人が参院議員の議案賛否検索サイトを作ってみた - zenn](https://zenn.dev/midorisawa07/articles/7b6b24a46925fd)を読んでいたこともあり、\n「DuckDB WASM ならローカル DB をそのまま扱えそう」と感じたのがきっかけです。MySQL など他の選択肢も考えたものの、個人開発なので気になった技術を試しました。\n\n## 技術スタックの前提\n\nアプリは手慣れている [T3 Stack](https://create.t3.gg/) で構築しています。\nNext.js は既存知識で片付け、今回はブラウザ内データ基盤の検証に集中しました。\n\n## DuckDBとOPFSを繋いだ初期化\n\nDuckDB WASM は npm の `@duckdb/duckdb-wasm` パッケージを利用します。\nバンドルされた `duckdb-eh.wasm` とワーカーを `public/` に配置し、初期化時に手動で読み込みます。\n\n```ts\n// src/contexts/duck-db/duck-db.hook.ts\nimport * as duckdb from \"@duckdb/duckdb-wasm\";\n\nconst MANUAL_BUNDLES = {\n  mvp: {\n    mainModule: \"/duckdb-eh.wasm\",\n    mainWorker: \"/duckdb-browser-eh.worker.js\",\n  },\n};\n\nconst bundle = await duckdb.selectBundle(MANUAL_BUNDLES);\nconst worker = new Worker(bundle.mainWorker!);\nconst db = new duckdb.AsyncDuckDB(new duckdb.ConsoleLogger(), worker);\n\nawait db.instantiate(bundle.mainModule, bundle.pthreadWorker);\nawait db.open({\n  path: \"opfs://google-myactivity-visualization.db\",\n  accessMode: duckdb.DuckDBAccessMode.READ_WRITE,\n});\n```\n\n`opfs://` を指定すると DuckDB 側が OPFS 上のデータベースファイルを面倒見てくれるので、ページをリロードしてもテーブルが残ります。\n今回、OPFS自体の操作はDuckDB WASM側で処理されていて、Web APIを直接叩いていませんが、以下のドキュメントは一読しておきました。\n\n- [オリジンプライベートファイルシステム - Web API | MDN](https://developer.mozilla.org/ja/docs/Web/API/File_System_API/Origin_private_file_system)\n\n上記ドキュメントから、OPFS は HTTPS が前提と知り、ローカル開発は `next dev --experimental-https` で起動しました。\n\nアプリ側ではこの初期化処理を React Context に閉じ込め、`runQuery` などのユーティリティ経由で DuckDB を参照します。\n\n```ts\n// src/contexts/duck-db/duck-db.hook.ts\nexport const runQuery = async (query: string) => {\n  const conn = await db.connect();\n  try {\n    const result = await conn.query(query);\n    return result.toArray();\n  } catch (err) {\n    const message = err instanceof Error ? err.message : String(err);\n    throw new Error(`Query failed: ${message}`);\n  } finally {\n    await conn.close();\n  }\n};\n```\n\nReact Context から `runQuery` を各コンポーネントに渡すことで、ビュー側からは SQL を書くだけで済む形にしました。\n\n## SQLはファイルで管理\n\n集計ロジックは SQL ファイルとして切り出し、インポートしています。\n\n```sql\n-- sample.sql\nSELECT *\nFROM activities\nLIMIT 10;\n```\n\n```ts\n// SomeComponent.tsx\nimport sampleSql from \"./sample.sql\";\n\nconst rows = await runQuery(sampleSql);\n```\n\nSQL をファイルとして保存しておくとフォーマッタをかけやすく、差分レビューもしやすいので気に入っています。\nブラウザ内で完結するプロダクトでも、サーバーサイドと同じく SQL を直接管理できるのが地味に嬉しいポイントでした。\n\n## ZIP/JSONをブラウザ内で取り込む\n\nGoogle Takeout の ZIPファイル をドラッグ＆ドロップすると、ZIPファイル を展開した JSONファイル を `registerFileText` 経由で DuckDB に登録します。\nDuckDBにデータを取り込むには、2つのステップを踏みます。\n\n1. `registerFileText` で、ローカルファイルシステムにデータをインポートします。\n1. SQLを実行して、テーブルに挿入します。\n\n他の方法については、以下のドキュメントを参考になります。\n\n- [Data Ingestion – DuckDB](https://duckdb.org/docs/stable/clients/wasm/data_ingestion.html)\n\n私は、以下のように実装しました。\n\n```sql\n-- create_activities.sql\nCREATE TABLE IF NOT EXISTS activities AS\nSELECT\n  json_extract_string(json, '$.title') AS title\nFROM read_json_objects('__PATH__');\n```\n\n```sql\n-- insert_activities.sql\nINSERT INTO activities\nSELECT\n  json_extract_string(json, '$.title') AS title\nFROM read_json_objects('__PATH__');\n```\n\n```ts\n// handleFile.ts\nimport createActivitiesSql from \"./create_activities.sql\";\nimport insertActivitiesSql from \"./insert_activities.sql\";\n\nconst path = `mem://activities_${Date.now()}.json`;\nconst jsonText = JSON.stringify(activities);\n\nawait db.registerFileText(path, jsonText);\n\nconst escapedPath = path.replaceAll(\"'\", \"''\");\nawait runQuery(createActivitiesSql.replace(\"__PATH__\", escapedPath));\nawait runQuery(insertActivitiesSql.replace(\"__PATH__\", escapedPath));\n```\n\nSQLファイル側では`'__PATH__'`のようにシングルクォート付きでプレースホルダを置いておき、最後にエスケープ済みのパスを差し込む形にしています。\n\n`read_json_objects`を使うと巨大な配列もうまく処理してくれるので、150MB超の履歴でもブラウザが固まらずに済みました。\nZIP内のJSONは1件ずつ進捗を出しながら挿入しているので、待ち時間の不安も軽減されています。  \n挿入後は`db.flushFiles()`でメモリ上の一時ファイルを掃除しておくと安心です。\n\n## データ削除とデバッグメモ\n\n全データを消したいときは `TRUNCATE TABLE activities;` を投げてリセットしています。\n念のため `db.reset()` も呼んで DuckDB WASM の状態をリフレッシュする運用です（理由は体験ベース）。\n\nDevTools の Application タブでは OPFS のファイルを削除できなかったので、`chrome://settings/content/siteDetails?site=...` からストレージをクリアしています。\n\n## ブラウザで SQL を書く楽しさ\n\nブラウザ上の DuckDB に対して SQL をそのまま流し込める体験は、なかなか新鮮なものでした。\nレイテンシはほぼ感じないので 「自分のマシンで分析している」 感覚が強く、SQL を書くのが好きな身としてはかなり楽しい時間でした。\nアプリ内には簡易的な SQL Viewer も用意してあり、クエリをその場で投げて結果を確認できるようにしています。\n\n## おわりに\n\nDuckDB WASM と OPFS を使ってみたのは初めてでしたが、セットアップさえ乗り越えればブラウザ完結でも十分に分析体験を作れると実感しました。\nまた一つ、世界が広がりました。","publishedAt":"2025-09-17","slug":"google-my-activity-visualization","title":"DuckDB WASMとOPFSでGoogleマイアクティビティをブラウザ完結で可視化してみた"},{"body":"こんにちは、[@silverbirder](https://x.com/silverbirder) です。最近、湖県に移住してWebフロントエンドのお仕事をしています。\nお仕事をしていると、ユーザー体験を良くするためには、大きな改善をせずとも小さな改善だけでも十分な効果があると思い始めました。\n本記事では、その小さな改善となる、3つのことについて書きたいと思います。\n\n## 3つのこと\n\nその小さな改善は、Webの世界に必ず存在する、以下の3つの要素を丁寧に扱うことです。\n\n- マイクロコピー\n  - 小さな文章\n- マイクロインタラクション\n  - 小さな操作\n- リンク\n  - 導線・動線\n\nあるライブラリやフレームワークの話ではありません。Webの基本的な要素です。\nそれぞれについて、私の考えていることをまとめます。\n\n## マイクロコピー\n\nWeb には、必ずと言っていいほどテキストが表示されています。\n例えば、以下のテキストがあります。\n\n- ボタンのラベル\n- 入力フォームのプレースホルダー\n- リンク\n- エラーメッセージ\n- 説明文\n\n考え出すと、いくらでも列挙できるかと思います。それぐらい、Web にはテキストがほぼ必ず存在します。\nこのような、小さな文章（コピー）をマイクロコピーと呼びます。\n\nこのマイクロコピーは疎かにしてはいけません。\nJavaScriptでプログラムを書くのと同じぐらい、文章を書くことも大事です。\nなぜ大事かというと、1つの文章次第でユーザー体験が大きく変わるからです。文章の書き方一つで、購買率などの指標にも大きく影響します。\nいくつか、例を書いていました。多くの場合、Bの方が良いかと思います。\n\n- 購入ボタンのラベル名\n  - A: 購入\n  - B: 注文を確定する\n- 返品手続きの案内\n  - A: 返品理由を入力してください\n  - B: 返品理由を教えていただければ、今後の改善に活かします\n- 画像のアップロード\n  - A: ファイルを選択\n  - B: 画像は 5MB 以内。jpg / png に対応\n\n上記について、**何かの機能を作るのではなく、文章を変えているだけ** なんです。\n文章を書くという小さなコストで、ユーザー体験が大きく変わる、非常に費用対効果の高い施策ですよね。\n\nただ、文章を書くにもコストがかかります。\n文章を書くテクニック（コピーライティング）は書籍で様々紹介されているかと思いますが、私は恥ずかしながら知りません。\n知らない私でも、いつも以下について意識するように心掛けています。\n\n- 文章を書くことに躊躇わない\n  - 短くてストレートに伝わる文章を書ければよいですが、最初からできないです。\n  - 伝えたい文章をストレートに書いてみて、そこから削るようにしています。\n  - デザイン上のスペースが限られている場合や、文章ばかりで窮屈に感じるときは、工夫しましょう。\n- ユーザー視点と言うが、具体を意識する\n  - どういう動線で当該ページに辿り着いたのか、実際に操作したり画面画像を並べてみる。\n  - アクセス経路やデータは、できる限り本物にする。\n  - できる限り、シンプルな具体に落とし込む。\n- メタファーに頼りすぎない\n  - アイコンだけで完結せず、アイコンは補助的に文章をメインに考える。\n  - アイコンだけであっても、ツールチップなどで補足する。\n- 文章の読み手だけでなく、誰が書いているのか意識する\n  - システムが機械的なトーンで書いているのか、人が寄り添って書いているのか。\n  - その結果、トーンや言い回しが揃う。\n\n他には、専門用語を使わない、1文を簡潔に書く、ポジティブな表現で書くなどもありますが、粗末なことです。\nまずは、**文章を書くことに躊躇わない** ことが大事と考えています。\n\n文章を書かずにアイコンやアニメーション、インタラクションの振る舞いだけでメッセージを伝えようとする\nスタイリッシュなUIを見かける機会が増えました。コンセプトやサービス形態によってはそれが良い場面も多いかと思います。\nしかし、Web というドキュメントを読んでもらうプラットフォームでは、文章で伝えることが最も確実です。\n\n## プログラムを書くより、文章を書こう\n\n## マイクロインタラクション\n\n- チェックボックスをクリックしたら、チェックマークが入ります。\n- トグルボタンをクリックしたら、ON/OFFが切り替わります。\n\nそういう、何か操作したら（トリガーを発火したら）何かフィードバックを得る、これがインタラクションと呼ばれます。\nインタラクションは、ユーザーとシステムのやり取り、相互作用のことです。\nそのインタラクションの最小単位を、マイクロインタラクションと呼びます。\n\nWebフロントエンドのお仕事をしていると、マイクロインタラクションを作る機会が多いです。\n一例だと、『何かをクリックしたら、（APIが呼ばれてデータが保存されて）メッセージが表示される』などです。\n\nマイクロインタラクションを作る際、**フィードバックを疎かにしてはいけません**。\n例えば、以下のようにフィードバックを疎かにすると、ユーザーは不安になります。\n\n- いいねボタンをクリックしても、最初の1秒間 何も反応しない\n  - 即座にいいねの数をカウントアップしてほしい\n- フォームの保存ボタンをクリックしても、保存できないときがある\n  - 保存できなかった原因を表示してほしい\n- ローディングスピナーが3秒以上ずっと、読み込み中のまま\n  - 進捗状況を表示してほしい\n- リストの並び替え時、どこが並び替わったか分からない\n  - 並び替えたアイテムの位置を示してほしい\n\nマイクロインタラクションの悪い例の一つは『iPhoneをマナーモードにしても、アラームが鳴ること』です。\n音を鳴らさないマナーモードにしたのに、アラームでは音が鳴るのです。\n\nそもそも、マイクロインタラクションとは、どのような構成をしているのでしょうか。\nそれは、以下の構成で表現されます。\n\n- トリガー\n  - 動きを始めるきっかけ。\n  - 例: クリック。\n- 条件\n  - 実行するための前提。\n  - 例: ログイン中。\n- フィードバック\n  - 操作への返答。\n  - 例: 送信中…表示。\n- ループ\n  - 繰り返し続くか。\n  - 例: アラーム時間まで繰り返す。\n\niPhoneの例でいうと、2番の条件にアラームは除外されるのです。それがユーザーにとって不透明なのです。\n\n私は、**些細なことでも良いので、フィードバックを必ず返す** ことを意識しています。\n\n- ボタンをクリックした瞬間にラベルが「送信中…」へ変わる\n- 二重送信を防ぐためボタンが一瞬無効化される\n- フォーム送信後、エラーがある箇所へ自動スクロール\n- 入力完了したら✓アイコンが表示される\n- コピー完了時に「コピーしました」と小さくトースト表示する\n- 入力中の文字数カウントが増える\n- ホバーした行の背景色が変わる\n- リストが空なら「まだデータがありません」と表示\n- 長文入力で自動的に高さが広がる\n\nこの細部のマイクロインタラクションを丁寧に作り込むことで、他と差別化できるポイントになると思います。\nマイクロインタラクションを丁寧にすることで **『神は細部に宿る』** のです。\n\n## リンク\n\nWeb は、ハイパーテキストを介して様々なページが繋がっています。\nリンクは、Web の基本的な要素です。\n\nWebフロントエンドのお仕事では、導線をどのように設計するか考える機会が多いです。\nどのように回遊してもらうか、どのように離脱を防ぐか、意図せず行き止まりにならないか などを考えます。\n\n**リンクは、ページとページをつなぐ架け橋です**。\nもしリンクが以下のような場合、ユーザーは道に迷うかもしれません。\n\n- 目的地へ直線的に行けるリンクがなく、経由地を何度も通らされる\n- リンクが一切なく、行き場を失って離脱してしまう\n  - 逆に、リンク数が多すぎてどれを選んだらよいか分からない\n- リンク先の内容とリンクテキストが一致しない\n- 退会などの重要ページへのリンクが、隠されている\n- 前に進むリンクはあるけど、戻るリンクはない\n\n道の迷わないためにも、以下のことを心がけたいですね。\n\n- リンクは、標準的なスタイルにする\n  - アンダーライン、色\n  - テキストは、コンテンツ内容を含める\n  - 異なるドメインの場合は、新しいタブで開く。\n- ナビゲーションを充実させる\n  - グローバルヘッダー・フッターの主要ページへのリンク\n  - サイドバーに補足・関連情報へのリンク\n  - ページの階層構造を示す パンくず\n  - コンテンツの関連リンク・おすすめリンク\n  - エラー画面での問い合わせやFAQリンク、トップページリンク\n  - データが空のときのアクションリンク\n\n## 終わりに\n\n短くまとめると、マイクロコピー、マイクロインタラクション、リンクの3点は、小さいけれど重要です。\n文章、操作、リンクを少し変えるだけで、ユーザー体験は確実に良くなります。\n\nここまで読んでいただき、ありがとうございました。","publishedAt":"2025-08-27","slug":"microcopy-microinteractions-and-links","title":"マイクロコピー、マイクロインタラクション、そしてリンク"},{"body":"こんにちは。\n先日、ちょっとしたきっかけでStorybookのアドオンをはじめて開発しました。\n本記事では、そのStorybookのアドオン開発の体験を共有したいと思います。\n\n## 開発したアドオン\n\nstorybook-addon-range-controls というアドオンを開発しました。\nnpmで公開しています。\n\n- https://www.npmjs.com/package/storybook-addon-range-controls\n\nこのアドオンは、端的にいうと Storybook上で、**コンポーネントの文字列・数値・配列の引数を、スライダーでデータ増減できるアドオン** です。\n作ろうと思ったきっかけは、StorybookのArgTypesでrangeの値を使って、**データ増減に伴うデザイン崩れをチェック** していたのですが、\n配列のスライダーをするのに少しだけコードを書く手間があり、もっと簡単にできないかというのがきっかけです。\n\nデモは、以下のリンクで公開していますので、気になる方はぜひ触ってみてください。\n\n- https://develop--689dd119bb72c220c0ddb738.chromatic.com\n\nこのアドオンを作るために、何をしたのかを振り返ります。\n\n実装したコードベースは、以下で公開していますので、よければご参考ください。\n\n- https://github.com/silverbirder/storybook-addon-range-controls\n\n## アドオンキット\n\nまず、Storybookのアドオンってどうやって作るのか、作った経験がない私にはわからなかったので、\n以下のStorybookのドキュメントを読みました。\n\n- https://storybook.js.org/docs/addons/writing-addons\n\n読んでいると、以下のアドオンキットがあることに辿り着きました。\n\n- https://github.com/storybookjs/addon-kit\n\nこれは、Storybookのアドオン開発に必要なものが最低限揃っていて、最初のとっかかりにはちょうどよかったです。\n\n## アドオンの種類\n\nアドオンキットを読んでいると、以下の3つの種類のアドオン開発があることを知りました。\n\n- パネル\n- ツール\n- タブ\n\n3つの種類についての説明は、以下の公式ページがわかりやすいです。\n\n- https://storybook.js.org/docs/addons/addon-types\n\n今回、私がなんとなく想像していたのはパネルだったので、今回はパネルを使ってみることにしました。\n\n## パネル開発\n\nアドオンキットでは、開発するアドオンを組み込んだStorybookを起動できる（npm run start）ようになっていて、起動させたStorybook上でアドオンの実装を進めていきます。\n\nアドオン開発には、さまざまなAPIが用意されており、公式のドキュメントが参考になります。\n\n- https://storybook.js.org/docs/addons/addons-api\n\n例えば、表示しているStoryのparamtersやargsを取得するhooksなどがあります。\n以下は、私が利用したhooksのコード例です。\n\n```tsx\nimport React, { memo } from \"react\";\nimport type { RangeControlsParameters } from \"src/types\";\nimport { useParameter, useArgs } from \"storybook/manager-api\";\nimport { useTheme } from \"storybook/theming\";\n\nimport { KEY } from \"../../constants\";\n\ntype Props = {\n  active: boolean;\n};\n\nexport const Panel = memo((props: Props) => {\n  const config = useParameter<RangeControlsParameters>(KEY, {});\n  const theme = useTheme();\n  const [args, updateArgs] = useArgs();\n\n  return (<>...</>);\n});\n```\n\nまた、パネルのUI開発には、以下にあるように、コンポーネントやスタイルなどが用意されています。\n\n- コンポーネント一覧\n  - https://github.com/storybookjs/storybook/blob/da8cf2095bfde31267c11652a5f18deb4c48e192/code/core/src/components/README.md\n  - emotionを使ってスタイルを書きます\n- スタイル一覧\n  - https://github.com/storybookjs/storybook/blob/da8cf2095bfde31267c11652a5f18deb4c48e192/code/core/src/theming/README.md\n  - ダークモードの対応も可能です\n\n上記のコンポーネントやスタイルにあるタイポグラフィやカラー、スペーシングなどを使うだけなので、\nゼロから作り上げるということはありません。また、ダークテーマの対応もできます。\n\n以下は、私が実装したパネルのコード例です。\nemotionを使ったことがある人なら、理解しやすいコードかと思います。\n\n```tsx\n// PropControl.styles.ts\nimport { Badge } from \"storybook/internal/components\";\nimport { styled, typography } from \"storybook/theming\";\n\nexport const StyledDetails = styled.details`\n  border: 1px solid\n    ${({ theme }) =>\n      theme.base === \"dark\" ? theme.color.dark : theme.color.border};\n  margin-bottom: ${({ theme }) => theme.layoutMargin}px;\n  background: ${({ theme }) => theme.color.lightest};\n`;\n\nexport const StyledSummary = styled.summary`\n  padding: ${({ theme }) => theme.layoutMargin}px;\n  cursor: pointer;\n  font-weight: ${typography.weight.bold};\n  font-size: ${typography.size.s2}px;\n  display: flex;\n  align-items: center;\n  justify-content: flex-start;\n  color: ${({ theme }) => theme.color.defaultText};\n  background: ${({ theme }) => theme.background.content};\n\n  &:hover {\n    background: ${({ theme }) =>\n      theme.base === \"dark\" ? theme.color.darker : theme.color.lighter};\n  }\n`;\n\nexport const SummaryBadge = styled(Badge)`\n  margin-left: auto;\n`;\n```\n\n## リリース\n\nnpmへの公開は、アドオンキットにあるGitHub Actionsの release.yml をほとんどそのまま使いました。\n必要なAPIトークンは、[README](https://github.com/storybookjs/addon-kit)に書いてあるので、その通りにやれば大丈夫です。\n\n## デモ\n\nアドオンの使い方を示すためにデモが欲しかったので、Chromaticのサービスを使用しました。\n\n以下のURLにデモを公開しています。\n\n- https://develop--689dd119bb72c220c0ddb738.chromatic.com\n\n## 困ったこと\n\n### ホットリロードが効かない\n\n以下のaddon-kitのissueにもあるように、ホットリロードがうまく動かないことがありました。\n\n- https://github.com/storybookjs/addon-kit/issues/49\n\nそのため、開発中はコード修正してリロードを繰り返していました。ちょっと面倒でしたね。\n\n### パラメータに関数を渡せない\n\nStorybookのParametersに関数を設定したとしても、useParameterでは関数が取得できません。\nJSONシリアライズの関係かと思います。\n\n少し強引なやり方かもしれませんが、プレビューのデコレータからだと、パラメータに関数がまだ残っているため、そのデータをパネルへ渡すようにしました。\n\n以下のように、プレビューのデコレータで、関数入りパラメータを独自シリアライズをし、パネルではそのデータを取得するようにしました。\n\n```tsx\n// withGlobals.ts\nimport type {\n  Renderer,\n  StoryContext,\n  PartialStoryFn as StoryFunction,\n} from \"storybook/internal/types\";\nimport { useEffect, useChannel } from \"storybook/preview-api\";\nimport { EVENTS, KEY } from \"./constants\";\nimport { serializeFunctions } from \"./utils/serialize\";\n\nexport const withGlobals = (\n  StoryFn: StoryFunction<Renderer>,\n  context: StoryContext<Renderer>,\n) => {\n  const emit = useChannel({});\n\n  useEffect(() => {\n    const params = context.parameters?.[KEY];\n    if (params) {\n      const serialized = JSON.stringify(serializeFunctions(params));\n      emit(EVENTS.PARAMETERS_SYNC, serialized);\n    }\n  }, [context.id, context.parameters]);\n\n  return StoryFn();\n};\n```\n\n```tsx\n// preview.ts\nimport type { ProjectAnnotations, Renderer } from \"storybook/internal/types\";\n\nimport { KEY } from \"./constants\";\nimport { withGlobals } from \"./withGlobals\";\n\nconst preview: ProjectAnnotations<Renderer> = {\n  decorators: [withGlobals],\n  initialGlobals: {\n    [KEY]: false,\n  },\n};\n\nexport default preview;\n```\n\n```tsx\n// Panel.tsx\nimport React, { memo } from \"react\";\nimport type { RangeControlsParameters } from \"src/types\";\nimport { useChannel } from \"storybook/manager-api\";\n\nimport { EVENTS } from \"../../constants\";\nimport { reviveFunctions } from \"../../utils/serialize\";\n\ntype Props = {\n  active: boolean;\n};\n\nexport const Panel = memo((props: Props) => {\n  useChannel({\n    [EVENTS.PARAMETERS_SYNC]: (serialized: string) => {\n      try {\n        const parsed = JSON.parse(serialized);\n        const revived = reviveFunctions<RangeControlsParameters>(parsed);\n        // Do something with the revived parameters\n      } catch (e) {\n        console.error(\"Failed to deserialize parameters\", e);\n      }\n    },\n  });\n\n  return (<>...</>);\n});\n```\n\n## 最後に\n\nStorybookのアドオン開発って、どれぐらい難しいのかなと思ったのですが、\nアドオンキットのおかげで、思ったよりも簡単に開発できました。\nコンポーネントやスタイルも整っているし、リリースも簡単にできましたし、素晴らしいエコシステムだなと思います。","publishedAt":"2025-08-20","slug":"storybook-addon-range-controls","title":"はじめてのStorybookアドオン開発体験記"},{"body":"こんにちは。CSSは苦手ですか？私は苦手でした。\n苦手でしたが、実務を経験していくうちに、だんだんとできる範囲が増えていき楽しくなってきました。\n\n本記事では1つのサンプルページを見ながら、CSSをどう考えて使っているのか解説したいと思います。\n読者の皆さんの、CSSに対する苦手意識が少しでも克服できれば幸いです。\n\nサンプルページのセクションごとに独立して解説しているので、読みたいところだけ読んでくださいね。\n\n## サンプルページ\n\nサンプルページは、以下のURLにあります。\n\n- https://learn-layout.vercel.app\n\n[![サンプルページ](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-hero-laptop.png)](https://learn-layout.vercel.app)\n\nサンプルページのソースコードは、以下のリポジトリにあります。\n勉強のお供に、お手元にダウンロードしておいてください。\n\n- https://github.com/silverbirder/learn-css\n\nHTMLとCSSのみで作成しているため、ブラウザさえあればすぐに動かすことができます。\nまた、JavaScriptは一切使用していません。\n\n### サンプルページの内容\n\nこのサンプルページは、よくあるSaaSのランディングページを想定しています。\nサービス名は「CSS AI」で、AI駆動のCSSスタイリングプラットフォームを提供する架空のサービスです。\nこのサンプルページのセクションは、以下のとおりです。\n\n- ヒーローセクション\n  - 「CSS AI」のタイトル・サブタイトル・説明文・ボタンを画面全体に大きく表示\n- 主要機能セクション\n  - 6つの機能をアイコン・タイトル・説明文でカード形式で紹介\n- 対応技術セクション\n  - GPT-4やClaudeなど複数の技術タグを横並び表示\n- デモセクション\n  - 左側にデモ動画、右側に3ステップの使用手順を解説\n- お客様の声セクション\n  - 複数のレビューカードを横スクロール可能な形で表示\n- 料金プランセクション\n  - スターター・プロ・エンタープライズの3つのプランを比較表示\n\nどれも、よくあるランディングページのセクションだと思います。\n\n### サンプルページで学べること\n\n個人の感想ですが、CSSを使って楽しくなってきたと実感したのは、**FlexboxやGridを使ったレイアウトができる** ようになった頃からです。\nテキストや画像を思い通りの場所に配置できるようになると、楽しくなってきたのです。\n\nサンプルページでは、[Every Layout](https://every-layout.dev/) を参考にしていて、よくあるレイアウトパターンを取り入れています。\n各セクションでは、以下のレイアウトを学ぶことができます。\n\n- ヒーローセクション\n  - タイトル、サブタイトル、説明文、ボタンを上下左右中央に配置しています。\n- 主要機能セクション\n  - 主要機能を2行3列で表示し、横幅が狭くなると列数が減るようにしています。\n- 対応技術セクション\n  - 技術タグを横に並べ、横幅が狭くなると折り返して表示するようにしています。\n- デモセクション\n  - 横幅が広いときは動画と説明を横に並べ、狭くなると動画が上、説明が下に落ちるようにしています。\n- お客様の声セクション\n  - レビューカードを横に並べ、横幅が狭くなると横スクロールできるようにしています。\n- 料金プランセクション\n  - 3つのプランを横並びにしつつ、ブラウザの横幅が狭くなると縦に並ぶようにしています。\n\nまた、本記事では解説しませんが、以下のコンテンツもあります。気になる方がいましたら、ぜひ[サンプルページのリポジトリ](https://github.com/silverbirder/learn-css)を覗いてみてください。\n\n- グローバルヘッダー\n  - 画面上部にヘッダー固定\n  - ある程度の横幅になると3本線のハンバーガーメニューに切り替わる\n- 画面上部に戻るボタン\n  - 画面右下に、固定で配置\n\nぜひ、さまざまなブラウザサイズで確認してみてください！\n\n### サンプルページで学ばないこと\n\n学ばないことについて明記しておきます。\n\n**私がCSSの苦手意識になった1つが、CSSプロパティの多さです**。\nたくさんあるCSSプロパティの中から、どれを使ったら良いのか、正直使いこなせるとは思いませんでした。\n\nそこで、本記事ではレイアウトに関する以下のCSSプロパティを使います。\n各CSSプロパティのリンクは、MDN Web Docs（以降、MDNと呼称）のページを参照しています。\nサンプルページのCSSを読むときに、下記のMDNリンクを活用してくださいね。\n\n- [display](https://developer.mozilla.org/ja/docs/Web/CSS/display)\n  - flex関連\n    - [flex-direction](https://developer.mozilla.org/ja/docs/Web/CSS/flex-direction), [flex-wrap](https://developer.mozilla.org/ja/docs/Web/CSS/flex-wrap), [flex-basis](https://developer.mozilla.org/ja/docs/Web/CSS/flex-basis), [flex-grow](https://developer.mozilla.org/ja/docs/Web/CSS/flex-grow), [flex-shrink](https://developer.mozilla.org/ja/docs/Web/CSS/flex-shrink)\n    - [align-items](https://developer.mozilla.org/ja/docs/Web/CSS/align-items), [justify-content](https://developer.mozilla.org/ja/docs/Web/CSS/justify-content), [gap](https://developer.mozilla.org/ja/docs/Web/CSS/gap)\n  - grid関連\n    - [grid-template-columns](https://developer.mozilla.org/ja/docs/Web/CSS/grid-template-columns), [grid-template-rows](https://developer.mozilla.org/ja/docs/Web/CSS/grid-template-rows), [grid-template-areas](https://developer.mozilla.org/ja/docs/Web/CSS/grid-template-areas)\n    - [grid-area](https://developer.mozilla.org/ja/docs/Web/CSS/grid-area), [grid-row](https://developer.mozilla.org/ja/docs/Web/CSS/grid-row), [gap](https://developer.mozilla.org/ja/docs/Web/CSS/gap), [row-gap](https://developer.mozilla.org/ja/docs/Web/CSS/row-gap), [column-gap](https://developer.mozilla.org/ja/docs/Web/CSS/column-gap)\n- 位置関連\n  - [position](https://developer.mozilla.org/ja/docs/Web/CSS/position)\n  - [top](https://developer.mozilla.org/ja/docs/Web/CSS/top), [right](https://developer.mozilla.org/ja/docs/Web/CSS/right), [bottom](https://developer.mozilla.org/ja/docs/Web/CSS/bottom), [left](https://developer.mozilla.org/ja/docs/Web/CSS/left)\n  - [transform](https://developer.mozilla.org/ja/docs/Web/CSS/transform)\n- spacing関連\n  - [padding](https://developer.mozilla.org/ja/docs/Web/CSS/padding), [margin](https://developer.mozilla.org/ja/docs/Web/CSS/margin)\n- [width](https://developer.mozilla.org/ja/docs/Web/CSS/width), [height](https://developer.mozilla.org/ja/docs/Web/CSS/height)\n\n## 上記以外のCSSプロパティは、本記事では気にしないでください\n\n## 前提となる知識\n\nサンプルページを学ぶ前に、CSSレイアウトについての前提知識をMDNを参考にして紹介します。\n本記事では、書字方向は横書きを前提としています。あまり覚える部分を増やしたくないからです。\n\n### ボックスモデル\n\nHTMLをCSSでスタイリングする際、その要素をボックスモデルという長方形の形で表現します。\nボックスモデルの説明は、以下の通りです。\n\n> ブラウザーのレンダリングエンジンは文書をレイアウトする際に、それぞれの要素を標準的な CSS 基本ボックスモデルに基づいた長方形のボックスとして表現します。 CSS はこれらのボックスの寸法、位置、プロパティ（色、背景、境界の幅など）を決定します。  \nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_box_model/Introduction_to_the_CSS_box_model\n\n具体的な図は、以下の通りです。\n\n[![CSS 基本ボックスモデル入門 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1693363991/silver-birder.github.io/blog/boxmodel.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_box_model/Introduction_to_the_CSS_box_model)\n\nボックスモデルには、以下の4つ領域があります。\n\n- コンテンツ領域\n  - 文字や画像などの実際のコンテンツ\n- 境界領域\n  - コンテンツの周りの線\n  - CSSプロパティ: border\n- パディング領域\n  - コンテンツとボーダーの間のスペース\n  - CSSプロパティ: padding\n- マージン領域\n  - ボーダーの外側のスペース\n  - CSSプロパティ: margin\n\n実際にボックスモデルがどのようになっているかは、ブラウザにあるDevToolsを使うと確認できます。\n\n[![CSS 機能リファレンス | Chrome DevTools | Chrome for Developers](https://res.cloudinary.com/silverbirder/image/upload/v1764465397/he-box-model-diagram-c955156cbf7bd_1920_pr2zrl.png)](https://developer.chrome.com/docs/devtools/css/reference?hl=ja#box-model)\n\nDevToolsを使うことで、paddingやmargin、borderの値が視覚的に確認できるようになります。\n\n### 通常フローとブロックとインライン\n\nHTML要素は、aタグやspanタグのようなインライン要素、divタグやpタグのようなブロック要素という分け方があります。\nどの要素がブロック要素かインライン要素かは、[HTML Standard - html.spec.whatwg.org](html.spec.whatwg.org)で \"display\" と検索すると分かります。\nHTML要素のブロック・インラインは、CSSのdisplayプロパティで変更できます。\n\nどのようにコンテンツが並ぶかというと、以下の図の様にブロックの場合は下方向に並び、インラインの場合は横方向に並びます。\n\n[![通常フローでのブロック及びインラインレイアウト - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465442/mdn-horizontal_b8fqjv.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_display/Block_and_inline_layout_in_normal_flow)\n\n#### ブロック要素とインライン要素の仕様\n\nブロック要素とインライン要素についての仕様があります。\nこのセクションは読み飛ばしてもらっても構いませんが、知識として知っておくと良いでしょう。\n\nまず、ブロック要素の仕様は、以下の通りです。\n\n> 既定では、**ブロック要素はインライン方向の空間をすべて消費する**ので、段落は広がり、包含ブロックの中で可能な限り大きくなります。ブロック要素に幅を設定した場合、段落が横に並ぶ空間があったとしても、**段落は下へ下へと配置されます**。それぞれは包含ブロックの先頭側の反対側から始まりますので、その書字方向で文章が始まる場所になります。  \nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_display/Block_and_inline_layout_in_normal_flow\n\nブロック要素は、下に下に配置され、横幅いっぱいに広がります。\n\nまた、マージンの相殺という仕様もあります。\n\n> 仕様書では、ブロック要素間のマージンは相殺されると説明されています。つまり、**上マージンを持つ要素がに下マージンを持つ要素の直後に来た場合**、空間の合計はこれら 2 つのマージンの合計になるのではなく、**マージンが相殺**され、本質的には 2 つのマージンのうち**大きい方のマージン**と同じくらいの大きさになるということです。  \nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_display/Block_and_inline_layout_in_normal_flow\n\nインラインの場合、以下の仕様があります。\n\n>.  インライン要素は、その特定の書字方向で文章が進む方向に次々と表示されます。インライン要素がボックスを持っていると考えることはあまりありませんが、 CSS のすべての要素と同様にボックスを持っています。これらのインラインボックスは、次から次へと配置されています。**すべてのボックスを含むブロックに十分な空間がない場合、ボックスは新しい行に分割されます**。生成された行は行ボックスと呼ばれています  \nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_display/Block_and_inline_layout_in_normal_flow\n\n当たり前ですが、インライン要素は横いっぱいまで広がると、折り返して次の行に配置されます。\n\n### フレックスボックスレイアウト\n\nブロック・インライン要素は、単純に1つ並べるだけです。\nしかしそう単純なレイアウトは少ないかと思います。縦横自由に配置したい時があります。\n\nそこで、フレックスボックスレイアウトの出番です。私は、この**フレックスボックスレイアウトを使い慣れることで、苦手意識が少しずつ克服できました**。\n\nフレックスボックスレイアウトの説明は、以下の通りです。\n\n> CSS フレックスボックスレイアウト (CSS flexible box layout) は、ユーザーインターフェイスの設計に最適化された CSS ボックスモデルと、**一次元のアイテムのレイアウト**を定義します。フレックスレイアウトモデルでは、フレックスコンテナーの子は任意の方向にレイアウトすることができ、また使われていない空間を埋めるために伸長したり、あるいは親のあふれることを避けるために収縮したりと、**そのサイズを「伸縮」することができます**。子の水平方向と垂直方向の両方の整列を、容易に操作することが可能です。  \nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_flexible_box_layout\n\nフレックスボックスレイアウトの例は、以下の図の通りです。\n\n[![フレックスボックス - ウェブ開発の学習 | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465481/flex_terms_om58mi.png)](https://developer.mozilla.org/ja/docs/Learn_web_development/Core/CSS_layout/Flexbox)\n\ndisplay: flex を指定した要素は、フレックスコンテナとなり、子要素を任意の方向に配置できます。\n以下のように、flex-directionというCSSプロパティを使うことで、横に並べるか縦に並べるか自由に決めることができます。\n\n[![フレックスボックスの基本概念 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465511/basics1_wibboh.svg)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_flexible_box_layout/Basic_concepts_of_flexbox)\n\n[![フレックスボックスの基本概念 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465542/basics2_kd0wdl.svg)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_flexible_box_layout/Basic_concepts_of_flexbox)\n\nフレックスボックスレイアウトの特徴は、**伸縮性** です。\nCSSプロパティの flex-grow (フレックス成長率)、flex-shrink (フレックス縮小係数)、flex-basis (初期の寸法) を使うことで、アイテムのサイズを伸ばしたり縮めたりできます。\nこれは、レスポンシブデザインを実現する上で非常に便利です。\nサンプルページでは、**デモセクションや料金プランセクションでこの伸縮性の特性を活用しています**。\n\n以下は、伸縮性の例です。以下のように、フレックスコンテナの中に3つのフレックスアイテムがある場合を考えます。\n\n[![主軸方向のフレックスアイテムの比率の制御 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465611/ratios2_jdsfpu.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_flexible_box_layout/Controlling_ratios_of_flex_items_along_the_main_axis)\n\n右側のスペースが開いているため、フレックスアイテムはそのスペースを埋めるように伸びます。\n\n[![主軸方向のフレックスアイテムの比率の制御 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465611/ratios3_zhshmo.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_flexible_box_layout/Controlling_ratios_of_flex_items_along_the_main_axis)\n\nちなみに、以下の図のようにフレックスボックスはDevToolsで可視化することができます。\n\n[![CSS Flexbox レイアウトを検査してデバッグする | Chrome DevTools | Chrome for Developers](https://res.cloudinary.com/silverbirder/image/upload/v1764465642/change-justify-content-f-c2b95dc213b96_1920_wvrkvs.png)](https://developer.chrome.com/docs/devtools/css/flexbox?hl=ja#examine)\n\n### グリッドレイアウト\n\n他のレイアウト方法として、グリッドレイアウトがあります。\nフレックスボックスレイアウトの様な伸縮性はありませんが、**グリッドレイアウトは2次元のレイアウト**が得意です。1次元ももちろん含まれます。\n\nグリッドレイアウトの説明は、以下の通りです。\n\n> CSS グリッドレイアウト (Grid Layout) は、ウェブ用の 2 次元レイアウトシステムです。 コンテンツを行と列に整理することができ、複雑なレイアウトの作成を簡素化する多くの機能を提供します。  \nhttps://developer.mozilla.org/ja/docs/Learn_web_development/Core/CSS_layout/Grids\n> グリッドとは、水平方向と垂直方向の線を集めたもので、デザイン要素を並べて表示することができます。 ページ間を移動するときに要素が跳び回ったり幅が変わったりしないようなデザインを作成するのに役立ちます。  \nhttps://developer.mozilla.org/ja/docs/Learn_web_development/Core/CSS_layout/Grids#%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%83%AC%E3%82%A4%E3%82%A2%E3%82%A6%E3%83%88%E3%81%A8%E3%81%AF\n\nグリッドの例としては、以下の図のように行・列を簡単に定義できます。\n\n[![グリッドレイアウトの基本概念 - CSS: カスケーディングスタイルシート | MDN](https://res.cloudinary.com/silverbirder/image/upload/v1764465642/change-justify-content-f-c2b95dc213b96_1920_wvrkvs.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_grid_layout/Basic_concepts_of_grid_layout#%E3%82%B0%E3%83%AA%E3%83%83%E3%83%89%E3%82%BB%E3%83%AB)\n\nグリッドを使えば、ヘッダー、サイドバー、メイン、フッターといった以下のようなレイアウトも簡単に構築できます。\n\n![グリッドレイアウトのサンプル](https://res.cloudinary.com/silverbirder/image/upload/v1753446214/silver-birder.github.io/blog/grid-sample-article.png)\n\nちなみに、以下の図のようにグリッドレイアウトはDevToolsで可視化することができます。\n\n[![CSS グリッド レイアウトを検査する | Chrome DevTools | Chrome for Developers](https://res.cloudinary.com/silverbirder/image/upload/v1764465704/layout-pane-7a3117d2d859_1920_fqcisu.png)](https://developer.chrome.com/docs/devtools/css/grid?hl=ja)\n\n### 重ね合わせコンテキスト\n\nフレックスボックスやグリッドレイアウトは、通常フローで要素を配置します。\n通常フローとは別に、重ね合わせコンテキスト（stacking context）という概念があります。\n\n重ね合わせコンテキストの説明は、以下の通りです。\n\n>.  重ね合わせコンテキスト (Stacking context) は、ビューポートまたはウェブページに面していると想定されるユーザーに対する**仮想的な Z 軸に沿って並べられた HTML 要素の三次元の概念化**です。 HTML 要素は、要素の属性に基づいてこの空間を優先度つきの順序で占有します\nhttps://developer.mozilla.org/ja/docs/Web/CSS/CSS_positioned_layout/Stacking_context\n\nZ軸の高い位置が前面に表示され、Z軸の低い位置が背面に表示されます。  \nZ軸の同じ位置にある要素は、重なり順序を考慮する必要があります。z-indexで重なり順序を変更できます。\n\n重ね合わせコンテキストは、[重ね合わせコンテキスト - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_positioned_layout/Stacking_context#%E8%A7%A3%E8%AA%AC) に書いてある通り、以下のような場合に生成されます。\n\n- position の値が absolute または relative であり、かつ z-index の値が auto 以外の要素\n- position の値が fixed または sticky の要素（sticky はすべてのモバイルブラウザーにありますが、古いデスクトップブラウザーにはありません）。\n- 省略\n\nこのあたりは、文章で説明するよりも実践を通して学ぶ方が理解しやすいと思いますので、**雰囲気だけ掴んでおいてください**。（私自身が説明できるほど理解していないので）\n\nよくあるケースとしては、positionプロパティを使った位置指定です。以下のHTMLが定番かと思います。\n\n```html\n<!-- 親要素 -->\n<div style=\"position: relative;\">\n  <!-- 子要素は、親の相対位置を基準に絶対位置で配置されます -->\n  <div style=\"position: absolute; top: 0; left: 0;\"></div>\n</div>\n```\n\n起点となる親要素に position: relative を指定し、子要素に position: absolute を指定することで、親要素の位置を基準に子要素を配置できます。\n\n### ブラウザに計算させる\n\nレイアウトを構築していくと、widthを100pxのように絶対値（固定）で定義することがあります。\nこれは、特定のブラウザサイズであればうまくいくかもしれません。\nしかし、以下のような問題が発生する可能性があります。\n\n- ブラウザの縦横の幅が変わると、レイアウトが崩れる\n- 表示するデータが変動すると、レイアウトが崩れる\n\nそのため、できる限りブラウザに計算させる方法をお勧めします。\n具体的には、以下のような方法があります。\n\n- 単位を%やdvw、cqwなど相対単位を積極的に使用する\n  - max-widthで固定値で制限値をかける\n- calc()を使用して、計算させる\n  - calc(100% - 20px)のように、相対値と固定値を組み合わせる\n\nもし固定で値を定義した際には、**\"ブラウザサイズやデータが変わったらどうなるのか？\"** を想像しましょう。\n\n## サンプルページのセクション\n\n長くなりましたが、それではサンプルページのセクションを見ていきましょう。\n再掲ですが、サンプルページとリポジトリは以下のURLにあります。\n\n- https://learn-layout.vercel.app\n- https://github.com/silverbirder/learn-css\n\n### 共通変数\n\nサンプルページでは、スペースや色、フォントサイズをCSS変数で定義しています。\nこれは、CSSの値を設定する際に、var(--spacing-xs) のように使用します。\n決まったスペースやフォントサイズを決めておくと、全体のデザインが統一されるため、お勧めです。\n\n### 全体セクション\n\nヒーローやヘッダー・フッターを除いたセクションは、以下のHTMLで囲むようにしています。\n\n```html\n<div class=\"container\">\n  <section>\n    <h2>タイトル</h2>\n    <div>コンテンツ</div>\n  </section>\n  <section>\n    <h2>タイトル</h2>\n    <div>コンテンツ</div>\n  </section>\n  <!-- 省略 -->\n</div>\n```\n\n各セクションには、セクションタイトルとコンテンツが含まれています。\n全体のレイアウトを整えるため、横幅の制限と左右中央寄せを行います。\n横幅制限をかけないと、画面横いっぱいにコンテンツが広がってしまうため、視線が散漫になってしまいます。\nそのため、横幅制限をかけることで、規則的なレイアウトを実現できます。\n\n具体的なCSSは、以下のとおりです。\n\n```css\n.container {\n  /* 横幅を制限します */\n  max-width: var(--breakpoint-desktop);\n  /* 横幅を左右中央寄せにします */\n  margin-left: auto;\n  margin-right: auto;\n}\n```\n\n## ヒーロー\n\n![ヒーローセクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-hero-laptop.png)\n\n![ヒーローセクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-hero-mobile.png)\n\nヒーローセクションは、でかでかとタイトルを目立つ様に配置しています。\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。\n想像してみると、以下について気づくかもしれません。\n\n- 画面全体に広がっている\n- 画面の上下左右中央に配置されている\n- 3つの要素が縦に並んでいる\n  - タイトルとサブタイトル\n  - 説明文\n  - ボタン\n\nまず、以下のHTMLを書いてみたとしましょう。\nHTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"hero-cover\">\n  <main class=\"hero-container\">\n    <hgroup>\n      <h1>CSS AI</h1>\n      <p>AI駆動CSSスタイリング<wbr />プラットフォーム</p>\n    </hgroup>\n    <div>\n      <p>\n        次世代AIがあなたのCSSを自動最適化。\n      </p>\n      <p>\n        自然言語でスタイルを指定するだけで、美しいCSSコードを瞬時に生成します。\n      </p>\n    </div>\n    <div class=\"cluster\">\n      <button>今すぐ始める</button>\n      <button>詳細を見る</button>\n    </div>\n  </main>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.hero-cover {\n  /* 上下左右中央の配置します。 */\n  /* 他にも方法は色々ありますが、こちらの書き方がシンプルで良いでしょう */\n  display: grid;\n  place-items: center;\n\n  /* 最小の高さを、ビューポートの最大まで広げます */\n  min-height: 100dvh;\n}\n\n.hero-container {\n  /* 左右中央寄せにしつつ、コンテンツの横を制限させます */\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n  /* 左右中央寄せにします */\n  justify-items: center;\n  /* 横幅を制限します */\n  max-width: var(--breakpoint-desktop);\n\n  /* 余白の調整 */\n  gap: var(--spacing-lg); /* 子要素の間隔を指定 */\n  padding: 0 var(--spacing-base); /* 左右の余白を指定 */\n}\n\n.cluster {\n  /* ボタンを単純に横に並べる */\n  display: flex;\n  /* ボタンを折り返す */\n  /* ボタンが増えたり、横幅が狭くなると効果を発揮します */\n  flex-wrap: wrap;\n\n  /* 余白の調整 */\n  gap: var(--spacing-sm);\n}\n```\n\ndvh などの単位は、[length - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/length)を参照してください。\n\n## 主要機能\n\n![主要機能セクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-features-laptop.png)\n\n![主要機能セクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-features-mobile.png)\n\n主要機能セクションでは、このサービスが提供する機能を6つ紹介します。\n6つの主要機能を横2行3列で表示します。各機能には、アイコンとタイトル、説明があります。\n\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。\n想像してみると、以下について気づくかもしれません。\n\n- 2行3列の2次元グリッドが扱いやすそう\n  - 横幅に応じて、3行2列、1行6列、と変化させたい\n- 機能の中のコンテンツは、シンプルに上から下に並べる\n\nまず、以下のHTMLを書いてみたとしましょう。\nHTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"section\">\n  <h2>主要機能</h2>\n  <div class=\"feature-grid\">\n    <div class=\"feature-card\">\n      <div class=\"card-icon\">🤖</div>\n      <h3 class=\"card-title\">AI CSS生成</h3>\n      <p class=\"card-description\">\n        自然言語でデザインを記述するだけで、最適化されたCSSコードを自動生成。\n      </p>\n    </div>\n    <div class=\"feature-card\">\n      <div class=\"card-icon\">🎨</div>\n      <h3 class=\"card-title\">スマートスタイル提案</h3>\n      <p class=\"card-description\">\n        AIがデザインパターンを分析し、美しいスタイルを自動提案。クリエイティブな発想をサポート。\n      </p>\n    </div>\n    <!-- 省略 -->\n  </div>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.section {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* 見出しとコンテンツの間隔を指定 */\n}\n\n.feature-grid {\n  /* 列数を変更しやすいように、ローカル変数に定義 */\n  --_column: 1;\n\n  display: grid;\n  /* 指定する列数で分割 */\n  grid-template-columns: repeat(var(--_column), 1fr);\n\n  /* 余白の調整 */\n  gap: var(--spacing-sm); /* 各機能の間隔を指定 */\n\n  /* tabletの列数 */\n  @media (min-width: 40rem) {\n    --_column: 2;\n  }\n\n  /* laptopの列数 */\n  @media (min-width: 48rem) {\n    --_column: 3;\n  }\n}\n\n.feature-card {\n  display: grid;\n  /* 親グリッドから子グリッドを入れ子にします */\n  grid-template-rows: subgrid;\n\n  /* グリッドアイテムを縦に並べる */\n  grid-template-areas:\n    \"icon\"\n    \"title\"\n    \"description\";\n\n  /* サブグリッドとして、3つの行があることを明示 */\n  grid-row: span 3;\n\n  /* 余白の調整 */\n  padding: var(--spacing-base); /* 自身のカードの内側の余白を指定 */\n\n  /* 装飾 */\n  border: 1px solid var(--color-border); /* 枠線の装飾 */\n}\n\n.card-icon {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: icon;\n}\n\n.card-title {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: title;\n}\n\n.card-description {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: description;\n}\n```\n\nサブグリッドについては、[サブグリッド - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_grid_layout/Subgrid)を参照してください。  \nサブグリッドを使うことで、機能カードの中のアイコン、タイトル、説明文が縦のラインで揃うようになります。\nこれは、例えば、1つのタイトルが2行になった場合、全体のタイトルの行が2行となり縦のラインが維持され、重宝します。\n\n### 対応技術\n\n![対応技術セクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-support-tech-laptop.png)\n\n![対応技術セクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-support-tech-mobile.png)\n\n対応技術セクションでは、たくさんの技術タグを横に並べて表示しています。技術タグはこれからも増えていく可能性があります。\n\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。 想像してみると、以下について気づくかもしれません。\n\n- 技術タグは左右中央に配置されている\n- 横がある一定を超えると、下に折り返されている\n\nまず、以下のHTMLを書いてみたとしましょう。 HTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"section\">\n  <h2>対応技術</h2>\n  <div class=\"cluster\">\n    <span class=\"tech-tag\">GPT-4</span>\n    <span class=\"tech-tag\">Claude</span>\n    <!-- 省略 -->\n  </div>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.section {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* 見出しとコンテンツの間隔を指定 */\n}\n\n.cluster {\n  /* ボタンを単純に横に並べる */\n  display: flex;\n  /* ボタンを折り返す */\n  /* ボタンが増えたり、横幅が狭くなると効果を発揮します */\n  flex-wrap: wrap;\n  /* 左右中央に寄せる */\n  justify-content: center;\n\n  /* 余白の調整 */\n  gap: var(--spacing-sm); /* タグの間隔を指定 */\n}\n\n.tech-tag {\n  /* 余白の調整 */\n  padding: var(--spacing-xs) var(--spacing-sm); /* タグの内側の余白を指定 */\n\n  /* 装飾 */\n  background-color: var(--color-black);\n  color: var(--color-white);\n}\n```\n\n### デモ\n\n![デモセクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-demo-laptop.png)\n\n![デモセクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-demo-mobile.png)\n\nデモセクションでは、デモ動画が左にあり、右にデモの説明ステップがリスト形式で表示されています。\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。\n想像してみると、以下について気づくかもしれません。\n\n- laptopでは、デモ動画が左にあり、説明ステップが右に配置されている\n- mobileでは、デモ動画が上にあり、説明ステップが下に配置されている\n\nまず、以下のHTMLを書いてみたとしましょう。 HTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"section\">\n  <h2>デモ</h2>\n  <div class=\"sidebar\">\n    <div class=\"sidebar-video\">\n      <div class=\"demo-video\">\n        <h3>ライブデモ</h3>\n        <p>実際のCSS AIの動作をご覧ください</p>\n        <button>デモを開始</button>\n      </div>\n    </div>\n    <div class=\"sidebar-steps\">\n      <div class=\"step-items\">\n        <div class=\"step-item\">\n          <strong class=\"step-item-title\">1. 要望を自然言語で入力</strong>\n          <p class=\"step-item-description\">\n            「モダンなカードデザインを作って」など、自然な言葉でデザインを指示\n          </p>\n        </div>\n        <div class=\"step-item\">\n          <strong class=\"step-item-title\">2. AIがCSSを自動生成</strong>\n          <p class=\"step-item-description\">高度なAIが最適化されたCSSコードを瞬時に生成</p>\n        </div>\n        <div class=\"step-item\">\n          <strong class=\"step-item-title\">3. プレビュー・調整・適用</strong>\n          <p class=\"step-item-description\">リアルタイムプレビューで確認し、微調整してプロジェクトに適用</p>\n        </div>\n      </div>\n    </div>\n  </div>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.section {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* 見出しとコンテンツの間隔を指定 */\n}\n\n.sidebar {\n  display: flex;\n  /* 説明ステップを折り返せるようにする */\n  flex-wrap: wrap;\n\n  /* 余白の調整 */\n  gap: var(--spacing-base); /* デモと説明ステップの間隔を指定 */\n}\n\n.sidebar-video {\n  flex-basis: 25rem; /* デモの基本幅を指定（最小限の見せたいサイズ） */\n  flex-grow: 1;      /* 余白があれば少し広がる */\n}\n\n.sidebar-steps {\n  flex-grow: 999;  /* スペースが余れば優先的に広がるようにする */\n  flex-basis: 50%; /* 横幅は最低50%を確保する（デモが25remなのでバランスを取る） */\n}\n\n.demo-video {\n  /* デモ動画のコンテンツを縦に並べる */\n  display: flex;\n  flex-direction: column;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md);       /* デモ動画のコンテンツの間隔を指定 */\n  padding: var(--spacing-base); /* デモ動画の内側の余白を指定 */\n\n  /* 装飾 */\n  background-color: var(--color-border);\n}\n\n.step-items {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-sm); /* タイトルと説明文の間隔を指定 */\n}\n\n.step-item {\n  display: grid;\n  /* 親グリッドから子グリッドを入れ子にします */\n  grid-template-rows: subgrid;\n\n  /* グリッドアイテムを縦に並べる */\n  grid-template-areas:\n    \"title\"\n    \"description\";\n\n  /* サブグリッドとして、2つの行があることを明示 */\n  grid-row: span 2;\n\n  /* 余白の調整 */\n  padding: var(--spacing-base); /* ステップアイテムの内側の余白を指定 */\n\n  /* 装飾 */\n  border-top: 1px solid var(--color-border);\n  border-right: 1px solid var(--color-border);\n  border-bottom: 1px solid var(--color-border);\n  border-left: 3px solid var(--color-black);\n}\n\n.step-item-title {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: title;\n}\n\n.step-item-description {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: description;\n}\n```\n\n今回のレイアウトを、サイドバーパターンと呼びます。\nこのレイアウトは、横幅が広いとサイドバーが横に並び、横幅が狭くなるとサイドバーが下に折り返されるパターンです。\nこの手法については、[Flex-grow 9999 Hack](https://www.joren.co/flex-grow-9999-hack/) を参考にしています。\n\nサブグリッドについては、[サブグリッド - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_grid_layout/Subgrid)を参照してください。  \n\n### お客様の声\n\n![お客様の声セクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-reviews-laptop.png)\n\n![お客様の声セクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-reviews-mobile.png)\n\nお客様の声セクションでは、感想をカード形式で表示し、横並びさせます。\n\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。\n想像してみると、以下について気づくかもしれません。\n\n- 途中でカードが途切れている\n  - 横スクロールできると伝えるためのデザイン\n\nまず、以下のHTMLを書いてみたとしましょう。 HTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"section\">\n  <h2>お客様の声</h2>\n  <div class=\"reel\">\n    <div class=\"review-card\">\n      <div>\n        \"CSS AIを使い始めてから、コーディング時間が半分になりました。\"\n      </div>\n      <div>\n        <strong>田中様</strong> - フロントエンドエンジニア\n      </div>\n      <div>★★★★★</div>\n    </div>\n    <div class=\"review-card\">\n      <div>\n        \"自然言語でデザインを指示するだけで、想像以上の美しいCSSが生成されます。\"\n      </div>\n      <div>\n        <strong>佐藤様</strong> - UIデザイナー\n      </div>\n      <div>★★★★★</div>\n    </div>\n    <!-- 省略 -->\n  </div>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.section {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* 見出しとコンテンツの間隔を指定 */\n}\n\n.reel {\n  /* flexboxで横に並べる */\n  display: flex;\n  /* 横スクロールを許可 */\n  overflow-x: auto;\n\n  /* アイテム間の間隔 */\n  --_gap: var(--spacing-sm);\n  gap: var(--_gap);\n\n  & > * {\n    /* 1.5列分表示 */\n    /* 0.5分非表示になるため、横スクロールできるように見える */\n    --_column: 1.5;\n\n    flex-grow: 0;   /* 伸びない */\n    flex-shrink: 0; /* 縮まない */\n\n    /* 指定された列数ぶん表示されるように幅を計算 */\n    flex-basis: calc(\n      (100% - (var(--_gap) * (var(--_column) - 1))) / var(--_column)\n    );\n\n    /* tabletの列数 */\n    @media (min-width: 40rem) {\n      --_column: 2.5;\n    }\n\n    /* laptopの列数 */\n    @media (min-width: 48rem) {\n      --_column: 3.5;\n    }\n  }\n}\n\n.review-card {\n  display: grid;\n\n  /* 余白の調整 */\n  row-gap: var(--spacing-sm);   /* グリッド行の間隔を指定 */\n  padding: var(--spacing-base); /* レビューカードの内側の余白を指定 */\n\n  /* 装飾 */\n  border: 1px solid var(--color-border);\n  background: var(--color-white);\n}\n```\n\n### 料金プラン\n\n![料金プランセクション - laptop](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-pricing-laptop.png)\n\n![料金プランセクション - mobile](https://res.cloudinary.com/silverbirder/image/upload/v1753446196/silver-birder.github.io/blog/learn-layout-pricing-mobile.png)\n\n料金プランでは、3つのプランをカード上に表示します。\n上記画像から、自分ならどう作るか、HTMLとCSSを想像してみましょう。\n想像してみると、以下について気づくかもしれません。\n\n- プランは、同じ幅で表示する。\n- 横幅がある小ささになると、全て縦に並ぶようになる。\n- プランの上に、人気のバッジがある。\n\nまず、以下のHTMLを書いてみたとしましょう。 HTMLはトップダウンで書いていき、関連しそうな要素を適切なタグでグループ化しています。\n\n```html\n<section class=\"section\">\n  <h2>料金プラン</h2>\n  <div class=\"price-items\">\n    <div class=\"price-item\">\n      <h4 class=\"plan-name\">スターター</h4>\n      <div class=\"plan-price\">¥980<span>/月</span></div>\n      <div class=\"plan-features\">\n        <div class=\"plan-feature\">✓ 基本AI CSS生成</div>\n        <div class=\"plan-feature\">✓ 月100回まで生成</div>\n        <!-- 省略 -->\n      </div>\n      <button class=\"btn btn-outline\">選択する</button>\n    </div>\n    <div class=\"price-item popular\">\n      <div class=\"popular-badge\">人気</div>\n      <h4 class=\"plan-name\">プロ</h4>\n      <div class=\"plan-price\">¥2,980<span>/月</span></div>\n      <div class=\"plan-features\">\n        <div class=\"plan-feature\">✓ 高度なAI機能</div>\n        <div class=\"plan-feature\">✓ 無制限生成</div>\n        <!-- 省略 -->\n      </div>\n      <button class=\"btn btn-primary\">選択する</button>\n    </div>\n    <div class=\"price-item\">\n      <h4 class=\"plan-name\">エンタープライズ</h4>\n      <div class=\"plan-price\">お問い合わせ</div>\n      <div class=\"plan-features\">\n        <div class=\"plan-feature\">✓ カスタムAIモデル</div>\n        <div class=\"plan-feature\">✓ 専用API</div>\n        <!-- 省略 -->\n      </div>\n      <button class=\"btn btn-outline\">相談する</button>\n    </div>\n  </div>\n</section>\n```\n\n次は、CSSを書いてみましょう。CSSには、それぞれコメントを残しています。\n\n```css\n.section {\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* 見出しとコンテンツの間隔を指定 */\n}\n\n.price-items {\n  display: flex;\n  /* プランカードを折り返せるようにする */\n  flex-wrap: wrap;\n\n  /* 余白の調整 */\n  gap: var(--spacing-md); /* プランカードの間隔を指定 */\n\n  & > * {\n    /* すべて同じ比率で伸びるようにする */\n    flex-grow: 1;\n\n    /* 横幅に応じて縦並び ⇄ 横並びが切り替わるように調整 */\n    /* 横幅が45rem未満では縦並び、それ以上では横並びになる */\n    flex-basis: calc((45rem - 100%) * 999);\n  }\n}\n\n.price-item {\n  /* 子要素の絶対配置（例: 人気バッジ）を基準にするための基点 */\n  position: relative;\n\n  display: grid;\n  grid-template:\n    /* プラン名を表示する行 */\n    \"name\" auto\n    /* 空行（スペースなし、調整用） */\n    \".\" 0\n    /* 価格を表示する行 */\n    \"price\" auto\n    /* 空行（価格と機能リストの間にスペースを入れる） */\n    \".\" var(--spacing-md)\n    /* 機能リストを表示する行 */\n    \"features\" auto\n    /* 空行（機能リストとボタンの間にスペースを入れる） */\n    \".\" var(--spacing-md)\n    /* ボタンを表示する行 */\n    \"button\" auto / auto; /* 列幅は自動（1列レイアウト） */\n\n    /* 余白の調整 */\n    padding: var(--spacing-base); /* プランカードの内側の余白を指定 */\n\n  /* 装飾 */\n  border: 1px solid var(--color-border);\n\n  &.popular {\n    /* 人気プランは枠線を強調 */\n    border-color: var(--color-black);\n  }\n\n  & > button {\n    /* grid-template-areasで指定された名前を定義する */\n    grid-area: button;\n    width: fit-content;  /* ボタン幅を内容に合わせる */\n    margin: 0 auto;      /* 左右中央寄せ */\n  }\n}\n\n.popular-badge {\n  /* 親要素 (.price-item) を基準に絶対位置で配置する */\n  position: absolute;\n\n  /* 上にずらして、カードの外にはみ出すように配置 */\n  top: -1rem;\n  /* 横中央に配置するために、左端を中央に設定 */\n  left: 50%;\n  /* 左に50%分ずらして、左右中央に揃える */\n  /* 横方向の中央寄せテクニック */\n  transform: translateX(-50%);\n\n  /* バッジの装飾 */\n  background-color: var(--color-black);\n  color: var(--color-white);\n\n  /* 余白の調整 */\n  padding: var(--spacing-xs) var(--spacing-sm); /* 上下左右の余白を指定 */\n}\n\n.plan-name {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: name;\n}\n\n.plan-price {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: price;\n  text-align: center;\n\n  & > span {\n    /* 単位との間隔 */\n    margin-left: var(--spacing-xs);\n  }\n}\n\n.plan-features {\n  /* grid-template-areasで指定された名前を定義する */\n  grid-area: features;\n  display: grid;\n  /* 1列で、横幅いっぱいに表示します */\n  grid-template-columns: 1fr;\n\n  /* 余白の調整 */\n  gap: var(--spacing-xs);       /* 特徴の間隔を指定 */\n  padding: 0 var(--spacing-sm); /* 左右の余白を指定 */\n}\n\n.plan-feature {\n  /* 余白の調整 */\n  padding: var(--spacing-xs) 0; /* 上下の余白を指定 */\n\n  /* 装飾 */\n  border-bottom: 1px solid var(--color-border);\n}\n```\n\n## 終わりに\n\n最後まで読んでいただき、ありがとうございます。\n読者の皆さんの、CSSに対する苦手意識が少しでも克服できれば幸いです。\n他にもこんなのが知りたい、という要望があれば、ぜひコメントやXなどで教えてください。","publishedAt":"2025-07-27","slug":"learn-layout","title":"苦手なCSSを克服しよう"},{"body":"今回、以下の書籍を読みました。\n\n- [ザ・ダークパターン ユーザーの心や行動をあざむくデザイン](https://www.shoeisha.co.jp/book/detail/9784798177892)\n\nせっかくなので、感じたことや気づきをまとめてみます。\n\n## ダークパターンとは\n\nざっくり言うと、ユーザーを意図的にだますデザインのことです。\nたとえば、以下の経験はありませんか？\n\n- 気づいたらメルマガを購読していた\n- いつの間にか有料会員になっていた\n- 解約方法が分かりづらい・隠されている\n- ボタンだと思ったら実は広告だった\n\nこういうのに遭遇すると、「騙された…」と感じてしまいますよね。\n私は一度でもこういう体験をすると、そのサービス自体を使いたくなくなりますし、似たような場面でもつい疑い深くなってしまいます。\n\n今回読んだ本では、こうした“ダークパターン”の具体例について、いろいろ紹介されていました。\n\n## メルマガ購読チェックボックス、うんざりだ\n\n![メルマガ購読の例](https://res.cloudinary.com/silverbirder/image/upload/v1751369916/silver-birder.github.io/blog/%E3%83%A1%E3%83%AB%E3%83%9E%E3%82%AB%E3%82%99%E8%B3%BC%E8%AA%AD.png)\n\nよくあるのが、メルマガ購読のチェックボックスが最初からONになっているパターン。\n心理学でいう \"デフォルト効果\" を利用したものですが、正直いらないものを勝手に購読させられるのは、もううんざりです。\n\n人は、何かをわざわざ変更するよりも、そのままデフォルトの状態で進めがちです。私もです。\nだからこそ、設定次第で「めっちゃ便利」か「やめてよ...」と感じ方が変わってきます。\n本来は、何も選んでいない状態がデフォルトであってほしいし、必要なときだけ自分の意思でONにしたいものです。\n\nメルマガ購読のチェックボックスは、基本的にOFFがいい。\n意図的に選ばせるなら、ちゃんとユーザーのアクションを伴ってほしいなと思います。\n\n## キャンセルを、キャンセルしますか\n\n![キャンセルのキャンセルの例](https://res.cloudinary.com/silverbirder/image/upload/v1751369829/silver-birder.github.io/blog/%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%BB%E3%83%AB%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%BB%E3%83%AB.png)\n\n以下の文章みたいな、「結局どっち？」と一瞬迷う表現に出会うことがあります。\n\n- 「解約をキャンセルしますか？」\n  - はい\n  - キャンセル\n\nこれ、「はい」を選ぶと解約されないんですよね。\nこういうの、意図的にユーザーを混乱させて解約させないための罠だと思っています。\n\nやっぱり、文章はシンプルで肯定的な表現の方が分かりやすいし、ユーザーのアクションも「ONにしたいときはONにする」みたいに直感的であってほしいです。\nチェックボックスも、チェックを入れたらON、外したらOFF、これが一番しっくりきます。\n\nあと、たまに「健康を一切気にしないので、解約する」みたいなネガティブな選択肢をわざわざ書かせるパターンも見かけます。\n最近は減った気がしますが、なんでそんなこと書くんでしょうね…。\n\n## 「こちらの物件に、5件の予約がありました」 本当に\n\n![宿泊予約サイトの例](https://res.cloudinary.com/silverbirder/image/upload/v1751369829/silver-birder.github.io/blog/%E5%AE%BF%E6%B3%8A%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E4%BE%8B.png)\n\n宿泊予約サイトや不動産サイトで、「この物件、今5件の予約が入っています！」みたいな表示、見かけませんか？\n「やばい、早く予約しなきゃ…」と焦らせるためのテクニックですが、全部が本当とは限りません。\nシステム的に、ランダムで表示されていることもあるし、実際には予約が入っていないこともあります。\n\n他にも「在庫残りわずか！」とか、「今だけ限定！」みたいな煽り文句もよくあります。\nこういうのって、情報の透明性がないからこそ、ユーザーを急がせて購買行動を促しているように感じます。\n口コミも同じで、お金で書かせている偽物（サクラ）もあったりします。\n本物の口コミかどうかは、ユーザー視点だと判断できません。\n\n「本当に？」と疑いたくなる場面は多いですが、なかなか確かめる術がないのが現実です。\nちなみに、私が実際に体験したのは、不動産サイトで問い合わせをした翌日、「この物件に1件のお問い合わせがありました」と表示されていたこと。\nこれは本当だなと感じて、少し信じるようになりました。\n\nでも、ほとんどの場合は自分でコントロールできないので、つい疑い深くなってしまいます。\n口コミも、星5つばかりや良いことしか書いていないレビューは除外するなど、みなさんも工夫しているんじゃないでしょうか。\n\nユーザーも、こうした手法にだんだん慣れてきて、学習しているんだと思います。\n\n情報の透明性を担保するのは本当に難しそうです。\nどこまで開示していいのかも悩ましいし、そもそもできない場面も多そうです。\n自分で確認できればいいですが、そうじゃない場合はどうしようもないですよね。\n\nサクラレビューをチェックするツールもありますが、特定のサービスの口コミだけです。\n第三者が情報の透明性を保証する仕組みがもっと普及すればいいのにな…と思います（自分が知らないだけかもしれませんが）。\n\n## 解約は簡単って、書いてたのに\n\n![解約についての例](https://res.cloudinary.com/silverbirder/image/upload/v1751369829/silver-birder.github.io/blog/%E8%A7%A3%E7%B4%84%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6.png)\n\n「いつでも簡単に解約できます！」って書いてあるサービス、よく見かけますよね...。\nでも、いざ解約しようとすると全然簡単じゃないことが多いです。\n\n- 解約リンクがどこにも見当たらない\n- 平日の限られた時間に電話しないといけない\n- 手続きに1週間以上かかる\n\nWebでサクッと会員登録できたのに、解約だけはやたら面倒…。\nこういう“妨害”があると、解約率は下がるかもしれませんが、その分クレームや不信感が増えるだけだと思います。\n今の時代、SNSでこういう体験がすぐ拡散されて、企業イメージも悪くなりがち。\n本当に、困ったものです…。\n\n## これより先は、会員登録が必要です\n\n![会員登録が必要な例](https://res.cloudinary.com/silverbirder/image/upload/v1751369829/silver-birder.github.io/blog/%E4%BC%9A%E5%93%A1%E7%99%BB%E9%8C%B2%E3%81%8B%E3%82%99%E5%BF%85%E8%A6%81.png)\n\ntoC向けのサービスだと、「ここから先は会員登録してください」と表示されること、よく目にします。\nしかも、登録時にメールアドレスや電話番号、住所、氏名など、いろいろ入力させられるパターンが多いです。\nその結果、知らない番号から電話がかかってきたり、営業メールが届いたり…（ウォーターサーバーの勧誘、ほんとやめてほしい）。\n\nこういうのが嫌で、そもそも会員登録したくない人も多いと思います。（個人の感想です）\n私は、住所やメールにはエイリアスを使って、どこで情報が漏れたか分かるようにしていますが、それでもできるだけ入力したくないのが本音です。\n\n最近は、何でもかんでもログインしないと使えない機能が増えていますが、「本当にログインが必要？」と思う場面も多いです。\n個人情報が関わる機能ならまだしも、そうでないのにログインを求められると、「なんで？」と感じてしまいます。\nそういうときは、ちゃんと理由や説明がほしいなと思います。\n\n## ダークパターンは、人を離れさせる\n\nKPIや数字を追いかけていると、つい「どうやったらCVR（コンバージョン率）が上がるんだろう？」と悩むことがあります。\nプレッシャーや納期があると、ついダークパターンに手を出したくなる気持ちも分からなくはありません。\n短期的には数字が伸びるかもしれませんし。\n\nでも、これまで挙げてきたような“人を騙す”手法は、結局のところ長期的には信頼を失ってしまいます。\n実際、私もダークパターンに遭遇したサイトは強く印象に残っていて、もう二度と使いたくないな…と思ってしまいます。\nむしろ、他のサービスを選ぶようになります。\n\nKPIを上げるときは、逆の指標（カウンターメトリック）も一緒に見ておくのが大事だなと感じます。\nたとえば、メルマガの開封率を上げたいなら解除率も見る、会員解約率を下げたいならクレーム数もチェックする、みたいな感じです。\n\n## ダークパターンに慣れていく\n\n- 「メルマガのチェックは最初からOFFにしておく」\n- 「レビューは偽物も混じってるかも」\n- 「在庫わずかって言われても、まずは落ち着こう」\n\nこうした“ダークパターン”に対して、ユーザー側もだんだん学習してきている気がします。\n一度や二度引っかかっても、経験を重ねるうちに「またか」と気づくようになります。\nそうすると、短期的な利益アップもできなくなりますし、むしろ信用の低下やクレーム増加につながることが多いかと思います。\n結局、ダークパターンを使い続けるのは、長い目で見るとマイナスになることが多いんじゃないでしょうか。\n\nとはいえ、ITリテラシーが高い人は気づきやすいですが、そうでない人の方が圧倒的に多いのも事実。\n気づかないまま利用してしまう人もたくさんいます。\nだからこそ、身近な人には「こういうの気をつけてね」ぐらいは伝えていこうと思います。\n\n## マイクロコピーが大事\n\nマイクロコピーとは、Webサイト上に表示される小さなテキストのことです。\nボタンのラベル、エラーメッセージ、説明文など、ユーザーが直接目にする文章全般を指します。\n一見地味ですが、実はユーザー体験を大きく左右する重要な要素と思います。\n\n最近よく見かけるのが、テキストを省いてアイコンだけで操作を表現しているサイト。\n確かにスタイリッシュに見えるし、カッコ良いと思います。\nでも、アイコンだけだと「これ押したら何が起こるんだろう？」と迷うことがあります。\n\n私も何度か経験があります。ゴミ箱アイコンを見かけたら「削除されるんだろうな」と思うし、「i」のマークがあれば「詳細情報が見られるのかな」と期待します。\nでも、実際に押してみると予想と違う動作をされると、「あれ？」となってしまいます。\n\nそういうときこそ、マイクロコピーが活躍します。\n「削除する」「詳細を見る」「設定を変更する」など、ちょっとした説明があるだけで、ユーザーは安心してボタンを押せるようになります。\nボタンの近くにある説明文も同じです。手抜きをせず、ちゃんと分かりやすい言葉で伝えることが大切だなと思います。\n\nマイクロコピーのライティングって、それだけで専門職があるぐらい奥が深い分野です。\nたった数文字の違いで、ユーザーの行動が変わることもありますし、親しみやすさや信頼感にも影響してくる。\n改めて、マイクロコピーの重要性を感じます。\n\n## 最後に\n\nWebサービスを作る立場として、これからも「本当にユーザーのためになっているか？」を意識しながら、ダークパターンに頼らないクリーンな設計を心がけていきたいと思います。\n\nここまで読んでいただき、ありがとうございました！\n\n## P.S\n\nこの記事に関連して、以下の記事もおすすめです！\n\n- 『[縁の下のUIデザインを読みました](../en-no-shita-ui-design/)』\n- 『[サクッと学べるデザイン心理法則108を読みました](../review_of_108-design-psychology-laws-you-can-learn-quickly/)』\n- 『[はじめてのUXデザイン図鑑を読みました](../review_of_hajimete-no-ux-zukan/)』\n- 『[マイクロインタラクション―UI/UXデザインの神が宿る細部を読みました。](../micro-interactions-the-god-given-details-of-ui-ux-design/)』","publishedAt":"2025-07-02","slug":"review_of_the-dark-pattern","title":"『ザ・ダークパターン ユーザーの心や行動をあざむくデザイン』書籍レビュー"},{"body":"マイクロインタラクションという言葉をネットで見かけて、興味を持ちました。\n詳しく知るには書籍が最適だと思い、オライリー社の[『マイクロインタラクション ―UI/UXデザインの神が宿る細部』](https://www.oreilly.co.jp/books/9784873116594/)を読みました。\n\n本書を通じて、細部にこだわることで、「仕方なく使う」から「次も使いたくなる」Webサービスを目指したいと感じました。\n以下は、本書を読んで感じたことや学んだことをまとめたものです。\n\n## iPhoneのアラーム\n\n本書で特に印象的だったのは、コンサート会場でのアラームのエピソードです。\nある人がiPhoneを**消音モードにしていた**にもかかわらず、コンサート中に**アラームが鳴ってしまいました**。\nその結果、周囲の人に迷惑をかけてしまいました。\n\n私も昔、iPhoneユーザーだったので、この状況には共感できます。\n\n「消音モードにしたのに、なぜアラームが鳴るの？」と不思議に思う人も多いでしょう。\nこれはiPhoneの仕様の一つですが、実際に経験しないと気づきにくいかもしれません。\n\nこのケースは、マイクロインタラクションにおける「フィードバック」が適切でない例と言えます。\n\n## マイクロインタラクションとは\n\nマイクロインタラクションとは、**製品やサービスにおける最小単位のインタラクション**を指します。\n具体的には、ユーザーとシステム間の相互作用や、ユーザー同士のやり取りの最小単位を意味します。\n\n例えば、ECサイトで商品ページで「カートに入れる」ボタンをクリックすると、カートアイコンの数字が1つ増える動作があります。\nこのとき、商品画像がカートに向かって入るアニメーションが加わると、より直感的な体験になります。\n\nこのマイクロインタラクションは、「ショッピングカートに商品を追加した」ということを視覚的に伝える役割を果たします。\nこうした仕組みは、良いマイクロインタラクションの例といえます。\n\n### マイクロインタラクションの構成要素\n\nマイクロインタラクションは、以下の4つの要素で構成されています。\n\n1. トリガー\n    - インタラクションのきっかけとなるもの。\n\n- ユーザーの操作（手動トリガー）やシステムの状態変化（システムトリガー）によって起動します。\n\n1. ルール\n    - トリガーによって開始されたインタラクションがどのように動作するかを決定する指針です。\n1. フィードバック\n    - ユーザーにインタラクションの結果や進行状況を伝える情報です。視覚的、聴覚的、触覚的な手段で提供されます。\n1. ループとモード\n    - インタラクションの繰り返しや状態変化を管理する要素です。ループはインタラクションの繰り返しサイクルを、モードは特定の条件下での動作状態を指します。\n\niPhoneの消音モードの例に戻ると、「消音スイッチをONにする」というトリガーに対して、「消音アイコンを画面に表示する」というフィードバックは提供されています。\nしかし、**「消音モード中でもアラーム音は鳴る」というルールがユーザーに適切に伝わっていない**ため、意図しないユーザー体験が生じることがあります。\nこのように、フィードバックが不十分だと、ユーザーに混乱や不便をもたらす可能性があります。\n\n## Webサービスにおけるマイクロインタラクション\n\nWebサービスには、多くのマイクロインタラクションが存在します。\nしかし、多くのWebサービスでは、基本的な機能の開発が優先され、マイクロインタラクションの実装は後回しにされがちです。\nその結果、「とりあえず動くから良い」という状態でリリースされることも少なくありません。\n\n**マイクロインタラクションが不十分だと、ユーザーは無意識のうちに「使いにくい」「魅力に欠ける」と感じてしまう**のかなと思います。\n例えば、以下のようなケースが考えられます。\n\n- エラーメッセージの不足\n  - フォーム送信後、「エラーがありました」とだけ表示される\n  - 対策: エラー箇所を明示し、「◯◯を修正してください」と具体的にフィードバックする\n- 検索結果が見つからない場合\n  - ECサイトで検索しても「該当なし」と表示される\n  - 対策: 「もしかして◯◯ですか？」などの検索候補を提示し、修正を促す\n\n一方で、細部までこだわったマイクロインタラクションを導入することで、他のサービスと差別化された「次も使いたくなる」体験を提供できるでしょう。\n**ユーザーが行った操作に対して、直感的にフィードバックが返ってきて、次のアクションがスムーズに進められると、快適に感じます**。\n\nでは、具体的にどのような場面でマイクロインタラクションが活きるのか、考えてみると面白いかもしれません。\nたとえば、以下のような状況では、どのような工夫ができるでしょうか？考えてみるとよいでしょう。\n\n- 処理時間が長い場合\n  - 動画配信サイトで動画をアップロードしたとき\n  - ECサイトで商品検索をしたとき\n- フォームの入力時\n  - メールアドレスを入力したとき\n  - 送信ボタンを押したとき\n- 通知の受け取り時\n  - 投稿したコンテンツに「いいね」を送った・もらったとき\n  - 購読していた記事が編集されたお知らせを受け取ったとき\n- 支払い時\n  - クレジットカード情報を入力したとき\n  - 支払い方法としてポイント利用を選択したとき\n- チャットの利用時\n  - チャットルームで入力したとき\n  - デフォルト言語以外でメッセージを受信したとき\n\n## 終わりに\n\nもともと、マイクロインタラクションという言葉には、「いいね」ボタンを押したときの鮮やかなエフェクトのような、見た目の演出を指す印象がありました。\nしかし、本書を読んで、それはあくまで**フィードバックの表現方法の一つ**に過ぎないと気づきました。\n\n本当に大切なのは、ユーザーがインタラクションを行った結果、**何が起こったのかをわかりやすく伝えること**です。\nフィードバックが適切であれば、ユーザーは迷うことなく次のアクションを取れます。\n\n視覚的なフィードバックは直感的に理解しやすいため、鮮やかなエフェクトも効果的なアイデアの一つでしょう。\n個人的には、noteの「いいね」ボタンの演出が楽しく、心地よいと感じます。","publishedAt":"2025-02-22","slug":"micro-interactions-the-god-given-details-of-ui-ux-design","title":"『マイクロインタラクション―UI/UXデザインの神が宿る細部』を読みました。"},{"body":"書店の本棚を眺めていると、「[レタースペーシング タイポグラフィにおける文字間調整の考え方](https://letter-spacing.mimiguri.co.jp/)」というタイトルが目に留まりました。\n興味を引かれ、手に取って購入しました。読み終えたので、その感想をまとめます。\n\n## どういう本か\n\n文字間のスペースをどのように調整するか。本書は、その一点に焦点を当てた内容です。\n\n文字と文字の間にあるスペースや、文字自体が持つスペースをどのように広げたり縮めたりするかによって、単語や文章のまとまりや読みやすさが変わります。\n適切に調整すれば、スムーズに読めますが、不適切な調整は読みにくさや誤解を招くこともあります。その影響について、理論的に説明されています。\n\n**文字の位置や形、太さ**によって、スペースが生まれる領域は異なります。\n例えば、『L』や『C』は内部に広いスペース（パーソナルスペース）を持ちますが、『H』は少なくなります。\nまた、『I』は正方形で囲むと中心に配置されますが、『L』は左寄りになります。\nこのように文字ごとのスペースの差が異なるため、単語や文章として並べるとバランスが崩れ、まとまりが悪くなることがあります。\n\n**欧文と和文、ひらがな・カタカナ・漢字**では、スペースの傾向も異なります。\n例えば、『囲』は内部のスペースが少ないのに対し、『O』や『I』は広めです。\nさらに、漢数字の『一』のように、特にスペースが広い文字もあります。\n\nまた、**欧文のベースラインと和文の中心線**の違い、それらを組み合わせた際のバランスについても詳しく解説されています。\n欧文では、文字が地面についているようなベースラインがありますが、和文は上下中央に配置されることが多く、例えば『lower』のベースラインと『いつも』の中心線を揃えようとするとズレが生じます。\nそのため、適切な調整が必要になります。\n\n文字ごとに多角的な視点で分析されており、新鮮な発見が多い一冊でした。\n\n## Webフロントエンド屋の私\n\nロゴや広告をデザインする人にとっては、テキストの配置を考えるうえで参考になる良い本だと思います。\n一方で、私はWebアプリケーション開発をするプログラマなので、実際に活用できる場面は少なそうでした。\n\n普段、私は Noto Sans Japanese を使う機会が多いですが、その文字のスペースがどれほどあるのかを気にしたことはありませんでした。\nたまに「上下の揃い方が気になるな」と思うことはありましたが、深く考えたことはなかったです。\n\n本書は1文字単位のチューニングが中心ですが、Web開発者として何か活かせる点がないか考えてみました。\n\n例えば、ランディングページは多くのユーザーに訪れてもらい、サービスを利用してもらうために作られます。\nそこにはサービスの画像を配置しつつ、キャッチコピーなどのテキストで表示することが一般的です。\nこうした場面では、1文字1文字を丁寧に扱いたいと感じました。\nレタースペーシングや行間、フォントのウェイトなど、一つひとつ確認しながら調整したくなります。\nとはいえ、多くの場合はデザイナーが用意して頂いたデザインを参考にすることになりますが……。\n\n読みやすさは感覚的なものと思われがちですが、本書を読んだことで、**理論的に読みやすさを考える視点が増えた気がします**。\n\nまた、ブログのような読み物系のサービスでは、レタースペーシングよりも 書体やスペースの調整 を考えたくなりました。\n1文字単位での微調整は現実的ではないですが、Web開発では以下のCSSプロパティを使って全体のバランスを調整できます。\n\n- word-spacing\n- letter-spacing\n- line-height\n- font-size\n- font-weight\n- white-space\n- text-indent\n\n[W3CのWCAG 2.1](https://www.w3.org/WAI/WCAG21/Understanding/text-spacing.html) では、テキストのスペーシングに関する基準が示されています。\n\n> - 行間（line spacing）はフォントサイズの1.5倍以上\n>\n> - 段落後のスペースはフォントサイズの2倍以上\n>\n> - 文字間（letter spacing）はフォントサイズの0.12倍以上\n>\n> - 単語間（word spacing）はフォントサイズの0.16倍以上\n\nこれらは最低限の指標だと思うので、実際にスタイルを適用しながらレタースペーシングの調整を試してみたいと思います。\n\n## 終わりに\n\n途中で「自分はこの本の読者対象ではないかも」と感じ、一度読むのをやめました。\nしかし、せっかく購入したので改めて読み直し、最後まで読んでみることにしました。\n結果として、単語や文章の読みやすさについて深く理解するきっかけになりました。\n普段何気なく見ている広告のテキストでも、レタースペーシングや文字の配置が大きく影響していることを実感しました。\n最後まで読んでいただき、ありがとうございました。","publishedAt":"2025-02-11","slug":"letter-spacing-the-concept-of-letter-spacing-in-typography","title":"『レタースペーシング タイポグラフィにおける文字間調整の考え方』を読みました。"},{"body":"ブログ記事のOGP画像に、ブログタイトルを入れたい場面があります。その際、タイトルが長い場合は複数行に分けたり、省略したりする必要があります。\n今回は、試してみてよさそうだった2つの方法を紹介します。\n\n## 前提\n\n- OGP画像の生成には、`vercel/og (satori)` を使用します\n  - [Next.jsのopengraph-image.tsx](https://nextjs.org/docs/app/api-reference/file-conventions/metadata/opengraph-image)ファイルを使います\n\n## 1. lineClampを使う方法\n\n最もシンプルな方法として、`satori` の `lineClamp` 機能を使用する方法があります。\n\n- https://github.com/vercel/satori#css\n\nこの機能を使うと、簡単に複数行の表示と省略が可能です。\nまた、省略時の文字をカスタマイズすることもできます。以下は、その実装例です。\n\n```tsx\nimport { ImageResponse } from \"next/og\";\n\nexport const runtime = \"edge\";\n\nexport const alt = \"alt\";\nexport const size = {\n  width: 1200,\n  height: 630,\n};\n\nexport const contentType = \"image/png\";\n\nconst WAGAHAI_IS_CAT =\n  \"吾輩は猫である。名前はまだない。どこで生れたか頓（とん）と見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪（どうあく）な種族であったそうだ。この書生というのは時々我々を捕（つかま）えて煮て食うという話である。しかしその当時は何という考（かんがえ）もなかったから別段恐しいとも思わなかった。\";\n\nexport default async function Image() {\n  const text = WAGAHAI_IS_CAT;\n\n  return new ImageResponse(\n    (\n      <div\n        style={{\n          background: \"white\",\n          width: \"100%\",\n          height: \"100%\",\n          padding: \"200px\",\n          display: \"flex\",\n          flexDirection: \"column\",\n          alignItems: \"flex-start\",\n          justifyContent: \"center\",\n        }}\n      >\n        <div\n          style={{\n            display: \"block\",\n            lineClamp: 3,\n            fontSize: \"24px\",\n            lineHeight: \"1.5\",\n            textAlign: \"left\",\n          }}\n        >\n          {text}\n        </div>\n      </div>\n    ),\n    {\n      ...size,\n    }\n  );\n}\n```\n\n以下の画像が、`lineClamp` を使用した OGP 画像の例です。\n\n![lineClamp](https://res.cloudinary.com/silverbirder/image/upload/v1738842539/silver-birder.github.io/blog/WAGAHAI_IS_CAT_simple.png)\n\n## 2. budouxを使う方法\n\n`lineClamp` では改行位置が不自然になることがあります。\nそんなときに、日本語向けの `budoux` を使うと、適切な位置で改行できます。\n\n- https://github.com/google/budoux\n\n以下の方法で `budoux` を OGP 画像の生成に活用できます。\n改行位置を調整しながら、最大行数を超えた場合は `...` を追加して省略するようにしています。\n\n```tsx\nimport { ImageResponse } from \"next/og\";\nimport { Parser, jaModel } from \"budoux\";\n\nconst parser = new Parser(jaModel);\n\nexport const runtime = \"edge\";\nexport const alt = \"alt\";\nexport const size = {\n  width: 1200,\n  height: 630,\n};\nexport const contentType = \"image/png\";\n\nconst PADDING = 200;\nconst FONT_SIZE = 24;\nconst MAX_LINES = 3;\nconst CONTENT_WIDTH = size.width - PADDING * 2;\nconst AVERAGE_CHAR_WIDTH = FONT_SIZE;\nconst MAX_CHARS_PER_LINE = Math.floor(CONTENT_WIDTH / AVERAGE_CHAR_WIDTH);\nconst WAGAHAI_IS_CAT =\n  \"吾輩は猫である。名前はまだない。どこで生れたか頓（とん）と見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪（どうあく）な種族であったそうだ。この書生というのは時々我々を捕（つかま）えて煮て食うという話である。しかしその当時は何という考（かんがえ）もなかったから別段恐しいとも思わなかった。\";\n\nexport default async function Image() {\n  const text = WAGAHAI_IS_CAT;\n  const lines = splitTextIntoLines(text, MAX_LINES, MAX_CHARS_PER_LINE);\n\n  return new ImageResponse(\n    (\n      <div\n        style={{\n          background: \"white\",\n          width: \"100%\",\n          height: \"100%\",\n          padding: `${PADDING}px`,\n          display: \"flex\",\n          flexDirection: \"column\",\n          alignItems: \"flex-start\",\n          justifyContent: \"center\",\n        }}\n      >\n        {lines.map((line, index) => (\n          <div\n            key={index}\n            style={{\n              fontSize: `${FONT_SIZE}px`,\n              lineHeight: \"1.5\",\n              textAlign: \"left\",\n            }}\n          >\n            {line}\n          </div>\n        ))}\n      </div>\n    ),\n    {\n      ...size,\n    }\n  );\n}\n\n/**\n * テキストを指定した行数と文字数で分割し、必要に応じて省略記号を追加する関数\n * @param text - 分割するテキスト\n * @param maxLines - 最大行数\n * @param maxCharsPerLine - 1行あたりの最大文字数\n * @returns - 分割されたテキストの配列\n */\nfunction splitTextIntoLines(\n  text: string,\n  maxLines: number,\n  maxCharsPerLine: number\n) {\n  const parsedText = parser.parse(text);\n  const lines = [];\n  let currentLine = \"\";\n\n  parsedText.forEach((segment) => {\n    if (currentLine.length + segment.length <= maxCharsPerLine) {\n      currentLine += segment;\n    } else {\n      lines.push(currentLine);\n      currentLine = segment;\n    }\n  });\n  if (currentLine) {\n    lines.push(currentLine);\n  }\n\n  if (lines.length > maxLines) {\n    lines[maxLines - 1] =\n      lines[maxLines - 1].slice(0, maxCharsPerLine - 3) + \"...\";\n    lines.length = maxLines;\n  }\n\n  return lines;\n}\n```\n\n以下の画像が、`budoux` を使用した OGP 画像の例です。\n\n![budoux](https://res.cloudinary.com/silverbirder/image/upload/v1738842539/silver-birder.github.io/blog/WAGAHAI_IS_CAT_budoux.png)\n\n## 終わりに\n\n`lineClamp` を使う方法と `budoux` を使う方法を紹介しました。\nOGP画像生成で悩んでいる人のお役に立てれば嬉しいです。","publishedAt":"2025-02-06","slug":"opengraph-image-lineclamp-budoux","title":"OGPのテキストを任意の行で省略する、lineClampとbudoux"},{"body":"買ったものリストを投稿・共有できるサービス『**かったものリスト**』を開発しました。\n今回は、そのサービスの紹介と技術的な話をしようと思います。\n\n## なぜ作ったのか\n\n### 背景\n\nもともと、私のサイトには、かったものリストを表示するページがありました。\n書籍やガジェットなどの購入履歴を JSON ファイルで管理し、そのデータをもとに簡単な一覧ページを作成していました。\nこの一覧ページは、誰かにお気に入りのアイテムを紹介する場面で役立っていました。\n\nしかし、サイトをリニューアルした際に、かったものリストのページがなくなってしまいました。\nそこで、**『かったものリストをサービスとして独立させよう』** と考えました。\n\n### 決断\n\n私が求めていたのは、自由にかったものリストを作成し、それを誰でも閲覧できる仕組みです。\nこの仕組みがあれば、自分のかったものリストを気軽に他の人に紹介できます。\n\nどう作ろうか悩んでいたとき、年末に「2024年に買ってよかったもの」というフレーズを目にしました。\n実際に、個人ブログでは購入した商品とその良かった点を自由に記述し、公開するケースが多くあります。\nそこで、『これだ！』とひらめき、ベストバイを共有するサービス『かったものリスト』を作ることを決断しました。\n\n## どのようなサービスか\n\nURLは以下です。\n\nhttps://my-buy-items.vercel.app\n\nこのサービスは、投稿型で、Notionのように自由な書き方ができます。\n画像や埋め込みも可能です。\n\n書いたかったものリストを公開すると、新着リストに掲載されたり、ユーザーごとにまとめて表示されます。\nこのかったものリストを活用すれば、自分のかったものリストを他の人に簡単に共有できます。\n\nまた、以下の機能も備えています。\n\n- いいね機能\n- 投稿の閲覧数表示\n\nこうして、私が求めていたサービスが完成しました。\n\n## 開発について\n\n『かったものリスト』は、約1ヶ月の開発期間で完成しました。\n初回のGitコミットは2025年1月1日23時31分で、最終的に2025年1月29日18時にリリースしました。\n\n開発には、**私オリジナルの個人開発向けのスターターキット** を活用しました。\nこのスターターキットは、T3Stackのコンセプトをベースにし、ホスティングにはVercelを使用しています。\n\n主な構成は以下のとおりです。\n\n- フレームワーク: Next.js\n- API: tRPC\n- 認証: Auth.js\n- データベース: Vercel PostgreSQL（ORM: Drizzle / クライアント: Drizzle Studio）\n- ストレージ: Vercel Blob\n- スタイル: TailwindCSS、shadcn/ui\n\nまた、以下のセットアップもマニュアル化しています。\n\n- よく使うUI要素（ヘッダー、フッター）\n- OGP、アイコン、マニフェスト、メタデータ\n- GA設定、問い合わせリンク\n- タスク管理用の TODO.md\n\n開発においては、v0とChatGPTを活用しました。  \nさらに、今回の開発では以下の技術を導入しました。\n\n- エディタ: Tiptap (Novel)\n- ドラッグ&ドロップ: dndkit\n- アバター編集: react-avatar-editor\n- OGPテキストの改行処理: budoux\n\n## 終わりに\n\n本記事では、『かったものリスト』の開発経緯と技術構成について紹介しました。\nこのサービスが、多くの人にとって便利なものになれば嬉しいです。","publishedAt":"2025-02-01","slug":"my-buy-items-retrospective","title":"かったものリストサービス開発の振り返り"},{"body":"みなさん、Testcontainersをご存知ですか？\n\nTestcontainersは、Dockerコンテナを利用して実際のサービスを統合テストで手軽に使用できるオープンソースのライブラリです。\n今回、Testcontainersを使って、GitHub Actions上でRails API、MySQL、Next.jsをDockerコンテナとして起動させ、複数のテストシナリオを独立してテストすることができました。以下はその概要図です。本記事では、このテストについての解説と学びを紹介したいと思います。\n\n![概要図](https://res.cloudinary.com/silverbirder/image/upload/v1735639067/silver-birder.github.io/blog/testcontainers-overview.png)\n\n動くコードは、[こちらのリポジトリ](https://github.com/silverbirder/testcontainers-rails-nextjs)にありますので、ご参考にしてください。\nGitHub Actionsのテストログは、[こちら](https://github.com/silverbirder/testcontainers-rails-nextjs/actions/workflows/e2e.yml)にあります。\n\nちなみに、過去にTestcontainersに関するブログ記事を書いていたので、そちらもよろしければお読みください。\n\nhttps://zenn.dev/silverbirder/articles/bcf9ae9b496a15\n\n## Testcontainersを使用する対象\n\nTestcontainersは、コンテナで管理されているサービスに対してテストを行うことができます。一方、コンテナで管理されていないサービスについても、以下のリンクにあるモジュールライブラリを利用することでテストが可能な場合があります。\n\n- [Modules | Testcontainers](https://testcontainers.com/modules/)\n\nTestcontainersのモジュールライブラリには、MySQL、Apache Kafka、Vaultなど、事前に構成済みのテストコンテナが提供されています。これらのモジュールにないサービスについても、[GenericContainer](https://testcontainers.com/getting-started/#genericcontainer-abstraction) と呼ばれる汎用コンテナを使用することで、独自のイメージを利用したテストが可能です。\n\nさらに、Testcontainersをサポートするプログラミング言語は、執筆時点で以下の通りです。\n\n- Java\n- Go\n- .NET\n- Node.js\n- Clojure\n- Elixir\n- Haskell\n- Python\n- Ruby\n- Rust\n\n※ [Supported languages and prerequisites | Testcontainers](https://testcontainers.com/getting-started/#supported-languages-and-prerequisites)\n\n今回は、Node.jsを使用して検証を行います。\n\n## 今回のテスト対象\n\n[前回の記事](https://zenn.dev/silverbirder/articles/bcf9ae9b496a15)では、[T3 Stack](https://create.t3.gg/) を使用して構築したアプリケーションでテストを行いました。このアプリケーションは、Next.js、tRPC、Prismaで構成されており、Testcontainersで扱うDockerコンテナはNext.jsとMySQLの2つだけでした。そのため、Testcontainersに慣れるには良い経験となりました。しかし、実際の業務ではフロントエンドとバックエンドを分離した開発が多く見られるかと思います。\n\nそこで今回は、フロントエンドとバックエンドを分離した以下の構成でテストを行いました。\n\n- バックエンド: API\n  - Dockerコンテナ\n    - Rails API\n    - MySQL\n  - docker-composeで管理\n- フロントエンド: Web\n  - Dockerコンテナ\n    - Next.js\n  - Dockerfileで管理\n\n使用している技術スタックやライブラリは一例に過ぎず、Dockerコンテナで管理されていれば、どのような技術でも適用可能だと考えています。\n\nテスト対象のアプリケーションは、TodoMVC風のアプリケーションとしました。ブラウザからAPI経由でTodoデータを取得・表示し、データをDBに保存する機能を備えています。以下が、画面のイメージです。\n\n![Todo App](https://res.cloudinary.com/silverbirder/image/upload/v1735639029/silver-birder.github.io/blog/testcontainers-todo-app.png)\n\n`Save All`ボタンをクリックすると、データがDBに保存されます。\n\n## テスト方法\n\n今回は、以下のテストファイルを作成し、Testcontainersを使用してテストを行います。\n\n- `health.test.ts`\n  - ヘルスチェック  \n    - DBに指定のデータベースおよびテーブルが存在するかを確認\n    - RailsのAPIエンドポイントにGETリクエストを送り、ステータスコード200を確認\n    - Next.jsのサーブURLにブラウザでアクセスし、ページタイトルを確認\n- `integration.test.ts`\n  - Todo Appの結合テスト\n    - ブラウザ操作でTodoを追加・保存し、DBに正しく保存されていることを確認\n\n各テストは、Testcontainersを使ってAPIやWebのDockerコンテナを独立して起動させます。テストが終了すると、Dockerコンテナは削除されます。Dockerコンテナは、テストで使い終わったら削除する、つまり**コンテナは使い捨て**です。再掲になりますが、以下の図が今回のテストの概要図です。\n\n![概要図](https://res.cloudinary.com/silverbirder/image/upload/v1735639067/silver-birder.github.io/blog/testcontainers-overview.png)\n\nそれでは、概要図にあるSetup・Teardown、Testについて紹介していきます。\n\n## Setup・Teardown\n\nまずは、SetupとTeardownについて説明します。Setupでは、主に以下のことを行います。\n\n1. APIおよびWebの各Dockerコンテナを起動\n1. APIおよびWebの各コンテナへのアクセスURLやオブジェクトを返す\n1. テスト終了後にDockerコンテナを停止するTeardownを提供\n\nSetupは、Vitestでいう`beforeAll`や`beforeEach`のように、テスト実行前に動作することを想定しています。各テスト内でDockerコンテナは、ボリュームなどを共有せずに独立して起動します。\nTeardownは、Vitestでいう`afterAll`や`afterEach`のように、テスト実行後に動作することを想定しています。\n\nどうしてもコンテナの起動・停止が重たくなる場合は、`globalSetup`や`globalTeardown`のような仕組みを利用し、Dockerコンテナをシングルトンとして起動・停止する方法もあります。\n\nそれでは、具体的なコードを紹介していきます。\n\n### APIのSetup・Teardown\n\nまずは、APIのSetupとTeardownについて説明します。以下に該当するコードをご覧ください。\n\n```ts\n// setup/api.ts\nimport path from \"path\";\nimport { DockerComposeEnvironment, RandomUuid } from \"testcontainers\";\nimport { writeFileSync, unlinkSync } from \"fs\";\nimport { join } from \"path\";\n\nconst API_PORT = 3000;\n\nexport const setupApiContainer = async () => {\n  const apiPath = path.resolve(__dirname, \"../../../apps/api\");\n  const apiComposeFileName = \"docker-compose.yml\";\n  const uuid = new RandomUuid();\n  const containerSuffix = `_${uuid.nextUuid()}`;\n  const apiEnvironment = await new DockerComposeEnvironment(\n    apiPath,\n    apiComposeFileName\n  )\n    .withEnvironment({\n      CONTAINER_SUFFIX: containerSuffix,\n    })\n    .up();\n\n  const apiContainer = apiEnvironment.getContainer(\n    `testcontainers_api${containerSuffix}`\n  );\n  const dbContainer = apiEnvironment.getContainer(\n    `testcontainers_api_db${containerSuffix}`\n  );\n\n  const networks = apiContainer.getNetworkNames();\n  const networkName = networks[0] ?? \"\";\n  const ip = apiContainer.getIpAddress(networkName);\n  const host = apiContainer.getHost();\n  const port = apiContainer.getMappedPort(API_PORT);\n\n  const executeSqlFile = async (sqlContent: string, fileName: string) => {\n    const tempSqlFile = join(__dirname, fileName);\n    writeFileSync(tempSqlFile, sqlContent, \"utf-8\");\n    try {\n      await dbContainer.copyFilesToContainer([\n        { source: tempSqlFile, target: `/temp.sql` },\n      ]);\n      const result = await dbContainer.exec([\n        \"mysql\",\n        \"-uroot\",\n        \"-proot\",\n        \"-e\",\n        \"source /temp.sql\",\n      ]);\n      return result.output.trim();\n    } finally {\n      unlinkSync(tempSqlFile);\n    }\n  };\n\n  return {\n    apiContainer,\n    dbContainer,\n    executeSqlFile,\n    apiInternalUrl: `http://${ip}:${API_PORT}`,\n    apiPublicUrl: `http://${host}:${port}`,\n    networkName,\n    teardown: async () => {\n      await apiEnvironment.down({ removeVolumes: true });\n    },\n  };\n};\n```\n\n`DockerComposeEnvironment`は、docker-composeを起動するためのクラスです。各コンテナは`apiContainer`や`dbContainer`という変数で定義されており、これらに対して`exec`コマンドなどを実行することが可能です。`networkName`は、APIとWebを同一ネットワークにするために使用されます（Webのセットアップ時に利用）。Teardown時には、`apiEnvironment.down`を使用してdocker-composeを停止します。\n\n上記で参照している`docker-compose.yml`は、以下の内容です。\n\n```yml\nservices:\n  db:\n    image: mysql:8.0\n    container_name: \"testcontainers_api_db${CONTAINER_SUFFIX}\"\n    environment:\n      DATABASE_USERNAME: root\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: api_development\n    healthcheck:\n      test: mysqladmin ping -h 127.0.0.1 -u$$MYSQL_USER -p$$MYSQL_PASSWORD\n      interval: 10s\n      timeout: 10s\n      retries: 3\n      start_period: 30s\n    ports:\n      - \":3306\"\n    volumes:\n      - db_data:/var/lib/mysql\n  api:\n    build:\n      context: .\n    container_name: \"testcontainers_api${CONTAINER_SUFFIX}\"\n    depends_on:\n      db:\n        condition: service_healthy\n    ports:\n      - \"${API_PORT-}:3000\"\n    environment:\n      DATABASE_HOST: db\n      DATABASE_USERNAME: root\n      DATABASE_PASSWORD: root\n      DATABASE_PORT: 3306\nvolumes:\n  db_data:\n```\n\n**重要なポイント**として、`ports`の設定があります。`\"${API_PORT-}:3000\"`は、`API_PORT`という環境変数が設定されていない場合、ホスト側のポートが動的に決定されます。デフォルト値を指定したい場合は、`\"${API_PORT:-3000}:3000\"`のように記述します。ホスト側のポートを固定すると、同じポートを利用する複数のコンテナを起動できず、テストが失敗する可能性があるため、動的ポートを使用しています。\n\n工夫している点として、`container_name`の設定があります。Testcontainersでは、docker-composeで起動する際にサービスへのアクセスにコンテナ名を使用します。そのため、コンテナ名を明示的に指定しています。ただし、同じ名前のコンテナを複数起動できないため、環境変数でランダムな接尾辞を付与する仕組みを採用しています。\n\nまた、`depends_on`を指定していますが、デフォルトではDBの起動完了を待たずにRailsが接続を試みて失敗することがありました。そこで、`healthcheck`を追加してDBの起動完了を確認するようにしています。\n\n`ports`のホスト側を固定しない設計については、Testcontainersのベストプラクティスを参考にしています。その他のTestcontainersのベストプラクティスについては、以下のリンクをご参照ください。\n\n- [Testcontainers のベスト プラクティス | Docker](https://www.docker.com/ja-jp/blog/testcontainers-best-practices/)\n\n### WebのSetup・Teardown\n\n次に、WebのSetupとTeardownについて説明します。以下に該当するコードをご覧ください。\n\n```ts\n// setup/web.ts\nimport path from \"path\";\nimport { GenericContainer, RandomUuid } from \"testcontainers\";\n\nconst WEB_PORT = 3200;\n\nexport const setupWebContainer = async (\n  apiInternalUrl,\n  apiPublicUrl,\n  networkName\n) => {\n  const webPath = path.resolve(__dirname, \"../../../apps/web\");\n  const uuid = new RandomUuid();\n  const containerSuffix = `${uuid.nextUuid()}`;\n  const webContainer = await (\n    await GenericContainer.fromDockerfile(webPath)\n      .withBuildArgs({\n        API_URL: apiInternalUrl,\n        NEXT_PUBLIC_API_URL: apiPublicUrl,\n      })\n      .build(`web:${containerSuffix}`, { deleteOnExit: true })\n  )\n    .withExposedPorts(WEB_PORT)\n    .withNetworkMode(networkName)\n    .start();\n\n  const webPort = webContainer.getMappedPort(WEB_PORT);\n  const webHost = `http://${webContainer.getHost()}:${webPort}`;\n\n  return {\n    webContainer,\n    webHost,\n    teardown: async () => {\n      await webContainer.stop({ remove: true, removeVolumes: true });\n    },\n  };\n};\n```\n\nWeb側では、シンプルなDockerのみを使用するため、`GenericContainer.fromDockerfile`を利用しています。イメージをビルドする際に`apiInternalUrl`と`apiPublicUrl`を渡すことで、Next.jsのSSR時およびCSR時のフェッチを確認できるようにしています。\n\nまた、Webへのアクセスを可能にするために`webHost`を`return`で返しています。Teardown時にはコンテナを停止しています。\n\nそれでは、いよいよテストのコードについて紹介します。\n\n## Test\n\n### ヘルスチェック\n\nヘルスチェックのテストコードを紹介します。\n\n```ts\nimport { chromium } from \"@playwright/test\";\nimport { describe, it, expect, beforeAll, afterAll } from \"vitest\";\nimport axios from \"axios\";\nimport { StartedTestContainer } from \"testcontainers\";\nimport { setupApiContainer, setupWebContainer } from \"../setup\";\n\ndescribe(\"Health check\", () => {\n  let apiContainer: StartedTestContainer;\n  let dbContainer: StartedTestContainer;\n  let webContainer: StartedTestContainer;\n  let apiPublicUrl: string;\n  let apiInternalUrl: string;\n  let executeSqlFile: (sqlContent: string, fileName: string) => Promise<string>;\n  let webHost: string;\n  let teardownApi: () => Promise<void>;\n  let teardownWeb: () => Promise<void>;\n\n  beforeAll(async () => {\n    const apiSetup = await setupApiContainer();\n    apiContainer = apiSetup.apiContainer;\n    apiInternalUrl = apiSetup.apiInternalUrl;\n    apiPublicUrl = apiSetup.apiPublicUrl;\n    const networkName = apiSetup.networkName;\n    dbContainer = apiSetup.dbContainer;\n    executeSqlFile = apiSetup.executeSqlFile;\n    teardownApi = apiSetup.teardown;\n\n    const webSetup = await setupWebContainer(\n      apiInternalUrl,\n      apiPublicUrl,\n      networkName\n    );\n    webContainer = webSetup.webContainer;\n    webHost = webSetup.webHost;\n    teardownWeb = webSetup.teardown;\n  });\n\n  afterAll(async () => {\n    await teardownWeb();\n    await teardownApi();\n  });\n\n  it(\"should perform a DB health check\", async () => {\n    // Arrange\n    const checkDatabaseSQL = \"SHOW DATABASES LIKE 'api_development';\";\n\n    // Act\n    const dbCheckOutput = await executeSqlFile(\n      checkDatabaseSQL,\n      \"check_database.sql\"\n    );\n    // Assert\n    expect(dbCheckOutput).toContain(\"api_development\");\n\n    // Arrange\n    const checkTableSQL = \"SHOW TABLES IN api_development LIKE 'todos';\";\n\n    // Act\n    const tableCheckOutput = await executeSqlFile(\n      checkTableSQL,\n      \"check_table.sql\"\n    );\n\n    // Assert\n    expect(tableCheckOutput).toContain(\"todos\");\n  });\n\n  it(\"should perform an API health check\", async () => {\n    // Arrange\n    const todosEndpoint = `${apiPublicUrl}/todos`;\n\n    // Act\n    const response = await axios.get(todosEndpoint);\n\n    // Assert\n    expect(response.status).toBe(200);\n    expect(Array.isArray(response.data)).toBe(true);\n  });\n\n  it(\"should perform a web health check\", async () => {\n    // Arrange\n    const todosPageUrl = `${webHost}`;\n\n    // Act\n    const browser = await chromium.launch();\n    const page = await browser.newPage();\n    await page.goto(todosPageUrl);\n\n    // Assert\n    expect(await page.title()).toBe(\"Create Next App\");\n  });\n});\n```\n\n先ほど紹介したSetupは、`beforeAll`および`afterAll`で使用しています。\n\nDBのヘルスチェックでは、`executeSqlFile`を使用してデータベース名とテーブル名を確認しています。Dockerに対して`exec`コマンドを用いてテストを行っています。\n\nAPIのヘルスチェックでは、`apiPublicUrl`を利用してエンドポイントのステータスおよびレスポンスデータをテストしています。\n\nWebのヘルスチェックでは、`webHost`を使用してPlaywrightでChromiumを起動し、`page.title`をテストしています。\n\n### 結合テスト\n\nTodo Appの結合テストについて紹介します。\n\n```ts\nimport { describe, it, beforeAll, afterAll, beforeEach, expect } from \"vitest\";\nimport { StartedTestContainer } from \"testcontainers\";\nimport { setupApiContainer, setupWebContainer } from \"../setup\";\nimport { chromium } from \"@playwright/test\";\nimport { TodoPage } from \"../pages\";\n\ndescribe(\"Integration Test\", () => {\n  let apiContainer: StartedTestContainer;\n  let webContainer: StartedTestContainer;\n  let apiPublicUrl: string;\n  let apiInternalUrl: string;\n  let webHost: string;\n  let teardownApi: () => Promise<void>;\n  let teardownWeb: () => Promise<void>;\n\n  beforeAll(async () => {\n    const apiSetup = await setupApiContainer();\n    apiContainer = apiSetup.apiContainer;\n    apiInternalUrl = apiSetup.apiInternalUrl;\n    apiPublicUrl = apiSetup.apiPublicUrl;\n    const networkName = apiSetup.networkName;\n    teardownApi = apiSetup.teardown;\n\n    const webSetup = await setupWebContainer(\n      apiInternalUrl,\n      apiPublicUrl,\n      networkName\n    );\n    webContainer = webSetup.webContainer;\n    webHost = webSetup.webHost;\n    teardownWeb = webSetup.teardown;\n  });\n\n  afterAll(async () => {\n    await teardownWeb();\n    await teardownApi();\n  });\n\n  beforeEach(async () => {\n    await apiContainer.exec([\"bin/rails\", \"runner\", \"Todo.delete_all\"]);\n  });\n\n  it(\"should allow adding, toggling, and deleting a todo item successfully\", async () => {\n    // Arrange\n    const todosPageUrl = `${webHost}`;\n    const browser = await chromium.launch();\n    const page = await browser.newPage();\n    const todoPage = new TodoPage(page);\n    await todoPage.navigate(todosPageUrl);\n\n    // Act\n    const newTodo = \"new Todo\";\n    await todoPage.addTodo(newTodo);\n    await todoPage.toggleTodo(newTodo);\n    await todoPage.deleteTodoByName(newTodo);\n\n    // Assert\n    const todos = await todoPage.getTodos();\n    expect(todos).toHaveLength(0);\n\n    await browser.close();\n  });\n\n  it(\"should save a todo item and persist it after reload\", async () => {\n    // Arrange\n    const todosPageUrl = `${webHost}`;\n    const browser = await chromium.launch();\n    const page = await browser.newPage();\n    const todoPage = new TodoPage(page);\n    await todoPage.navigate(todosPageUrl);\n\n    // Act\n    const newTodo = \"persistent Todo\";\n    await todoPage.addTodo(newTodo);\n    await todoPage.saveAllTodos();\n    await page.waitForTimeout(1000); // BAD!\n    await todoPage.navigate(todosPageUrl);\n\n    // Assert\n    // Web\n    const todos = await todoPage.getTodos();\n    expect(todos).toHaveLength(1);\n    expect(todos[0]).toEqual({ name: newTodo, checked: false });\n    // Rails\n    const result = await apiContainer.exec([\n      \"bin/rails\",\n      \"runner\",\n      \"puts Todo.all.to_json\",\n    ]);\n    const railsTodos = JSON.parse(result.output.trim());\n    expect(railsTodos).toHaveLength(1);\n    expect(railsTodos[0].name).toBe(newTodo);\n    expect(railsTodos[0].checked).toBe(false);\n\n    await browser.close();\n  });\n});\n```\n\nテストを実行する前に、`beforeEach`で各テストの前に`await apiContainer.exec([\"bin/rails\", \"runner\", \"Todo.delete_all\"]);`を実行し、**データを削除しています**。\nこの状態でPlaywrightを使用して、ブラウザ上でのテストを実施します。さらに、`apiContainer.exec`を用いて**データのテストも行っています**。\n\n上記のテストのように、**コンテナに直接アクセスできる**ため、Railsのコマンド実行やDBのデータ確認が可能です。これにより、単純にPlaywrightで結合テストを行うだけでなく、**必要に応じてデータの加工や準備も容易に行えます**。データだけでなく、コンテナに対して柔軟な操作をすることができます。(例えば、日付の変更、バッチの起動、イベントの発火など)\n結合テストではデータ準備やメンテナンスが課題となりますが、必要なデータのみを用意することで、メンテナンス負荷を軽減できます。\n\n#### TestContainersのよさ\n\n[What is Testcontainers, and why should you use it? | Testcontainers](https://testcontainers.com/guides/introducing-testcontainers/) でも述べられている通り、従来の統合テスト環境ではテストデータの管理が煩雑でした。特定のシナリオをテストするとテストデータが変更され、別のシナリオテストが失敗するなど、データの干渉が課題となっていました。これらの問題を解決してくれたのが、Testcontainersです。\n\nさらに、結合テスト環境のインフラ維持やメンテナンスの手間も大きな悩みの種でした。Testcontainersを利用することで、特別な結合テスト環境を用意する必要がなくなり、**テストのたびに環境が自動的に構築・削除されます**。これにより、コスト面でも効率的であり、より安定したテスト環境を実現できます。\n\n#### Page Object Model\n\n`TodoPage` については、[Page Object Model](https://playwright.dev/docs/pom)を採用しています。そのため、以下のようなTodoページに対するクラスを作成しています。\n\n```ts\nimport { Locator, Page } from \"@playwright/test\";\n\nexport class TodoPage {\n  page: Page;\n  newTodoInput: Locator;\n  addButton: Locator;\n  todoCheckbox: (name: string) => Locator;\n  deleteButton: (name: string) => Locator;\n  saveAllButton: Locator;\n\n  constructor(page: Page) {\n    this.page = page;\n    this.newTodoInput = page.getByPlaceholder(\"Add a new todo\");\n    this.addButton = page.getByRole(\"button\", { name: \"Add\" });\n    this.todoCheckbox = (todoName) =>\n      page\n        .locator(\".todo-list li\")\n        .filter({ hasText: todoName })\n        .getByRole(\"checkbox\");\n    this.deleteButton = (todoName) =>\n      page\n        .locator(\".todo-list li\")\n        .filter({ hasText: todoName })\n        .getByRole(\"button\");\n    this.saveAllButton = page.getByRole(\"button\", { name: \"Save All\" });\n  }\n\n  /**\n   * Navigate to the Todo app.\n   */\n  async navigate(url: string) {\n    await this.page.goto(url);\n  }\n\n  /**\n   * Add a new todo item.\n   */\n  async addTodo(text: string) {\n    await this.newTodoInput.fill(text);\n    await this.addButton.click();\n  }\n\n  /**\n   * Toggle a todo item by its name.\n   */\n  async toggleTodo(todoName: string) {\n    const checkbox = this.todoCheckbox(todoName);\n    await checkbox.check();\n  }\n\n  /**\n   * Delete a todo item by its name.\n   */\n  async deleteTodoByName(todoName: string) {\n    const deleteBtn = this.deleteButton(todoName);\n    await deleteBtn.click();\n  }\n\n  /**\n   * Save all todos.\n   */\n  async saveAllTodos() {\n    await this.saveAllButton.click();\n  }\n\n  /**\n   * Get all visible todo items with their names and checked status.\n   */\n  async getTodos() {\n    const todoItems = this.page.locator(\".todo-list li\");\n    const results: { name: string; checked: boolean }[] = [];\n    const itemsCount = await todoItems.count();\n\n    for (let i = 0; i < itemsCount; i++) {\n      const todo = todoItems.nth(i);\n      const name = await todo.locator(\"span\").textContent();\n      const checked = await todo.locator(\"input[type='checkbox']\").isChecked();\n      results.push({ name: name?.trim() || \"\", checked });\n    }\n\n    return results;\n  }\n}\n```\n\n蛇足になりますが、テストサイクルを高速化するために、`TodoPage`オブジェクトの検証には`examples`フォルダを用意しています。このフォルダでは、対象ページを`playwright codegen`で開き、操作手順を自動生成しながらアクセス方法を確認・テストします。問題がないことを確認できた段階で、これらの操作を結合テストに組み込むことで、`TodoPage`の個別テストを省略することが可能になります。\n\n## 終わりに\n\nいかがだったでしょうか。Testcontainersの魅力に気づきましたでしょうか。\nぜひ、結合テストの1つに利用してみてください。\n\n## 参考\n\n- [Getting Started | Testcontainers](https://testcontainers.com/getting-started/)\n- [Getting started with Testcontainers for Node.js | Testcontainers](https://testcontainers.com/guides/getting-started-with-testcontainers-for-nodejs/)\n- [Search for Testcontainers | Docker](https://www.docker.com/search/?_sf_s=Testcontainers)","publishedAt":"2025-01-03","slug":"testcontainers-integration-test-disposable","title":"Testcontainersで実現する、使い捨て結合テスト環境構築とテスト実施"},{"body":"こんにちは、Webフロントエンド開発者のみなさま。silverbirderと申します。\n\n突然ですが、みなさんは普段どのようにCSSを設計していますか？愚直にプロパティを書いていますか？それとも、何かしらのルールがありますか？\n\n私自身、この1年間、スタイルに関わるさまざまな開発を経験してきました。その経験から、CSS設計に関するプラクティスが少しずつ固まってきました。そこで今回は、私が得た知見の中から**10つの考え**を共有したいと思います。これらの考えが、みなさんのCSS設計に少しでも役立つヒントになれば幸いです。\n\n## CSS設計\n\nHTMLとCSSのサンプルを使って具体例をご紹介します。コードは CodePen でプレビューできるようにしていますので、視覚的に確認しながらお読みください。\n\nまた、各見出しは独立しているため、興味のあるセクションだけをお読みいただいても問題ありません。ぜひご活用ください。\n\n### 親が子をレイアウトする\n\nCSSで `padding` や `margin` を使うのは日常茶飯事です。\n例えば、以下のようなコードを考えてみましょう。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item1\">item1</div>\n  <div class=\"item2\">item2</div>\n</div>\n```\n\n```css\n.wrapper {\n  background-color: lightgray;\n}\n\n.item1 {\n  margin-bottom: 0.25rem;\n  margin-top: 0.5rem;\n  background-color: lightblue;\n}\n\n.item2 {\n  margin-bottom: 0.25rem;\n  background-color: lightblue;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/gbYwrOa)\n\nこのコードでは、以下のようにスペースを調整しています。\n\n- `.item`間に `0.25rem` のスペース\n- `.item`全体の上下に `0.5rem` のスペース\n\nスペースを適切に調整することで、要素のグループ分けが視覚的にわかりやすくなります。\nこのコードでも、意図したデザインを表現することはできます。\n\nしかし、機能が増えてデザインが変更される場合を考えてみましょう。例えば、以下のような修正が発生したとします。\n\n- item1 と item2 の間に item3 を追加\n\nこの場合、多くの人は item1 や item2 をコピーして item3 を挿入するでしょう。\nしかし、間のスペースを正しく保つために、item3 の `margin-bottom` を `0.25rem` に設定しなければなりません。\nさらに、**item間のスペースが変更された場合は、item1、item2、item3 それぞれのスタイルを修正する必要**があります。\n\nこのような状況を避けるために、**itemの周りのスペースは「親」が調整するべき** だと私は考えます。\n**item自身の責務は、自身の内部スタイルに限定するべき** です。\nそこで、以下のようにコードを修正します。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item\">item1</div>\n  <div class=\"item\">item2</div>\n</div>\n```\n\n```css\n.wrapper {\n  display: flex;\n  flex-direction: column;\n  gap: 0.25rem;\n  margin-top: 0.5rem;\n  margin-bottom: 0.5rem;\n  background-color: lightgray;\n}\n\n.item {\n  background-color: lightblue;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/xbKEVYo)\n\nこの方法では、以下のようなメリットがあります。\n\n- 親要素（`.wrapper`）が、子要素（`.item`）の間のスペースを調整\n- `.item`自身のスタイルは再利用可能に\n- レイアウト調整は `.wrapper` だけで済む\n\nまた、[Every Layout](https://every-layout.dev/) の Stack パターンのように、以下の方法も利用できます。\n\n```css\n.wrapper > * + * {\n  margin-top: 0.25rem;\n}\n/* 再帰的にする場合 */\n.wrapper * + * {\n  margin-top: 0.25rem;\n}\n```\n\nこの方法も有効ですが、少し直感的ではないかもしれません。\n特に、後から読む人やメンテナンスをする人にとっては難解に感じる場合があります。\n\nその点、`gap` を使った方法はシンプルでわかりやすく、メンテナンス性が高いでしょう。レイアウトでよく使うのは、以下のものでしょうか。\n\n- `flex`\n  - `gap`\n- `grid`\n  - `row-gap`\n  - `column-gap`\n- `margin`\n- `padding`\n\n今後も、理解しやすく柔軟性のある設計を意識していきたいですね。\n\n### できれば、固定値を使わない\n\nCSSを書く際、ついｴｲﾔｯと固定値を使ってしまうことがあるかもしれません。\n例えば、以下のようなコードです。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item\"></div>\n</div>\n```\n\n```css\n.wrapper {\n  position: relative;\n  background-color: lightblue;\n  width: 200px;\n  height: 100px;\n}\n.item {\n  position: absolute;\n  top: 10px;\n  left: 10px;\n  background-color: lightgreen;\n  width: 180px;\n  height: 80px;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/vEBXGjG)\n\nこのようなスタイルが絶対に悪いわけではありません。状況によっては適切な場合もあります。\nしかし、**固定値を多用すると、次のような理由でレイアウトが崩れるリスクが高まります**。\n\n- ブラウザのウィンドウサイズが変更された場合\n- アイテム内のコンテンツが動的に変化した場合\n\n意図するデザインに応じて対処は異なりますが、私なら以下のように修正します。\n\n```css\n.wrapper {\n  background-color: lightblue;\n  /* 親要素の幅に合わせる */\n  width: 100%;\n  /* 最大の幅を200pxに制限 */\n  max-width: 200px;\n  /* 横:縦 = 2:1 の比率を維持 */\n  aspect-ratio: 2 / 1;\n  /* 内部の余白を10pxに設定 */\n  padding: 10px;\n  /* widthにpaddingやborderを含める */\n  box-sizing: border-box;\n}\n.item {\n  background-color: lightgreen;\n  /* 親要素のサイズにフィットさせる */\n  width: 100%;\n  height: 100%;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/jENMqxz)\n\nこの修正では、以下のような柔軟性が得られます。\n\n- 親要素に応じて自動で調整されるサイズ\n- 最大幅の制限や比率維持により意図したデザインを保つ\n- コンテンツが動的に変化しても崩れにくいレイアウト\n\n基本的な考え方として、CSSでは **『ブラウザに計算させる』** ことを意識するのがベターです。\n固定値に頼らず、柔軟な設計を心がけることで、より適応性の高いスタイルが実現できます。\n\n#### 絶対長と相対長\n\nCSSの単位には、**絶対長** と **相対長** の2種類があります。\nその名のとおり、**絶対長** は常に固定の長さを表し、**相対長** は他の要素や値に基づく相対的な長さを示します。\n\n- 絶対長の例\n  - `px`\n  - `in`\n- 相対長の例\n  - フォントサイズを基準\n    - `em`、`rem`\n    - `ex`、`rex`\n    - `cap`、`rcap`\n    - `ch`、`rch`\n    - `ic`、`ric`\n  - ビューポートを基準\n    - `vh`、`lvh`、`svh`、`dvh`\n    - `vw`、`lvw`、`svw`、`dvw`\n  - 行の高さを基準\n    - `lh`、`rlh`\n  - コンテナクエリを基準\n    - `cqw`、`cqh`\n  - 親要素を基準\n    - `%`\n\n##### `em` と `rem` の違い\n\n- `em`: 親要素のフォントサイズを基準にした相対値。\n- `rem`: ルート要素（`:root`）のフォントサイズを基準にした相対値。\n\n例えば、`:root { font-size: 16px; }` の場合、`1rem` は常に `16px` に相当します。一方、`em` はその要素の親に依存します。\n\n##### 動的な計算: CSS 関数\n\nCSS の関数を使うと、柔軟なスタイル設定が可能です。\n\n- `calc()`: 四則演算を用いて動的に値を計算。\n- `minmax()`: 最小値と最大値を指定して柔軟なレイアウトを設定。\n\n---\n\nこれらの相対長や CSS 関数を使うことで、**値の計算をブラウザに任せられる**ため、**開発者が細かく四則演算を行う必要が減ります**。また、基準値を `:root` で定義しておけば、**基準を変更するだけで相対値も自動的に調整され**、柔軟性が向上します。\n\n例えば、フォントサイズを `rem` で管理すれば、デバイスに応じたフォントサイズの調整が容易になります(次の見出しで解説します)。さらに、ページの横幅をビューポート単位（`vw` や `%`）で基準にしつつ、コンテナクエリを組み合わせれば、画面幅に応じてレイアウトが自動的に変化します。また、`flex` コンテナを活用することで、より柔軟で適応性の高いデザインが実現します。\n\nその他の単位について詳しく知りたい方は、以下のMDNのリンクをご参照ください。\n\n- [CSS 値と単位 - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_Values_and_Units)\n- [length - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/length)\n\n##### 実例：デバイスに応じたフォントサイズの調整\n\n以下のCSSは、デバイスごとに異なるフォントサイズを指定する例です。\n\n```css\n.wrapper {\n  /* スマートフォン向けスタイル */\n  font-size: 16px;\n\n  /* タブレット向けスタイル */\n  @media (768px <= width < 1024px) {\n    font-size: 24px;\n  }\n  /* ラップトップ向けスタイル */\n  @media (1024px <= width < 1280px) {\n    font-size: 32px;\n  }\n  /* デスクトップ向けスタイル */\n  @media (1280px <= width) {\n    font-size: 40px;\n  }\n}\n```\n\nこのコードでも問題ありませんが、より柔軟な書き方として `rem` を使用する方法があります。\n\n##### `rem` を使った柔軟なスタイル\n\nまず、`:root` に基準となるフォントサイズを指定します。\n\n```css\n:root {\n  font-size: 16px;\n}\n```\n\nそして、以下のように `rem` を使ってスタイルを記述します。\n\n```css\n.wrapper {\n  /* 1rem = 16px; */\n  font-size: 1rem;\n\n  /* タブレット向けスタイル */\n  @media (768px <= width < 1024px) {\n    font-size: 1.5rem;\n  }\n  /* ラップトップ向けスタイル */\n  @media (1024px <= width < 1280px) {\n    font-size: 2rem;\n  }\n  /* デスクトップ向けスタイル */\n  @media (1280px <= width) {\n    font-size: 2.5rem;\n  }\n}\n/* 全体に関わるなら、:rootの中でやるのも良いかもしれません。 */\n```\n\nこの方法では以下のメリットがあります。\n\n- 相対的な値がわかりやすい\n  - 例えば、デスクトップ向けのフォントサイズが基準サイズ（`16px`）の 2.5 倍であることが一目でわかります。\n- 全体の調整が簡単\n  - `:root` のフォントサイズを変更すれば、すべての `rem` の値が一括で更新されます。これにより、デザイン全体の調整が効率的になります。\n\n##### `clamp()` を使った高度な例\n\nさらに、以下のように `clamp()` を使うことで、フォントサイズを1行で指定することも可能です。\n\n```css\n.wrapper {\n  /* 最小viewportが375px、最大が1280px */\n  font-size: clamp(1rem, 0.378rem + 2.65vw, 2.5rem);\n  /* ref: https://github.com/9elements/min-max-calculator */\n}\n```\n\n1行で書けますが、直感的には分かりにくいかもしれません。そのため、`font-size`を分けて書く方がメンテナンスしやすいかもしれません。\n\n### レスポンシブのメディアクエリは、小さい順に\n\nWebサイトを閲覧するデバイスには、さまざまな大きさがあります。\n一般的には、以下のようなデバイスごとにスタイルを分けることが多いです。\n\n- スマートフォン\n- タブレット\n- ラップトップ\n- デスクトップ\n\nサービスによっては、さらに細かく分けたり、特殊なデバイスに対応する場合もあります。\n幅広いデバイスに対応するためには、デバイスのサイズに応じて見やすいCSSを書くことが重要です。その際によく使われる手法が **メディアクエリ** です。\n\n#### メディアクエリの書き方\n\nメディアクエリは主に2種類の書き方があります。\n\n##### 1. 小さい順\n\n```css\n.wrapper {\n  /* スマートフォン向けスタイル */\n\n  @media (min-width: 768px) {\n    /* タブレット向けスタイル */\n  }\n\n  @media (min-width: 1024px) {\n    /* ラップトップ向けスタイル */\n  }\n\n  @media (min-width: 1280px) {\n    /* デスクトップ向けスタイル */\n  }\n}\n```\n\n##### 2. 大きい順\n\n```css\n.wrapper {\n  /* デスクトップ向けスタイル */\n\n  @media (max-width: 1024px) {\n    /* ラップトップ向けスタイル */\n  }\n\n  @media (max-width: 768px) {\n    /* タブレット向けスタイル */\n  }\n\n  @media (max-width: 640px) {\n    /* スマートフォン向けスタイル */\n  }\n}\n```\n\n#### おすすめなのは小さい順\n\n最近では、**モバイルファースト** のアプローチが一般的になっています。\n小さい順にスタイルを記述することで、デバイスのサイズが大きくなるに従ってスタイルを **上書き** する形になり、直感的に分かりやすいというメリットがあります。\n\nただし、「タブレットの `min-width` や `max-width` は何だっけ？」といった疑問が生じることもあります。\nこの点を改善するために、**Media Queries Level 4** の記法を活用する方法があります。\n\n#### Media Queries Level 4 の記法\n\n以下のように記述すると、デバイスの範囲が明確になり、直感的に理解しやすくなります。\n\n```css\n.wrapper {\n  /* スマートフォン向けスタイル */\n\n  @media (768px <= width < 1024px) {\n    /* タブレット向けスタイル */\n  }\n\n  @media (1024px <= width < 1280px) {\n    /* ラップトップ向けスタイル */\n  }\n\n  @media (1280px <= width) {\n    /* デスクトップ向けスタイル */\n  }\n}\n```\n\nこのように記述することで、例えば「タブレットは `768px` から `1024px` の間」と範囲がはっきり分かります。\n\n### CSSの値は、共通変数で扱う\n\nCSSを書く際、フォントサイズ、背景色、ボーダーの角丸などの値を記述するのはよくあることです。\n\n```css\n.item {\n  border: 1px solid hsl(360deg 100% 15%);\n  border-radius: 30px;\n  padding: 2px;\n  margin: 2px;\n}\n```\n\nこのような値を繰り返し記述するうちに、同じ意図を持つ値が複数箇所に出現することがよくあります。\n例えば、ブランドカラーやスペーシングの値などです。このような繰り返しは、**DRY（Don't Repeat Yourself）原則に反している**と言えます。\n\n近年、多くの企業がデザインシステムを導入・運用しており、こうした色やスペーシングの値はデザイントークンとして管理されています。([Tokens Studio for Figma](https://www.figma.com/community/plugin/843461159747178978/tokens-studio-for-figma)がお気に入りです)\n\nそこで、CSSの値を共通変数として定義することをお勧めします。\nCSSではカスタムプロパティ、CSS-in-JSではJavaScript変数、SassではSass変数を使用できます。\n\n```css\n:root {\n  --radius-outer: 30px;\n  --color-border: hsl(360deg 100% 15%);\n  --spacing-x: 2px;\n}\n\n.item {\n  /* var(変数名, デフォルト値) */\n  border: 1px solid var(--color-border);\n  border-radius: var(--radius-outer);\n  padding: var(--spacing-x);\n  margin: var(--spacing-x);\n}\n```\n\nこのように定義すれば、ボーダー色を変更したい場合でも、`:root` の変数を修正するだけで済みます。\n\n#### Z軸を意識する\n\nCSSを書く中で、`z-index` を使用して要素の重なり順を調整する場面があります。以下の例を見てみましょう。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"layer1\">layer1</div>\n  <div class=\"layer2\">layer2</div>\n  <div class=\"layer3\">layer3</div>\n</div>\n```\n\n```css\n.wrapper {\n  position: relative;\n}\n\n.layer1 {\n  position: absolute;\n  background-color: lightblue;\n  z-index: 1;\n  width: 300px;\n  height: 300px;\n}\n.layer2 {\n  position: absolute;\n  background-color: lightgreen;\n  z-index: 3;\n  width: 100px;\n  height: 100px;\n}\n.layer3 {\n  position: absolute;\n  background-color: lightcoral;\n  z-index: 2;\n  width: 200px;\n  height: 200px;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/KwPgzJx)\n\nこのコードでは、`z-index` の値に基づいて、`layer2（lightgreen）`が一番上に表示されます。\nこのように要素が増えると、`z-index` の値を管理するのが複雑になります。\n\nそこで、`z-index` の値も共通変数として定義すると、管理が簡単になります。\n\n```css\n:root {\n  --layer-bottom: 1;\n  --layer-middle: 2;\n  --layer-top: 3;\n}\n\n.wrapper {\n  position: relative;\n}\n\n.layer1 {\n  position: absolute;\n  background-color: lightblue;\n  z-index: var(--layer-bottom);\n  width: 300px;\n  height: 300px;\n}\n.layer2 {\n  position: absolute;\n  background-color: lightgreen;\n  z-index: var(--layer-top);\n  width: 100px;\n  height: 100px;\n}\n.layer3 {\n  position: absolute;\n  background-color: lightcoral;\n  z-index: var(--layer-middle);\n  width: 200px;\n  height: 200px;\n}\n```\n\n`z-index`に関連して大事な概念が、**重ね合わせコンテキスト**です。重ね合わせコンテキストとは、以下のとおりです。\n\n> 重ね合わせコンテキスト (Stacking context) は、ビューポートまたはウェブページに面していると想定されるユーザーに対する仮想的な Z 軸に沿って並べられた HTML 要素の三次元の概念化です。 HTML 要素は、要素の属性に基づいてこの空間を優先度つきの順序で占有します。\n[重ね合わせコンテキスト - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_positioned_layout/Understanding_z-index/Stacking_context)\n\n重ね合わせコンテキスト内では、`z-index`の値を比較して要素の重なり順を制御できます。しかし、**異なる重ね合わせコンテキストに属する `z-index` 同士は比較できません**。詳しく知りたい方は、以下のリンクを参考にしてください。\n\n- [君は真に理解しているか？z-indexとスタッキングコンテキストの関係 - ICS MEDIA](https://ics.media/entry/200609/)\n\n重ね合わせコンテキストを生成する条件にはいくつかのパターンがあります。以下は、特によく見られるものです。\n\n- `position` の値が `absolute` または `relative` であり、かつ `z-index` の値が `auto` 以外の要素\n- `position` の値が `fixed` または `sticky` の要素\n- フレックスコンテナーの子であり、 `z-index` の値が auto 以外の要素。\n- グリッド (grid) コンテナーの子であり、 `z-index` の値が auto 以外の要素。\n\n詳しくは、以下の MDN の記事をご覧ください。\n\n- [重ね合わせコンテキスト - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_positioned_layout/Understanding_z-index/Stacking_context) より引用\n\n新しい重ね合わせコンテキストを生成する簡単な方法として `isolation` プロパティがあります。`isolation`プロパティを使って新しい重ね合わせコンテキストを生成することできるので、**他の重ね合わせコンテキストにあるz-indexの影響を受けず**に、`z-index`の値を設定できます。\n\n以下は、`isolation`プロパティの例です。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item\"></div>\n</div>\n<div class=\"outer\"></div>\n```\n\n```css\n.wrapper {\n  position: absolute;\n  /* 新しく、重ね合わせコンテキストを生成 */\n  /* コメントアウトしてみて、挙動を確認してみてください。 */\n  isolation: isolate;\n}\n\n.item {\n  position: absolute;\n  width: 100px;\n  height: 150px;\n  background-color: lightpink;\n  /* wrapperが新しく重ね合わせコンテキストを生成した場合、outerよりitemが下になる */\n  /* wrapperが新しく重ね合わせコンテキストを生成しない場合、outerよりitemが上になる */\n  z-index: 999;\n}\n\n.outer {\n  position: absolute;\n  width: 150px;\n  height: 100px;\n  background-color: lightgreen;\n  z-index: 1;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/mybrPoW)\n\n重ね合わせコンテキストについて視覚的に理解したくなると思う方には、以下のChrome拡張機能がオススメです。\n\n- [CSS Stacking Context inspector - Chrome ウェブストア](https://chromewebstore.google.com/detail/css-stacking-context-insp/apjeljpachdcjkgnamgppgfkmddadcki?hl=ja)\n\n#### 影とエレベーション\n\n`box-shadow`を使用すると、要素に影をつけることができます。以下は基本的な例です。\n\n```html\n<div class=\"wrapper\"></div>\n```\n\n```css\n.wrapper {\n  width: 100px;\n  height: 100px;\n  background-color: #dddddd;\n  border-radius: 4px;\n  /* x方向6px、y方向6px、ぼかし6px、広がり0px、色 */\n  box-shadow: 6px 6px 6px 0px rgba(0, 0, 0, 0.45);\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/GgKNEwQ)\n\n`box-shadow` は以下の要素を定義できます。\n\n- 影の方向 (x軸、y軸)\n- ぼかし\n- 広がり\n- 色 (RGBAやHEX形式など)\n\n影のぼかしや広がり具合は、**要素の物理的な高さに応じて変化する**ことが一般的です。そこで、エレベーションというものを紹介します。\n\n[エレベーション（概要）｜デジタル庁デザインシステムβ版](https://design.digital.go.jp/foundations/elevation/) より引用しますと、\n\n> エレベーションは、ブラウザ上で表示されるコンポーネントの高さの度合いを示します。\n\n**要素のZ軸の高さによって影のぼかしや広がりを定義しておく**と、より直感的なデザインが可能になります。以下は、エレベーションのレイヤーごとに影を定義し、それをカスタムプロパティを使用して適用する例です。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item layer-1\"></div>\n  <div class=\"item layer-2\"></div>\n  <div class=\"item layer-3\"></div>\n</div>\n```\n\n```css\n:root {\n  --shadow-layer-1: 2px 2px 4px rgba(0, 0, 0, 0.2);\n  --shadow-layer-2: 4px 4px 8px rgba(0, 0, 0, 0.3);\n  --shadow-layer-3: 6px 6px 12px rgba(0, 0, 0, 0.4);\n}\n\n.wrapper {\n  display: flex;\n  gap: 10px;\n}\n\n.item {\n  width: 100px;\n  height: 100px;\n  background-color: #dddddd;\n  border-radius: 4px;\n}\n\n.layer-1 {\n  box-shadow: var(--shadow-layer-1);\n}\n\n.layer-2 {\n  box-shadow: var(--shadow-layer-2);\n}\n\n.layer-3 {\n  box-shadow: var(--shadow-layer-3);\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/WbeoOVm)\n\n#### `position: absolute` を使用する際の注意点\n\n`position: absolute` を使う場合、基準となる祖先要素に `position: relative` などを設定する必要があります。**設定しない場合、ルート要素(html)が基準となってしまいます**。以下の例のように、必ず `position: relative` をつけましょう。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"image\"></div>\n  <div class=\"text\">Hello, World</div>\n</div>\n```\n\n```css\n.wrapper {\n  /* 位置指定要素として定義 */\n  position: relative;\n  width: 200px;\n  height: 200px;\n  background-color: lightblue;\n}\n\n.image {\n  width: 200px;\n  height: 150px;\n  background-color: lightgreen;\n}\n\n.text {\n  /* wrapperに対して、top:0, left:0 の位置 */\n  position: absolute;\n  top: 0px;\n  left: 0px;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/jENMqJp)\n\nこの設定により、`.text` 要素は `.wrapper` を基準に配置されます。基準を明示的に設定することで、意図した配置が確実になります。\n\n### `flex` で要素を伸縮させる\n\n要素を縦横に柔軟に配置する際には、`display: flex` を使用することが一般的です。\n以下のように、`flex-direction` を使うことで、フレックスアイテムの配置を調整できます。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"item\">item1</div>\n  <div class=\"item\">item2</div>\n</div>\n```\n\n```css\n.wrapper {\n  display: flex;\n\n  /* スマートフォンやタブレットでは縦に積む */\n  flex-direction: column;\n\n  /* ラップトップ以上の画面幅では横に並べる */\n  @media (min-width: 1024px) {\n    flex-direction: row;\n  }\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/RNbGaOK)\n\n`flex` の大きな特徴は、**フレックスコンテナ内でアイテムの伸縮を制御できる点**です。主に以下の3つのプロパティを利用します。\n\n- `flex-grow`: 残りの空間をどれだけ占めるか（デフォルト: 0）。\n- `flex-shrink`: コンテナ内が狭い場合にどれだけ縮むか（デフォルト: 1）。\n- `flex-basis`: 初期の寸法。この値を基準に、`flex-grow` や `flex-shrink` によって大きさが変化します（デフォルト: `auto`）。\n\n`flex-basis: auto` の場合、横方向では `width`、縦方向では `height` の `auto` に基づきます。\n\n#### Sidebarパターンの活用\n\n[Every Layout の Sidebar パターン](https://every-layout.dev/layouts/sidebar/) は、`flex` を活用した良い例です。\n以下のコードは、そのSidebarパターンの例です。\n\n```html\n<div class=\"with-sidebar\">\n  <div class=\"sidebar\"></div>\n  <div class=\"not-sidebar\"></div>\n</div>\n```\n\n```css\n.with-sidebar {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 1rem;\n  background-color: lightblue;\n  height: 500px;\n  width: 800px;\n}\n\n.sidebar {\n  /* ↓ The width when the sidebar _is_ a sidebar */\n  flex-basis: 20rem;\n  flex-grow: 1;\n  background-color: lightgreen;\n}\n\n.not-sidebar {\n  /* ↓ Grow from nothing */\n  flex-basis: 0;\n  flex-grow: 999;\n  /* ↓ Wrap when the elements are of equal width */\n  min-width: 50%;\n  background-color: lightpink;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/NPKRNmY)\n\nこの例では、`.with-sidebar` をフレックスコンテナとして定義し、アイテムごとに伸縮を設定しています。\nさらに、`.not-sidebar` に `min-width` を指定することで、幅が足りなくなった場合は `flex-wrap` により自動的に折り返します。\n\n結果として、以下のようなレスポンシブデザインが実現します。\n\n- 横幅が広い場合: サイドバーは左、ノットサイドバーは右に並びます。\n- 横幅が狭い場合: サイドバーは上、ノットサイドバーは下に積まれます。\n\nメディアクエリを使わず、`flex` の伸縮性を活用することで、柔軟なレイアウトを実現できる点がこの方法の利点です。\n\n### `display: contents` で要素を「なかったこと」にする\n\nHTMLやCSSを書いていると、レスポンシブデザインで困ることがあります。例えば、以下のようなHTML構造があったとします。\n\n```html\n<div class=\"card\">\n  <div class=\"title\">タイトル</div>\n  <div class=\"description\">説明</div>\n  <img class=\"image\" src=\"https://via.placeholder.com/150\" />\n</div>\n```\n\n以下のような表示要件を満たす必要があるとします。\n\n- スマートフォン表示: タイトル、説明、画像を縦に並べる。\n- ラップトップ表示: 左側に画像、右側にタイトルと説明を縦に並べる。\n\nスマートフォン表示だけなら、`flex-direction: column` を指定するだけで対応できます。\nしかし、ラップトップ表示を考慮すると、HTML構造を変える必要が出てきます。\n\nここで活用できるのが `display: contents` です。このプロパティを使えば、要件を満たす柔軟なデザインが可能になります。\n\n#### `display: contents` を用いた解決方法\n\n以下のHTMLとCSSを見てみましょう。\n\n```html\n<div class=\"card\">\n  <div class=\"wrapper\">\n    <div class=\"title\">title</div>\n    <div class=\"description\">description</div>\n  </div>\n  <img class=\"image\" src=\"https://via.placeholder.com/150\" />\n</div>\n```\n\n```css\n.card {\n  display: flex;\n  /* スマホの場合、縦に積む */\n  flex-direction: column;\n  gap: 1rem;\n\n  /* ラップトップの場合、横に並べる */\n  @media (1024px <= width) {\n    flex-direction: row;\n  };\n}\n\n.wrapper {\n  /* スマホの場合、なかったことにする */\n  display: contents;\n\n  /* ラップトップの場合、縦に積む */\n  @media (1024px <= width) {\n    display: flex;\n    flex-direction: column;\n  };\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/azomNgb)\n\n`display: contents` を指定すると、**その要素は「なかったこと」として扱われます。**\n以下のようにブラウザ上で解釈されます。\n\n```html\n<div class=\"card\">\n  <!-- <div class=\"wrapper\"> -->\n    <div class=\"title\">title</div>\n    <div class=\"description\">description</div>\n  <!-- </div> -->\n  <img class=\"image\" src=\"https://via.placeholder.com/150\" />\n</div>\n```\n\nこのため、`.card` の `flex-direction` や `gap` のスタイルが `.title` や `.description` に直接適用されます。\n結果として、スマートフォン表示とラップトップ表示の両方の要件を満たすことができます。\n\n### テキストスタイルはテキストに適用する\n\nCSS は \"Cascading Style Sheets\" の略で、「カスケーディング（Cascading）」とは、親から子、孫へとスタイルが継承されることを指します。\nこの特性を利用すると、親要素にスタイルを定義するだけで子要素にも適用されます。\n\n例えば、以下のような HTML と CSS を考えます。\n\n```html\n<div class=\"wrapper\">\n  <span class=\"text\">Hello, World</span>\n</div>\n```\n\n```css\n.wrapper {\n  /* レイアウトスタイル */\n  padding: 1rem;\n\n  /* テキストスタイル */\n  font-size: 1rem;\n  font-weight: 400;\n  line-height: 1.5;\n  color: red;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/jENMqjv)\n\nこの場合、`.wrapper` で定義したスタイルが `.text` 要素にも適用され、期待する結果が得られます。\nしかし、この設計には問題が潜んでいます。\n\n#### 問題点: 意図しない継承のリスク\n\n親要素にテキストスタイルを定義すると、子要素全体に適用されます。\n例えば、以下のように `.wrapper` に新しいテキストを追加した場合を考えます。\n\n```html\n<div class=\"wrapper\">\n  <span class=\"text\">Hello, World</span>\n  <div>\n    <span>Thank you</span>\n  </div>\n</div>\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/qEWaZeO)\n\nここでは、`Thank you` にも `font-size` や `color` といったスタイルが適用されます。\nこれが意図通りであれば問題ありません。しかし規模が大きくなると、このような継承は意図しないデザインの崩れや混乱を引き起こす原因になります。\n\n#### 解決策: テキストスタイルをテキストに適用する\n\n親要素にまとめてテキストスタイルを適用したくなるかもしれませんが、それは意図しないデザイン崩れを引き起こす可能性があります。CSS設計が曖昧にならないよう、以下のように**テキストスタイルをテキストに適用すること**をお勧めします。\n\n```css\n.wrapper {\n  /* レイアウトスタイル */\n  padding: 1rem;\n\n  /* 特定の子要素 (.text) にスタイルを限定 */\n  & > .text {\n    font-size: 1rem;\n    font-weight: 400;\n    line-height: 1.5;\n    color: red;\n  }\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/qEWaNWb)\n\nまた、汎用的に使用するテキストスタイルは、以下のようにクラスを分離して定義するのが良いでしょう。\n\n```css\n.wrapper {\n  /* レイアウトスタイル */\n  padding: 1rem;\n}\n\n.text {\n  font-size: 1rem;\n  font-weight: 400;\n  line-height: 1.5;\n  color: red;\n}\n```\n\n`font-size`、`font-weight`、`line-height` のセットは、デザインシステムでいう「**タイポグラフィ**」として定義するとさらに効果的です。これにより、統一感のあるデザインが実現できます。\n\n### CSSボックスモデルを理解する\n\nブラウザのレンダリングエンジンは、コンテンツを描画する際に **CSS基本ボックスモデル** を使用します。このボックスモデルは、要素を長方形のボックスとして表現し、以下の4つの領域で構成されています。\n\n- コンテンツ領域: 文字や画像などの「実際の」コンテンツが含まれる部分。\n- パディング領域: コンテンツと境界（ボーダー）の間のスペース。\n- 境界領域: ボーダーが描画される部分。\n- マージン領域: ボックスの外側の余白。\n\n詳しくは以下のリンクを参考にしてください。\n\n- [CSS 基本ボックスモデル入門 - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_box_model/Introduction_to_the_CSS_box_model)\n\n#### `width` や `height` の指定が引き起こす問題\n\nCSSで `width` や `height` を指定すると、その値は **コンテンツ領域** のみに適用されます。\nボーダーやパディングはその値に含まれません。この挙動を知らないと、以下のような問題に直面することがあります。\n\n```html\n<div class=\"wrapper\"></div>\n```\n\n```css\n/* 横幅は、100px + paddingの左右 2px + borderの左右 2px = 104px */\n.wrapper {\n  width: 100px;\n  height: 100px;\n  padding: 1px;\n  border: 1px solid black;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/OPLRXLz)\n\nこの場合、表示される `.wrapper` の横幅は `100px` ではなく、ボーダーとパディングを加えた `104px` になります。\n\n#### 解決策: `box-sizing` プロパティを使う\n\nこうした問題を解決するために、`box-sizing` プロパティを使います。\n`box-sizing: border-box;` を指定すると、`width` や `height` の値にボーダーとパディングが含まれるようになります。\n\n```css\n/* 横幅は 100px */\n.wrapper {\n  width: 100px;\n  height: 100px;\n  padding: 1px;\n  border: 1px solid black;\n  box-sizing: border-box;\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/azomZbz)\n\nこれにより、要素の外側のサイズが意図通りに計算され、デザインの予測がしやすくなります。\n\n#### グローバル設定での注意点\n\n多くのプロジェクトでは、全ての要素に対して `box-sizing: border-box;` を適用するスタイルを採用しています。\n\n```css\n*,\n*::before,\n*::after {\n  box-sizing: border-box;\n}\n```\n\nただし、このようなグローバル設定を採用する場合は、以下の点に注意してください。\n\n##### チーム内での周知\n\n全員がこのスタイルを理解していることが重要です。\n知らない人が個別に `box-sizing: border-box;` を追加してしまうと、冗長なコードが発生します。\n\n### 縦横のラインを揃える\n\nデザインにおいて、**縦横のラインが揃っていることは非常に重要**です。\nラインが揃うことで、どの要素が同じグループであるかが視覚的に明確になり、コンテンツの理解がしやすくなります。\n\n例えば、カードUIを横に並べた際、画像やタイトル、説明文の位置が揃っていないと、全体的に乱雑な印象を与えます。\n以下の例では、画像サイズが異なるために上下が揃っていません。\n\n```html\n<div class=\"wrapper\">\n  <div class=\"card\">\n    <img src=\"https://via.placeholder.com/150\" />\n    <div class=\"title\">Title 1</div>\n    <div class=\"description\">Description 1</div>\n  </div>\n  <div class=\"card\">\n    <img src=\"https://via.placeholder.com/160\" />\n    <div class=\"title\">Title 2</div>\n    <div class=\"description\">Description 2</div>\n  </div>\n  <div class=\"card\">\n    <img src=\"https://via.placeholder.com/150\" />\n    <div class=\"title\">Title 3</div>\n    <div class=\"description\">Description 3</div>\n  </div>\n</div>\n```\n\n```css\n.wrapper {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr);\n  gap: 16px;\n  background-color: lightblue;\n}\n\n.card {\n  display: grid;\n  background-color: lightgreen;\n\n  & > .title {\n    background-color: lightcoral;\n  }\n\n  & > .description {\n    background-color: lightyellow;\n  }\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/NPKRrWz)\n\nこのままでは、カードごとに高さが異なり、全体が揃いません。\n\n#### 解決策: サブグリッドの活用\n\n`subgrid` を使用すると、縦のラインを揃えることができます。以下の例では、サブグリッドを活用してカードの要素間の位置を揃えています。\n\n```css\n.wrapper {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr);\n  gap: 16px;\n  background-color: lightblue;\n}\n\n.card {\n  display: grid;\n  /* サブグリッドを適用する */\n  grid-template-rows: subgrid;\n  grid-row: span 3;\n  grid-row-gap: 0px;\n\n  background-color: lightgreen;\n\n  & > .title {\n    background-color: lightcoral;\n  }\n\n  & > .description {\n    background-color: lightyellow;\n  }\n}\n```\n\n@[codepen](https://codepen.io/silverbirder/pen/JoPRKoY)\n\nこの設定により、カード内の要素の高さが統一され、縦のラインが揃います。\n\n#### 他の解決策\n\nサブグリッドが適用しにくい場合、以下の方法を検討してください。\n\n##### 1. `min-height` を設定\n\n要素ごとに最低限の高さを確保することで、全体のラインを揃えます。\n\n##### 2. テキストの省略\n\nテキスト量を調整し、要素間の見た目を揃えます。\n\n##### 3. グリッドの活用\n\nサブグリッドを使用しなくても、グリッドレイアウト自体で縦横のラインを調整できます。\n例えば、`grid-template-rows` を設定するだけでも揃えやすくなります。\n\n### 画像表示は `img` 要素か `background-image` プロパティか\n\nWebサイトで画像を表示する方法として、主に以下の2つがあります。\n\n1. `img` 要素で画像を表示\n1. CSS の `background-image` プロパティで画像を表示\n\nどちらの方法でも画像を表示できますが、適切な使い分けをすることで、コードの可読性やアクセシビリティが向上します。\n\n#### 使い分けの基準\n\n画像の役割によって、以下の基準で使い分けると良さそうです。\n\n##### 1. コンテンツの一部として必要な画像\n\nコンテンツとして画像がないと意味が成り立たない場合は、`img` 要素を使用します。\n例えば、記事中の画像や商品写真が該当します。\n\n##### 2. 装飾的な画像\n\nコンテンツとして必須ではなく、デザイン上の背景要素として使用する場合は、`background-image` プロパティを使います。\n例えば、ページの背景やボタンの装飾が該当します。\n\n#### 別の視点からの使い分け\n\n以下の観点で使い分けることも有効です。\n\n- 背景画像として使用する場合 → `background-image` プロパティ\n- 背景画像ではない画像として使用する場合 → `img` 要素\n\n`background-image` という名前なので、それはそうですよね。(笑)\n\n## 終わりに\n\n最後までお読みいただき、ありがとうございました。この記事が、みなさんのCSS設計に少しでも役立つきっかけになれば幸いです。","publishedAt":"2024-12-16","slug":"css-design-for-frontend-maintainability","title":"フロントエンド開発者のためのCSS設計ガイド：メンテナンス性を高める10の実践"},{"body":"[サクッと学べるデザイン心理法則108](https://www.shoeisha.co.jp/book/detail/9784798175775)を読みました。\n108つの心理法則を、Webサイトや広告のデザインに活用される例が紹介されています。\n\nどれも納得できる心理法則が多いので、『こういう考えでデザインされているんだな』と読んでいてためになりました。\n\n私はWeb屋なので、Webに関連しようなもので面白かったものをピックアップして、感想を述べます。\n\n## ヤコブの法則\n\n### 法則内容\n\n経験則からくる行動のイメージ。\n慣れ親しんだルールで作られていれば初めてでも使える。\n\n### 感想\n\n\"左上のブランドロゴをタップしたら、トップページに遷移する\" など、これまでの経験則から想像できる体験は、その通りになるように作りたいものです。ナビゲーションやレイアウトなど、汎用的なパターンはそのまま踏襲するのがベターなのかなと思ったり。\n\n## ヒックの法則\n\n### 法則内容 (2)\n\n選択肢を多くすると人をひきつけることが可能なる反面、選択の決断をしにくくなり売り上げや満足度が落ちる心理効果。\n\n### 感想 (2)\n\nECサイトとかだと、選択肢が多いところから欲しいものを選びたいという気持ちになります。\nただ、選択の決断は確かに鈍くなってそうです。\n選りすぐりの3つとかまで選択肢が狭まってくれると、決断しやすそうです。\n\n## Zの法則\n\n### 法則内容 (3)\n\nZの形状の視線パターン\n\n### 感想 (3)\n\n視線はZのように流れます。\nそのため、左上が一番きっかけとなるところで、最後に右下に次につながるものがあるとよいのかな。\n左上は、強烈なメッセージとか画像とかで目を引いて、右下に購入ボタンとかを配置すると流れが良さそうです。\n\n## デフォルト効果\n\n### 法則内容 (4)\n\n標準で指定されたものを変更せずにそのままにしたくなる心理効果。\n選択肢がある場合、デフォルト状態のものが選ばれやすくなる。\n\n### 感想 (4)\n\nメール通知をデフォルトONにするサービスは、本当に嫌だ。\nただ、そうではなくサービス設定などは、たしかに大体はデフォルトにしたままだなぁと思った。\n\n## 目標勾配\n\n### 法則内容 (5)\n\nゴールや完成目前になるとモチベーションが上がる心理効果。\n\n### 感想 (5)\n\nゲーミフィケーション的に、何かゴールとなる目標を設定して、それに向けたステップがグラフで可視化されると達成したくなるのはとてもよくわかる。パン屋さんのスタンプカードで、来店のたびに1スタンプ押して10個のスタンプが貯まると20%OFFのサービスは、まんまとその通りに行動しちゃってる。\n\n## フィッツの法則\n\n### 法則内容 (6)\n\n選択の速さは、大きさと距離で決まる。\n\n### 感想 (6)\n\nクリックするボタンが、指から近くてボタンが大きいと良いとのこと。たしかに、ボタンが小さいものはイライラしちゃうかも。ある程度ボタンは余白がある大きさにしてほしい。ボタンの置く位置はマウスやタップしやすい箇所だと、スムーズなのかもしれない。\n\n## チャンク\n\n### 法則内容 (7)\n\nチャンクとは人が近くする情報の塊のことを指す。\n\n### 感想 (7)\n\n電話番号や郵便番号、当選番号など数字の羅列にはハイフンをつけて表示すると良い。瞬間記憶的には3つが良いみたい。\n\n## ゴルディロックス効果\n\n### 法則内容 (8)\n\n3つの選択肢があった場合、真ん中の選択肢を選びやすくなる心理効果。\n\n### 感想 (8)\n\n松竹梅的なこと。まあ、必ずしもとは言えないけど、竹か梅を選びがちな私。\n\n## ツァイガルニック効果\n\n### 法則内容 (9)\n\n中断しているものは未完成のもののほうが、完成したものよりも記憶に残りやすくなる心理効果。\n\n### 感想 (9)\n\n一例は、\"詳しくはこちら!\"。まあその通りだけど、やりすぎされると嫌だと思うときはある。ほどよく未完成なら許せる。続きはWebで！\n\n## 連続の法則\n\n### 法則内容 (10)\n\n人は連続している形状をグループとして認識されやすい。\n\n### 感想 (10)\n\n横にスクロールできるコンテンツは、一部のコンテンツが欠けていると『あ、横スクロールするんだな』と思う。よくわかる。\n\n## 近接の法則, 反復の法則, 類同の法則, 対称の法則, 共通運命の法則\n\n### 法則内容 (11)\n\n近接: 人は近いものを同じグループとして認識されやすい。\n反復: 人は同じ形状のものが繰り返し使用されると同じグループに属するものと判断する。\n類同: 色、形、サイズなど類似性によって同じグループと認識される\n対称: 対称にあるものを同じグループとして認識する。また相互に関連していると認知しやすい。\n共通運命: 人は同時に動くものや同じ方向に動くものは同じグループに所属すると認識する。\n\n### 感想 (11)\n\nとてもとてもとてもよくわかる話。そのためには、UI実装の設計が重要に感じる。個別調整すると、近接が間違ったり反復が一部変になっちゃったりする。そうしないように、レイアウトをちゃんとしたいと思う。","publishedAt":"2024-12-15","slug":"review_of_108-design-psychology-laws-you-can-learn-quickly","title":"サクッと学べるデザイン心理法則108を読みました"},{"body":"今年は、秋が短く感じましたね。かわいい猫とともに、毎年恒例の一年の振り返りをします。\n\n![giphy](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExYXVpanowbnU1eDExNGxwOTU2OWNrMjBjajQzeTZrZWVjbWt6dGE1MiZlcD12MV9naWZzX3NlYXJjaCZjdD1n/wollgOXZPyUYvxht3V/giphy.gif)\n\n## 週4勤務のスタート\n\n[週4勤務で7ヶ月経過した所感](https://silverbirder.github.io/blog/contents/reflections-after-7-months-4-day-workweek/) でも触れた通り、今年は人生で初めて週4勤務を始めました。\n月曜、火曜、木曜、金曜に働き、水曜と週末（土日）が休みです。週の真ん中に休めるのはエネルギーを蓄えるのに最適で、非常に良い習慣になっています。\n\n平日に外出すると、意外と人が多いことに驚きます。\n親子連れやご高齢の方、学生や子供たちが遊ぶ姿、外国の方の観光など、さまざまな景色が広がっています。\n社会人になってからこうした景色を見る機会が減っていたため、新鮮に感じました。\n\nまた、ただ寝ているだけの休みや、予定を詰め込む日もあります。\n個人開発では、やりたくなったときに集中して作り込むこともあり、自分のペースで生活できていることに穏やかな満足感を覚えています。\n\n![giphy](https://media.giphy.com/media/JIX9t2j0ZTN9S/giphy.gif?cid=790b7611q3h279x6dc4xh3xjxc7q6l8f1kghok9aq402sk2h&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n\n## 車との生活\n\n車移動にも随分と慣れました。今年は高速道路に乗る機会が増え、300kmほどの長距離移動も経験しました。\nサービスエリアは特産品や景色、フードコードなどが充実していて、訪れるたびにワクワクします。\n\n私の住む県から離れてさまざまな場所を訪れることで、これまで行けなかった観光スポットにも足を運ぶことができました。\n行動範囲が広がるとともに、多くの良い思い出を作ることができました。\n\nおいしい食べものや、きれいな景色を体験するために、いろいろな場所に訪れたいと思います！\n\n![giphy](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbW1lNDZsbnBjbjZxNTE5NDNzbGM2ZzI3aTloMjFsdXZxMzZsbDUyNiZlcD12MV9naWZzX3NlYXJjaCZjdD1n/xy4ULIiri9j32/giphy.gif)\n\n## 仕事の振り返り\n\n今年一番の衝撃は、やはりVercelのv0でした。\nチャット形式でWebデザインを指示すると、あっという間にそれっぽい見た目の画面がコードと一緒に出力されます。\nアニメーションも作ってくれますし、指定したライブラリを使って実装もしてくれるなんて、本当に驚きました。\n思わずv0に課金してしまいましたが、めちゃくちゃ捗っています。\n\nただ、v0を繰り返し使っていると、shadcnをUIコンポーネントに採用している影響もあってか、\nどうしても「v0っぽい」デザインに仕上がることが気になってきました。\nこれは、自分の指示が曖昧なせいだと感じています。\nもっと的確に指示を出せるよう、デザインや要件の言語化を鍛えたいですね。\n\nさらに、AIを使ってFigmaや画像からCSSを生成する手段も見つけ、開発速度が格段に上がったと実感しています。\n生成されたCSSを見ながら勉強し、不要なコードを削除したり、調整したりする中で、自分のスキルが少しずつ上達しているのを感じています。\n\nデザイナーになれるかは分かりませんが、Webフロントエンドエンジニアとして、よりデザイン寄りの分野に進んでみたいと思っています。\n\n![giphy](https://media.giphy.com/media/mlvseq9yvZhba/giphy.gif?cid=ecf05e47uujm192fcj42kmrsjabkxv2hl085b0awkkjx2poa&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n\n## 来年の抱負\n\n大きな変化がなければ、今の働き方を続け、住む場所もそのままになると思います。\n\n仕事では、デザインスキルをさらに伸ばしつつ、自分の強みである「フルスタック経験を基盤とした、フロントエンド、テスト、デザイン」の交差点を探していきたいです。\nこの強みを活かせる場を見つけることで、より価値を提供できるようになりたいと思っています。\n\nプライベートでは、いろいろな場所に出掛けて、新しい景色や体験を楽しみたいです。\nもしかしたら引っ越しも視野に入れていますが、何より妻とたくさんの思い出を作ることを大切にしたいと思います。\n\n![giphy](https://media.giphy.com/media/yFQ0ywscgobJK/giphy.gif?cid=ecf05e47grheso4wgh4q0mc73yms1wfp59732nk64akjnf61&ep=v1_gifs_search&rid=giphy.gif&ct=g)\n\n## 終わりに\n\n以上、2024年の振り返りでした。最後までお読みいただき、ありがとうございました。\n\n![giphy](https://media.giphy.com/media/iPiUxztIL4Sl2/giphy.gif?cid=ecf05e47cuy8c30q4mzo2erwz99c3zvkm2xgmrhbpaelqu0t&ep=v1_gifs_search&rid=giphy.gif&ct=g)","publishedAt":"2024-12-08","slug":"2024_furikaeri","title":"2024年の振り返り。マイペースな一年"},{"body":"本屋で目に留まった「[はじめてのUXデザイン図鑑](https://www.amazon.co.jp/dp/4502461210/)」というタイトルに惹かれ、思わず手に取って購入しました。\n読み進める中で、自分が関わるサービスではどのようにデザインを活かせるだろう？と想像しながら考える時間がとても充実していました。\n特に「読んで良かった！」と思えるポイントがいくつかあったので、今回ご紹介したいと思います。\n\n## UXデザイン\n\nUXとは「User eXperience」、直訳すると「ユーザー体験」を意味します。\n本書では、UXを「ユーザーの体験を設計すること」として紹介しています。\nどのようなデザインパターンがあるのか、本書の目次を抜粋してみると以下のような分類が挙げられています。\n最近話題のBeRealのようなサービスから、お見合いといった古くからの文化に至るまで、多岐にわたる視点が含まれています。\n\n- 居心地系\n  - 言い訳の提供\n    - BeReal, 社長のおごり自動販売機, ツイキャス, CHIMNEY TOWN GIFT\n  - 所属感アシスト\n    - Neighbors, Fanicon, oVice\n  - ハードル下げ\n    - nana, スプラトゥーン\n  - 罪悪感の転嫁\n    - ラクサス, スナックミー\n  - 見え“ない”化\n    - スマートバスマット, LINEギフト\n- 後押し系\n  - 心のサンクコスト\n    - RIZAP, MESON, デアゴスティーニ\n  - 自分で決めない\n    - dozo, airCloset, お見合い, Yohana\n  - 失敗OK\n    - あと値決め, Snapchat, レゴブロック, はがせるマーカー\n  - 難問\n    - Google の採用広告, ギネス世界記録\n  - トライアル2.0\n    - オーマイグラス, 丸善ジュンク堂書店, レンティオ\n  - 使う分だけ\n    - PillPack, Kit Oisix\n- 納得系\n  - 理由の説明\n    - Facebook 広告の表示説明, 訳アリ商品, セサミクレジット\n  - プロセス参加\n    - リビングラボ, 人事評価\n  - 使い道の明示\n    - ベルマーク, Lemonade, EVERLANE\n  - 診断\n    - スピークバディ, 大塚家具, MEDULLA\n- 参加系\n  - 応援のリッチ化\n    - 少年ジャンプ＋, フリータンク, BTSファン\n  - 無名からの育成\n    - テニミュ, 宝塚歌劇団のファンクラブ\n  - 差からの連帯\n    - ビアボール, Everytable, ダイアログ・イン・ザ・ダーク\n  - 脱顧客\n    - ネスカフェアンバサダー, 京都のお茶屋, スクラム採用\n  - 貢献の余白\n    - ADDress, NewsPicks, OriHime\n  - ナラティブ\n    - ハッシュタグ, Ninja DAO\n  - マイルド参加\n    - ライブゲーム, イマーシブシアター\n\nこの中から、特に気になった項目について、いくつかピックアップして感想を述べたいと思います。\n\n## 気になった項目\n\n### 言い訳の提供\n\n「言い訳の提供」は、私の好きな体験の1つです。\n時間制限や文字制限など、あえて体験に制約を設けることで、ユーザーに「～したかったけど、仕方がないよね」と言い訳できる余地が生まれます。\nこれは不思議な安心感を与えるだけでなく、心地よさをもたらしてくれるものです。\n\nさらに、制約があるからこそ、その範囲内で表現や工夫を模索する楽しさが生まれます。たとえば、\n\n- 「時間がないからこそ、XXをしてみよう」\n- 「入力できる文字数が短いからこそ、YYをしてみよう」\n\n制限が生み出す創意工夫な発想が、より楽しい体験を見つけれるかもしれません。\n\n### 失敗OK\n\n何かを体験したあとに「もう一度やり直したい！」と思ったことはありませんか？\nまた、体験を始める前に「もし失敗したらどうしよう」という不安を抱いたことはないでしょうか。\nそんなとき、「やり直せる」という設計があると、とても安心できますよね。\n\n例えば、ECサイトの返品・返金ポリシーや、ゲームのセーブポイントなどは失敗OKの1つかなと思います。\nまた、レゴブロックのように、そもそも正解や不正解が存在しない体験もあります。\n\nこうしたデザインは、ユーザーに安心感を与え、一歩を踏み出す勇気をもたらします。\nただし、何でも「やり直せる」としてしまうと、サービスの成立が難しくなったり、他のユーザー体験を損なったりする可能性もあります。\nそのため、バランスを取ることが非常に重要です。\n\n### 自分で決めない\n\n何かを「自分で決める」という行為は、意外と大変なものです。\n決断するためには情報を調べたり、選択肢を比較したりと多くの時間と労力が必要です。\nそして、一度決断すれば、その結果に責任を持たなければなりません。\n\nそんな負担を軽減する仕組みのひとつが、カタログギフトのサービスです。\nプレゼントを贈りたいけれど相手の好みがわからない場合、最終的な選択を相手に委ねることで、贈る側も受け取る側も満足できるWin-Winの形が生まれます。\n\n毎日の献立を考えたり、着る服を決めたりと、私たちは日々、何度も「決める」ことに追われています。\nこのように、「決める」ことが大変だと感じる場面は、意外と多く存在しているのかもしれません。\n\n### 所属感アシスト\n\nリモートワークが普及した際、oViceを使ったことがあります。\nバーチャルオフィスを通じて、会社の人たちと「一緒に働いている感覚」を共有することで、まるでリアルオフィスで働いているような体験が得られました。\n\n一人で働いていると、ふと不安を感じることもありますよね。\nでも、誰かと繋がっている実感が得られると、安心感や一体感が生まれます。その結果、孤独感が薄れ、チームからの離脱も減るのではないかと感じました。\n\n### トライアル2.0\n\n洋服屋さんでは試着ができたり、家具屋さんでは展示品を試しに使ってみたりと、体験型のサービスは身近にありますよね。\nそこからさらに一歩踏み込んだ「トライアル2.0」とも言える新しいお試し体験が登場しています。\n\nたとえば、オーマイグラスではメガネを自宅で試着できたり、ニトリではARを使って自宅に家具を試し置きできるサービスがあります。\nこうした工夫により、実際に使用する場面を具体的にイメージしやすくなり、購入前の不安が軽減されるのが魅力的です。\n\n### 理由の説明\n\nある広告がなぜ自分に表示されているのか、その理由を説明する機能がFacebookにはありました。\n同様に、ECサイトで「Xを閲覧した人は、以下の商品を購入しています」といった形でレコメンドの理由が説明されると、不思議と納得感が得られますよね。\n\n勝手に何かを押し付けられるよりも、「なぜそうしたのか」を丁寧に教えてもらえると、親切に感じられ、ユーザーとしても安心できるものです。\n\n## 最後に\n\n日常生活で、どのようなUXが隠されているか探してみると良い気づきになるかもしれません。\nそこから、真似できるエッセンスを見つけだしたいなと思います。","publishedAt":"2024-11-24","slug":"review_of_hajimete-no-ux-zukan","title":"はじめてのUXデザイン図鑑を読みました"},{"body":"先日、『[Every Layout - モジュラーなレスポンシブデザインを実現するCSS設計論](https://www.amazon.co.jp/dp/486246517X)』を読みました。\nCSS設計に関する深い洞察が詰まった一冊で、多くの学びを得られました。本記事では、その中で特に印象に残ったポイントを紹介します。\n\n## CSS設計の基本方針: ブラウザに計算させる\n\nCSSを書く際に、\"height: 100px;\" や \"width: 100px;\" のような絶対値を使うと、表示するデバイスやビューポートによって崩れる可能性があります。\nこれを防ぐには、相対的な値を活用するのが有効です。\n\n例えば、以下のような単位や手法を使うことで、レスポンシブなデザインを実現できます。\n\n- 相対単位: em、ch、vw、cqw など\n- パーセンテージ：\"width: 100%\"\n- 関数：\"calc() で動的な値を計算\n- コンテナクエリ：親要素に応じたスタイリングを可能にする\n\n相対的な指定にすることで、ブラウザが親要素やビューポートのサイズを元にスタイルを計算してくれるため、デザインの柔軟性が向上します。\n特にコンテナクエリは、より精密なレスポンシブデザインを可能にするため、積極的に使いたい機能です。\n\n参考リンク：[length - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/length)\n\nそのため、CSSを書く際にpxを見かけたら「もっと相対的にできないか？」を考えるのが私の習慣になっています。\nメディアクエリを極力使わずに対応できることを目指してみるのも面白いアプローチだと思います。\n\n## レイアウトの責任はどこに置くべきか\n\nリスト表示のUIを作成する際、リストアイテム間のスペースをどこで制御するべきか迷うことがあります。私は以下のアプローチが有効だと考えています。\n\n- **リスト全体で制御**  \n\nflexのgapや、以下のようなCSSルールでリスト要素間のスペースを管理します。\n\n```css\n.list > * + * {\nmargin-top: 1rem;\n}\n```\n\nこのように、子要素ではなく親要素にスペース管理を委ねると、個別要素の再利用性が高まります。\n特に、要素が自分の外側のスタイル（marginなど）を持つと、再利用時に制約が生じやすいため注意が必要です。\n\nまた、スペースの管理には以下を使い分けるのが重要です。\n\n- padding: 要素の内側のスペースに使用\n- margin: 要素間のスペースを管理する際に使用\n\nこの考え方を元に、flexやgridを使いこなせば、効率的なレイアウト設計が可能です。\nまた、最近ではサブグリッドも利用できるようになり、複雑なカードレイアウトでも縦横の整列が容易になっています。\n\n## まとめ\n\n『Every Layout』はCSS設計の新しい視点を与えてくれる良書でした。\n特に、 **「ブラウザに計算させる」という考え方や、「レイアウトの責任を親要素に持たせる」** というアプローチは、日々の実装にすぐに役立つ内容です。\n\nCSSにおける「責任の分離」を意識することで、再利用性が高く、メンテナンス性の良いコードを目指せます。ぜひ興味のある方は一読してみてください!","publishedAt":"2024-11-16","slug":"review_of_every-layout","title":"Every Layoutを読みました"},{"body":"昔、HTML要素についてざっと学んだことがありましたが、記憶が曖昧になっています。\n改めてHTML要素を網羅的に理解し直したいと思い、[HTML解体新書-仕様から紐解く本格入門](https://www.amazon.co.jp/dp/4862465277) という書籍を読んでみました。\nまた、[HTML 要素リファレンス - HTML: ハイパーテキストマークアップ言語 | MDN](https://developer.mozilla.org/ja/docs/Web/HTML/Element)も参考にしました。  \n\nこの記事では、その中で特に印象に残った要素について紹介し、個人的な気づきについてお伝えします。\n\n## main\n\n**main** は、ページ内で最も重要なコンテンツをまとめる要素で、ページごとに1つだけ使用います。\n\nmain内には、ナビゲーションなど、他のページでも共通して表示されるコンテンツは含めない方が良いとされています。  \nこれまでは、main要素内に他のページでも繰り返される要素を含めていましたが、これを機に構成を見直したいと思います。\n\n## header・footer\n\n**header** と **footer** は、コンテンツを読む前後に配置される要素です。\n\n書籍を読む前は、headerはグローバルナビゲーション、footerはサイト全体のフッターに使うものだと思っていました。\nしかし、articleやsection要素内でも、記事のタイトルや執筆日をheader、コメントやリアクションをfooterとして使う考えに気づき、柔軟な使い方ができると感じました。\n\n## aside\n\n**aside** は、メインコンテンツと直接的な関係はないものの、補足的な情報を提供する要素です。\nサイドバーや注意書き、補足説明に適しており、たとえば記事内の関連リンクなどに使用できます。\n\nブログ記事のarticle要素では、記事を読み終わった後のコメントやリアクションはメイン内容に直接関わるためfooterに配置し、\n一方、関連記事や関連タグのリストは補足的な要素としてasideに配置するのが良さそうだと感じました。\n\n## article\n\n**article** は、ブログ記事のように自己完結するコンテンツを表す要素です。\n自己完結しているため、article要素内の内容は、その部分だけ切り取っても意味が通じることが求められます。\nまた、article内にはh1〜h6の見出しを付けることが推奨されます。\n\narticleという名称からも、ブログ記事や雑誌の記事、フォーラムの投稿など、事実や内容を独立して伝える文章に使うことが想定されています。\n「記事」とは「事実を書くこと、またはその文章」を指すため、この要素が自己完結的な情報に適していると理解しました。\n\n## time\n\n**time** は、日時を表現するための要素で、datetime属性にマシンリーダブルな形式の日付を入れ、人間が読みやすい日付を表示すると良いとされています。\n\nこれまで日付の表示を何度も実装してきましたが、time要素を使用すべきだったと感じました。より正確でセマンティックな実装ができる点が魅力です。\n\n## address\n\n**address** は、住所だけでなく連絡先を示すための要素です。\n\n住所の他にも、SNSリンクやメールアドレスなど、連絡手段をaddress要素に含めると良さそうです。幅広く使える要素だと感じました。\n\n## section\n\n**section** は汎用的なセクション区切りの要素で、見出しを伴うことが推奨されています。\n\nnavやasideなど、より適切な要素がある場合はそちらを優先し、それらがない場合にsectionを使用します。\nセクションを区切りたいときに活用できる便利な要素です。\n\n## fieldset\n\n**fieldset** は、form内でチェックボックスやラジオボタンのグループをまとめる際に使用する要素です。\nグループ名はlegend要素で付けることができます。\n\nこれまでに何度もチェックボックスやラジオボタンの実装を行ってきましたが、fieldsetを活用していなかったと反省しました。\nより意味のあるマークアップができると感じました。\n\n## anchor（a要素）\n\nリンクに関する関係性は、**rel属性** で定義できます。外部リンクにはrel=\"external\"を付けた方が良いでしょう。\n\nまた、**ping属性** を使うと、リンク先に遷移する前に指定したURLへPOSTリクエストが送信され、トラッキングに利用できます。\nこれまで独自実装で対応していましたが、ping属性を使えば簡単に実現できるため、とても便利だと感じました。\n\n## small\n\n**small** は、補足的な情報を小さく表示するための要素です。\n例えば「180円（税込）」の「税込」のような付加情報を視覚的に小さくしたいときに便利です。\n\n## em・strong・mark\n\n**em** は強調を示し、**strong** はさらに緊急性や重要性を持つ強調に使用します。\n**mark** は、参照や関連性がある場合に注目させたい部分に使うのが適しています。\n\nこれまでは「目立たせたい」という意味で何となくemやstrongを使っていましたが、用途に応じて使い分けることが大切だと改めて感じました...。\n\n## form\n\n**novalidate属性** を使用すると、入力チェック（バリデーション）を無効化できます。\n下書き保存や一時的なデータ入力を許可するフォームなどで活用すると便利です。\n\n## input\n\n**autocomplete属性** は、ユーザーが入力する際に候補を提示するために便利です。\n\n## datalist\n\n**datalist** を使用すると、input（テキスト）フィールドに候補を表示できます。\nただし、すべてのブラウザでサポートされているわけではない点に注意が必要です。\n\n## caption・figcaption\n\n**caption** はtableに説明を付けるための要素で、\n**figcaption** はfigureに説明を付けるために使用します。\n\nどちらも、画像やテーブルの補足説明を明確にできるため、より分かりやすいコンテンツ作成に役立つと感じました。\n\n## hgroup\n\n**hgroup** は、タイトルとサブタイトルをグループ化する際に使用します。\nこれにより、関連する見出しをひとまとまりにして、より整理された構造を提供できます。\n\n## 終わりに\n\nHTMLを書く際、「どちらが正しいのだろう？」と悩むことが多々ありましたが、\n今回の気づきを通して、いくつかの疑問に答えが見つかったように思います。\n今後は、よりセマンティックに合った要素を意識して使っていきたいです。\n\n## 参考\n\n- [MDN Web Docs - HTML要素](https://developer.mozilla.org/ja/docs/Web/HTML/Element)\n- [HTML解体新書-仕様から紐解く本格入門](https://www.amazon.co.jp/dp/4862465277)","publishedAt":"2024-11-02","slug":"review_of_html-kaitai-shinsho","title":"HTML解体新書を読みました"},{"body":"[縁の下のUIデザイン──小さな工夫で大きな効果をもたらす実践TIPS＆テクニック (WEB+DB PRESS plus)](https://www.amazon.co.jp/dp/4297134098) を読みました。\n読んで学びが多く、今回は特に印象に残った内容を感想としてまとめてみます。\nすべての章に触れるのではなく、特に心に残った部分について自分の視点から気づきを書き留めました。\n振り返りやすい備忘録として、今後の仕事で役立てたいと思います。\n\n## 書籍について\n\n書籍『[縁の下のUIデザイン──小さな工夫で大きな効果をもたらす実践TIPS＆テクニック (WEB+DB PRESS plus)](https://www.amazon.co.jp/dp/4297134098)』は\nWebアプリ開発における **「あるある」なUI設計に関する実践的なアイデアが豊富に詰まった一冊** です。\nWEB+DB PRESSの5年間の連載をもとに、UIデザインのノウハウが体系的にまとめられており、全35章が7つのテーマに分かれ、それぞれ異なる観点からUIの工夫が紹介されています。\n\n書籍で紹介されている内容の一部はWeb上でも確認できるので、購入前に見てみるのもおすすめです。\n\n- [縁の下のUIデザイン―少しの工夫で大きな改善！ 記事一覧 | gihyo.jp](https://gihyo.jp/list/group/縁の下のUIデザイン-少しの工夫で大きな改善)\n\n## 対象読者\n\n書籍の対象読者は以下の通りです。\n\n- 自分のデザイン視点を広げたいUIデザイナー\n- UIデザインに興味を持つデザイナー\n- UIデザインも担当しているエンジニア\n- デザインラフまで自分で考えることがあるディレクター\n\n## 気になった章\n\n読んで印象に残った章を以下に挙げます。\n\n- 画像はどう置く？──位置、大きさ、そろえ方\n- ユーザーに使い方を文字で説明するためのUI\n- カードUIの向き不向き\n- 長くなりがちなコンテンツをどう見やすくするか\n\nここから、それぞれの章について掘り下げます。\n\n## 画像はどう置く？──位置、大きさ、揃え方\n\n画像の配置が視線誘導に与える影響を改めて実感しました。一般的に人の視線は左から右、上から下へ移動するため、**左側に画像を配置し、右側にテキストを置くと、画像を見た後に自然に内容を読み進められます** 。\n反対に右側に画像があると、視線がテキストに向かいやすく、画像が目立ちにくくなります。\n\n画像の大きさも大きな効果を与えます。宿泊サービスのサイトでは、部屋の写真を大きく表示することで「行ってみたい」という気持ちが引き出され、小さな画像を並べるよりも強い印象を与えます。また、Pinterestのようにランダムなサイズで画像を配置する手法も視線をさまざまな場所に誘導し、情報が目に留まりやすくなります。\n\nネットサーフィンで観察してみたところ、**多くのサイトでこの原則がうまく活用されていました** 。たとえば、[Yahooニュースランキング](https://news.yahoo.co.jp/ranking/access/news)では、左に画像、右にタイトルが配置され、画像が先に目に入り、次にニュースタイトルが読まれる流れが作られています。同じページ内のコメントランキングでは、左にタイトル、右に画像が配置されており、ページの補足的な要素として扱われています。\n\n[日経](https://www.nikkei.com/business/net-media/)では、左に大きくタイトルを配置し、右側に画像があるため、タイトルが目立ち情報が強調されるデザインになっています。\n\nまた、[びゅうトラベル](https://www.jre-travel.com/)では宿泊先の部屋がリストで表示され、「選択」ボタンが右側に配置され、視線の流れに合わせてアクションを促します。同様に、[トリバコ](https://www.trivago.jp/)も宿泊先候補を左から画像、ホテル名、料金の順で表示し、画像が重要な視覚要素として強調されています。\n\nECサイトのAmazonでも、PC表示では商品リストが縦長に並び、上から商品画像、商品名、評価、価格、カートボタンという順です。**まず商品画像を見て、次に商品名、評価、価格を確認し、最後にカートボタンへ** と自然に誘導されています。\n\nこのように、サービスの種類やユーザーの動線に応じた視線誘導をデザインに取り入れる重要性を再確認しました。\n\n## ユーザーに使い方を文字で説明するためのUI\n\nユーザーが操作しやすい画面を作るには、ある程度の説明が欠かせません。特にtoB向けの場合、専門用語が多くなるため丁寧な説明が必要です。\n\n**書籍の中で「説明を惜しまない」という言葉が印象的** でした。シンプルにしようとしすぎると、かえって説明が不足し、意味が伝わりにくくなります。分かりやすさを意識して、しっかり伝わる説明文を用意することが大切です。\n\n専門用語やよくある質問は別ページにまとめてリンクを付け、必要に応じて参照しやすくすると良いですが、モーダル表示で同ページ内に出す方法も効果的です。バルーンヘルプやツールチップも、必須ではないけれどあると助かる補助情報として有効です。\n\nアイコンで意味を伝えるのも手段のひとつですが、一般的に認知されたアイコンに限ります。その他のアイコンには補助テキストを添えるのが望ましいでしょう。\n\nボタンの文言も「登録」ではなく「登録する」とすることで、柔らかい印象が生まれ、ボタンサイズも少し大きくなり見やすくなります。\n\nまた、テーブルレイアウトで右側に重要な情報を配置すると画面の端に隠れてしまうことがあるため、縦に並べるなどして重要なものは左側に配置し、視認性を向上させます。\n\n最近ではサイドパネルを隠したり表示したりできるUIも多く見られますが、初回はチュートリアルのようなオンボーディング機能があると親切です。写真や動画、インタラクティブなチュートリアルなどが操作方法の理解を助け、再度表示できるようにもしたいところです。\n\n## やはり最も重要なのは、しっかり伝わる説明文を用意することだと感じます\n\n## カードUIの向き不向き\n\n普段からカードUIをよく使ってきました。情報がひとまとめにできて目立たせやすく、レイアウト上も使いやすいからです。\nしかし、今回改めてカードUIの特徴について学び、考え直すきっかけになりました。\n\nカードUIは、複数の情報をひとまとめに表示する際に便利で、影をつけることで情報が整理され、\n存在感を持たせられるという利点があります。ただし、使いすぎには注意が必要です。\n\nたとえば、商品レビュー一覧をカードで表示すると、各コメントが目立ちすぎて比較がしにくくなり、シンプルなリスト表示のほうが適している場合もあります。\n一方、1つ1つのレビューをじっくり読ませたい場合にはカードが効果的です。カードで区切ることで、個々のレビューにフォーカスを当てやすくなります。\n\nカードUIは、1つの情報をしっかり見せたいときに向いていますが、情報同士の比較には不向きな場合もあります。\nまた、カードはレスポンシブ対応がしやすく、内部レイアウトを柔軟に変更できるため、画面サイズに応じた調整が容易です。\n\n## テーブルやカードはよく目にするUIですが、使いどころを見極めて、効果的に活用することが大切です\n\n## 長くなりがちなコンテンツをどう見やすくするか\n\n改善を重ねるとコンテンツが増えて画面がごちゃごちゃした印象になり、使い勝手が悪くなることがあります。この章で、著者が紹介する次のルールは非常に参考になりました。\n\n> 「その画面に本来あるべき要素が7割、関連する情報など関係の薄い要素は3割」\n\n新しいコンテンツを追加する際は、既存の内容を整理することが重要です。**既存コンテンツを減らしたり、表示する面積を調整したりして、情報の渋滞を防ぎます。**\nこうすることで、必要なコンテンツの量とバランスが維持されやすくなります。\n\n似たコンテンツをまとめて表示する工夫も有効ですが、同じ内容が続くとユーザーが飽きてしまうため、たとえば検索結果一覧にレコメンド項目を差し込んだり、ページ下部に配置するなどして適度に分散させることで視覚的なメリハリが生まれます。\n\nまた、スマホではディスプレイサイズが小さいため、縦スクロールを減らしてページを切り替える工夫が良いのかもしれません。\n\n## 最後に\n\nこの本を通して、UIデザインの細やかな工夫が最終的にユーザー体験全体に大きな影響を与えることを再認識しました。\n小さな改善でも、今後の開発にも積極的に取り入れていきたいと思います。","publishedAt":"2024-10-26","slug":"en-no-shita-ui-design","title":"縁の下のUIデザインを読みました"},{"body":"5回目となる個人サイトのリニューアルを行いました。  \n個人サイトは自由にカスタマイズできるため、私にとっての練習場でもあります。今回はリニューアルの背景や目的について紹介します。\n\nリニューアル後のページは、以下の画像になります。\n\n[![サイトリニューアル](https://res.cloudinary.com/silverbirder/image/upload/v1729664114/silver-birder.github.io/blog/site-renewal.png)](https://silverbirder.github.io/blog/contents/web_frontend_test_pattern_guide/)\n\n## 背景\n\nこれまでは、CSSフレームワークや静的サイトジェネレーターを利用してシンプルなWebサイトを構築してきました。  \n業務では、Webアプリケーションの開発が中心で、APIやデータ生成、フロントエンドの実装に注力していました。\n\nしかし、昨年からCSSを書く機会が増え、Figmaを使ったデザイン作業の楽しさに目覚めました。  \nフォントやスペーシング、ラインなど細部にこだわるようになり、デザインを強く意識するようになりました。\n\n以前執筆した[生成AI時代のフロントエンド開発術](https://silverbirder.github.io/blog/contents/frontend-development-in-the-age-of-generative-ai/)でも触れましたが、AIを活用して効率的に開発を進めています。  \nまた、[Figmaと仲良くなる](https://silverbirder.github.io/blog/contents/becoming-friends-with-figma/)の記事でも述べた通り、Figmaでのゼロからのデザイン構築に楽しさを見出しました。\n\n## v0との出会い\n\n最近、Vercel社のUI生成AIツール[v0](https://v0.dev)がリリースされました。v0はChatGPTのようにチャット形式でUIデザインを生成してくれるツールです。  \nUIデザインには、Reactコンポーネント、Tailwind、shadcn/uiの3つでコードを提供されており、簡単にサンプルを作成してくれます。\n\n特に衝撃的だったのは、わずか2回のチャットのやり取りでスイカゲームのようなWebアプリが作成できたことです。以下のリンクから確認できます。\n\n- [Create a Similar Web App - v0 by Vercel](https://v0.dev/chat/a8RfpL90mO4)\n\n[![みかんドロップ](https://res.cloudinary.com/silverbirder/image/upload/v1729664496/silver-birder.github.io/blog/orange-drop.png)](https://v0.dev/chat/a8RfpL90mO4)\n\n**このみかんドロップに感動し、すぐにv0を積極的に活用するようになりました**。  \n\nv0には無料枠があるものの、制限にすぐ達してしまったため、最終的にPremiumプランに課金しました。\nアニメーションの生成も瞬時に行えるため、非常に便利です。文言の生成はChatGPTに任せています。\n\nv0を使えば、私でももう少しWebデザインが得意になれるのでは？と感じました。ここで言う「Webデザイン」は、\"それっぽく見える\"という程度の意味です。\n\n## コンセプト\n\n最初は、GitHubやSlack、VSCodeのようなデザインを模倣しようと考えていましたが、ただ真似するだけでは自分らしさが出せず、面白くありませんでした。\n\nそこで、v0と対話を進めていく中で、「書籍やノート」をテーマにするアイデアが浮かびました。特に **「罫線」** を取り入れたデザインが面白いと感じ、**ノート風のサイトを作ることにしました**。\n\n罫線は縦のリズムが一定で、読み物にちょうどよいです。学生時代に使っていたノートのような親しみやすさがあり、付箋やシール、ページめくりなどの要素も追加しました。\n\n調査を進めているうちに、「バーティカルリズム」というデザイン手法に出会い、私の取り組みがまさにそれだと気づきました。\n\nバーティカルリズムについての詳細は、以下のリンクから確認できます。\n\n- [なぜタイポグラフィにおいてVertical Rhythm（バーティカルリズム）は重要な手法なのか？ | POSTD](https://postd.cc/why-vertical-rhythms/)\n\n## デザインのこだわり\n\nノート風デザインをさらに追求し、フォントについてもこだわるようにしました。  \nフォントサイズは16px、行間は24pxに設定し、読みやすさを重視しました。\n\n参考にしたのは、W3Cのテキストスペーシングに関するガイドラインです。\n\n> - Line height (line spacing) to at least 1.5 times the font size;\n>\n> - Spacing following paragraphs to at least 2 times the font size;\n>\n> - Letter spacing (tracking) to at least 0.12 times the font size;\n>\n> - Word spacing to at least 0.16 times the font size.\n\n※ [Understanding Success Criterion 1.4.12: Text Spacing | WAI | W3C](https://www.w3.org/WAI/WCAG21/Understanding/text-spacing)\n\nまた、Lighthouseの診断で指摘される通り、font-sizeは12px以上にする必要があります。\n\n- [書類で判読可能なフォントサイズが使用されていません | Lighthouse | Chrome for Developers](https://developer.chrome.com/docs/lighthouse/seo/font-size?hl=ja)\n\n最終的には、Tailwindのtext-baseが最適なフォントサイズ・行間であることに気づき、それを採用しました。letter-spacingは、.12emとしました。\n\n一方、見出しのように大きな文字を2行（48px）の罫線内に収める際、行間の調整が難しいことに気づきました。行間を逆マージンで調整し、罫線上に文字を載せようとしましたが、文字選択時にずれが生じたため、最終的にはデフォルトの余白設定に戻しました。\n\nまた、フォントにもこだわり、日本語対応のフォントとして定番のNoto Sans JPではなく、Google Fontsからノートに合う手書き風フォントを探しました。\n最終的に選んだのは、**Shippori Mincho** というフォントです。「す」の払いの感じが特に気に入りました。ZEN紅道も良いフォントですが、weightが400のみであったため断念しました。\n\n## 落書き風アニメーション\n\nノートのテーマに合わせ、落書き風のアニメーションも取り入れました。  \n以下は手書き風のSVGアニメーションの一例です。\n\n![手書きアニメーション](https://res.cloudinary.com/silverbirder/video/upload/e_loop/v1729665650/silver-birder.github.io/blog/spiral.gif)\n\n### 作り方\n\n1. FigmaのPencilツールを使って手書きデザインを作成\n1. Vectorを書いた順番でGroup化\n1. Group化したデザインをSVGでエクスポート\n1. v0にSVGを渡し、アニメーションや色を調整\n\n以下に先ほどの手書きアニメーションのサンプルコードを示します。\n\n```ts\nimport { motion } from \"framer-motion\";\n\ntype Props = {\n  className?: string;\n  startDelay?: number;\n  duration?: number;\n  strokeColor?: string;\n};\n\nexport default function Spiral({\n  className,\n  startDelay = 0,\n  duration = 1.5,\n  strokeColor = \"stroke-current\",\n}: Props) {\n  const pathVariants = {\n    hidden: { pathLength: 0, opacity: 0 },\n    visible: (i: number) => {\n      const delay = startDelay + i * 0.5;\n      return {\n        pathLength: 1,\n        opacity: 1,\n        transition: {\n          pathLength: { delay, type: \"spring\", duration, bounce: 0 },\n          opacity: { delay, duration },\n        },\n      };\n    },\n  };\n\n  return (\n    <div className={`flex items-center justify-center ${className}`}>\n      <motion.svg\n        viewBox=\"0 0 87 39\"\n        fill=\"none\"\n        xmlns=\"http://www.w3.org/2000/svg\"\n        initial=\"hidden\"\n        animate=\"visible\"\n        style={{ width: \"100%\", height: \"100%\" }}\n      >\n        <motion.path\n          d=\"M1.97026 36.9618C1.19643 36.7683 1.96666 31.3258 2.09215 30.679C2.72864 27.3987 4.56686 24.2314 5.75988 21.1164C6.95065 18.0071 8.98806 15.6845 11.3446 13.4152C14.0269 10.8323 16.6736 8.35552 19.91 6.46761C23.5992 4.31557 29.4809 2.07392 33.5282 4.45092C37.4842 6.7743 39.4171 11.6927 39.4675 16.13C39.5277 21.427 36.2336 26.2284 32.398 29.6707C29.8802 31.9303 25.6408 36.2336 22.2148 33.0614C18.0729 29.2263 22.5615 23.4355 24.7523 19.964C27.0244 16.3634 29.8257 13.0751 32.7969 10.0356C34.9748 7.80761 37.2876 6.09817 40.221 4.93847C46.294 2.53753 54.1661 4.76478 57.9169 10.1464C59.0882 11.8269 60.0846 14.7706 60.1996 16.8392C60.3222 19.0469 60.5526 21.6854 59.9004 23.8201C59.301 25.7818 58.5796 27.5892 57.1302 29.0723C55.4315 30.8105 54.124 32.7833 52.2325 34.3246C49.8724 36.2477 46.5335 36.7844 44.8084 33.7262C42.1398 28.9956 44.9682 23.5947 46.9802 19.2659C48.685 15.5981 50.5464 11.6295 53.6508 8.92754C56.4805 6.46464 59.9402 3.698 63.7011 2.87745C70.1389 1.47284 77.2674 3.36637 82.6159 7.11029C83.9748 8.06154 84.7941 8.79153 85.3418 10.4345\"\n          strokeWidth=\"2\"\n          strokeLinecap=\"round\"\n          className={strokeColor}\n          variants={pathVariants}\n          custom={0}\n        />\n      </motion.svg>\n    </div>\n  );\n}\n```\n\n## その他\n\nノートのページめくりを実現したかったのですが、うまく再現できませんでした。\nSticker.jsやCodeSandboxのサンプル（参考）を参考に色々試みましたが、上手くいきませんでした。\n\n## 終わりに\n\n今回のリニューアルでは、v0との協業によって新たなデザインアプローチを体験しました。\nこれまでの私の個人サイトに比べると、随分と好みのWebデザインになりました。大変気に入っています!\n引き続き、Webデザインについて追求していきたいなと思います。","publishedAt":"2024-10-24","slug":"site-renewal-with-v0","title":"v0と協業した個人サイトリニューアル"},{"body":"どうも、Web業界で働き始めて9年目の駆け出しエンジニア、silverbirderです。\n\nSpotifyで音楽を聴いていると「**この曲、どこかで聞いたことがあるけど、何の主題歌だったかな？**」と思うこと、ありませんか？特にドライブ中や作業中に、ふと気になることが多いですよね。  \n私もそんな経験があり、気になったその曲が主題歌だったアニメを見始めたことがきっかけで、「**簡単にタイアップ情報（アニメやドラマなど）を調べられるアプリがあったら便利だな**」と思い、このアプリを作ることにしました。\n\n以下が、実際に作成したWebアプリの画面とリンクです。\n\n![タイアップ検索 デモ画像](http://res.cloudinary.com/silverbirder/image/upload/v1727178744/pvfrczj9b5ogw58ooulu.png)\n\n[https://tie-track.vercel.app](https://tie-track.vercel.app)\n\nこの記事では、このアプリの**技術的な部分**について詳しく紹介します。\n\nちなみに、Spotifyでよく[Anime Now](https://open.spotify.com/playlist/37i9dQZF1DWT8aqnwgRt92)を聴いています。タイアップ情報の検索にはもってこいです！\n\n## アーキテクチャ概要\n\nこのアプリは、Spotifyで再生中の曲のタイアップ情報を素早く取得し、ユーザーに表示します。以下がそのアーキテクチャ図です。\n\n![タイアップ検索アーキテクチャ図](http://res.cloudinary.com/silverbirder/image/upload/v1727178746/skhbbzuekqszzhkm5lgu.png)\n\n使用した技術スタックは以下の通りです。\n\n- **Spotify API**: 再生中の曲情報を取得\n- **Google Custom Search API**: タイアップ情報をGoogle検索\n- **OpenAI API**: 検索結果からタイアップ情報を抽出\n- **Next.js**: アプリケーションフレームワーク\n  - デザイン参考: [v0.dev/chat](https://v0.dev/chat)\n- **Icon生成**: [AI Icon Generator - perchance.org](https://perchance.org/ai-icon-generator)\n\n## 開発の流れ\n\n### タイアップ情報の取得\n\n最初に、タイアップ情報を取得するためのAPIを探しましたが、**直接的にタイアップ情報を提供するものは見つかりません**でした。レコチョクなどのサービスも検討しましたが、必要な情報が不足していたため、断念しました。\n\n次に、**ChatGPTを使ってタイアップ情報を取得**する方法を試しました。ChatGPTは、Web検索結果を含めた回答を返してくれるため、うまくいくこともありました。しかし、**OpenAI APIを使う場合はWeb検索が行われない**ため、タイアップ情報を取得するには不十分でした。\n\n### Google Custom Search API + OpenAI API\n\nそこで、**Google Custom Search API**を使い、タイアップ情報が掲載されているWebページを取得し、その情報を**OpenAI API**に渡して解析させる手法を採用しました。  \n\n## この組み合わせにより、精度の高いタイアップ情報を得ることができました\n\n### データの保存\n\nAPI使用は**従量課金**のため、コスト管理が重要です。そこで、**Google検索結果とOpenAI APIの結果をデータベースに保存**し、同じ情報を何度も検索しないようにしています。\n\n## 結果: Spotifyでアニメ主題歌を楽しむ\n\nこのアプリを使えば、Spotifyで再生中の曲が**どのアニメやドラマの主題歌**なのか、すぐに確認できます。特に、**秋のアニメシーズン**が近づいている今、気になる曲があればすぐに関連作品をチェックできるので、これからが楽しみです！\n\n## 1週間で完成\n\nアイデアを思いついてから完成までにかかった時間は、[わずか1週間](https://x.com/silverbirder/status/1838179210403414103)。  \n**思いついたアイデアを形にする**のは、本当に楽しい経験でした。\n\n興味がある方はぜひ、アプリをお試しください！","publishedAt":"2024-09-24","slug":"spotify-tieup-app","title":"1週間で完成！Spotifyタイアップ検索アプリを作った話（駆け出し9年目）"},{"body":"2024年2月から、Web業界でフリーランスのフロントエンドエンジニアとして週4日勤務を始めました。勤務日は月曜、火曜、木曜、金曜です。今回は、その7ヶ月を振り返り、感じたことを書いてみます。\n\n## 各曜日の気分\n\n週4日勤務で感じた曜日ごとの感覚をまとめてみます。\n\n- **月曜日**\n  - 特に憂鬱な気分はありません。\n  - 「明日働いたら休み」という意識で、一番ノーマルな状態です。\n- **火曜日**  \n  - ハイパフォーマンスの日！\n  - 「明日が休み」という事実がモチベーションを高めます。\n- **水曜日**  \n  - 休み。\n  - 後述しますが、ここでリフレッシュします。\n- **木曜日**  \n  - 月曜日と似た感覚です。\n  - 疲労はあまり蓄積されていません。\n- **金曜日**  \n  - もう一度ハイパフォーマンスの日！\n  - 水曜日に蓄えたエネルギーを解放します。\n\n毎朝の日光浴と散歩、瞑想、仕事終わりの軽いランニングを習慣化しており、それが心身の安定に寄与しています。また、生活リズムは働く日も休みの日も変わらず、いつも同じ時間に寝起きしています。\n\n## 水曜日の過ごし方\n\n水曜日は、役所や銀行、病院など、平日しかできない用事を済ませる日です。ただし、毎週そうしたタスクがあるわけではないので、ランニング（約8km）をして体を動かすことも習慣です。混雑を避けて、平日に日用品の買い出しをすることもよくあります。\n\nまた、クリエイティブな時間として、Google Keepのメモを元に開発やブログ記事を書いたり、妻と一緒に映画やアニメを楽しんだりもします。平日だと商業施設も空いているため、買い物や外食をするにも快適な時間です。\n\n## 土日の過ごし方\n\n土日は家の掃除や家族との時間を優先しています。妻はパート勤務で、土日は休みであることが多いため、一緒に過ごすことが多いです。また、家族や友人の誕生日や記念日、季節のイベントや祝日などに合わせて、買い物に出かけることも土日に多くなります。\n\n## 週4勤務のメリット\n\n個人的な感想として、日本人は働きすぎじゃないかなと思っています。5日連続で働くことは心身に大きな負担がかかります。それは自分自身だけでなく、周りの人にも影響を与えますし、その負担を回復するために土日の2日だけでは足りないのではないかと思います。\n\n週4勤務は、私にとってちょうど良いバランスです。集中力が持続しやすく、休みが間にあることでリフレッシュもできるため、疲労やストレスがたまりにくくなりました。\n\n## デメリットとその対策\n\n収入が週5勤務時の5分の4になるため、節約が必要です。また、将来への不安や焦りを感じることもあります。しかし、これは週5勤務でも感じることがあるでしょう。だからこそ、貯金や投資をしっかりと行い、計画的に取り組むことが大切だと思います。\n\n## 今後の展望\n\n今の仕事は楽しく、長く続けたいと思っています。技術をひたすら追い求めるよりも、無理せず自分のペースで続けることが大事だと考えています。家族との時間や、好きなことを楽しむ時間を優先しつつ、フリーランスの柔軟さを活かしていきたいです。\n\n## 誰でも週4勤務できる\n\n東京などの大都市ではフリーランスの仕事も豊富ですが、地方ではリモートワークが可能でないと難しいかもしれません。正社員で週4勤務を実現できる企業はまだ少ないため、フリーランスとして働き方を自由に選べるのは大きな利点です。","publishedAt":"2024-09-16","slug":"reflections-after-7-months-4-day-workweek","title":"週4勤務で7ヶ月経過した所感"},{"body":"GPTを活用した開発では、AIが生成する出力の正確性を判断するスキルが欠かせません。すべてをGPT任せにせず、開発者自身の積極的な関与が求められます。\n\n本記事では、最近手がけた2つの個人Webアプリ開発を例に、GPT駆動開発の実践方法とその効果をご紹介します。\n\n## 開発フローと使用ツール\n\n以下のダイアグラムは、GPTを活用した開発フローを示しています。この図は [DiagramGPT](https://app.eraser.io) を使用して作成しました。\n\n![GPT駆動開発フロー](https://res.cloudinary.com/silverbirder/image/upload/v1726449647/silver-birder.github.io/blog/GPT駆動開発フロー.png)\n\n※ ダイアグラムを直接ご覧になりたい方は、[こちら](https://app.eraser.io/workspace/gAcNphpXbCuDjYQq4tU1?elements=A2JnuhPG7Cx3eZVzwzjS3Q)からご確認ください。\n\n私は主にディレクションを担当し、ChatGPTやV0などのGPTツール（以下、GPTs）に具体的な指示を出して成果物を作成しています。ツールは以下のように使い分けています。\n\n- **汎用的な用途**：[ChatGPT](https://chat.openai.com/)\n- **デザイン**：[V0](https://v0.dev)\n  - **UIコンポーネント**：[ui.shadcn](https://ui.shadcn.com/)\n- **アイコン**：[LogoAI](https://logoai.com)  \n  ※現在は他のツールを検討中。良いものがあればぜひ教えてください！\n- **実装支援**：[GitHub Copilot](https://github.com/features/copilot)  \n  ※最終的にはChatGPTを使用しています\n\nGPTsから得られた成果物は、**何度も評価・修正を重ねて最終的な形に仕上げています**。出力が期待通りでない場合は、自分で実装することもあります。後述する問題解決の際には、GPTsで対応が難しい場合もあるため、自ら調査を行います。\n\nAPIやデータベースなどのインフラ設計やアプリケーション設計については、慣れ親しんだものを採用し、個人開発向けにコストの低いものを選択しています。\n\n次に、開発したアプリの例をご紹介します。\n\n## クチコミ仲間アプリの事例\n\nGoogleマップで共通のクチコミを持つ投稿者を見つけるWebアプリ「クチコミ仲間（仮）」を開発しました。\n\n![クチコミ仲間（仮）- アーキテクチャ](https://res.cloudinary.com/silverbirder/image/upload/v1726449647/silver-birder.github.io/blog/クチコミ仲間_仮_-_アーキテクチャ.png)\n\n※ ダイアグラムを直接ご覧になりたい方は、[こちら](https://app.eraser.io/workspace/3vjLLD4J9wE9bl96067E?elements=dy5KZbkEICES9M3yCHcYFQ)からご確認ください。\n\n画面イメージは以下のとおりです。\n\n![クチコミ仲間（仮）- 画面イメージ](https://res.cloudinary.com/silverbirder/image/upload/v1726449647/silver-birder.github.io/blog/レビュー仲間_仮.png)\n\n[アプリリンク](https://review-connect.vercel.app)\n\n技術スタックは以下のとおりです。\n\n- **Webフレームワーク**：[Next.js - T3 Stack](https://create.t3.gg)\n- **クローリング**：[Crawlee](https://crawlee.dev)\n- **ヘッドレスブラウザ**：[Chromium - Playwright](https://playwright.dev/)\n\n外部要因（例：Google Mapsのメモリ問題）によるトラブルが発生した際は、自ら積極的に問題解決に取り組みました。\n\n## 開発中に直面した問題\n\n### メモリリークの問題\n\nGoogle Mapsを長時間動作させると、メモリ使用量が増加してクラッシュする問題が発生しました。本来はPlaywrightのページを新しく作り直すのが理想でしたが、Crawleeの制約により、ページをリロードすることで一時的に対処しました。\n\nこうした予期せぬ問題に対しては、トライアンドエラーを繰り返しながら、GPTツールと共に解決策を模索しています。エラーログをGPTに送信する際、**あえて自分の考察を伝えずに客観的なアドバイスを求める** ようにしています。エラーの原因に心当たりがある場合は、その考察も含めてGPTに伝え、早期解決を図ります。\n\n### 同じことを繰り返す問題\n\nGPTとの対話を続けていると、同じ回答が繰り返されることがあります。例えば、特定の制約下で仕様を満たすロジックを考えてほしいと伝えると、GPTは回避策を提案してくれます。しかし、そのロジックが一部の仕様を満たしていない場合に「●●がうまく動作していないので修正してほしい」と依頼すると、元の制約を無視してしまうことがあります。\n\nこのような場合、**制約条件を常に明示的に伝えて修正を依頼する** ようにしています。これにより、GPTが制約を再認識し、期待通りの出力を得やすくなります。\n\n## もうひとつのシンプルなアプリ：「元とらなアカン」\n\n「元とらなアカン」というWebアプリも開発しました。これは、商品価格を使用頻度や期間から1日あたりのコストを計算するシンプルな電卓アプリです。画面イメージは以下のとおりです。\n\n![元とらなアカン - 画面イメージ](https://res.cloudinary.com/silverbirder/image/upload/v1726449647/silver-birder.github.io/blog/元とらなアカン.png)\n\n[アプリリンク](https://moto-torana-akan.vercel.app)\n\nデザインは [V0](https://v0.dev) に任せ、シンプルな1ページ構成で完結しています。API通信も行っておらず、軽量なアプリとなっています。\n\nここでの課題はあまり感じませんでした。[V0](https://v0.dev) には、[v0.dev/chat](https://v0.dev/chat) というチャット形式でWebデザインを作成する機能があります。構成としては、Next.js と [ui.shadcn](https://ui.shadcn.com/) でプレビューされます。精度が高く、ほとんどそのまま採用しました。\n\n一点気になったのは、特定のCSSフレームワークなどを使用したい場合、バージョン指定が必要で、指定しないとエラーになることです。\n\n### 印象的だったこと\n\nWebアプリのデザインがまだ固まっていない段階で、アプリのコンセプトや実現したい体験を V0 に伝えると、驚くほど洗練されたWebデザインを提案してくれました。\n\nさらに、「もっと遊び心を加えてほしい」といった抽象的なリクエストにも、グラデーションやアイコン、アニメーションなどを取り入れて応えてくれます。その柔軟性と創造性には非常に感動しました。具体的な要望を細かく伝えなかったのが、かえって良かったと感じます。\n\n特筆すべきは、V0 とのわずか2回のやり取りでスイカゲーム風のアプリが完成したことです。これは衝撃的な体験でした。\n\n- [V0で作成したスイカゲーム風アプリ](https://v0.dev/chat/a8RfpL90mO4)\n\n## おわりに\n\nGPTに頼る部分は多いものの、役割を明確に分担することで、効率的な開発が可能であると実感しています。以前はすべてをゼロから実装していましたが、現在では GPT ツールに叩き台を用意してもらうことで、チーム開発のようなスピード感でプロジェクトを進められています。\n\n今後も GPT 駆動開発を活用し、新たなアプリやサービスの開発に挑戦していきたいと思います。","publishedAt":"2024-09-15","slug":"gpt-driven-development","title":"GPT駆動開発：GPTsと共に進める効率的なアプリ開発"},{"body":"3ヶ月ほど、モバイルアプリを開発していましたが、最終的には諦めることになりました。\n端的に言えば、**iOSのバックグラウンド実行に制約**が多く、思い描いていたものを実現できなかったのです。\nこの記事では、開発経緯と諦めた理由についてお話しします。くぅ〜疲れましたw\n\n## 開発したかったアプリの概要\n\n私が開発したのは、**アラームを共有するアプリ**です。\n家族やグループで同じ時間に起床することが多いため、皆が同じ時間に起きられるように、\n**グループ内でアラームの時間や曜日を共有できるアプリ**があれば便利だと考えました。\n似たようなアプリは少数ありましたが、どれも私のニーズに完全には合致しなかったため、\n自分で作ることにしました。\n\n実際に作ったアラーム共有アプリの画面は、以下のとおりです。\n\n![アラーム共有(iOS)](http://res.cloudinary.com/silverbirder/image/upload/v1723344679/ypmvtlw47psksvdapsg2.png)\n\nこのアラーム共有アプリでは、アラームのON/OFF、時間、曜日、サウンド、\n音量の設定が可能です。サウンドと音量は試聴することもできます。\n\n**ログインなしに、アラームを共有する**ことが可能です。\nアラームを作成した人がオーナーとなり、共有コードを友達に伝えることで、\n友達もそのアラームに参加できます。\nオーナーがアラームの時間や曜日を変更すると、共有されているアラームはすべてリアルタイムで同期されます。\n\n## 技術選定：なぜReact Nativeなのか\n\nまず、開発言語はReact Nativeを選びました。\n理由は簡単で、**私がReactに慣れているから**です。\nFlutterやKotlin、Swiftのような他の選択肢もありましたが、\n新しい言語を学ぶコストをかけたくありませんでした。\nいくらキャッチアップが簡単だとしても、\nその周辺知識を学ぶことを踏まえると時間がかかってしまうためです。\n私は、作りたい機能が作れれば良いのです。\n\n## 開発環境の構築\n\nReact Nativeを使い、AndroidとiOS向けのフレームワークであるExpoを採用しました。\n目的は、効率よく開発を進めることでした。\n基本的にはExpo SDKを使用し、必要に応じてサードパーティライブラリを追加しました。\n\nExpo SDKで追加したものは以下のとおりです。\n\n- **expo-background-fetch**: バックグラウンド処理用\n- **expo-clipboard**: 共有コードをコピーするために使用\n- **expo-task-manager**: バックグラウンドタスク管理用\n\nサードパーティライブラリで追加したものは以下のとおりです。\n\n- **@react-native-async-storage/async-storage**: ローカルストレージにデータを保存\n- **@react-native-firebase/\\***: Realtime Database, Messaging, Function\n- **@notifee/react-native**: 通知管理\n- **@rneui/\\***: UIツールキット\n- **react-native-background-timer**: バックグラウンド用のタイマー\n- **react-native-modal-datetime-picker**: 日付選択用\n- **react-native-picker-select**: セレクトボックス\n- **react-native-notification-sounds**: デバイスのサウンド取得\n- **react-native-track-player**: オーディオ再生\n- **react-native-volume-manager**: ボリューム管理\n\n動作確認は、Android/iOSエミュレーターで行いました。\nしかし、一部の機能（例：ボリューム管理）はエミュレーターでは動作せず、本物のデバイスでの確認が必要でした。\n\nデバイスでアプリを動かすには、Expo Goというアプリで実現可能ですが、一部のライブラリが動作しません。\nそこで、EAS（Expo Application Services）でビルドしたアプリを直接デバイスにインストールする必要がありました。\n\niOSでは、デバイスにインストールするために**有料のApple Developer Programへの登録**が必要で、\nこの手続きが非常に面倒でした。\n申請後、1週間以上も反応がなく、問い合わせたところようやく2日後に返答が来るという状況でした。\n（問い合わせたらすぐに返事が来るのはなぜでしょうか…）\n\n## データとアラームトリガー\n\nアラームの時間や音量などのデータは、以下の2つに保存しています。\n\n- ローカルストレージ\n- Firebase Realtime Database\n\nFirebase Realtime Databaseを使用する理由は、アラームを共有した際に共有されたすべてのユーザーに同期させる仕組みを簡単に実現できるからです。\n\n次に、アラームの時間になったときに鳴らすトリガーについて、\n以下のパターンに分けて説明します。\n\n### アプリがバックグラウンドにある時\n\nバックグラウンドとは、以下のいずれかの状態を指します。\n\n- デバイスがロックされた状態\n- アプリが動作しているが画面に表示されていない状態\n- アプリが動作していない(シャットダウンされた)状態\n\nこの状態では、アプリは自力で動作することが困難なため(特にiOS...!!!)、\n外部からトリガーを発する必要があります。\nそのため、FCM（Firebase Cloud Messaging）を利用し、\nFirebase Functionのスケジュール実行（内部ではCloud Scheduler）を毎分起動して、\nアラームを鳴らす対象へメッセージを送信し、アラームを鳴らします。\n\n※ 後述しますが、毎分メッセージ通知するとiOSの場合レートリミットがかかります。\n\n### アプリがフォアグラウンドにある時\n\nフォアグラウンドとは、アプリが開いていて画面に表示されている状態です。\nこの状態では、React Nativeのコンポーネントがマウントされているため、\n5秒ごとにローカルストレージのデータを参照して、アラームを鳴らします。\n\n## 機能要件と課題\n\nアラーム共有アプリの開発において、以下の要件を満たすことを目標としていました。\n\n- **音量がミュート（サイレント）状態や音量ゼロの状態でも、アラーム時にのみ音量を調整できること**\n  - 理由: アラームを使用する前に、手動でミュートを解除し、大音量に調整する手間を省きたい\n- **バックグラウンドでもアラームが鳴ること**\n  - 理由: アラームをずっとフォアグラウンドにする体験にしたくない\n- **Android/iOSの両プラットフォームをサポートすること**\n  - 理由: 私の家族が、AndroidとiOSの両方を使用しているため\n\n### アラームの音に関する問題\n\nアラームの通知音は、`react-native-notification-sounds` を利用してデバイス内蔵の音を使用しましたが、\nサイレントモードや音量が低い状態では通知音が鳴らないという問題が発生しました。\n\nこの問題に対処するため、`react-native-volume-manager` を使用して音量を制御することにしました。\nフォアグラウンドでは音が鳴るようになりましたが、バックグラウンドでは依然として音が鳴らないという課題が残りました。\nそこで、`react-native-track-player`を導入し、音声を再生することで、\nリピート再生やバックグラウンドでの音声再生が可能になりました。\n\nこの方法で音の問題はある程度解決しましたが、\n通知(`@notifee/react-native`)に音を付ける場合、サイレントモードや低音量の状態では聞こえない問題が依然として残り、\nこの方法は諦めることになりました。\n\n### iOSのバックグラウンド動作制限\n\nここが、**諦めた最大の理由** です。\niOSでは、バックグラウンドでアプリを動かすことが非常に困難です。\n\n[Background Tasks - Apple Developer Documentation](https://developer.apple.com/documentation/backgroundtasks) に記載されているとおり、\n`BGAppRefreshTaskRequest` や `BGProcessingTaskRequest` を使用することで、\nバックグラウンドでも一定の処理を実行することが可能です。\nしかし、バックグラウンドでアラームを毎分、何時間も動かす方法は見つかりませんでした。\n\nそこで、[Choosing Background Strategies - Apple Developer Documentation](https://developer.apple.com/documentation/backgroundtasks/choosing-background-strategies-for-your-app) にある\n`Wake Your App with a Background Push` の方法を参考にして、\nFirebase Functionのスケジュール実行を毎分動かし、FCMからデータプッシュしてアプリを起動させる方法を試みました。\nプッシュ通知のヘッダーは以下を参考に設定しました。\n\n> When sending a background push, set content-available: to 1 without alert, sound, or badge.\n> The system decides when to launch the app to download the content.\n> To ensure your app launches, set apns-priority to 5, and apns-push-type to background.\n\nしかし、以下のような制限により、この方法も十分には機能しませんでした。\n\n> If you send background pushes more frequently than three times per hour, the system imposes rate limitations.\n> See Pushing background updates to your App for more information.\n\nこの制限のため、5分後などに確実にアラームを鳴らすことが難しく、\n安定したアラームの動作を実現できませんでした。\n\nアプリを常にフォアグラウンドで使用してもらうことで回避は可能ですが、\n私自身がポケモンスリープを使用しているため、夜間に同時使用ができないのが現実です。\nポケモンスリープは寝る前にアプリをフォアグラウンドで放置して使用します。\n\n[Configuring background execution modes | Apple Developer Documentation](https://developer.apple.com/documentation/xcode/configuring-background-execution-modes) を見ると、\n位置情報やBluetoothをアラームに活用する方法が考えられますが、\n具体的なアイデアがなく、いびきを録音したり、寝返りを計測するなどのバックグラウンド機能を追加する必要があるかもしれません。\n無音をずっと鳴らすという方法も考えられますが、バッテリーの消耗が激しくなるリスクがあります。\n\nその他、参考になるリンクを以下に示します。\n\n- [How do you allow tasks that take longer than the 30 seconds allowed in the background thread to continue performing until done? - Apple Developer Forums](https://forums.developer.apple.com/forums/thread/695910)\n- [iOS Background Execution Limits | Apple Developer Forums](https://forums.developer.apple.com/forums/thread/685525)\n\nこれらの理由から、バックグラウンドでアラームを安定して鳴らすことは非常に難しいと判断しました。\n\nちなみに、「おこしてME（Alarmy）」がiOSで上手く動作していて、どのようにこの問題を解決しているのか、とても気になるところです。\n\n- [swift - Wake up application in background using AudioSession like Alarmy iOS app - Stack Overflow](https://stackoverflow.com/questions/55546865/wake-up-application-in-background-using-audiosession-like-alarmy-ios-app)\n\n## 次にモバイルアプリを作るとしたら\n\n今回、React Nativeを選択しましたが、開発スピードは比較的早かったものの、\nトラブルシューティングに多くの時間がかかりました。\nアプリ自体の問題、ライブラリの問題、またはネイティブの仕様に起因する問題を切り分けるのに苦労しました。\nこれは、おそらく他のクロスプラットフォーム向けフレームワークでも同様の課題があると思います。\n\n一方で、KotlinやSwiftのようなネイティブ言語を使用した場合、\nこのような問題の一部は解決しやすくなるかもしれません。\nもちろん、ネイティブ開発でもライブラリを使用することが一般的だと思うのですが、\n今回の経験を通じて多くのことを学びました。\n\nまた、要件を変更すれば、別のアプローチでの開発が可能でした。\n例えば、アラーム音を通知音にすることで、開発自体は進められました。\nミュートを解除し、音量を上げて通知に音を付ければ、音を鳴らすことができます。\nしかし、通知音は1回しか鳴らず、サイレントモードでの対応を考えると、\n私の理想とする体験には妥協できませんでした。\nそのため、今回の要件を変えることはできませんでした。\nあるいは、視点を変えて考えることで、別の解決策が見つかったかもしれません。\n（アラームのAPIがあればなぁ...）\n\n## まとめ\n\nこの3ヶ月間の経験を通じて、モバイルアプリ開発の難しさを痛感しました。\n特に、iOSのバックグラウンド動作に関する制限は、想像以上に厳しく、\n想定した機能を実現するための大きな壁となりました。\nまた作りたいアイデアが生まれたら、再チャレンジしたいと思います！","publishedAt":"2024-08-13","slug":"first-mobile-app-failure","title":"はじめてモバイルアプリ開発して諦めた話"},{"body":"## はじめに\n\n学生の頃からiPodやiPhone（iPhone 4から）を愛用してきた私ですが、ついにGoogle Pixel 8aに機種変更しました。この記事では、その理由と感想についてお話しします。\n\n## iPhoneからGoogle Pixelに乗り換えた理由\n\n現在使用しているiPhone XSから新しいデバイスに買い替えようと考えましたが、新しいiPhone 15にはあまり魅力を感じませんでした。カメラやストレージ、バッテリーなどの改善点は耳にしましたが、正直なところ、自分には必要ないと感じました。\n\n## Google Pixel 8aの魅力\n\nそれに対して、Google Pixel 8aには魅力的な機能がたくさんあります。以下の点が特に気に入っています。\n\n- **通話スクリーニングと待機機能**:\n  - Googleアシスタントが代わりに通話対応\n  - 代わりに待ってくれる機能\n  - 知らない番号の検索がすぐにできる\n- **多彩な認証機能**:\n  - 顔認証と指紋認証の両方が使える\n- **「この曲何？」機能**:\n  - 流れている曲の名前を教えてくれる\n- **Googleレンズ**:\n  - カメラで映るものを検索\n  - スマホ画面に表示されているものを囲って検索\n- **レコーダー**:\n  - 録音を自動で文字起こし\n  - 録音に対してラベル付けや検索が可能\n\n消しゴムマジックなどのカメラ機能は正直あまり使っていません。あまりカメラで凝ったことをしないからです。\n\n## Googleと我が家の関係\n\nGoogle Pixel 8aを選んだもう一つの理由は、Googleのサービスと我が家の連携が非常に密接だからです。\n\n私はGoogle Oneでプレミアム2TBプランを契約しているので、写真はすべてGoogleフォトで管理しています。プライベートでの資料や書籍などもGoogle Driveに保存しており、特に画像内のテキスト検索がとても便利です。Googleの検索力は非常に強力で、日常生活において非常に重宝しています。\n\nさらに、Google Mapも日常的に利用しており、Google Mapへの口コミ投稿数は489件にもなります。\n\nまた、我が家には以下のGoogleデバイスが揃っています。\n\n- Chromecast\n- Google Nest Hub\n- Google Nest Mini\n- Google Nest Cam\n- Google Nest Wifi\n\nこれらのデバイスを揃えるのが楽しくて、ついつい増えてしまいました。ただ、タブレットはiPadを使っています。\n\n## 操作感の違いについて\n\niPhoneからAndroidへの乗り換え時に操作感がどうなるか心配でした。業務でAndroidを触ることがあるのですが、あまり使いこなせなかったので。しかし、Google Pixelの操作感はiPhoneとほとんど変わりませんでした。アプリの起動や停止、ホーム画面でのウィジェット操作など、違和感は一切ありませんでした。\n\n## 使い勝手の違い\n\nただし、以下の点には不便を感じました。\n\n- **AirPodsの接続**:\n  - iPhoneならAirPodsを耳に装着するだけで自動的に接続されましたが、Google Pixelではそれができません。\n- **Apple Watchの利用不可**:\n  - Google PixelではApple Watchと接続できません。\n- **Macとの連携**:\n  - iPhoneとMacの組み合わせでは、電話が着信した際にMacでも通知を受け取ることができましたが、Google Pixelではそれができません。\n\n## 終わりに\n\n昔はiPhoneの進化に感動していました。iPodもそうですが、かっこよく美しいデザインに驚いたり、タッチパネル、Siri、指紋認証、Retinaディスプレイなど、新しい機能が発表されるたびに興奮していました。しかし最近は、画面が大きくなり、カメラやバッテリーの改善に力を入れている感がありますが、正直あまり興味が湧かなくなってしまいました。","publishedAt":"2024-05-28","slug":"switching-from-iphone-to-google-pixel-8a","title":"長年愛用していたiPhoneからGoogle Pixelに機種変更した"},{"body":"## はじめに\n\n何でも**こつこつ**記録して可視化できるWebアプリ、[こつこつ](https://kotsu-kotsu.vercel.app)を作りました！\n\n![kotsu-kotsu AreaChart](http://res.cloudinary.com/silverbirder/image/upload/v1716635435/wepuhxujcptqz2rixztk.png)\n\n## なぜ作ったのか\n\n家計簿や筋トレのような専門的な記録アプリはありますが、ニッチなものを記録したいと思いました。例えば、以下のようなものです。\n\n- **薬を飲んだ日と錠剤名**\n\n鼻炎薬をたまに飲むのですが、飲む頻度を抑えたいので、どれくらい飲んでいるのかを記録したかったのです。また、コーヒーの摂取量（ml）も同様の理由で記録したい時があります。\n\n- **コンタクトレンズを交換した日**\n\nコンタクトレンズは2週間用のものを使っていますが、週末に交換するようにしていたものの、1週間で捨てることもあったためです。もったいないので記録して改善したいと思いました。\n\n- **夜中に起きた回数**\n\n夜中に起きてしまうことがたびたび発生していました。\n熟睡したいので、何が影響しているのか分析するために、起きたかどうか記録しようと思いました。\n\nこれらを記録するアプリがあればそれを使えば良いのですが、そんなものはないので今回作ってみました。\n\n## こつこつの使い方\n\n「こつこつ」の使い方はシンプルです。\n\n1. 記録するフォーマットを自由に定義できる「ノートブック」を作成します。\n1. 定義したフォーマットでデータを登録できる「ページ」を作成します。\n1. ノートブックに登録されたページをもとに、グラフを表示します。\n\n記録するフォーマットの項目名として、以下のパターンを選べます。\n\n- 文字\n- 数値\n- はい・いいえ\n- カテゴリ\n\n以下は、ノートブックとページの例です。\n\n![kotsu-kotsu Notebook](http://res.cloudinary.com/silverbirder/image/upload/v1716643172/vtodrr6bzzg3siw2zel0.png)\n\n![kotsu-kotsu Page](http://res.cloudinary.com/silverbirder/image/upload/v1716643174/oqobq91izn1nin1wlruw.png)\n\n## 可視化の例\n\n初めてログインすると、サンプルのデータが登録されます。そのデータを使って、以下のようなグラフが表示されます。\n\n![kotsu-kotsu AreaChart](http://res.cloudinary.com/silverbirder/image/upload/v1716635435/wepuhxujcptqz2rixztk.png)\n\n![kotsu-kotsu BarChart](http://res.cloudinary.com/silverbirder/image/upload/v1716635437/mudp6eb8karjcsr4ghqf.png)\n\n![kotsu-kotsu LineChart](http://res.cloudinary.com/silverbirder/image/upload/v1716635439/vptkdthlk9ky035xhwkf.png)\n\n![kotsu-kotsu DonutChart & PieChart](http://res.cloudinary.com/silverbirder/image/upload/v1716635442/gvl19gniunq5hy29gxjn.png)\n\n## 未実装の機能\n\n以下の機能はまだ実装していません。何か要望があれば実装します。\n\n- データのインポート/エクスポート\n- 可視化グラフの共有機能\n\n## 終わりに\n\n私はこつこつと記録することが好きで、振り返って可視化するのも好きです。\nこのアプリはそんな私にピッタリです。興味のある方はぜひ試してみてください。","publishedAt":"2024-05-25","slug":"introducing-kotsu-kotsu-app","title":"自由フォーマットでこつこつ記録して可視化するアプリを作った"},{"body":"2022年11月にChatGPTがリリースされて、1年と約半年が経過しました。\n私はChatGPTが話題になった頃から、継続して利用しています。\nChatGPTを使い続けていると、Webアプリケーションのフロントエンド開発に役立つことがありました。\n\nそこで、本記事では**フロントエンド開発でChatGPTを活用して効率よく進める3つのパターン**にまとめました。\nこれらのパターンを紹介し、読者の皆さんの開発に役立ててもらえればと思います。\n\n以下は、本記事で紹介するFigma、ソースコード、デプロイ先URLです。\n\n- [Wireframing photo - Figma](https://www.figma.com/design/aYRsXAqHD2AQp2OHbrnDn1/Wireframing-in-Figma)\n- [silverbirder/figma-photo-sample-app-for-ai - GitHub](https://github.com/silverbirder/figma-photo-sample-app-for-ai)\n- https://figma-photo-sample-app-for-ai.vercel.app\n\n## ChatGPTを使う前に\n\nChatGPTにフロントエンドのソースコードなどを学習させないために、データコントロールをOFFにしておきましょう。\n\n[Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq)\n\n## 前提\n\nこれから紹介する方法は特定の技術スタックに限定されるものではありません。\n皆さんのお好みのものに読み替えていただければと思います。今回は以下の技術スタック・ツールを使用します。\n\n- デザインツール: Figma\n- Webアプリフレームワーク: Next.js\n- スタイル: CSS Module\n- テスト: Vitest\n\n### デモ対象\n\n対象となる画面は、[Wireframing in Figma](https://www.figma.com/design/aYRsXAqHD2AQp2OHbrnDn1/Wireframing-in-Figma)にあるPhotoというサービスの1画面です。\n\n![Photo - Wireframing in Figma](http://res.cloudinary.com/silverbirder/image/upload/v1716296631/xmpiivtyzkq5wnelcwde.png)\n\nソースコードは、[silverbirder/figma-photo-sample-app-for-ai - GitHub](https://github.com/silverbirder/figma-photo-sample-app-for-ai) にありますのでご参考にください。\n\n## 紹介する内容\n\n今回紹介するのは、フロントエンド開発における以下の流れです。\n\n① FigmaのデザインからReactコンポーネント作成  \n② 仕様を満たすビジネスロジックの実装  \n③ 開発したReactコンポーネントのテストコード作成  \n\n新規開発や既存改修のどちらでも、この流れは大きく変わりません。今回は上記の順番で進めます。\n\n## FigmaのデザインからReactコンポーネント作成\n\nFigmaのデザインからReactコードを生成するための方法をご紹介します。\n\nちなみに、Figmaのデザインからコード生成するプラグインやサービスは、ネットで検索すると沢山見つかりますが、コード生成結果の精度はあまり芳しくありませんでした。\n\n### FigmaからCSSをエクスポート\n\n以下の図のように、Figmaから対象のデザインのCSSを抽出します。また、デザインのスクリーンショットも撮っておきます。\n\n![Figma > Copy as code > CSS (all layers)](http://res.cloudinary.com/silverbirder/image/upload/v1716296634/cccbdmvxlhbr0pkkbskn.png)\n\n### エクスポートしたCSSをChatGPTに渡し、ReactとStyleのコードを生成してもらう\n\n以下のようなメッセージをChatGPT(GPT-4o)に送ります。\n\n```plaintext\n以下は、Figmaから抽出したCSSです。\n---\n<コピーしたCSS> (内容は確認しておいてください。)\n---\n\n添付画像は、上記CSSのスクリーンショットです。\nこれらから、ReactとCSS Moduleのコードを生成してください。\nコード生成は、以下のコードを参考にしてください。\n---\nimport React from \"react\";\nimport styles from \"./Hoge.module.css\";\n\nconst Hoge = () => {\n  return ();\n};\n\nexport default Hoge;\n---\n```\n\n返答されたコードを基にReactコンポーネントを作成します。\nFigmaのデザインを忠実に再現しようとするため、適宜「positionを使わずに」や「横幅は固定せず」といった指示を出して調整します。\nレスポンシブデザインやアニメーション、ホバーなども適宜調整します。\n\n以下の画像は、実際にコード生成されたものを適用したものです。完璧ではありませんが、**数分程度でFigmaの1画面が構築できました**。(修正は2度ぐらい)\n\n![React Photo - Wireframing in Figma](http://res.cloudinary.com/silverbirder/image/upload/v1716297392/nlcwjvbsbsnv2oaya43e.png)\n\nゼロから開発するよりも、ある程度**雛形となるコードを作成してくれる方が時間短縮になります**。\nまた、**自身では知らない方法でコード作成してくれる場合もあり、勉強になります**。\n\n## 仕様を満たすビジネスロジックの実装\n\nWebアプリケーションのフロントエンドで、仕様を満たすための実装をします。\n例えば、フォームのバリデーションやAPI通信、クリックなどのインタラクションなどがあります。\nこのような実装方法について、ChatGPTに尋ねることが多いです。\n\n尋ねる内容は、Reactのコードと仕様文書をChatGPTに送って回答をもらいます。\nたびたび仕様を満たせない回答もありますが、基本的には自分の設計案を確認するために使います。\n\n以下は、ナビゲーションヘッダーを固定し、透過グラデーションさせたい場合の例です。\n\n```plaintext\n以下のReactコードとスタイルから、ヘッダーを固定させて かつ 透過しグラデーションしてほしい。\n---\n<Reactのコード>\n---\n<スタイルのコード>\n---\n```\n\n生成されたCSSと画面の例です。\n\n```css\n.navbar {\n  position: fixed; /* 固定表示にする */\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 72px;\n  background: linear-gradient(to bottom, rgba(255, 255, 255, 0.9), rgba(255, 255, 255, 0.7));\n  box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.05);\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n  padding: 0 32px;\n  z-index: 1000; /* 他の要素より前面に表示するためにz-indexを追加 */\n  backdrop-filter: blur(10px); /* 背景をぼかして通過させる */\n}\n```\n\n![Photo Navbar](http://res.cloudinary.com/silverbirder/image/upload/v1716341355/eqolmpun1a5o34wclgxf.png)\n\nこれは単なる例に過ぎませんが、**生成されたコードから設計方法について参考にしたり、知らない方法を学べる良い機会**になります。\n\nこのプロセスは仕様に依存するため、具体的な方法を紹介することは少ないです。\n\n## 開発したReactコンポーネントのテストコード作成\n\nプロダクトのコード（Reactコード）をChatGPTに渡し、単体テストを書いてもらいます。\n参考になるテストコードも一緒に渡すと、それに合わせたコードを生成してくれます。\nテストが動作しない場合や型の誤りがある場合は、指示を出して修正します。\n\n```plaintext\n以下のReactコードに対して、テストコードを書いてください。\n---\n<Reactコード>\n---\n\nテストコードは、以下のコードを参考にしてください。\n---\nimport { expect, it, describe } from \"vitest\";\nimport { render } from \"@testing-library/react\";\nimport Hoge from \"./Hoge\";\n\ndescribe(\"Hoge\", () => {\n  const setup = () => {\n    const utils = render(<Hoge />);\n\n    return { ...utils };\n  };\n\n  it(\"should render correctly and match snapshot\", () => {\n    // Act\n    const { asFragment } = setup();\n\n    // Assert\n    expect(asFragment()).toMatchSnapshot();\n  });\n});\n---\n```\n\n以下は、生成されたテストコードの例です。\n\n```tsx\nimport { expect, it, describe } from \"vitest\";\nimport { render } from \"@testing-library/react\";\nimport Navbar from \"./Navbar\";\n\ndescribe(\"Navbar Component\", () => {\n  const setup = () => {\n    const utils = render(<Navbar />);\n\n    return { ...utils };\n  };\n\n  it(\"should render correctly and match snapshot\", () => {\n    // Act\n    const { asFragment } = setup();\n\n    // Assert\n    expect(asFragment()).toMatchSnapshot();\n  });\n\n  it(\"should render the logo\", () => {\n    // Act\n    const\n\n { getByText } = setup();\n\n    // Assert\n    expect(getByText(\"photo\")).toBeDefined();\n  });\n\n  it(\"should render all navigation links\", () => {\n    // Act\n    const { getByText } = setup();\n\n    // Assert\n    const navLinks = [\"Features\", \"Pricing\", \"Community\", \"Support\"];\n    navLinks.forEach((linkText) => {\n      expect(getByText(linkText)).toBeDefined();\n    });\n  });\n\n  it(\"should render the login and register buttons\", () => {\n    // Act\n    const { getByRole } = setup();\n\n    // Assert\n    expect(getByRole(\"button\", { name: \"Log in\" })).toBeDefined();\n    expect(getByRole(\"button\", { name: \"Register\" })).toBeDefined();\n  });\n});\n```\n\n仕様が複雑になると、テストケースが増え、ChatGPTの便利さをより実感できます。\n\n個人的に、テストコードが書きやすいプロダクトコードは、設計として見通しの良いものになると考えています。\nそのため、テストコードが読みにくい場合は、プロダクトコードを修正するようにしています。\n\n## なぜChatGPTを選んだのか\n\nもともと、生成AIが話題になった頃から使っていたツールだからです。\nGitHub Copilotも良いツールですが、**デザインなど視覚的な情報が必要な場合**にはChatGPTが役立ちます。\n\n最近、ChatGPTのMacOSアプリがリリースされ、スクリーンショットのしやすさが改善されています。\n\n[Using the ChatGPT MacOS App | OpenAI Help Center](https://help.openai.com/en/articles/9275200-using-the-chatgpt-macos-app)\n\n## 終わりに\n\nこのように、ChatGPTを活用することでフロントエンド開発の効率化を図ることができます。\n時間短縮だけでなく、知らないことを学べる機会にもなり一石二鳥です。\nぜひ、皆さんの開発にも取り入れてみてください。","publishedAt":"2024-05-22","slug":"frontend-development-in-the-age-of-generative-ai","title":"生成AI時代のフロントエンド開発術"},{"body":"Dockerイメージ内の構造や設定が期待通りかどうかを検証する `container-structure-test` を知りました。\n\n[container-structure-test GitHub リポジトリ](https://github.com/GoogleContainerTools/container-structure-test)\n\nせっかくなので、試してみました。\n\n## 環境構築\n\nまず、`container-structure-test` をインストールします。MacOSの場合、Homebrewを使用すると簡単にインストールできます。\n\n```sh\nbrew install container-structure-test\n```\n\n次に、テスト対象のDockerイメージをビルドするために、以下の内容のDockerfileを準備し、イメージをビルドします。\n\n```Dockerfile\n## ./Dockerfile\n## @see: https://github.com/silverbirder/testcontainers-nextjs/blob/main/Dockerfile\n\n## ...\n\n##### RUNNER\n\nFROM --platform=linux/amd64 node:18.17-alpine3.18 AS runner\nWORKDIR /app\n\nENV NODE_ENV production\n\n## ENV NEXT_TELEMETRY_DISABLED 1\n\nRUN addgroup --system --gid 1001 nodejs\nRUN adduser --system --uid 1001 nextjs\n\nCOPY --from=builder /app/next.config.js ./\nCOPY --from=builder /app/public ./public\nCOPY --from=builder /app/package.json ./package.json\n\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static\n\nUSER nextjs\nEXPOSE 3000\nENV PORT 3000\n\nCMD [\"node\", \"server.js\"]\n```\n\nビルドコマンドは以下の通りです。\n\n```sh\ndocker build . -t app:latest\n```\n\nこのコマンドは、タグ名を `app:latest` としてDockerイメージをビルドします。\n\n## container-structure-test を使ったテスト\n\n`container-structure-test` は、ビルドしたDockerイメージに対して様々なテストを実行することができます。\n以下のコマンドを実行することでテストを開始できます。\n\n```sh\ncontainer-structure-test test \\\n  --image app:latest \\\n  --platform linux/amd64 \\\n  --config config.yml\n```\n\n`config.yml` には、実行したいテストの設定を記述します。以下はその例です。\n\n```yml\n## config.yml\nschemaVersion: \"2.0.0\"\ncommandTests:\n  - name: \"cat server.js\"\n    command: \"cat\"\n    args: [\"server.js\"]\n    expectedOutput: [\".*startServer.*\"]\nfileContentTests:\n  - name: \"package.json\"\n    expectedContents: [\"testcontainers-nextjs\"]\n    path: \"/app/package.json\"\nfileExistenceTests:\n  - name: \"package.json\"\n    path: \"/app/package.json\"\n    shouldExist: true\n    permissions: '-rw-r--r--'\n    uid: 1001\n    gid: 1001\nmetadataTest:\n  envVars:\n    - key: PORT\n      value: 3000\n    - key: NODE_ENV\n      value: production\n  exposedPorts: [\"3000\"]\n  cmd: [\"node\", \"server.js\"]\n  workdir: \"/app\"\n  user: \"nextjs\"\n## licenseTests:\n## - debian: true\n##   files: [\"/foo/bar\", \"/baz/bat\"]\n```  \n\n`container-structure-test` で実行できるテストには、以下のような種類があります。\n\n- **commandTests**\n  - イメージからコマンドを実行し、期待する出力が得られるかを検証します。\n- **fileContentTests**\n  - 特定のファイルが期待する内容を含んでいるかをテストします。\n- **fileExistenceTests**\n  - ファイルの存在有無、権限、所有者を検証します。\n- **metadataTest**\n  - 環境変数やポートの露出、実行ユーザーなどのメタデータを検証します。\n- **licenseTests**\n  - 著作権ファイルのリストをチェックして、Googleで許可されているライセンスのみが使用されていることをテストします。\n\n詳しくは、[container-structure-test GitHub リポジトリ](https://github.com/GoogleContainerTools/container-structure-test) をご確認ください。\n\n**commandTests** は、Dockerコンテナを作成して、CMDを実行してテストするようです。\nエラーやワーニング、セキュリティなどのログが発生しないことを確認するのはよさそうです。\n\n**fileContentTests** は、何に使えそうか思いつかなかったです。\n\n**fileExistenceTests** は、permissionsやuid,gidを確認できるので、許可してはいけないものをチェックするのによさそうです。\n\n**metadataTest** は、アプリに必要な環境変数を正規表現でテストするのは良さそうです。\n\n**licenseTests** は、何に使えそうか思いつかなかったです。\n\n## まとめ\n\n`container-structure-test`  は、Dockerイメージが期待する仕様を満たしているかを自動で検証するためのツールです。\nこの記事で紹介した基本的な使い方とテストの例を参考に、安全で信頼性の高いコンテナ環境の構築に役立ててください。","publishedAt":"2024-03-29","slug":"try-container-structure-test","title":"Docker Image に 構造化テスト container-structure-test を試してみた"},{"body":"[Testcontainers](https://testcontainers.com/) というものを知りました。\nTestcontainersは、コンテナを利用してテスト環境を構築し、簡単に統合テストを行うことができるツールです。\nこの便利なツールを用いて、Next.jsとデータベース(DB)を組み合わせた結合テストを実施しました。\n使い捨て可能なエンドツーエンド(E2E)テストの実装ができそうで、とても良さそうに思いました。\n試した内容について、簡単に紹介します。\n\n以下のGitHubリポジトリで、今回紹介するコードを確認できます。\n\n- https://github.com/silverbirder/testcontainers-nextjs\n\n## 実装手順\n\n私が試したことを以下に簡単にまとめました。\n\n- テストのセットアップ\n  - テストフレームワークとしてVitestを設定\n  - MySQLコンテナをデータベースとして作成し、必要なマイグレーションとシーディングを実施\n- アプリケーションのセットアップ\n  - Dockerfileを使用してNext.jsアプリケーションを起動\n  - アプリケーションがMySQLデータベースに適切に接続できるように設定\n- テストの実施\n  - ブラウザ自動化ツールであるPlaywrightを使用し、Next.jsアプリケーションへのアクセス及びテストの実行\n\nこの設計は特別な環境を用意する必要がなく、GitHub Actions でも動くことを確認しました。\n\n## 実装例を見よう\n\nここでは、前述した実験手順に基づいて実際に記述したコードの紹介を行います。\n具体的な実装に関しては、[GitHub上に公開しています](https://github.com/silverbirder/testcontainers-nextjs)。\n\n### テストのセットアップ\n\nまずはテストのセットアップを行います。\nこれには、テストフレームワークのVitestのセットアップから始めます。Vitestの詳細なセットアップ方法については、[Vitestの公式ガイド](https://vitest.dev/guide/)を参照してください。\n\n以下のサンプルコードは、テストの基本的な構造を示しています。\n\n```ts\n// sample.test.ts\nimport { afterAll, beforeAll, describe, vi } from \"vitest\";\n\ndescribe(\"App and Database Containers Integration Test\", () => {\n  vi.setConfig({ testTimeout: 600_000, hookTimeout: 600_000 });\n  beforeAll(async () => {});\n  afterAll(async () => {});\n});\n```\n\nTestcontainersを使用する際、テストの実行時間が長くなる可能性があるため、`testTimeout`と`hookTimeout`の値を拡大しています。\nテストの実行には、以下のコマンドを使用します。\n\nこのコードに対して、以下のコマンドを実行します。\n\n```bash\nDEBUG=testcontainers* vitest\n```\n\nこのコマンドでは、`DEBUG=testcontainers*`を指定しており、これはTestcontainersによる詳細なログ出力を有効にするためです。\nログの設定に関する詳細は、[Testcontainersの設定ページ](https://node.testcontainers.org/configuration/)を参照してください。\n\n次に、テストに必要なデータベースの準備を行います。\n以下のサンプルコードでは、MySQLコンテナの起動と、マイグレーションおよびダミーデータのシーディングを実行しています。\n\n```ts\n// sample.test.ts\nimport { afterAll, beforeAll, describe } from \"vitest\";\nimport { MySqlContainer, StartedMySqlContainer } from \"@testcontainers/mysql\";\nimport { createPool } from \"mysql2\";\nimport { drizzle } from \"drizzle-orm/mysql2\";\nimport { migrate } from \"drizzle-orm/mysql2/migrator\";\nimport { faker } from \"@faker-js/faker\";\nimport * as schema from \"../server/db/schema\";\n\ndescribe(\"App and Database Containers Integration Test\", () => {\n  // ...\n  let mysqlContainer: StartedMySqlContainer;\n  beforeAll(async () => {\n    mysqlContainer = await new MySqlContainer()\n      .withDatabase(\"t3-app-nextjs-testcontainers\")\n      .start();\n    const databaseUrl = `mysql://${mysqlContainer.getUsername()}:${mysqlContainer.getUserPassword()}@${mysqlContainer.getHost()}:${mysqlContainer.getFirstMappedPort()}/${mysqlContainer.getDatabase()}`;\n    const db = drizzle(\n      createPool({\n        uri: databaseUrl,\n      }),\n      {\n        schema,\n        mode: \"default\",\n      },\n    );\n    await migrate(db, { migrationsFolder: \"src/server/db/out\" });\n    const data: (typeof schema.posts.$inferInsert)[] = [];\n    for (let i = 0; i < 20; i++) {\n      data.push({\n        name: faker.internet.userName(),\n      });\n    }\n    await db.insert(schema.posts).values(data);\n  });\n  afterAll(async () => {\n    await mysqlContainer.stop();\n  });\n});\n```\n\nテスト完了後は、`afterAll`フックを使用してMySQLコンテナを停止します。これにより、テスト環境をクリーンな状態に保つことができます。\n\nTestcontainersでは、サポートされているコンテナ（例えばMySQL）と汎用的なコンテナ（Generic）の両方を使用することができ、\nどちらを使っても良いと思います。\nサポートされているコンテナの詳細については、[Testcontainersのモジュール一覧ページ](https://testcontainers.com/modules/)を参照してください。\n\n### アプリケーションのセットアップ\n\nアプリケーションのセットアップは、Next.jsのフレームワークを用いて効率的に進めます。\nまず、`npm create t3-app@latest` コマンドを使用し、Next.jsでデータベースを含めたアプリケーションの基盤を簡単に作成します。\nこのプロジェクトでは、ORMとして`drizzle`を使用しています。\nNext.jsのDocker化に関しては、[T3スタックの公式ガイド](https://create.t3.gg/en/deployment/docker)に従い、Dockerfileを作成します。\n\n以下は、テストコード`sample.test.ts`の続きで、アプリケーションとデータベースのコンテナを統合する部分です。\n\n```ts\n// sample.test.ts\nimport { afterAll, beforeAll, describe } from \"vitest\";\nimport { MySqlContainer, StartedMySqlContainer } from \"@testcontainers/mysql\";\nimport { GenericContainer, StartedTestContainer } from \"testcontainers\";\n\ndescribe(\"App and Database Containers Integration Test\", () => {\n  // ...\n  let mysqlContainer: StartedMySqlContainer;\n  let appContainer: StartedTestContainer;\n  beforeAll(async () => {\n    mysqlContainer = await new MySqlContainer()\n      .withDatabase(\"t3-app-nextjs-testcontainers\")\n      .start();\n    // ...\n    const innerDatabaseUrl = `mysql://${mysqlContainer.getUsername()}:${mysqlContainer.getUserPassword()}@${mysqlContainer.getIpAddress(mysqlContainer.getNetworkNames()[0] ?? \"\")}:3306/${mysqlContainer.getDatabase()}`;\n    const appImage = await GenericContainer.fromDockerfile(\"./\")\n      .withBuildArgs({ NEXT_PUBLIC_CLIENTVAR: \"clientvar\" })\n      .withCache(true)\n      .build(\"app\", { deleteOnExit: false });\n    appContainer = await appImage\n      .withEnvironment({ DATABASE_URL: innerDatabaseUrl, PORT: \"3000\" })\n      .withExposedPorts(3000)\n      .start();\n  });\n  afterAll(async () => {\n    await appContainer.stop();\n    await mysqlContainer.stop();\n  });\n});\n```\n\nこのコードでは、`GenericContainer.fromDockerfile` を使用して、\n現在のディレクトリにあるDockerfileからアプリケーションのDockerイメージをビルドしています。\nビルド時の引数は`withBuildArgs`を通じて渡され、コンテナの環境変数は`withEnvironment`で設定されます。\nこれは、Docker CLIを使用するときと似ていますね。Docker Compose も使えます。\n\nまた、データベースへの接続情報として`innerDatabaseUrl`には、ホスト側ではなくコンテナ側のポート（この場合は3306）を使用する必要があります。\nこれは、コンテナ間通信を意識した設定です。\n\nこれにより、データベースとアプリケーションのコンテナが準備完了となり、統合テストの実行に移ることができます。\n\n### テストの実施\n\nテストの最終段階では、Playwrightを用いてブラウザを介したアプリケーションのテストを行います。\nPlaywrightのセットアップと基本的な使い方については、[Playwrightの公式ドキュメント](https://playwright.dev/docs/intro)を参照してください。\n\n以下のコードスニペットは、`sample.test.ts` ファイルにPlaywrightを組み込んだテストの例を示しています。\n\n```ts\n// sample.test.ts\nimport { afterAll, beforeAll, describe, it } from \"vitest\";\nimport { MySqlContainer, StartedMySqlContainer } from \"@testcontainers/mysql\";\nimport { GenericContainer, StartedTestContainer } from \"testcontainers\";\nimport { type Browser, type Page, chromium } from \"@playwright/test\";\n\ndescribe(\"App and Database Containers Integration Test\", () => {\n  // ...\n  let mysqlContainer: StartedMySqlContainer;\n  let appContainer: StartedTestContainer;\n  let browser: Browser;\n  let page: Page;\n  beforeAll(async () => {\n    mysqlContainer = await new MySqlContainer()\n      .withDatabase(\"t3-app-nextjs-testcontainers\")\n      .start();\n    // ...\n    appContainer = await appImage\n      .withEnvironment({ DATABASE_URL: innerDatabaseUrl, PORT: \"3000\" })\n      .withExposedPorts(3000)\n      .start();\n    browser = await chromium.launch();\n    page = await browser.newPage();\n  });\n  afterAll(async () => {\n    await appContainer.stop();\n    await mysqlContainer.stop();\n    await browser.close();\n  });\n  it(\"should interact with the app through the browser\", async () => {\n    const url = `http://${appContainer.getHost()}:${appContainer.getFirstMappedPort()}`;\n    await page.goto(url);\n    await page.screenshot({ path: \"screenshots/screenshot-1.png\" });\n    await page.getByPlaceholder(\"Title\").fill(\"Hello World\");\n    await page.screenshot({ path: \"screenshots/screenshot-2.png\" });\n    await page.getByRole(\"button\", { name: \"Submit\" }).click();\n    await page.screenshot({ path: \"screenshots/screenshot-3.png\" });\n    await page.locator(\"button\").isEnabled();\n    await page.waitForSelector(\"text=Your most recent post: Hello World\");\n    await page.screenshot({ path: \"screenshots/screenshot-4.png\" });\n  });\n});\n```\n\nこのコードでは、まずChromiumブラウザを起動し、新しいページを開きます。\nその後、テスト対象のアプリケーションにアクセスし、フォームへの入力やボタンのクリックなど、ユーザー操作をシミュレートしています。\nスクリーンショットを見るとわかるのですが、DBへのPOSTやGETも機能しているので、実際に稼働しているアプリケーションに近いものになっています。\n\nこのテストは、GitHub Actionsを使用して自動化することも可能です。\n以下のコードは、GitHub Actionsの設定例です。\n\n```yml\nname: Node.js CI\non:\n  push:\n    branches: [ \"main\" ]\n  pull_request:\n    branches: [ \"main\" ]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Use Node.js 18.x\n      uses: actions/setup-node@v3\n      with:\n        node-version: 18.x\n        cache: 'npm'\n    - run: npm ci\n    - run: npx playwright install --with-deps\n    - run: npm test\n    - uses: actions/upload-artifact@v4\n      if: always()\n      with:\n        name: screenshots\n        path: ./screenshots/\n        retention-days: 30\n```\n\nこのようにして、Next.jsとデータベースが統合された使い捨ての結合テスト環境をGitHub Actionsを通じて実現することができます。\n\n## テストのメリットとデメリット\n\nTestcontainersを使用したテストアプローチには、いくつかのメリットとデメリットがあると思います。\n\n### メリット\n\n1. **環境の即時構築**  \n\nDockerイメージを使用してテスト環境をゼロから構築し、データのシーディングまで一気に行うことが可能です。\nこれにより、実際の環境を模倣したテストが手軽に実施できます。\n\n1. **軽量かつ迅速**  \n\nDockerコンテナを起動するだけで済むため、環境構築にかかる時間と労力を削減できます。\nこれにより、開発サイクルを速めることが可能になります。\n\n1. **使い捨てが可能**  \n\nテスト後に環境を簡単に破棄できるため、毎回クリーンな状態からテストを開始することができます。\nこれは、テストの再現性と信頼性を保証します。\n\n1. **GitHub Actionsでの実行**  \n\nGitHub Actionsを活用することで、テストプロセスを自動化し、CI/CDパイプラインに組み込むことが可能です。\nこれにより、小規模プロジェクトでも効率的に開発を進めることができます。\n\n### デメリット\n\n1. **セットアップ時間の増加**  \n\nコンテナの規模が大きくなると、セットアップに要する時間が長くなることがあります。これは、テストプロセスの迅速化を求める場合には考慮すべき点です。\n\n1. **マシンリソースの消費**  \n\n複数のコンテナを同時に稼働させると、マシンリソースを大量に消費する可能性があります。これは、特にリソースに限りのある環境でのテスト実施において注意が必要です。\n\nテストの使い捨て可能な性質とこれらのトレードオフがあるのかと思います。\nアプリケーションの規模が大きくなるにつれ、コンテナセットアップの複雑さが増す可能性があります。\nしかし、Dockerイメージの事前準備やDocker Composeの活用により、これらの課題をある程度軽減することが可能です。\n\n## 結論\n\nTestcontainersを活用したことで、Node.js環境でも、Vitestなどのテストライブラリと併用して使えることが明らかになりました。\nこれまで、エンドツーエンド(E2E)テストを行う際には、テスト環境の準備やメンテナンスに伴うコストと労力が課題となっていました。\nしかし、Testcontainersを用いることで、使い捨て可能な結合テスト環境を簡単に構築できるようになり、新たな選択肢の一つになるかと思います。\n\nまだ検証段階で、実際に実務で考えると課題もあると思います。\nしかし、個人的にはこの設計に魅力を感じています！","publishedAt":"2024-03-25","slug":"testcontainers-nextjs-db-integration","title":"Testcontainersを用いたNext.jsとDBの結合テスト"},{"body":"[Million.dev](https://million.dev/) を知り、少し試してみました。\n\n## Million.jsについて\n\nこのライブラリは、React DevToolsのProfilerより簡単にプロファイリングできるみたいです。\nパフォーマンスのプロファイリングは通常、面倒で時間のかかる作業です。もしもこれを簡単に実行できるのであれば、めちゃくちゃ捗るなとわくわくしました。\n\n一応、公式からも、Million.jsについて引用しておきます。\n\n> Million Lint is a VSCode extension that keeps your React website fast.\nWe identify slow code and provide suggestions to fix it. It’s like ESLint, but for performance!\n\n※ https://million.dev/blog/lint\n\nVSCodeの拡張機能を使うそうです。\n\n## 実際にやってみた\n\nMillion Lintを試す過程は非常にシンプルでした。次のコマンドを実行するだけで自動的にインストールされます。\n\n```bash\nnpx @million/lint@latest\n```\n\nインストール後、アプリケーションを起動し、いくつかの操作を行うと、描画回数や描画時間などの情報がVSCode常に表示されました。\nまた、有料オプションとして、Lintによる問題解決の提案も受けることができます。\n例えば、「Callback関数を使用してください」や「Debounceを行ってください」といったアドバイスがありました。\nしかし、無料で利用できるのは3回程度と限られているようでした。\n\n![Million Lint in VSCode](http://res.cloudinary.com/silverbirder/image/upload/v1711022284/jtukcrtmxeo4fxgl9pd8.png)\n\n## 所感\n\n**現時点では、パフォーマンス調査には、まだ React DevToolsを使用する** のかなと思います。\nMillion Lintの分析機能は有料であり、また、提案の出力が安定していない（時には提案が表示されず、時にはされる）点が気になりました。\nまた、親コンポーネントの描画やパフォーマンスデータを確認できましたが、子コンポーネントには、それらの情報が表示されませんでした。\n\nしかし、**VSCode上で描画や処理時間を把握できることは、パフォーマンス問題に直面する前に気づく機会を与えてくれるかもしれないと感じました。**\nMillion Lintの提案は有料ですが、描画や時間に関する情報が表示される点は利用価値があると思います。\n\n## 終わりに\n\nReactで開発する際、パフォーマンス問題に直面することが多いですが、Million Lintはその解決に向けた一助となる可能性を秘めています。\nただし、その全機能を活用するには課金が必要であり、無料版の利用には限界があることを認識しておく必要があります。","publishedAt":"2024-03-21","slug":"try-million-lint","title":"Million Lintを試してみた"},{"body":"Playwright上で直接ブラウザ上のコンポーネントテストを実行できる「[Playwright Component Test](https://playwright.dev/docs/test-components)」（以下、playwright-ct）について知り、実際に試してみました。\nこの記事では、その体験を共有します。実際に使用したリポジトリは下記の通りです。\n\nhttps://github.com/silverbirder/react-todoMVC-2\n\n## 準備\n\nplaywright-ctはReactなど複数のフレームワークをサポートしています。\n今回は、`create-react-app`が非推奨となっているため、Next.jsを使ってアプリケーションを構築しました。\n[TodoMVC](https://todomvc.com/)を例に取り入れました。\n\nplaywright-ctのセットアップは `npm init playwright@latest -- --ct`で行い、いくつかのファイルが生成されます。\n生成されたファイルのうち、`playwright-ct.config.ts` に以下のようなコードを追加しました。\nこれは、Next.jsのtsconfigでpaths設定をしているので、その内容をplaywright-ctにも反映させるためです。\n\n```ts\n// playwright-ct.config.ts\nexport default defineConfig({\n  ...\n  use: {\n    ...\n    ctViteConfig: {\n      resolve: {\n        alias: {\n          '#': resolve(__dirname, './'),\n        },\n      },\n    },\n  },\n});\n```\n\nまた、todoMVCのスタイルを適用するために、`playwright/index.tsx` というファイルに、以下のコードを追加しました。\n\n```tsx\n// playwright/index.tsx\nimport \"todomvc-app-css/index.css\";\n```\n\nplaywright-ctの仕組みは、**コードをコンパイルし、それをローカルWebサーバーで提供し、playwright/index.html に読み込ませて描画し、テストします** 。\n\n## テストコードの例\n\nTodoリストコンポーネントのコードは以下のようになります。\n\n```tsx\n// todo-list.tsx\nimport React from \"react\";\nimport { Todo } from \"./types\";\n\nconst TodoList = ({ todos, toggleTodo, deleteTodo }) => (\n  <ul className=\"todo-list\">\n    {todos.map((todo) => (\n      <li key={todo.id} className={todo.completed ? \"completed\" : \"\"}>\n        <div className=\"view\">\n          <input\n            type=\"checkbox\"\n            className=\"toggle\"\n            checked={todo.completed}\n            onChange={() => toggleTodo(todo.id)}\n          />\n          <label>{todo.text}</label>\n          <button className=\"destroy\" onClick={() => deleteTodo(todo.id)}></button>\n        </div>\n      </li>\n    ))}\n  </ul>\n);\n\nexport default TodoList;\n```\n\nテストケースは、以下のように書きました。\n\n```tsx\n// テストケース\nimport { test, expect } from \"@playwright/experimental-ct-react\";\nimport TodoList from \"./todo-list\";\n\ntest.use({ viewport: { width: 500, height: 500 } });\n\ntest(\"completed状態でtodoの表示が異なること\", async ({ mount, page }) => {\n  await mount(\n    <TodoList\n      todos={[\n        { id: 1, text: \"My Todo 1\", completed: true },\n        { id: 2, text: \"My Todo 2\", completed: false },\n      ]}\n      toggleTodo={() => {}}\n      deleteTodo={() => {}}\n    />\n  );\n  await expect(page).toHaveScreenshot();\n});\n```\n\nplaywright-ctでは **本物のブラウザ環境でテストができる** のが魅力です。viewportやwindowオブジェクト、WebAPIも扱えます。\nまた、クロスブラウザテスト(chromium,firefox,webkit)も可能です。\n\nテストは、`playwright test -c playwright-ct.config.ts` で実行できます。\n\n次は、Next.jsのページコンポーネントのコードです。(React Server Components ではありません)\n\n```tsx\n// page.tsx\n\"use client\";\n\nimport TodoList from \"@/ui/todo-list\";\nimport { Todo } from \"@/ui/types\";\nimport { useState, type KeyboardEvent } from \"react\";\n\nexport default function Home() {\n  const [todos, setTodos] = useState<Todo[]>([]);\n  const [text, setText] = useState(\"\");\n\n  const addTodo = () => {\n    if (!text) return;\n    const newTodo: Todo = { id: Date.now(), text, completed: false };\n    setTodos([...todos, newTodo]);\n    setText(\"\");\n    const params = new URLSearchParams(\"\");\n    params.set(\"added\", \"true\");\n    window.history.pushState(null, \"\", `?${params.toString()}`);\n  };\n\n  const toggleTodo = (id: number) => {\n    setTodos(\n      todos.map((todo) => {\n        if (todo.id === id) {\n          return { ...todo, completed: !todo.completed };\n        }\n        return todo;\n      })\n    );\n  };\n\n  const deleteTodo = (id: number) => {\n    setTodos(todos.filter((todo) => todo.id !== id));\n  };\n\n  const handleKeydown = (e: KeyboardEvent) => {\n    if (e.key !== \"Enter\") {\n      return;\n    }\n    addTodo();\n  };\n\n  return (\n    <section className=\"todoapp\">\n      <header className=\"header\">\n        <h1>todos</h1>\n        <input\n          className=\"new-todo\"\n          value={text}\n          onChange={(e) => setText(e.target.value)}\n          onKeyDown={(e) => handleKeydown(e)}\n          placeholder=\"What needs to be done?\"\n          autoFocus\n        />\n      </header>\n      <main className=\"main\">\n        <TodoList\n          todos={todos}\n          toggleTodo={toggleTodo}\n          deleteTodo={deleteTodo}\n        />\n      </main>\n    </section>\n  );\n}\n```\n\n`addTodo` 関数は、敢えて `window.history` を使用しています。\nNext.jsのuseRouterのような機能を使うためには、ある程度の準備が必要となります。\n従来のテストでは、このようなwindowオブジェクトに関連する部分をモック（模倣）してテストすることが一般的でした。\nしかし、playwright-ctを使用すると、これらの本物のブラウザ機能を使ってテストを行うことが可能です。\n\nページコンポーネントのテストコード例を、以下に示します。\n\n```tsx\n// page.test.tsx\nimport { test, expect } from \"@playwright/experimental-ct-react\";\nimport App from \"./page\";\n\ntest.use({ viewport: { width: 500, height: 500 } });\n\ntest(\"todosの文字が表示されること\", async ({ mount }) => {\n  // Act\n  const component = await mount(<App />);\n\n  // Assert\n  await expect(component).toContainText(\"todos\");\n});\n\ntest(\"todoを追加したらURLにaddedクエリパラメータが追加されること\", async ({\n  mount,\n  page,\n}) => {\n  // Arrange\n  const component = await mount(<App />);\n  await component.getByRole(\"textbox\").fill(\"My Todo 1\");\n\n  // Act\n  await page.keyboard.press(\"Enter\");\n\n  // Assert\n  expect(page).toHaveURL(/added/);\n});\n```\n\nplaywright-ctでは、コンポーネントに対する操作だけでなく、Playwrightのpageオブジェクトを直接操作することも可能です。\nこれにより、テストのバリエーションが大きく広がり、より多角的なテストシナリオの実行が可能になります。\n\n## まとめ\n\nplaywright-ctは、実際のブラウザ環境により近い形でテストを行うことを可能にし、結合テストの役割を果たします。\nPlaywrightはJestのようなモッキング機能を持たないため、例えば `todo-list.tsx` のハンドラ関数が正しく実行されたかどうかの検証は難しい面があります。\n単体テストレベルの詳細な検証には、依然としてJestのようなツールが必要ですが、画面を構成するコンポーネントのテストには、playwright-ctが非常に役立つと思います。\n今後もこのようなツールを積極的に活用し、品質の高いWebアプリケーションの開発を目指していきたいと考えています。","publishedAt":"2024-03-20","slug":"try-playwright-component-testing","title":"Playwright Component Test を試してみた"},{"body":"TypeScriptを使用している開発者であれば、コードにドキュメントを書いた人もいるかと思います。\nドキュメントに対して、ドキュメントテストというのが書けるらしいです。\nこの記事では、TypeScriptでドキュメントテストを行うためのツールをいくつか紹介します。\n\nサンプルコードは、以下にあります。\n\n[https://github.com/silverbirder/playground](https://github.com/silverbirder/playground/tree/main/node/doctest-sample-app)\n\n## Document Testingとは\n\nドキュメントテストとは、JSDocやTSDocのコメントを利用して、コード上にドキュメントを記述し、\nそのドキュメント内のコードサンプルを実際にテストすることです。\nこのアプローチにより、ドキュメントが常に最新の状態に保たれ、コードの使用方法が正確に反映されるようになります。\nただし、JavaScriptやTypeScript自体にはこの機能が組み込まれていないため、外部のライブラリを使用する必要があります。\nDeno では公式に [Documentation Tests](https://docs.deno.com/runtime/manual/basics/testing/documentation) が用意されているようです。素晴らしいですね。\n\n## 試したツール\n\n私が試したツールは以下の3つです。\n\n- [doctest-ts](https://www.npmjs.com/package/doctest-ts)\n  - コード内のコメントからテストコードを生成し、Jestを使用して実行します。\n    - Jest以外のテストツールも選択可能です\n- [tsdoc-testify](https://www.npmjs.com/package/tsdoc-testify)\n  - TSDocコメントからテストコードを生成し、Nodejsのassertモジュールでテストを実行します。\n- [the-real-doctest](https://www.npmjs.com/package/the-real-doctest)\n  - TSDocコメント内で直接テストを記述し、独自のコマンドでテストを実行します。\n\nまた、[doc-vitest](https://www.npmjs.com/package/the-real-doctest)も魅力的に見えましたが、今回は検証から除外しました。\n\n## 各ツールの使い方\n\n### doctest-ts\n\ndoctest-tsは、特定のフォーマットでコメントにテストケースを記述することで、テストを簡単に追加できます。\nドキュメントは、以下のように書きます。\n\n```ts\n// src/hasFoo.ts\n/** Does this string contain foo, ignoring case?\n\n    hasFoo('___foo__') // => true\n    hasFoo('   fOO  ') // => true\n    hasFoo('Foo.') // => true\n    hasFoo('bar') // => false\n    hasFoo('fo') // => false\n    hasFoo('oo') // => false\n\n*/\nfunction hasFoo(s: string): boolean {\n  return null != s.match(/foo/i);\n}\n```\n\n以下のコマンドを使用してテストファイルを生成し、Jestでテストを実行できます。\n\n```bash\ndoctest-ts --jest src/hasFoo.ts\n```\n\n生成されたテストコードは以下です。\n\n```ts\n/** Does this string contain foo, ignoring case?\n\n    hasFoo('___foo__') // => true\n    hasFoo('   fOO  ') // => true\n    hasFoo('Foo.') // => true\n    hasFoo('bar') // => false\n    hasFoo('fo') // => false\n    hasFoo('oo') // => false\n\n*/\nfunction hasFoo(s: string): boolean {\n  return null != s.match(/foo/i);\n}\n\nimport \"jest\"\nconst __expect: jest.Expect = expect\n\n    describe(\"hasFoo\", () => {\n      it(\"hasFoo\", () => {\n        __expect(hasFoo(\"___foo__\")).toEqual(true)\n        __expect(hasFoo(\"   fOO  \")).toEqual(true)\n        __expect(hasFoo(\"Foo.\")).toEqual(true)\n        __expect(hasFoo(\"bar\")).toEqual(false)\n        __expect(hasFoo(\"fo\")).toEqual(false)\n        __expect(hasFoo(\"oo\")).toEqual(false)})\n    })\n```\n\n### tsdoc-testify\n\ntsdoc-testifyは、TSDocコメント内にテストケースを記述し、Nodeのassertモジュールを使用してテストを実行します。\nドキュメントは、以下のように書きます。\n\n```ts\n// ./src/sub.ts\n/**\n * sub function\n *\n * @remarks\n * demo\n *\n * @example\n *\n * ```\n * import * as assert from \"assert\";\n * import { sub } from \"./sub\";\n *\n * assert.equal(sub(2, 1), 1);\n * ```\n *\n * @example\n *\n * ```\n * import * as assert from \"assert\";\n * import { sub } from \"./sub\";\n *\n * assert.equal(sub(4, 5), -1);\n * ```\n * @param a\n * @param b\n */\nexport function sub(a: number, b: number) {\n  return a - b;\n}\n```\n\nテストケースは以下のコマンドで生成されます。\n\n```bash\ntsdoc-testify --filepath ./src/sub.ts\n```\n\n生成されたテストコードは以下です。\n\n```ts\n// Code generated by \"tsdoc-testify\"; DO NOT EDIT.\n\nimport * as assert from \"assert\";\nimport { sub } from \"./sub\";\ntest(\"/<path_to_app>/src/sub.ts_0\", () => {\n  assert.equal(sub(2, 1), 1);\n});\ntest(\"/<path_to_app>/src/sub.ts_1\", () => {\n  assert.equal(sub(4, 5), -1);\n});\n```\n\n### the-real-doctest\n\nthe-real-doctestは、TSDocコメント内で直接テストを記述し、独自のコマンドを使用してテストを実行します。\nこれはテストコードの生成を省略し、シンプルな比較演算子(`==, !=, === or !==`)を使用してテストを記述できます。\nドキュメントは、以下のように書きます。\n\n```ts\n// ./src/nsum.ts\n/**\n * @param n\n * @returns the sum of the n first integers\n * @example\n * const n = 5\n * const expected = 1 + 2 + 3 + 4 + 5\n * const actual = nsum(n)\n * actual == expected\n * @example nsum(3) == 1 + 2 + 3\n * @example nsum(8) == 36 // This should fail\n */\nfunction nsum(n: number): number {\n  return (n * (n + 1)) / 2;\n}\n```\n\n以下のコマンドで、テストを実行できます。\n\n```bash\nthe-real-doctest test ./src/nsum.ts\n```\n\n## 結論\n\nドキュメントテストは、コードの使用方法を明確に理解し、ドキュメントを最新の状態に保つのに非常に役立ちます。\n開発エディタのコード補完を使えば、コード内部を読まなくても使い方の理解が深まります。\n個人的には、Denoのドキュメントテスト機能が最も興味深いと感じましたが、選択はプロジェクトのニーズや好みによって異なるでしょう。\nドキュメントテストを積極的に利用して、より良いコードベースを目指しましょう！","publishedAt":"2024-03-14","slug":"try-document-testing","title":"Typescript で Document Testing したい"},{"body":"これまで、ブログへのコメントサービスに[Giscus](https://giscus.app/ja)をブログサイトに設置していました。\n本日、同コメントサービスの[Disqus](https://disqus.com/)に切り替えました。\n\nGiscusの場合、GitHubアカウントが必須だったのですが、DisqusならGoogleやXなどのアカウントでも可能となるからです。\nこれで、非エンジニアでもコメントできるようになります！はろー！","publishedAt":"2024-03-13","slug":"install-disqus-on-my-site","title":"Disqusを設置したよ!"},{"body":"私はこれまで、ハードスキルやソフトスキルを鍛えてきました。\n最近、書籍を通じてセルフマネジメントの能力を高めたいと考え始めました。\nそこで、約1ヶ月間 毎朝マインドフルネス瞑想を続けたので、その体験と得られた成果についてここに記します。\n\n## 1ヶ月の瞑想実践\n\n毎朝、仕事を始める前、Spotifyから選んだ以下のマインドフルネス瞑想のトラックに耳を傾けました。\n\n- https://open.spotify.com/show/0ZnS3NDIWsZRxSd8xzvLPJ\n- https://open.spotify.com/show/34w345Ubyl30h8E2QJLqAH\n\nそれぞれ約20分間のセッションで、ソファに座り、静かで落ち着いた環境を整えることからスタート。\nAirPodsを使って外界の音を遮断し、毛布をかけて暖かくしながら、瞑想に集中しました。\n\n瞑想中は、ガイドの指示に従って深呼吸し、\n**「呼吸に集中し、心に浮かぶ雑念を認識したら、それが自然と消え去るのを待つ」というプロセスをひたすら繰り返しました** 。\n仕事やプライベートの様々な考えが頭をよぎりましたが、それらを静かに **認識** し、泡が消えるのを待つように、そのまま放置しました。\n\n## 瞑想から得たこと\n\n瞑想を続けることで、特にストレスが高まる瞬間に、自分の心の動きを早く察知し、感情の波が高まる前に抑えることができるようになったのかなと思います。\nこの変化は、怒りや不安といった感情が湧いた時に特に実感しています。\nたとえば **「今、これで怒ってるんだな」と自分自身で認識する** ことが増え、その **気づきが感情をコントロールする** 上で助けとなりました。\nこの結果、感情に振り回されることなく、目の前のタスクに集中できるようになったと感じています。\n\nもちろん、今後もっと大きな挑戦やストレスがあった時の反応はまだ試されていませんが、\n瞑想によって培ったこの心の平穏を保つスキルをこれからも維持し、さらに深めていきたいと思います。","publishedAt":"2024-03-12","slug":"mindfulness-meditation-beginner","title":"毎朝のマインドフルネス瞑想を1ヶ月間やってみた"},{"body":"## はじめに\n\ntRPCは、型安全なAPIを簡単に構築できるフレームワークです。\n開発中、バックエンドの実装を待たずに、Storybook上でフロントエンドの開発を進めたい場合、\nMock Service Worker (MSW) を使用してAPIのモックを行うことができます。\nこの記事では、[maloguertin/msw-trpc](https://github.com/maloguertin/msw-trpc) を用いて、tRPC通信をMSWでモックする方法について解説します。\n実用例として、サンプルコードをGitHubリポジトリ [silverbirder/trpc-msw-storybook-nextjs](https://github.com/silverbirder/trpc-msw-storybook-nextjs.git) で共有しています。\n\n## 技術スタック\n\nまずは、使用するライブラリを紹介します。\n`package.json` には以下のような依存関係が記載されています。(一部抜粋しています)\n\n```json\n{\n  \"dependencies\": {\n    \"@tanstack/react-query\": \"^4.36.1\",\n    \"@trpc/client\": \"^10.45.1\",\n    \"@trpc/next\": \"^10.45.1\",\n    \"@trpc/react-query\": \"^10.45.1\",\n    \"@trpc/server\": \"^10.45.1\",\n    \"next\": \"^14.1.0\",\n    \"react\": \"18.2.0\"\n  },\n  \"devDependencies\": {\n    \"@storybook/nextjs\": \"^7.6.17\",\n    \"@storybook/react\": \"^7.6.17\",\n    \"msw\": \"^2.2.2\",\n    \"msw-storybook-addon\": \"^2.0.0--canary.122.b3ed3b1.0\",\n    \"msw-trpc\": \"^2.0.0-beta.0\",\n    \"storybook\": \"^7.6.17\"\n  }\n}\n```\n\n## 準備\n\nプロジェクトの雛形を作成するため、以下のコマンドを実行します。\n\n```bash\nnpm create t3-app@latest\nnpx storybook@latest init\nnpm i msw\nnpx msw init ./public --save\n```\n\nこれにより、tRPCとMSWを統合する基本的なセットアップが整います。\n\n## サンプルコンポーネント\n\n次に、サンプルとして使用するコンポーネントは以下です。\nt3-appで生成されたコンポーネントで、一部アレンジしています。\n\n```tsx\n// ~/app/_components/create-post.tsx\n\"use client\";\n\nimport { useState } from \"react\";\n\nimport { api } from \"~/trpc/react\";\n\nexport function CreatePost() {\n  const [name, setName] = useState(\"\");\n  const [postName, setPostName] = useState(\"\");\n\n  const createPost = api.post.create.useMutation({\n    onSuccess: ({name}) => {\n      setName(\"\");\n      setPostName(name);\n    },\n  });\n\n  return (\n    <form\n      onSubmit={(e) => {\n        e.preventDefault();\n        createPost.mutate({ name });\n      }}\n      className=\"flex flex-col gap-2\"\n    >\n      <input\n        type=\"text\"\n        placeholder=\"Title\"\n        value={name}\n        onChange={(e) => setName(e.target.value)}\n        className=\"w-full rounded-full px-4 py-2 text-black\"\n      />\n      <button\n        type=\"submit\"\n        className=\"rounded-full bg-white/10 px-10 py-3 font-semibold transition hover:bg-white/20\"\n        disabled={createPost.isLoading}\n      >\n        {createPost.isLoading ? \"Submitting...\" : \"Submit\"}\n      </button>\n      <div>{postName}</div>\n    </form>\n  );\n}\n```\n\n`api.post.create.useMutation` を用いてtRPCでデータの送信を行なっています。\n\n## MSWとtRPCの統合\n\nMSWとtRPCを統合するには、まず[maloguertin/msw-trpc](https://github.com/maloguertin/msw-trpc)パッケージをインストールします。\n\n```bash\nnpm i msw-trpc --save-dev\n```\n\nそして、MSWとtRPCの統合コードは `~/trpc/msw.tsx` に配置し、以下のように記述します。\n\n```tsx\n// ~/trpc/msw.tsx\n\"use client\";\n\nimport { useState } from \"react\";\nimport { createTRPCMsw } from \"msw-trpc\";\nimport { httpLink } from \"@trpc/client\";\nimport { createTRPCReact } from \"@trpc/react-query\";\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { getUrl, transformer } from \"./shared\";\nimport type { AppRouter } from \"~/server/api/root\";\n\nexport const trpcMsw = createTRPCMsw<AppRouter>({\n  baseUrl: getUrl(),\n  transformer: { input: transformer, output: transformer },\n});\n\nexport const api = createTRPCReact<AppRouter>();\n\nexport const TRPCReactProvider = (props: { children: React.ReactNode }) => {\n  const [queryClient] = useState(() => new QueryClient());\n  const [trpcClient] = useState(() =>\n    api.createClient({\n      transformer,\n      links: [\n        httpLink({\n          url: getUrl(),\n          headers() {\n            return {\n              \"content-type\": \"application/json\",\n            };\n          },\n        }),\n      ],\n    }),\n  );\n\n  return (\n    <QueryClientProvider client={queryClient}>\n      <api.Provider client={trpcClient} queryClient={queryClient}>\n        {props.children}\n      </api.Provider>\n    </QueryClientProvider>\n  );\n};\n```\n\n`trpcMsw` は MSWのハンドラで使用します。\n詳しくは、[maloguertin/msw-trpc](https://github.com/maloguertin/msw-trpc) の `createTRPCMsw` をご確認ください。\ncreateTRPCMsw の引数が最初分からなかったので、困りました。\n`TRPCReactProvider` は tRPCのプロバイダのMSW用です。\n\n## MSWとStorybookの統合\n\nMSWをStorybookで動かすためには、[mswjs/msw-storybook-addon](https://github.com/mswjs/msw-storybook-addon) を使います。\nインストールは、以下のコマンドを実行します。\n\n```bash\nnpm i msw-storybook-addon --save-dev\n```\n\n※ 諸事情により、`msw-storybook-addon@2.0.0--canary.122.b3ed3b1.0` を指定しています。\n\nStorybookでの表示を設定するには、`.storybook/preview.tsx` を以下のように設定します。\n\n```tsx\n// /.storybook/preview.tsx\nimport React from \"react\";\nimport type { Preview } from \"@storybook/react\";\nimport { initialize, mswLoader } from \"msw-storybook-addon\";\nimport { TRPCReactProvider } from \"../src/trpc/msw\";\ninitialize();\n\nconst preview: Preview = {\n  parameters: {\n    actions: { argTypesRegex: \"^on[A-Z].*\" },\n    controls: {\n      matchers: {\n        color: /(background|color)$/i,\n        date: /Date$/i,\n      },\n    },\n  },\n  loaders: [mswLoader],\n  decorators: [\n    (Story) => (\n      <TRPCReactProvider>\n        <Story />\n      </TRPCReactProvider>\n    ),\n  ],\n};\n\nexport default preview;\n```\n\ndecorators に `TRPCReactProvider` で包みます。\nこれにより、Storybook内でtRPCの通信をMSWでモックできるようになります。\n\n## Storybookのstoriesファイル\n\n最後に、Storybookのstoriesファイルは、以下のように定義します。\n\n```tsx\n// ~/app/_components/create-post.stories.tsx\nimport type { Meta, StoryObj } from '@storybook/react';\n\nimport { CreatePost } from './create-post';\nimport { trpcMsw } from '~/trpc/msw';\n\nconst meta = {\n  title: 'create-post',\n  component: CreatePost,\n  parameters: {\n    layout: 'centered',\n  },\n  tags: ['autodocs'],\n  argTypes: {\n    backgroundColor: { control: 'color' },\n  },\n} satisfies Meta<typeof CreatePost>;\n\nexport default meta;\ntype Story = StoryObj<typeof meta>;\n\nexport const Main: Story = {\n  parameters: {\n    msw: {\n      handlers: [\n        trpcMsw.post.create.mutation(({name}) => {\n          const post = { id: 1, name: name };\n          return post;\n        })\n      ],\n    },\n  }\n};\n```\n\n`parameters.switch.handlers` に、tRPCのmutationをMSWでモックしています。\nこれで、`npm run storybook` を実行すると、tRPCのモックが反映されたUIを確認できます。\n\n## 終わりに\n\nこの記事を通して、読者のお役に立てれば幸いです。","publishedAt":"2024-03-07","slug":"trpc-msw-mocking","title":"Storybook上で tRPC通信をMSWでモックする方法"},{"body":"ペーパードライバーだった私が新車を購入し、4ヶ月が経過しました。\n最初は不安でいっぱいでしたが、今ではドライブを一週間の楽しみとしています。\nその変化に至る過程を紹介します。\n\n## 2023年8月 - 車を持つ夢\n\n家庭の用事で静岡県を訪れる機会がありました。\n静岡は車無しでは生活が難しい地域で、友人のおかげで車での移動の自由さと便利さを実感しました。\n彼らが連れて行ってくれたショッピングモール、オシャレなカフェ、賑やかな市場など、\n車があれば手軽に訪れることができる様々な場所を体験しました。\n\nこれらの経験から、自分自身で運転し、どこへでも行ける自由を手に入れたいと強く感じ、\n車を購入する決心を固めました。\n\n## 2023年9月 - 車選びを、父をお供に\n\n車に関する知識がまったくない私にとって、高額な車の購入は大きな不安でした。\nそこで、車に詳しい父と一緒に車屋さん(ディーラー)を訪れ、軽自動車を選びに行きました。\n\n様々なディーラーを回り、営業担当者と話をする中で、父のアドバイスを借りながら、\nペーパードライバーの私にも安全で運転しやすい車を選びました。\n\n父はしばしば営業担当者に「もう少し勉強してくれませんか」と交渉しているのを耳にしました。\nこの一言が実は値引き交渉の一環だったことを後に知り、驚きました。(勉強ってなんだよ!)\n\n最終的には、マイナーチェンジ前の新車、日産を選び、\n約20〜30万円の割引を受けることができました。\n\n## 2023年10月 - 納車と準備\n\n納車日に向けて駐車場の手配、任意保険の契約、ETCカードの準備をしました。\n運転技術に自信をつけるためにも、出張運転講習を受講し、さらには父と共に運転練習を重ねました。\n教習所で習ったか記憶がないのですが、ハザードランプの使うタイミングを初めて知りました。\n\nMT免許を持っていた私にとって、AT車の操作は比較的簡単でしたが、車庫入れの技術だけは苦手意識がありました。\nそこで、YouTubeを活用して車庫入れのコツを学ぶなど、自宅でできる学習も積極的に行いました。\nまた、標識や交通ルールの知識も改めて学習し直しました。\n\nこれらの準備と練習のおかげで、ついに納車日には自信を持ってディーラーから\n自宅近くの駐車場まで車を運転することができました。\n\n## 2023年11月 - 運転への自信を育む\n\n妻を助手席に座らせ、運転の範囲を徐々に広げていきました。\nまずは近距離からスタートし、雨天時の運転、夜間の運転、そして最終的には一人でのドライブにも挑戦しました。\nこれらの経験が、運転に対する自信を深めてくれました。\n\n全く車がない駐車場で、1時間ほど車庫入れの練習をしたことは内緒です。\n\nこれらの一歩一歩が積み重なり、ついには一人でも安心して車を運転し、\n行動範囲を大きく広げることができるようになりました。\n\n## 2023年12月 - ドライブの日々\n\n運転に対する自信が深まるにつれ、様々な目的地へのドライブを楽しむようになりました。\n大型ショッピングモール、公共交通機関ではアクセスしにくいカフェや病院、天然温泉、そして広大なDIY店など、多岐にわたります。\n当初は広々とした立体駐車場を選んでいましたが、やがては狭いスペースにもスムーズに車を停めることができるようになりました。\n\n特に週末は、時間を見つけては車での外出を楽しんでいます。\nその中で、予期せぬ状況に遭遇するヒヤリハットも数回ありましたが、\n「悩んだら待つ」という重要な教訓を学びました。\n\n自信がつくにつれて、車用品のコレクションも増えていきました。\n充電器、三角表示板、清掃用具、お守り、クッション、消臭剤など、ドライブをより快適かつ安全にするアイテムを揃えました。\n\n## 2024年1月 - 再び静岡へ\n\nまた、静岡県に訪れる機会がありました。\nしかし、雪の中の運転は避けたいと感じ、静岡県へは新幹線を利用しました。\n前回の訪問時よりもさらに増して『いつか静岡県へ車で行きたいな!』と強く感じました。\n\n## 2024年2月 - 新たな挑戦\n\n遠出への憧れが強くなり、滋賀県や愛知県、和歌山県などへの旅行を計画しています。\nまだ高速道路の運転をペーパードライバー以来経験していないので、練習したいなと思います。\n短い距離で交通量が少ない高速道路を選んでいこうと思います。\n\n## 終わりに\n\n振り返れば、もっと早く車を購入しておけばよかったと思います。今では、車が私の生活に欠かせない楽しみとなっています。\nいつかは、静岡県へ行くぞ！","publishedAt":"2024-02-22","slug":"from-paper-driver-to-road-adventures","title":"ペーパードライバーはドライブを楽しみに"},{"body":"これまで、デザイナーの方々が作成した素晴らしい Figma の成果物を参考にしながら、Web フロントエンドの実装を行ってきました。\n何度もこれを経験するうちに、私も Figma を使いこなせるようになりたいと思うようになりました。\n\n## CSS フレームワークへの依存\n\nこれまでの個人開発においては、Bootstrap や Material UI などの CSS フレームワークを利用して、見た目が整った Web アプリケーションを開発していました。\n「Bootstrap っぽさが強すぎる」と感じることもしばしばありました。しかし、オリジナリティ溢れる Web の見た目を良くする方法を知らなかったのです。\n数年前からは Tailwind CSS がトレンドとなり、より自由なスタイリングを目指したくなりました。\nさらに、業務で Figma を使ったデザインから React のコードに落とし込む作業が増え、自らスタイリングを行うことが多くなりました。\nそれが、Figma を自分で使いたいと思うようになったきっかけです。\n\n## コンセプトの策定\n\nいきなり Figma を開始するのではなく、まずは描きたい Web アプリの目的やターゲット、解決したい問題などを大まかに考えました。\n私が個人開発している「[bochi bochi](https://bochi-bochi.vercel.app/)」という食材価格比較サービスを例に、これらを思考しました。\n\n## デザインシステムの参照\n\nコンセプトがある程度固まったら、デジタル庁のデザインシステムを参考にしました。\nタイポグラフィ、カラー、スペーシングなどの基本的なスタイルから、ボタンやテキストフィールドなどのコンポーネントまで、使えそうなものを参考にします。\n\n## Figma の使い方を学ぶ\n\nプロジェクトを Figma で開始した際、最初は PC やタブレットのレスポンシブデザインを考慮せず、\nスマートフォン向けのデザインに焦点を当てました。\nFigma の操作には当初苦労しましたが、繰り返し使用することで徐々に機能への理解が深まりました。\n特に、スタイルやコンポーネントの定義と再利用の便利さを実感しました。\n中でも Auto Layout 機能は格別で、その使い勝手の良さから頻繁に利用しています。\n\n## 実際にデザインを行う\n\n実際にデザイン作業を行い、デザインの前後で大きな変化を実感しました。\n以前 Figma を使っていた時は、基本的な形状を積み重ねたり、手書きでラフなスケッチをする程度でした。\nしかし、現在はより構造化された、ちゃんとしたデザインが作成できるようになったと感じています。\n\n以下は、Figma を使わずに実装した[bochi bochi](https://bochi-bochi.vercel.app/)の見た目です。\n\n![Before bochi bochi](http://res.cloudinary.com/silverbirder/image/upload/v1708087927/sfejkucd37ran72ljhp7.png)\n\nそして、この数日間で取り組んだ Figma を使用した[bochi bochi](https://bochi-bochi.vercel.app/)の新しいデザインです。\n\n![After bochi bochi](http://res.cloudinary.com/silverbirder/image/upload/v1708087929/v5kdg2iiuz5zsizam0h1.png)\n\nどちらが優れているかは一概には言えませんが、個人的には新しいデザインに満足しています。\n\n## まとめ\n\nこれからは、Figma で作成したデザインを React のコードに落とし込み、既に稼働している[bochi bochi](https://bochi-bochi.vercel.app/)にデザイン適用していく予定です。\nFigma との出会いは、私の開発スキルに新たな一歩を加えました。","publishedAt":"2024-02-16","slug":"becoming-friends-with-figma","title":"Figmaと仲良くなる"},{"body":"ショッピングモールに車で行った際、駐車場の料金が入庫から 1 時間まで無料だったのですが、「いつ入庫したんだっけ？」と記憶があいまいになったことがありました。そんな時、Google Map のタイムラインを見ると、正確に何時何分に到着したかが分かり、本当に便利だと感じました。\n\nまた、外食をした後にその場所の口コミを書こうと思った際、食事の写真は撮っているものの、「このお店の名前が何だったか？」となることがあります。そんな時も、Google Map のタイムラインを参照すると、訪れたお店の名前を確認できることがあり、とても役立ちます。\n\nこれらの経験から、Google Map のタイムライン機能は日常生活で非常に便利なツールであると実感しました。忘れがちな細かな情報もこれで解決できます。ぜひ試してみてください。\n\n以上、ちょっとした豆知識を共有させていただきました。","publishedAt":"2024-02-11","slug":"tips-google-maps-timeline","title":"Google Map タイムラインの便利さ"},{"body":"「ここのスーパーの白菜はちょっと高いかな。他に安いところはないのかな？」そんな日常の小さな疑問から、スーパーごとの食材価格を手軽に比較できる Web アプリ「ぼちぼち」を開発しました。\n\n![bochi-bochi top page](http://res.cloudinary.com/silverbirder/image/upload/v1707573620/akdswcwwxatnfemrbo4e.png)\n\nhttps://bochi-bochi.vercel.app\n\n## アプリの使い方\n\nトップページから、**スーパーを探す**をクリックします。\n\n![bochi-bochi search page](http://res.cloudinary.com/silverbirder/image/upload/v1707574240/z3li36nol50hxlvcvrha.png)\n\n次に、スーパーを探す手段を選びます。例えば、**現在地から探す**をクリックします。\n現在地を公開したくないので、ここからは画像を割愛します。\n\n近所のスーパーの一覧が Google Map で表示されます。\nまた、画面下部に食材が表示されます。表示された食材をクリックすると、**どのスーパーで安く買えるかが一目瞭然**になります。\n表示される食材は、スーパーに食材が登録されている場合に限ります。\n\n※ スーパーの食材は、一度だけ AI によるスクレイピングでデータ登録されます。\n\n### 作った結果\n\n私の妻はこのアプリを利用してから、「白菜はここのスーパーが安いね」「ひき肉はあそこのスーパーだね」と言って、**満足しながら買い物を楽しんでいます**。\n買い物後のレシートを使って、食材の価格情報を簡単にアプリに登録する機能も備えています。\nまた、AI 技術を活用してスーパーの食材データを自動で収集・登録する仕組みを構築しています。\nスーパーの検索・表示には Google Map を活用しており、[無料枠](https://mapsplatform.google.com/intl/ja/pricing/)をうまく使うことで、コストを抑えつつスーパーの情報を取得しています。\n\n## 全ての食材が安いスーパー\n\nしかしこのアプリを利用していたある日に、近所に「全ての食材が安いスーパー」ができました。\nそのため、ほとんどの買い物をそこでするようになりました。\n結果、アプリ自体の利用頻度は少なくなりました。(笑)\n\n## 開発備忘録\n\n### OpenAI 話\n\nOpenAI をシステムに組み込む際、全プロセスを一括で行うよりも、段階的に処理を分けることで精度が向上しました。\n具体的には、レシート画像から構造化データを作成するプロセスにおいて、最初に OCR を用いて画像からテキストを抽出し、\nその後抽出したテキストを OpenAI で分析する方法が効果的であることがわかりました。\nまた、指示をシンプルに保つことで、より高精度な結果を得られました。\n例えば、「商品名が商品カテゴリに属するか否か」という明確な問いにすることで、分析の精度が向上しました。\n\n### 使用した技術スタック\n\n開発には以下の技術スタックを使用しました。\n\n- Web フレームワーク\n  - Next.js\n- API\n  - tRPC\n- データベース\n  - PlanetScale\n  - Prisma\n- UI\n  - @tremor/react\n- 状態管理\n  - jotai\n- 地図関連\n  - @vis.gl/react-google-maps\n  - Google Places API\n- レシートデータ抽出\n  - Google Cloud Vision\n  - OpenAI\n- スクレイピング\n  - Crawlee\n  - Cloud Run Jobs\n  - OpenAI\n\n開発中、妻からの直接的なフィードバックを通じて、アプリの方向性を確認しながら進めることができ、これが非常に楽しい経験となりました。\nUI/UX デザインについてはまだ改善の余地がありますが、現時点では個人利用を目的としているため、このまま使用を続ける予定です。\n\n## 終わりに\n\n最後に、私は最近 Bluesky に登録しました。もし興味があれば、ぜひフォローしてください。\n\nhttps://bsky.app/profile/silverbirder.bsky.social","publishedAt":"2024-02-10","slug":"bochi-bochi-app-development","title":"手軽に安い食材を見つけられるアプリ「ぼちぼち」を開発"},{"body":"急に寒くなりましたね。\nわずか一週間前までは半袖で過ごせたのに、今では暖房が必要不可欠です。\nもう 11 月も半ばを迎え、今年も残りわずかとなりました。そこで、2023 年を振り返ってみたいと思います。\n\n## はじめての新幹線通勤\n\n名古屋拠点での新しい挑戦を望み、社内異動制度を利用して名古屋へ異動しました。\n私の住まいは関西にあるため、新幹線での通勤となりました。\n当時は新幹線の駅に近くに住んでおり、Door to Door で約 1 時間かかりました。\n\n新幹線なんて、滅多に乗らないので、めちゃくちゃ新鮮でした。\n諸事情により、乗車賃を安く済ませる必要があったので、ぷらっとこだま というサービスを利用していました。\nそのサービスの 1 つに、ドリンク 1 本無料券が付いていたので、毎回 みっくちゅじゅーちゅを購入していました。(美味しいんだよなぁ)\n\n[![みっくちゅじゅーじゅ](http://res.cloudinary.com/silverbirder/image/upload/v1699959939/gbuf2gtdwndgmphqocfg.jpg)](https://amzn.to/476G9FI)\n\n車内では、外の景色を眺めたり、考えを整理したりしていました。\nしかし、残念ながらシンカンセンスゴイカタイアイスは車内販売されていませんでした。\n\n名古屋への通勤は人生で初めての経験であり、地元の名物を試すのも楽しみの一つでした。\n初期の頃は、毎回お土産を購入して帰宅していました。\n\n名古屋拠点のチームメンバーは、人柄が良く技術力も高い素晴らしい人たちでした。\n能力の高い個々人が、足りない部分を互いに補い合いながら協力していました。\n合宿や飲み会を通じて、たわいもないことを楽しく話して、懐かしく感じました。\nBUCYO Coffee へまた訪れたいなと思っています...!\n\n[![BUCHO Coffee](http://res.cloudinary.com/silverbirder/image/upload/v1699960292/rtx71dlqvpliatnolzi4.jpg)](https://www.bucyocoffee.com/)\n\n## 一戸建てを手に入れた\n\n子供の頃に住んでいた実家の近く、わずか徒歩 5 歩の距離にある祖父母の中古の家を譲り受けることになりました。\n\n家賃が不要になり、固定資産税も年間で数万円程度ということで、大幅な節約が可能になりました。\nただし、やや田舎に位置するため、車がないと移動が不便な点はあり、電動自転車での移動が日常になりました。\n\n家がある場所には子供の頃の記憶が溢れており、懐かしさに浸ることができました。\n近所の方々との会話が増え、昔話の話題で盛り上がることもしばしばです。\n（私が昔、ご近所の庭の柵を登ってしまったことも...ごめんなさい！）\n\n![わんちゃんのひなたぼっこ](http://res.cloudinary.com/silverbirder/image/upload/v1699960580/xsg40dsgcter43wk5zhs.jpg)\n\n古い家特有の問題もあり、夏は暑く冬は寒いです。\nさらに、ゴキブリや蜘蛛、蚊などの虫が家内で出没するため、家中に虫除けスプレーが常備されています。（笑）\n\n地元には、昔の友達が都会へ出てしまい、高齢者が多くなっています。\nしかし、私の姉夫婦や妻の親戚などと仲良く過ごしており、ゲームを楽しんだり、美味しいものを食べに行ったりすることで、充実した時間を過ごしています。\n\n## はじめてのフリーランス\n\n多くの変化を経て、正社員を辞め、フリーランスとしてのキャリアをスタートしました。\nフリーランスとしては、働く時間や曜日を自由に選べるようになり、週 3 日働き、残りの時間は趣味や家事に充てています。\n\n[![USJへ遊びに行ってきた!](http://res.cloudinary.com/silverbirder/image/upload/v1699966272/ucwcjvsz6sizs6cubuoq.jpg)](https://www.usj.co.jp/)\n\n「Findy」という転職サービスを経由して「Findy Freelance」に登録し、そこから案件を得ることができました。\n複数の企業との面談を経て、無事に働き始めることができました。\nまた、フリーランスとして必要な知識や手続きについても詳しく教えてもらい、非常に感謝しています。\n\nFindy ではユーザーサクセス面談というサービスも利用し、約 5 ヶ月間、不定期に面談を行いました。\nこれにより客観的なアドバイスを受け、自己分析や自分の強みや弱みを深く理解することができました。\n\nフリーランスになって初めて直面したのは、健康保険や国民年金の手続きの面倒さでした。\n正社員時代は意識していなかったこれらの事項を自分で管理することになり、また税の控除や開業届、青色申告などについても調べる必要がありました。\n\n正社員時代には会社が行ってくれていたことを自分で行う必要があるため、その便利さを再認識しました。\nそれでも、新しい責任や業務を自分でこなすことで、個人としての成長を感じています。\n\nフリーランスとして様々な企業で働くことで、新しい技術や知識を得ることができるのは非常に魅力的です。\n異なる企業の設計技術を学ぶことで、新たな発見や学びが豊富にあります。\n様々な場所で働くことの魅力を改めて実感しています。\n\nちなみに、今年の 12 月には正社員としての転職を果たしました。\n宅食サービス会社で週 5 日出社することになります。\nリモートワーク経験を経て、出社が自分に合っていると感じていました。\n関西では出社できる企業が限られているため、この機会は貴重です。\nまた、過去に一緒に働いた尊敬する方がいるため、新しい職場での安心感もあります。\n\n## はじめての車購入\n\n車を購入したきっかけは、夏に静岡の妻の実家に帰省した時でした。\nその地域は車社会で、常に妻の家族に車で送ってもらう状況で、自分も運転したいと思い始めました。\n大学生の頃に取得した免許は使っておらず、ゴールドのペーパードライバーでした。\n\n[![げんこつハンバーグ](http://res.cloudinary.com/silverbirder/image/upload/v1699966849/hyzq4xs08db9wvzyqaqm.jpg)](https://www.genkotsu-hb.com/)\n\n車選びは父と一緒にいくつかのディーラーを訪れ、父と共に試乗しました。\n父が熱心に値段交渉をしてくれたおかげで、20 万円近く値引きしてもらうことができました。(父が『勉強してくれ』と言っていた意味は、値引きだったようだ)\n結果、新車の軽自動車を購入できました！！\n\n[![まいにゅーかー！](http://res.cloudinary.com/silverbirder/image/upload/v1699961973/bsbvrbok9wi1opctlwqg.png)](https://www3.nissan.co.jp/vehicles/new/dayz.html)\n\n運転に自信がなかったため、ペーパードライバー講習を 1 回受け、その後は納車まで父の車で練習を続けました。\nおかげで、今ではドライブが楽しみの一つになりました。行動範囲が広がり、子供の頃に行けなかった場所に妻と一緒にドライブしています。\nまだ駐車には苦労していますが、パーキングアシストを活用しながら少しずつ上達しています。\n\n## 来年の抱負\n\n今年も多くの出来事がありましたが、来年はどのような年になるのか楽しみです。\n新しい職場に慣れ、ゆっくりと仕事を進めながら、家でのんびりとした時間を過ごしたいと思います。\n\nコロナ禍の影響で海外旅行を避けてきましたが、来年は海外に行ってみたいなと思っています。\nまた、運転スキルを向上させ、遠出するのも楽しみにしています。\n\n子供が授かれれば嬉しいですが、現在の環境でも十分幸せなので、無理せず進めていきたいと思います。\n技術面では、作りたいものがいくつかあるので、それを実現し、ブログも時々更新していきたいです。\nまた、ISTQB や JSTQB のような資格の取得も良いかもなと思っています。\n\n## 終わりに\n\n以上、最後まで読んでいただき、ありがとうございました。","publishedAt":"2023-11-14","slug":"2023_furikaeri","title":"2023年の振り返り。家と車と私"},{"body":"Web アプリケーション開発において、自動化テストは不可欠です。\n特にリリース前の E2E テストの重要性は高いでしょう。\n今回、 BDD で有名な Cucumber と Screenplay 設計を取り入れた経験を紹介します。\n\n## テスト設計のアプローチ\n\nまず、E2E テスト設計には複数のアプローチが存在すると思います。\n\n- **ユーザーストーリーに基づくテスト**\n  - アジャイル開発で使用され、ユーザーの視点を反映した要件記述に基づいてテストを設計します。\n- **ビジネス要件に基づくテスト**\n  - ビジネスの目的や要求を直接反映したテストをデザインし、ビジネスの価値と目標に焦点を当てます。\n- **シナリオテスト**\n  - 実世界の業務プロセスやユーザーシナリオを模倣したテストケースを用いて、システムの振る舞いを評価します。\n\n私はこれまで、Web 業界におけるアジャイル開発での開発経験が多いです。\nプロダクトマネージャーやその他の非開発者ビジネスサイドのメンバーと協業する際、1 番目のユーザーストーリーを決めてテスト設計することが多いです。\nそのため今回、1 番目のアプローチを想定します。\n\n次に、ユーザーストーリーからテストケースを作成するのはどの段階でしょうか。\nシフトレフトの考え方で、実装段階よりも前の段階で行う方が改修コストやリリース遅れなどのリスクを低減できます。\nそこで、以下のようなアプローチを取ります。\n\n- **受け入れテスト駆動開発(ATDD)**\n  - 開発前に受け入れ基準を定義し、それを満たすテストケースを作成してから開発を進めるアプローチです。\n\n開発前に達成したいユーザーストーリーと、それを満たすテストケースを作成します。ここの作業は、ビジネスサイドのメンバーと協業します。\nテストケースのフォーマットは、Given-When-Then で表現する Gherkin 形式を採用します。\n\n- **振る舞い駆動開発(BDD)**\n  - 「Given-When-Then」形式の振る舞いシナリオを用いて、システムの振る舞いを定義し、それに基づいてテストケースを作成します。\n\nテストツールとして、Gherkin を読み込みテストを実行できる Cucumber を使います。\n\nhttps://cucumber.io/\n\n### 例 Gherkin 形式のシナリオ\n\n例えば、オンラインストアでの商品を見つけるユーザーストーリーに関して、以下のようなシナリオを想定します。\n\n```gherkin\n## online-store.feature\n\nFeature: Online Store\n\n  Scenario: customer finds product by name\n\n## - Apisitt, responsible for setting up test data using the REST API\n## - Wendy, representing a customer interacting with the web UI\n\n    Given Apisitt sets up product catalogue with:\n      | name    | price |\n      | Apples  | £2.50 |\n    When Wendy looks for 'Apples'\n    Then she should see top search result of:\n      | name  | Apples |\n      | price | £2.50  |\n```\n\n※ [Screenplay Pattern - serenity-js.org](https://serenity-js.org/handbook/design/screenplay-pattern/) より引用\n\nこのシナリオは、Gherkin 形式で書いています。\nファイル名は `*.feature` となります。Markdown でも記述できます。\n\nhttps://github.com/cucumber/gherkin/blob/main/MARKDOWN_WITH_GHERKIN.md\n\nさらに、シナリオを日本語で書くこともできます。\n\nhttps://cucumber.io/docs/gherkin/languages/\n\nその他、Gherkin の書き方やプラクティスついて、以下を参照してください。\n\nhttps://cucumber.io/docs/gherkin/\n\n次に、シナリオを満たすテストを書きましょう。以下が、シナリオを満たすテストコードです。\n先のシナリオの Given、When、Then が、以下のテストコードに対応してます。(Actor は無視して良いです)\n\n```ts\n// online-store.steps.ts\n\nimport { Given, When, Then, DataTable } from \"@cucumber/cucumber\";\nimport { Actor } from \"@serenity-js/core\";\n\nGiven(\n  \"{actor} sets up product catalogue with:\",\n  (actor: Actor, products: DataTable) => actor.attemptsTo()\n);\n\nWhen(\"{actor} looks for {string}\", (actor: Actor, productName: string) =>\n  actor.attemptsTo()\n);\n\nThen(\n  \"{pronoun} should see top search result of\",\n  (actor: Actor, expectedResult: string) => actor.attemptsTo()\n);\n```\n\nテストを実行するには、以下のコマンドで実行できます。\n\n```sh\nnpx cucumber-js\n```\n\nこちらのテストが成功すれば、online-store.feature の機能が担保していることが分かります。\nつまり、受け入れ可能となり、リリース可能となります。\n\n## テスト実装\n\nそれでは、テストを実装しましょう。\nテストの実装方法には、以下のようなものがあります。\n\n- **ページオブジェクトモデル**\n  - ウェブアプリケーションの各ページをオブジェクトとしてモデル化し、UI テストのメンテナンスと再利用性を向上させるデザインパターン。\n- **キーワード駆動テスト**\n  - キーワード（アクションや操作）を用いてテストスクリプトを記述し、非技術者でも理解しやすく、メンテナンスしやすいテストを実現する方法。\n- **Screenplay**\n  - 「アクター」と「タスク」に基づいてテストシナリオをモデル化し、テストの可読性と柔軟性を向上させるデザインパターン。\n\nScreenplay は、ユーザーストーリーに基づくテストとの相性が良いと思い、今回試してみました。\n\n### ライブラリ選定\n\nScreenplay 設計を試す場合、以下の候補がありました。\n\n- [Tallyb/cucumber-playwright](https://github.com/Tallyb/cucumber-playwright)\n- [cucumber/screenplay.js](https://github.com/cucumber/screenplay.js)\n- [serenity-js/serenity-js](https://github.com/serenity-js/serenity-js)\n\n個人的な好みで、E2E テストは Playwright を使いたかったので、[cucumber/screenplay.js](https://github.com/cucumber/screenplay.js) を除外しました。\nまた、Screenplay という設計手法を取り入れるだけであれば、[Tallyb/cucumber-playwright](https://github.com/Tallyb/cucumber-playwright) でも良かったのですが、以下の点で困ったので除外しました。\n\n- Screenplay の五つの要素(後述します)を自身で実装する必要がある。\n- 各シナリオごとに Actor を管理する必要が生じる。\n\nそこで、Screenplay 設計に必要な要素が実装されている [serenity-js/serenity-js](https://github.com/serenity-js/serenity-js) を採用しました。\n\n## Screenplay とは\n\nScreenplay とは、[Screenplay Pattern - serenity-js.org](https://serenity-js.org/handbook/design/screenplay-pattern/) より要約すると、以下のようなものです。\n\n---\n\nScreenplay パターンは、ビジネスの用語をテストシナリオに取り入れ、抽象化の層を効果的に使用することで、高品質な自動受け入れテストを書くためのユーザー中心のアプローチです。\nこのパターンは、アクターとその目標に焦点を当て、ドメイン言語を使用することで、技術者とビジネス関係者の間の協力と理解を促進します。\n\n---\n\n私が Screenplay パターンを良いなと思ったのは、以下の点です。\n\n- ユーザー中心のアプローチ\n  - Actor というユーザーを中心に、テストを設計できる点\n- 技術者とビジネス関係者の協力と理解を促進\n  - feature ファイルをビジネスサイドのメンバーと協業して作成できる点\n- 抽象化の層がある\n  - タスク(後述します) を再利用することで、テストのメンテナンス性を向上できる\n\n### Screenplay における 5 つの要素\n\nScreenplay には、以下の 5 つの要素が存在します。\n\n[![Five elements of the Screenplay Pattern - https://serenity-js.org](https://res.cloudinary.com/silverbirder/image/upload/v1699704842/silver-birder.github.io/blog/serenity-js-screenplay-pattern.5eead28.1200.png)](https://serenity-js.org/handbook/design/screenplay-pattern/)\n\n5 つの要素について紹介します。\n\n- Actor\n  - テスト対象のシステムとやりとりする人や外部システムを表します。\n  - 例\n    - ユーザー\n    - API\n- Ability\n  - テスト対象のシステムとのインタラクションに必要な統合ライブラリを簡易に扱うためのものです。\n  - 例\n    - Web ページにアクセスする能力\n      - ブラウザ操作するためのライブラリ(Playwright など)をラップしたもの\n    - API リクエストを送信する能力\n      - API リクエストを送信するためのライブラリ(axios など)をラップしたもの\n- Interaction\n  - アクターが特定のインターフェースを使用して行うことができる低レベルの活動を表します。\n  - 例\n    - ログインする\n      - ログインフォームにユーザー名とパスワードを入力し、ログインボタンをクリックする\n    - 商品をカートに追加する\n      - 商品ページにアクセスし、商品をカートに追加する\n- Task\n  - ドメイン内のビジネスワークフローを意味のあるステップとしてモデル化するために使用されます。\n  - 例\n    - オンラインで商品を購入する\n      - ログインする\n      - 商品をカートに追加する\n      - 購入する\n- Question\n  - テスト対象のシステムやテスト実行環境から情報を取得するために使用されます。\n  - 例\n    - 現在のアカウント残高は？\n      - ユーザーのアカウント残高を取得する\n\nまた、serenity-js では、Note と呼ばれる Actor が情報を記憶できる要素もあります。\n\nhttps://serenity-js.org/api/core/class/TakeNotes/\n\n先ほどの online-store.steps.ts に、5 つの要素を実装した例を以下に紹介します。\n\n```ts\n// online-store.steps.ts\n\nimport { Given, When, Then, DataTable } from \"@cucumber/cucumber\";\nimport { Actor, Task } from \"@serenity-js/core\";\nimport { CallAnApi, PostRequest, Send, LastResponse } from \"@serenity-js/rest\";\nimport { BrowseTheWebWithPlaywright } from \"@serenity-js/playwright\";\nimport { Navigate, Page } from \"@serenity-js/web\";\nimport { Ensure, equals, endsWith } from \"@serenity-js/assertions\";\n\nGiven(\n  \"{actor} sets up product catalogue with:\",\n  (actor: Actor, products: DataTable) =>\n    actor.attemptsTo(setupProductCatalogue(products.hashes()))\n);\n\nWhen(\"{actor} looks for {string}\", (actor: Actor, productName: string) =>\n  actor.attemptsTo(openOnlineStore(), findProductCalled(productName))\n);\n\nThen(\n  \"{pronoun} should see top search result of\",\n  (actor: Actor, expectedResult: string) =>\n    actor.attemptsTo(\n      // Question\n      Ensure.that(\n        topSearchResult().name,\n        equals(expectedResult.rowsHash().name)\n      ),\n      // Question\n      Ensure.that(\n        topSearchResult().price,\n        equals(expectedResult.rowsHash().price)\n      )\n    )\n);\n\n// Task\nconst setupProductCatalogue = (products: Product[]) =>\n  Task.where(\n    `#actor sets up the product catalogue`,\n    // Interaction\n    Send.a(PostRequest.to(\"/products\").with(products)),\n    // Question\n    Ensure.that(LastResponse.status(), equals(201))\n  );\n\n// Task\nconst openOnlineStore = () =>\n  Task.where(\n    `#actor opens the online store`,\n    // Interaction\n    Navigate.to(\"https://example.org\"),\n    // Question\n    Ensure.that(Page.current().title(), endsWith(\"My Example Shop\"))\n  );\n\n// Task\nconst findProductCalled = () =>\n  Task.where(`#actor looks for a product`, undefined); // コード例がなかったため、省略\n```\n\nまた、`{actor}`や`{pronoun}`は、以下のように定義できます。\n\n```ts\n// parameter.steps.ts\nimport { defineParameterType } from \"@cucumber/cucumber\";\nimport { actorCalled, actorInTheSpotlight } from \"@serenity-js/core\";\nimport { CallAnApi } from \"@serenity-js/rest\";\nimport { BrowseTheWebWithPlaywright } from \"@serenity-js/playwright\";\n\ndefineParameterType({\n  regexp: /[A-Z][a-z]+/,\n  transformer(name: string) {\n    if (name === \"Apisitt\") {\n      return actorCalled(name).whoCan(\n        // Ability\n        CallAnApi.at(\"https://api.example.org\")\n      );\n    }\n    if (name === \"Wendy\") {\n      return actorCalled(name).whoCan(\n        // Ability\n        BrowseTheWebWithPlaywright.using(browser)\n      );\n    }\n  },\n  name: \"actor\",\n});\n\ndefineParameterType({\n  regexp: /he|she|they|his|her|their/,\n  transformer() {\n    return actorInTheSpotlight();\n  },\n  name: \"pronoun\",\n});\n```\n\n※ [parameter.steps.ts - serenity-js/serenity-js-cucumber-playwright-template](https://github.com/serenity-js/serenity-js-cucumber-playwright-template/blob/main/features/step-definitions/parameter.steps.ts)\n\n以上、Screenplay についての紹介でした。\n\n## シナリオのアンチパターン\n\nせっかくなので、シナリオのアンチパターンも紹介します。\n\nhttps://www.thinkcode.se/blog/2016/06/22/cucumber-antipatterns\n\n要約すると、以下のようなアンチパターンが存在します。\n\n- コード後のフィーチャーファイルの記述\n  - ソフトウェア実装後に Gherkin のフィーチャーファイルを書くこと。開発推進ではなく、記録に過ぎない。\n- ビジネス関係者によるシナリオの単独作成\n  - 製品オーナーやビジネスアナリストが単独でシナリオを作成すると、実際のビジネスニーズやテスト実行可能性を反映しない可能性がある。\n- 開発者やテスターによるビジネス関係者との協議なしのシナリオ作成\n  - 開発者やテスターが単独でシナリオを作成すると、現実離れしたり非現実的なデータやユーザー記述になりがち。\n- レベルが高すぎるシナリオ\n  - 高レベルで曖昧なシナリオは、具体的なビジネスルールを反映しておらず、信頼性が低い。\n- 生きていないドキュメント\n  - 不十分な Gherkin は、システムの機能を正確に伝えるドキュメントとして機能しない。\n- 不要な詳細による誤解\n  - シナリオに不要な詳細が含まれると、テストしたいビジネスルールの本質が曖昧になる。\n- 不適切なシナリオ名\n  - シナリオの名前は内容を端的に示すべきだが、不適切な名前は内容の理解を妨げる。\n- 初心者の間違い\n  - UI の詳細に過度に焦点を当てたり、個人的な代名詞「I」を使用するなど、初心者が犯しやすい間違い。\n- Given/When/Then の不明確な区分\n  - Given、When、Then の区別が不明確な場合、シナリオの意図が不明瞭になる。\n\n## 終わりに\n\n今回、Screenplay 設計を取り入れた経験を紹介しました。\nぜひ、参考にしてみてください。","publishedAt":"2023-11-13","slug":"e2e-testing-with-cucumber-and-screenplay-design","title":"CucumberとScreenplay設計によるE2Eテスト"},{"body":"こんにちは。[@silverbirder](https://x.com/silverbirder)です。\n最近、私のブログページを Qwik フレームワークで刷新しました。以下のリンクが、刷新したページになります。\n\nhttps://silverbirder.github.io/blog/\n\nこれで、私のブログページの刷新は 4 回目になります。この記事では、その過程で得た学びや経験を共有します。\n\nGitHub のリリースタグも利用していますので、以下のリンクから過去のソースコードを参照できます。\n\nhttps://github.com/silverbirder/silverbirder.github.io/tags\n\nソースコードも公開しているので、こちらもよければ参考にしてみてください。\n\nhttps://github.com/silverbirder/silverbirder.github.io\n\n## なぜ刷新したのか\n\n刷新の動機は主に好奇心です。\nそれに続いて、自分の技術的知見を広げるためでもあります。\n過去には静的サイトジェネレータの Hugo や Google が推奨する AMP、WebComponents を活用できる Rocket などを試してきました。\nそれぞれの技術には当時の流行や興味を反映していました。今回も、現在のトレンドや興味を持っている技術を中心に選択しました。\n\n## Qwik フレームワークの選択\n\nQwik はパフォーマンスを重視した Web フレームワークですが、そこはあまり重要視していませんでした。\n私が Qwik を選んだ主な理由は 以下の点です。\n\n- Markdown のサポート\n  - ブログ記事を書くのに Markdown が使うため\n- `State of JS`での高い評価\n  - 評価が高いからこそ、学ぶ価値があると思った\n- React に近い構文\n  - 自身の学習コストを下げたかった\n\nブログ記事の Markdown の Frontmatter にタグ情報を記入していたので、それを活用したいと考えました。調べていくと、 `import.meta.glob` という構文を知り(Vite の機能)、Frontmatter を抽出する方法を発見しました。これを参考にブログページの構築を開始しました。\n\n## 機能実装したこと\n\n実際にブログで実装した機能は、[silverbirder/silverbirder.github.io - GitHub](https://github.com/silverbirder/silverbirder.github.io) の README に詳しく記載しています。\n主な機能や導入技術を以下に列挙します。\n\n- **@unpic/qwik** 🚀📸\n- **Partytown** 🥳🌐\n- **PandaCSS** 🐼💃\n- **Playwright & Vitest** 🎭🔬\n- **Qwik** ⚡🕸️\n- **qwik-speack** 🌏🔊\n- **Storybook** 📓🌟\n- **Buy me a coffee** ☕💖\n- **Chromatic** 🌈📊\n- **Cloudinary** 🌌🖼️\n- **giscus** 🐦🗨️\n- **Google Analytics** 🕵️‍♂️📈\n- **icones.js** 📌🌈\n- **lottiefiles** 🎬📁\n- **OpenAI** 🧠🌐\n- **OpenReplay** 🎥🔄\n- **OneSignal** 📡💌\n\nまた、Markdown の Frontmatter を抽出し JSON 化し、それを使ってブログページを構築しています。(RSS フィードも同様)\n\n## 学んだこと\n\n元々は、Qwik というフレームワークのコンセプトを知り学びを深めようと考えていました。\n\nhttps://qwik.builder.io/docs/concepts/think-qwik/\n\nしかし、Qwik でブログ構築する過程で、フレームワーク自体ではなく、関連する技術やツールに興味関心が移りました。私の知る範囲でキャッチアップするよりも、こういった伸び代ある技術を学ぼうすることで、知らない技術を知る良い機会となりました。\n以下は、その中で学んだことです。\n\n### PandaCSS\n\nPandaCSS というスタイルエンジンを知りました。\n私は、これまで Bootstrap や materialUI のような CSS フレームワークを使うことが多かったのです。\nしかし、最近業務でランディングページの開発をする経験から、CSS を書いてみたくなりました。\nそこで、PandaCSS を使って、自分で CSS を書いてみました。\n\nglobal.css を初めて 0 から書いてみましたし、タイポグラフィ定義やセマンティックトークン定義を使ってみたりしました。こういった再利用性の高い CSS を書けるのは良いなと思いました。CSS-in-JS の記法が使えつつ、CSS ファイルを生成できていて、便利だなと思いました。(詳しくない)\n\n### 多言語対応\n\n多言語対応、初めてチャレンジしました。といってもなんちゃってです。\n多言語対応の対象は、Markdown の日本語記事やコンポーネントに含まれる日本語です。日本語を英語に翻訳します。\n本来は、日本語から英語に翻訳したものをチェックする人が必要だと思います。しかし個人レベルなら、そこまでやる必要はないかなと思いました(というより能力がない)。そこで、qwik-speack、chatgpt-md-translator の 2 つを使って翻訳しました。内部では、OpenAI の使っているようです。\n\n多言語対応をすると、WebPush する通知コンテンツやリンクコンテンツにも気を使うようになりました。\n実際に業務として使うならば、最初の段階からあると良いかもなぁと思います。(仕組みだけでもあると良い)\n\n### SaaS の利用\n\n今回は、SaaS を色々使ってみました。\n\n#### OpenReplay\n\nOpenReplay というものを導入しました。\n\nhttps://openreplay.com/\n\nこれは、ユーザーの行動を監視するものです。\n実際の運用としては、トラブルシュートや UX 改善などに使えそうなものに思いました。\n\nこれをブログページに入れたので、どのページのどのあたりにマウスカーソルが動かすのか見れるので、リンク配置や動線を考えさせられるきっかけとなりました。\n\n#### OneSignal\n\nWebPush 通知もやってみたいと思いました。\nしかし、WebPush 通知するサーバー側の用意が必要と思うのですが、それを掛けるコストはなくしたいと思い、\nよく知られている OneSignal というものを入れてみました。\n\nhttps://onesignal.com/\n\n通知をするときに、言語の選択や、通知を受け取るためのベストプラクティスが OneSignal に書いてあり、勉強になりました。\n\nhttps://documentation.onesignal.com/docs/permission-requests#what-are-some-best-practices-around-web-push-prompting\n\n#### Giscus\n\nQwik を選ぶ前、技術調査をしていたときに Material for MkDocs というのを発見し、\nその中で、giscus というを見つけました。\n\nhttps://giscus.app/ja\n\nこれは、GitHub の Discussions をブログに埋め込むことができます。これにより、ブログにコメントを残せるようになりました。\n\n## 途中で諦めたもの\n\n### Changesets\n\n`changesets`を利用してバージョン管理を試みましたが、途中で運用が面倒になり挫折しました。\n\n### Turborepo\n\n`turborepo`での monorepo 構成も夢見ていましたが、挫折しました。考えていた構成は以下の通りです。\n\n- apps/docs\n- packages/ui\n- packages/blog-contents\n- packages/translate\n\nしかし、PandaCSS や Qwik の UI ライブラリをうまく組み合わせるのが難しく、実現できませんでした。\n\n## 今後の展望\n\n例えば、dark モード対応、もしくはテーマカラーの変更ができる機能を作ってみたいなと思いました。\n他には、Playwright を使って、cucumber を試してみたいなと思っています。\nデザインは、初めて CSS でフルスクラッチでやったので、デザインにもっと強くなりたいと思いました。\n\n## 最後に\n\nこの刷新を通じて、多くの新しい技術やツールに触れることができました。\nそれぞれの技術には独自の魅力や学びがあり、非常に充実した経験となりました。\nこれからも、新しい技術やアイディアを追求していきたいと思います。","publishedAt":"2023-10-23","slug":"replace_my_portfolio_by_qwik_v3","title":"Qwikでブログページを刷新して学んだこと"},{"body":"私は 2023 年 6 月末に正社員として勤めていた企業を退職しました。勤務期間は 1 年 6 ヶ月で、私にとっては短い期間でした。業務に対するモチベーションは高く、チームメンバーとも和気あいあいとした良い環境で仕事ができました。しかし、以下の理由により、仕事とプライベートのバランスが崩れてしまい、結果として退職することにしました。この記事は、私の感情を整理するためのものです。\n\n- 会社の英語化に伴う勉強\n- 諸事情による引っ越しと新幹線通勤\n- 妻との 1 年間の妊活と不妊娠の問題\n- 高齢の祖母への介護と手術の準備\n\n## 英語化\n\n会社の方針により、英語の勉強を始めることになりました。私の TOEIC のスコアが低く、また、諸事情により英語の研修を始めるのが遅れてしまったため、他の誰よりも一生懸命勉強しなければならないと感じていました。\n\n2023 年 1 月から英語の勉強を開始し、平日の日中はチームとの合意により、チーム全員で 1 時間勉強することになりました。さらに、夜も 1 時間勉強することにしました。土日も 1 時間は勉強しています。\n\n## 新幹線での通勤\n\n元々、新幹線を利用した通勤を認識した上で、社内の移動制度を活用し、遠い地域の拠点に所属しました。当時、私の居住地は新幹線にアクセスしやすい位置にあったため、出社は楽でした。また、週一出社です。しかし、祖父母が高齢になり、さらに、祖父母が所有していた空き家を私が引き継ぐことになりました。その空き家は新幹線から離れた場所にあるため、通勤時間が往復 6 時間になってしまいました。引っ越しは、2023 年の 4 月頃でした。\n\n## 妊活\n\n私と妻は子供が大好きです。妻は以前保育士をしており、2023 年 3 月末に退職しました。その理由はいくつかありますが、妊娠を計画していることも一つです。2022 年から、妊活を始めるためにクリニックに通い始めました。当初は、タイミング療法を試しながら、並行して妻の検査と私の検査を行っていました。様々な事情があり、私の検査結果が 2023 年 5 月頃に判明しました。結果は機能不全で、つまり私の問題で子供ができないことがわかり、妻や親族にとても申し訳ない気持ちになってしまいました。それでもなんとか改善できるよう、お薬を飲んだり、ランニングを始めるなど、健康的な生活を心掛けるようになりました。\n\n## 介護\n\n80 歳を超える祖母が、昔から足が悪く、そろそろ足が動かなくなってしまいそうでした。足を動かさないため、運動しなくなり、血糖値がどんどんと上がってしまいました（HbA1c 9%）。足の手術をするのですが、血糖値が高いと手術ができないようです。足が悪いため、たまに湯船で溺れてしまうことが多く、その度に救助していましたが、とても危険な状態でした。生死に関わるため、祖父も父母も感情的になり、激しく喧嘩するようになりました。私は、祖父母、父母みんなが好きなんですが、喧嘩するたびに悲しい思いになりました。週に一度程度、祖父母の家へ向かい、家事を手伝ったり、祖父母の話（愚痴や不安）を聞いていました。この介護は、2023 年 5 月下旬頃から始まった出来事でした。\n\n## 結果\n\nこれらの要素から、プライベートな精神的な負荷が増大し、英語の勉強によりプライベート時間が削られ、新幹線通勤による身体への負担が増え、私のワークライフバランスが崩れてしまいました。その結果、精神科を受診し、うつ病と診断されました。薬を処方されましたが、効果はあまり感じられませんでした。\n\n私の感情は非常に不安定になっていました。些細なストレスに対して怒りと悲しみが極端に揺れ動き、すぐに怒ったり泣いたりしていました。しかし、仕事に持ち込まないように心がけていました。このままではいけないと感じ、業務委託という提案もしましたが、最終的には退職することに決めました。\n\n## 反省\n\n私は 2023 年の 4 月頃から、自分の感情が溢れそうだと感じていました。そのままでは問題が起こるかもしれないと思い始めていました。その後の出来事は、英語学習、新幹線通勤、妊活、介護と続きましたが、どうすればこれらの問題を解消できるのか、悩んでいる最中にさまざまな事が起こりました。ストレス解消のために過度な飲食や浪費をしてしまったこともありました。これらの行動は無意識に行っていたのかもしれません。ストレス解消は一時的な対策であり、問題が継続するとストレスは蓄積する一方です。今振り返ると、妻や家族に相談しにくい出来事だったため、問題を抱え込んでしまったのかもしれません。当時の私の認識は、「自分の感情が溢れそうだけど、今を乗り越えれば…」というものでした。\n\n今思うと、**何かを抱え込んだときは何かを手放すことが大切だ**と感じています。例えば、英語学習では、他人に追いつこうとする思いを手放し、自分のペースでゆっくりと学ぶべきだったと思います。また、長時間の新幹線通勤が確定した時点で、出社を諦めるか別の拠点に移動するべきだったかもしれません。妊活で私の機能不全が判明し、落ち込んだときは、妻と向き合い、しっかりと休養を取るべきだったと思います。介護の問題では、祖母の手術が終わるまで、介護休暇を取るか働き方を見直すべきだったと思います。もちろん、これらはすべて後の祭りで、実際に過去に戻ってそれができたかどうかはわかりません。しかし、何かを抱え込んだときには何かを手放すという意識を持つことで、より良い行動をとることができたのではないかと思います。\n\n## 現在\n\n現在は無職です。職を離れたため、英語の勉強や通勤は必要ありません。また、妊活も一時休止しています。祖母の家には頻繁に訪れています。色々と手放した結果、感情の溢れ具合は回復し、心に余裕が生まれました。そのため、趣味に時間を使う気持ちが湧いてきました。筋トレや遠出、アプリ開発や執筆などをしています。しかし、時々「このままで良いのか」と自問自答することもあります。妻や親族に相談していますが、焦らなくて良いと助言してくれています。\n\n私は空き家を譲り受けているため、家賃やローンの心配はありません。そのため、金銭的に困ることは今のところほとんどありません。しかし、私の収入が一切ないのもどうかと思い、アルバイトを始めようと考えていました。その時、Findy のカスタマーサクセスと話す機会があり、業務委託の提案を頂きました。そして、Findy Freelance を通じて、ありがたいことに案件のオファーを頂きました。働く時間は週に 2、3 回程度ですが、時給が高い（普通のアルバイトに比べて）ので、これは良い機会だと思いました。\n\n明日から、少しずつ働き始める予定です。","publishedAt":"2023-07-17","slug":"left_my_full-time_job","title":"正社員を辞めました"},{"body":"最近、ビアードパパの焼きチーズケーキシューにハマっている silverbirder です。\n文章作成が苦手な私は、AI が文章を代筆する「AI Ghostwriter」という Chrome の拡張機能を開発しました。今回は、この便利なツールの紹介をします。\n\nChrome ウェブストアで公開しています。気になる方は、以下のリンクよりダウンロードしてください! 無料です!\nhttps://chrome.google.com/webstore/detail/ai-ghostwriter/hpcokeldeijnfmbbbjkedhnedjjbjmoa\n\n## AI Ghostwriter って\n\nAI Ghostwriter は、ChatGPT を活用して執筆者のライティング作業を助け、その品質を向上させる Chrome 拡張機能です。これはブラウザ上で選択したテキストに対して様々なアクションを実行できるツールで、ライティングにおけるあらゆる問題を解決します。\n\nアクションは、デフォルトで以下の 3 つを用意しています。(後述しますがカスタマイズ可能です!)\n\n- **校正(Proofreading)**\n- **タイトル生成(Generate title)**\n- **続きの文章生成(Generate following text)**\n\n仕組みは、とてもシンプルです。選択されたテキストを[OpenAI の API](https://platform.openai.com/docs/api-reference/chat/create)のパラメータとして指定した状態でリクエストし、レスポンスをサイドパネルに表示するだけです。\n\n百聞は一見にしかず、デモ動画を紹介します。以下の画像をクリックするとデモ動画が再生されます。\n\n![AI Ghostwriter DEMO](https://res.cloudinary.com/silverbirder/image/upload/v1693381103/silver-birder.github.io/blog/ai_ghost_writer_demo.gif)\n\n以下は、デモ動画で紹介している AI Ghostwriter の操作手順です。\n\n1. 右上の AI Ghostwriter アイコンをクリックし、サイドパネルを開く\n1. ブラウザ上のテキストを選択する\n1. 右クリックし、コンテキストメニューを開き、校正などのアクションをクリック\n1. サイドパネルに、AI Ghostwriter からコメントが表示される\n\n## コンテキストメニューのアクションをカスタマイズ\n\nコンテキストメニューのアクションは、ユーザーのニーズに合わせて自由にカスタマイズ可能です。具体的には、アクションの追加・削除・編集が可能です。以下の画像の通りです。アクションは、オプションページで登録できます。\n\n![Chrome拡張機能のオプションページ](https://res.cloudinary.com/silverbirder/image/upload/v1693364104/silver-birder.github.io/blog/088188b02d18-20230716.png)\n\n※ オプションページは、右上の AI Ghostwriter アイコンを右クリックするとオプションという選択肢があり、それをクリックするとオプションページに遷移できます。\n\nカスタマイズにより、ご自身の好みに合わせたライティング補助が可能となります。つまり、**自分だけのアクションを作成し、より効率的なライティングを実現できます**。AI からのコメントがイマイチの場合、コンテンツパラメータのテキストに少し手を加えてみると良いでしょう。また、**翻訳や要約**といったアクションも便利だと感じるかもしれません。これらの機能を活用して、より効率的なライティング体験を実感してみてください。\n\n## その他の機能\n\nその他に、ユーザーの利便性を考慮して、以下の機能も提供しています。\n\n- **多言語対応**\n  - 英語と日本語に対応しています。\n- **フィードバックリンク**\n  - ユーザーからのフィードバックを受け付けるためのリンクを設置しています。\n- **誤操作防止**\n  - API トークンが未定義であったり、サイドパネルが未オープンであったりする場合に、Chrome の通知を通じて誤操作を防止します。\n- **生成停止**\n  - 不要な生成処理を停止するために、アクションを停止するボタンも用意\n- **ショートカットキーの設置**\n  - サイドパネルをショートカットキーで開くようにしています\n  - `chrome://extensions/shortcuts` で確認できます\n\n## 終わりに\n\nAI Ghostwriter のおかげで、私の執筆効率はとてもよくなりました。既にアクションが 6 つあります(笑)。皆さんの執筆効率もよくなることを願っています！\n\n## 余談: 開発経緯\n\nここからは、余談です。なぜ、このアプリを開発に至ったかについて簡単に紹介します。\n\n1. **アイデアの出発点**: 日頃から ChatGPT をブログ執筆に活用していた経験から、何か新しいものを創れないかと考え始めました。\n\n1. **市場調査**: AI ライティング補助のサービスを調査しましたが、既存のサービスはメールテンプレート生成など、私が求めていた特定テキストの校正機能を持っていませんでした。\n\n1. **アプリのイメージ**: 特定テキストに対する特定アクション、具体的には校正機能を持つアプリを作りたいと考えました。\n\n1. **開発方法の検討**: 新しい Web フレームワークや技術を試すことも考えましたが、継続性を考慮し、既存の経験と知識を活用することにしました。\n\n1. **Vercel のテンプレート**: Vercel のテンプレートにある[novel](https://vercel.com/templates/next.js/novel)というものを見つけ、これが理想的なツールだと感じました。このエディタは Notion のような形式で、OpenAI の組み込みが可能で、選択したテキストに対してアクションを実行できます。\n\n1. **エディタ開発の断念**: しかし、エディタを作ることは大変で、開発時間が伸びることから断念しました。私が求めていたのは、任意のテキストを校正した結果を知るだけでした。\n\n1. **Chrome 拡張機能の活用**: その考えを元に、Deepl の Chrome 拡張機能を思い出しました。Chrome 拡張機能にはコンテキストメニューの API がビルドインされており、最近リリースされたサイドパネル機能を使えば、現在開いているタブの隣に別のウィンドウを表示できます。そこに校正後のテキストを表示すれば良いと考えました。\n\n以上、私の簡単な開発経緯についてでした。最後までお読み頂きありがとうございました。","publishedAt":"2023-07-17","slug":"writing_efficiency_tool_introducing_ai_ghostwriter","title":"ライティングの効率化ツール：AI Ghostwriterの紹介"},{"body":"英語の勉強を始め、TOEIC のスコアが 6 ヶ月で 285 点もアップしました。この経験を共有し、自分の学習の記録してこの記事を書きます。\n\n## TOEIC の点数と学習時間\n\nまずはじめに、TOEIC の点数について、時系列順に列挙します。\n\n| 受験日             | 点数 | リスニング/リーディング |\n| ------------------ | ---- | ----------------------- |\n| 2023 年 1 月時点   | 355  | 215/140                 |\n| 2023 年 2 月 26 日 | 510  | 280/230                 |\n| 2023 年 5 月 27 日 | 640  | 320/320                 |\n\n見て分かる通り、2 月と 5 月のそれぞれの受験にて、どちらも 100 点はアップしています。元々、点数が悪ったというのもありますが。。。\n\n次に私の学習時間について、以下の図で示します。これらのデータは、私が学習の管理に使用しているサービス、[Study Plus](https://www.studyplus.jp/)から取得しました。学習期間は、2023 年 1 月から 2023 年 6 月までです。\n\n![study_plus_1](https://res.cloudinary.com/silverbirder/image/upload/v1688543381/silver-birder.github.io/blog/study_plus_1.png)\n\n図からわかるように、私は毎月 30 時間以上を学習に費やしています。日で分割すると、一日 1 時間以上は勉強していたことになります。\n6 月は特別な事情があり、学習時間を確保することができませんでした。\n\n## 英語学習法\n\n私の TOEIC スコアが 300 点台だった頃、私は英単語をひたすら覚えていました。特に意識していたのは以下の 3 つです。\n\n1. 英単語の品詞を覚える\n1. 覚えるときは必ず耳と口を使う\n1. 少しずつではなく、大量に見て繰り返し覚える\n\n1 つ目は、英単語の訳を覚えるだけでなく、その単語が動詞（他動詞/自動詞）、名詞、形容詞など、どの品詞に属するのかも覚えるようにしました。これは英文法を理解する上で重要なため、常に意識しています。\n\n2 つ目は、英単語を覚えるときに、英単語の発音を耳で聞き、自分の口で発音し、それを自分の耳で聞くという方法を取りました。発音を覚えることで、リスニングするときの聞き取りが容易になります。\n\n3 つ目は、1 日に 1 つずつ丁寧に覚えるよりも、1 日に 100 個の英単語を覚えるようにしました。初日は完全に覚えられないかもしれませんが、同じことを 1 週間繰り返すと、目と耳に記憶が残り、効率的に覚えられるようになります。\n\n私が最初に使用した英単語の教材は「ユメタン 0」でした。レベルとしては非常に簡単なものですが、意外と覚えていなかった単語もあったため、この教材を使って良かったと感じています。\n\n- [夢をかなえる英単語 新ユメタン 0 中学修了〜高校基礎レベル](https://amzn.to/3NYea40)\n\n次に、キクタンを試してみました。これは非常に有用でした。特定の量の英単語を音声で聞き、発音するトレーニングが可能でした。\n\n- [改訂第 2 版キクタン【Basic】4000 語レベル](https://amzn.to/3K7jCiP)\n\n## 英語学習の継続について\n\n英語学習における最大の課題は、英語学習の継続でした。私は毎日、最低でも 1 時間は英語の勉強をすると決めていました。しかし、仕事が忙しくなると、どうしても英語の勉強を疎かにしてしまうことがありました。 さらに、英語の勉強は淡々と進めるもので、時として非常につまらないと感じることもありました。成果がすぐには見えないため、努力が報われないように感じることもしばしばでした。\n\n英語の勉強を継続しようと思っても、モチベーションが低下し、学習をやめてしまいます。好きなことなら、時間をいくらでも使えるのですが、英語の勉強となると、そこまで好きとは言えない自分がいます。 学習継続が難しいときには、以下の 3 つの方法が有効です。\n\n1. **できなかった時間よりもできた時間を考える**：数分でも継続が大事です。納得感を大事にしましょう。\n1. **共同体を作る**：誰かと褒め合ったり、愚痴り合ったりすることで、学習のモチベーションを保つことができます。\n1. **定期的に TOEIC や単語テストなどで結果の数値で可視化する**：自分の進歩を具体的に見ることで、学習意欲を維持することができます。\n\n## 英語学習の喜びとその影響\n\n英語の勉強を継続していく中で感じた喜びは、TOEIC の点数が上がったことだけではありませんでした。日常生活で英語に触れる機会が増えるたびに、聞き取れるようになったり、読み取れるようになったり、新たな意味を理解できるようになったりと、自分の成長を実感する瞬間が増えました。\n\n業務での経験も大きな喜びがありました。日本語が母国語ではない外国人の方と 1 対 1 で急な会議を行い、その際、私は相手に迷惑をかてしまいましたが、それでも何とか会話を進め、目的とする話を終えることができました。その時、自分の言葉が相手に通じる喜びを強く感じました。\n\nこれらの小さな喜びを体験する度に、私のモチベーションは高まりました。これらは、英語学習を続ける上で非常に重要な経験だと感じています。\n\n## 次にすること\n\n私の目標は TOEIC で 700 点を獲得することです。そのためには、リスニングとリーディングのスキルを磨くために、これらの学習を繰り返し行います。\n700 点を超えたら、次のステップとしてスピーキングの練習に移ります。そのためには、瞬間英作文トレーニングや、適切なサービスを探すことを計画しています。\n\n- [どんどん話すための瞬間英作文トレーニング](https://amzn.to/3pA1y9P)","publishedAt":"2023-07-05","slug":"increased_TOEIC_score_by_285_points_in_6_months","title":"6ヶ月でTOEICのスコアを285点アップ"},{"body":"フィーチャーフラグ（Feature Flag）をご存知でしょうか？これは新機能のリリース制御や AB テストを容易にする強力なツールです。しかし、適切な管理ツールなければ、フィーチャーフラグの管理は容易なことではありません。今回は、そんなフィーチャーフラグの管理を効率化するツール、**Unleash**について解説します。\n\n![Unleash](https://res.cloudinary.com/silverbirder/image/upload/v1693364020/silver-birder.github.io/blog/353d890469ef-20230628.png)\n\nUnleash のリポジトリはこちら 👉[GitHub - Unleash](https://github.com/Unleash/unleash)\n\n## フィーチャーフラグの課題と解決策\n\nフィーチャーフラグとは、新機能の活性化・非活性化を制御するためのブール値のスイッチをコードに組み込む手法です。カナリアリリースや AB テストのように、特定のユーザーにだけ新機能を表示したり、新機能のパフォーマンスをテストしたりするために用いられます。\n\nフィーチャーフラグの管理方法はいくつかありますが、それらは環境変数、定義ファイル（CSV、YML、JSON）、データベースなどが一般的です。しかし、これらの管理方法にはフラグの切り替えに時間がかかる、不要なフラグの削除を忘れがちなどの問題点があります。ここで紹介したいのが、フィーチャーフラグ管理ツール**Unleash**です。\n\n## なぜ Unleash なのか\n\nUnleash は、フィーチャーフラグの管理を容易にするオープンソースツールです。様々な言語やフレームワークで利用でき、新機能の制御、テストの効率化、機能の並行作業などを可能にします。\n\nUnleash の主な特長は以下の通りです。\n\n- **GUI ベースの操作**：フラグの ON/OFF 切り替えが簡単で、フラグの管理が非エンジニアでも可能です。(データアナリストとか)\n- **柔軟なテスト機能**：AB テストだけでなく、多変量テストも可能です。\n- **豊富な連携**：Slack や Datadog などと連携してフラグの状態を共有できます。\n- **API first**：他のアプリケーションやシステムとの連携が容易です。\n- **セルフホスティングとクラウドサービス**：自分でホスティングすることも、クラウドサービスを利用することも可能です。\n\nこれらの特性により、Unleash はフィーチャーフラグの管理を効率化し、開発フローを加速します。\n\n## Unleash のセットアップとフィーチャーフラグの使用方法\n\nそれでは、Unleash を実際に使用する流れを紹介していきます。今回は Unleash でフィーチャーフラグを一つ作成し、それを React から参照するというシナリオとします。\n\nUnleash のセットアップについては、公式ドキュメンテーションの[Unleash - Get started in 2 steps](https://github.com/Unleash/unleash#get-started-in-2-steps)を参考に、まずはローカル環境で試してみましょう。クラウド環境での構築を希望する場合は、PostgreSQL が無料で利用可能な[fly.io](https://fly.io)を推奨します。\n\n構築が完了すると、Unleash の画面が表示されます。\n\n![Unleash](https://res.cloudinary.com/silverbirder/image/upload/v1693364020/silver-birder.github.io/blog/353d890469ef-20230628.png)\n\nフィーチャーフラグを作成してみましょう。`New feature toggle`をクリックし、名前には`new_feature`を入力します。\n\n![New feature toggle](https://res.cloudinary.com/silverbirder/image/upload/v1693364040/silver-birder.github.io/blog/b06e11b8f38a-20230628.png)\n\n続いて、React から Unleash への接続に必要な API token を生成します。Unleash の画面上部から `Configure > API access` を選択します。\n\n![API access](https://res.cloudinary.com/silverbirder/image/upload/v1693364043/silver-birder.github.io/blog/4fea3cd45d9c-20230628.png)\n\n`New API token` をクリックし、API token を作成します。\n\n![New API token](https://res.cloudinary.com/silverbirder/image/upload/v1693364046/silver-birder.github.io/blog/1ac3a5595c02-20230628.png)\n\n今回、クライアントサイド(React)で Unleash を利用するため、`Client-side SDK` を選択して API token を生成します。もちろん、サーバーサイドから Unleash を利用することも可能です。\nここで、environment を`development`に設定します。これにより環境ごとに API token を設定できます。production 向けの API token が必要な場合は、別途生成します。\n\n次に生成した API token を `REACT_APP_UNLEASH_API_TOKEN` に設定し、以下の React のコードで使用します。\n\n```javascript\nimport React from \"react\";\nimport ReactDOM from \"react-dom/client\";\nimport App from \"./App\";\nimport { FlagProvider } from \"@unleash/proxy-client-react\";\n\nconst config = {\n  url: `${process.env.REACT_APP_UNLEASH_URL}/api/frontend`,\n  clientKey: `${process.env.REACT_APP_UNLEASH_API_TOKEN}`,\n  refreshInterval: 1,\n  appName: \"default\",\n};\n\nconst root = ReactDOM.createRoot(\n  document.getElementById(\"root\") as HTMLElement\n);\nroot.render(\n  <React.StrictMode>\n    <FlagProvider config={config}>\n      <App />\n    </FlagProvider>\n  </React.StrictMode>\n);\n```\n\nここでは、フィーチャーフラグ`new_feature`を使用する例を示します。\n\n```javascript\nimport React from \"react\";\nimport { useFlag } from \"@unleash/proxy-client-react\";\n\nfunction App() {\n  const flag = useFlag(\"new_feature\");\n  return <div>{flag && \"new_feature\"}</div>;\n}\n\nexport default App;\n```\n\nこの設定により、Unleash の GUI からフィーチャーフラグをリアルタイムで ON/OFF することが可能になります。変更結果は Unleash 経由でフロントエンドにリアルタイムで反映されます。\n\n以下にフィーチャーフラグのデモを示します。都合上、`production`の environment を使用しています。以下の画像をクリックすると動画を閲覧できます。\n\n[![Feature flag demo](https://res.cloudinary.com/silverbirder/image/upload/v1693364382/silver-birder.github.io/blog/feature-flag-demo.gif)](https://res.cloudinary.com/silverbirder/image/upload/v1693364382/silver-birder.github.io/blog/feature-flag-demo.gif)\n\n以上が Unleash の基本的な使用方法です。\n\n## Unleash 機能: Activation Strategies\n\nUnleash では、フィーチャーフラグの活性化を制御するための Activation Strategies を設定することができます。\n\n[Unleash - Activation Strategies](https://docs.getunleash.io/reference/activation-strategies)\n\nActivation Strategies は以下の 4 つがあります。\n\n- Gradual rollout\n  - ユーザーの一部に対して段階的に展開します。また、各ユーザーが訪問するたびに同じ経験が提供されることを保証します。\n- Standard\n  - このストラテジーは全てのユーザーに対してフィーチャーをオン/オフします。\n  - ただし、Gradual rollout ストラテジーを使用することを推奨します。\n- IPs\n  - 特定の IP アドレスのセットに対してフィーチャーを有効にします。\n- Hosts\n  - 特定のホスト名のセットに対してフィーチャーを有効にします。\n\n以下の画像は、Gradual rollout の設定画面です。\n\n![Gradual rollout](https://res.cloudinary.com/silverbirder/image/upload/v1693364049/silver-birder.github.io/blog/aa326c9fcba8-20230628.png)\n\n## Gradual rollout\n\n特に、Gradual Rollout ストラテジーは AB テストとしても利用可能です。\n\n## Unleash 機能: Variant\n\nUnleash では、全てのフィーチャーフラグに Variant という機能が用意されています。これにより、ユーザーをより詳細なセグメントに分けることが可能となります。\n\n[Unleash - Feature toggle variants](https://docs.getunleash.io/reference/feature-toggle-variants)\n\n例として、先ほど作成した new_feature のフィーチャーフラグに対して、以下の画像の通り、4 つの Variant を設定しました。それぞれの Variant は設定した `Weight` に基づいて選択されます。\n\n![Feature toggle variants](https://res.cloudinary.com/silverbirder/image/upload/v1693364052/silver-birder.github.io/blog/d0869460f07b-20230628.png)\n\n以下に、new_feature の Variant を使用する例を示します。`variant.name` には、先ほど設定した Variant の name が入力されます。そのため、この`variant.name`を基に処理を分岐させることが可能です。\n\n```javascript\nimport React from \"react\";\nimport { useVariant } from \"@unleash/proxy-client-react\";\n\nfunction App() {\n  const variant = useVariant(\"new_feature\");\n  if (!variant.enabled) return <>Default</>;\n  switch (variant.name) {\n    case \"BlueButton\":\n      return <>BlueButton</>;\n    case \"GreenButton\":\n      return <>GreenButton</>;\n    case \"RedButton\":\n      return <>RedButton</>;\n    case \"YellowButton\":\n      return <>YellowButton</>;\n  }\n}\n\nexport default App;\n```\n\nこのようにして、AB テストだけではなく、多変量テストを行うことが可能となります。\n\n## Unleash 機能: Toggle type\n\nUnleash では、フィーチャーフラグに様々なタイプが設定できます。各タイプは寿命(ライフタイム)が異なり、寿命が尽きたフィーチャーフラグはマークされます。マークされたフィーチャーフラグは、アーカイブすることを推奨します。\n\n[Unleash - Feature toggle types](https://docs.getunleash.io/reference/feature-toggle-types)\n\nフィーチャートグルのタイプは以下のように分類されます。\n\n- **Release** : 継続的デリバリーを実践するチームのトランクベース開発を有効にします。予想される寿命は 40 日です。\n- **Experiment** : 多変量テストまたは AB テストを実施します。予想される寿命は 40 日です。\n- **Operational** : システムの動作に関する運用面を制御します。予想される寿命は 7 日です。\n- **Kill switch** : システム機能のグレースフルな劣化を可能にします。(永続的)\n- **Permission** : 特定のユーザーが受け取るフィーチャーや製品体験を変更します。(永続的)\n\n寿命が尽きたフィーチャーフラグは、技術的負債となります。フィーチャーフラグに関する技術的負債についての詳細な記事が以下のリンクで紹介されています。是非ご覧ください。\n\n[Unleash - technical-dept](https://docs.getunleash.io/reference/technical-debt)\n\nUnleash では、Health と呼ばれる指標が表示されます。この値が低いと、技術的負債が蓄積されているということを示します。フィーチャーフラグを適切にアーカイブする運用を心掛けましょう。\n\n![Unleash health](https://res.cloudinary.com/silverbirder/image/upload/v1693364066/silver-birder.github.io/blog/1a4ba5569cf8-20230628.png)\n\n## Unleash 機能: その他\n\nUnleash には、他にも以下に述べるような様々な機能が備わっています。\n\n- 環境の追加\n  - `development`や`production`以外にも、テストやステージング環境など、自由に環境を作成することができます。\n  - 詳細：https://docs.getunleash.io/how-to/how-to-clone-environments\n- Playground の利用\n  - フィーチャーフラグの挙動を確認するための Playground が利用可能です。\n  - アクセス URL：`https://<UNLEASH_URL>/playground`\n- CORS origins の設定\n  - フロントエンドから Unleash サーバーへのアクセスを許可するための CORS 設定ができます。\n- フィーチャーフラグの承認フローの設定\n  - フィーチャーフラグを有効化するための承認フローを設定することができます。\n  - 詳細：https://docs.getunleash.io/reference/change-requests\n\n## まとめ\n\nフィーチャーフラグの管理に最適なツールとして Unleash が一押しです。Unleash を使用することで、フラグの切り替えが容易になり、デプロイフローを通さずに高速にフィーチャーフラグを管理することが可能となります。多様なテストを行い、その結果を元に製品の改善が行えます。製品開発のスピードと品質が大幅に向上しますので、ぜひ一度試してみてください。\n最後までお読み頂き、ありがとうございました。バッジを贈ってね！\n\n## supported by ChatGPT","publishedAt":"2023-06-29","slug":"unleash_feature_flag","title":"Unleashで始めるフィーチャーフラグ"},{"body":"こんにちは、テストが好きな silverbirder と申します。Web フロントエンドのテストは実施していますか？ユニットテストやビジュアルリグレッションテストは広く知られていると思います。しかし、パフォーマンステストのためのテストコードはありますか？また、カオスエンジニアリングテストやアクセシビリティテストはありますか？\n\n今回、私は Web フロントエンドにおける網羅的なテストパターンを調査し、その結果をここで紹介したいと思います。これらを理解することで、読者の皆さんが適切なテスト戦略を策定する際の参考になれば幸いです。\n\n## 前提\n\n今回、テスト対象として取り上げる題材は、[TodoMVC](https://todomvc.com/)という TODO アプリです。フレームワークとして React を使用しますが、紹介するテストパターンはフレームワークに依存しないものです。ただし、使用するライブラリは React に関連しているため、その点についてはご了承ください。また、テストライブラリとして、Jest を使用します。\n\n参考となるコードは次のリポジトリに用意していますので、ぜひご参照ください。\n\nhttps://github.com/silverbirder/react-todoMVC/\n\nまた、動作するアプリケーションを Vercel で公開しています。こちらも参考にしてください。\n\nhttps://silverbirder-react-todo-mvc.vercel.app\n\nコンポーネントの構造は以下の通りです。\n\n![component_structure](https://res.cloudinary.com/silverbirder/image/upload/v1693364069/silver-birder.github.io/blog/8fcf377eaa36-20230423.png)\n\n- App.tsx\n  - TodoInput.tsx\n  - TodoList.tsx\n    - TodoItem.tsx\n  - TodoContext.ts\n\n## 概要\n\nまず、これから紹介するテストパターンの全体図を紹介します。\n\n![overview](https://res.cloudinary.com/silverbirder/image/upload/v1693364073/silver-birder.github.io/blog/5182e7bd04a5-20230425.png)\n\nテストパターンは、大きく以下の 3 つに分類されます。\n\n- 機能テスト\n- 非機能テスト\n- UI/UX テスト\n\nそれぞれの内容について、これから説明していきます。\n\n## テストパターン\n\n### 機能テスト(Functional)\n\n機能とは、システムやソフトウェア、製品、またはサービスが提供する特定の目的を達成するために実行されるタスクや操作を指します。Web フロントエンドにおける機能は、Web アプリケーションのユーザーインターフェース（UI）部分で実現されるタスクや操作を指します。これには画面表示や操作、ページ遷移や更新などが含まれます。\n\n機能テストには、テストトロフィーやテストピラミッドが有名です。一般的に次の 3 つのカテゴリがあります。\n\n- ユニットテスト\n  - 関数やコンポーネントなど、単体レベルのテスト\n- インテグレーションテスト\n  - 複数の関数やコンポーネントが正しく連携するかのテスト\n- E2E(システム)テスト\n  - フロントエンドからバックエンドまで一気通貫したテスト\n\nユニットテストとインテグレーションテストは、フロントエンドだけで完結し速度重視のテストです。一方、E2E テストはバックエンドと連携し、速度は遅く重たいものの、より本番環境に近い状態でテストを行います。\n\nユニットテストは一つの機能やコンポーネントに対して行うのに対し、インテグレーションテストではユーザーにとって意味のある単位で結合したコンポーネントに対してテストを行うことがお勧めです。画面を構成するページレベルのコンポーネントが適切でしょう。\n\n#### ユニットテスト\n\nまず、よく知られているユニットテストから始めましょう。TodoItem コンポーネントのテストを行ってみましょう。\n\nTodoItem コンポーネントは以下の通りです。\n\n```typescript\n// src/components/TodoItem/TodoItem.tsx\n\nimport React, { useContext } from \"react\";\nimport type { Todo } from \"../../types\";\nimport { TodoContext } from \"../context\";\n\ntype Props = {\n  todo: Todo;\n};\n\nexport const TodoItem: React.FC<Props> = ({ todo }) => {\n  const { toggle, deleteTodo } = useContext(TodoContext);\n  return (\n    <li className={todo.completed ? \"completed\" : \"\"}>\n      <div className=\"view\">\n        <input\n          className=\"toggle\"\n          type=\"checkbox\"\n          checked={todo.completed}\n          onChange={() => toggle(todo.id)}\n        />\n        <label data-testid=\"todo-title\">{todo.title}</label>\n        <button className=\"destroy\" onClick={() => deleteTodo(todo.id)} />\n      </div>\n    </li>\n  );\n};\n```\n\nこのコンポーネントに対するテストコードは、以下のようになります。\n\n```typescript\n// src/components/TodoItem/TodoItem.test.tsx\n\nimport React from \"react\";\nimport { render, screen } from \"@testing-library/react\";\nimport { TodoItem } from \"./TodoItem\";\nimport { TodoContext } from \"../context\";\nimport userEvent from \"@testing-library/user-event\";\n\nconst mockToggle = jest.fn();\nconst mockDeleteTodo = jest.fn();\nconst mockAdd = jest.fn();\n\ndescribe(\"TodoItem\", () => {\n  // Arrange\n  const mockTodo = {\n    id: \"1\",\n    title: \"Test Todo\",\n    completed: false,\n  };\n\n  it(\"renders todo title\", () => {\n    // Act\n    render(\n      <TodoContext.Provider\n        value={{\n          toggle: mockToggle,\n          deleteTodo: mockDeleteTodo,\n          addTodo: mockAdd,\n        }}\n      >\n        <TodoItem todo={mockTodo} />\n      </TodoContext.Provider>\n    );\n\n    // Assert\n    expect(screen.getByText(mockTodo.title)).toBeInTheDocument();\n  });\n\n  it(\"toggles todo completion\", () => {\n    // Arrange\n    render(\n      <TodoContext.Provider\n        value={{\n          toggle: mockToggle,\n          deleteTodo: mockDeleteTodo,\n          addTodo: mockAdd,\n        }}\n      >\n        <TodoItem todo={mockTodo} />\n      </TodoContext.Provider>\n    );\n\n    // Act\n    userEvent.click(screen.getByRole(\"checkbox\"));\n\n    // Assert\n    expect(mockToggle).toHaveBeenCalledWith(mockTodo.id);\n  });\n\n  it(\"deletes a todo\", () => {\n    // Arrange\n    render(\n      <TodoContext.Provider\n        value={{\n          toggle: mockToggle,\n          deleteTodo: mockDeleteTodo,\n          addTodo: mockAdd,\n        }}\n      >\n        <TodoItem todo={mockTodo} />\n      </TodoContext.Provider>\n    );\n\n    // Act\n    userEvent.click(screen.getByRole(\"button\"));\n\n    // Assert\n    expect(mockDeleteTodo).toHaveBeenCalledWith(mockTodo.id);\n  });\n});\n```\n\n特に目新しいテストコードはないでしょう。今回はコンポーネントに対するテストコードでしたが、コンポーネントから切り離されたロジックファイル（例えば、React の hooks）ももちろん対象です。\n\nユニットテストを作成する際には、以下の 3 つのポイントに注意しています。\n\n- Arange-Act-Assert（AAA）パターンを使用する\n  - 上から下に読みやすい構造にする\n    - 下から上を読み返さない\n  - 自然言語を意識して記述する\n    - テスト実行後の出力メッセージが読みやすくなる\n- DRY 原則や、制御文（if/while など）を避け、愚直に書く\n  - シンプルで直感的なテストコードを好む\n    - ハードコードした変数も良い\n  - 1 つのテストファイルで内容を確認できるようにする\n    - 例えば、データファイルを別ファイルに分割しない\n- 1 つのテストケースには 1 つの検証を行う\n  - 異なる目的の検証は、テストケースを分ける\n\n##### 脱線) なんでテストコードを書くのか\n\nテストコードは、プロダクトを利用するユーザーではなく、開発するエンジニアのために存在すると、私は考えています。そのため、私が考えるテストコードの目的は以下の 3 つです。\n\n- 開発効率の向上（キーストロークの削減）\n- 機能品質の維持\n- 仕様の明確化\n\n開発効率の向上では、例えば多くの組み合わせパターンがあるスキーマバリデーションの場合、手動での確認は大変です。そこで、パラメタライズドテストやプロパティベースドテストを実施することで効率的に開発できます。\n\n機能品質の維持では、CI/CD プロセスでテストを実行し、テストが成功した場合にのみデプロイするリリースフローを構築します。そうすると、デプロイされたプロダクトは、テストで記述された内容の品質を担保できます。\n\n仕様の明確化では、テストコードを自然言語として分かりやすく書くことで、どのような機能があるのかが理解できます。仕様書をプロダクトコードから読み取るのは不親切ですが、テストコードが分かりやすい場合、機能の現状の動作がある程度把握できるようになります。\n\n#### インテグレーションテスト\n\nユニットテストでは、個々のコンポーネントや関数が対象となります。一方、インテグレーションテストでは、1 画面に構成されるコンポーネントなど、ユーザーに価値を提供できる状態のものが対象です。今回の場合、TodoList.tsx や TodoInput.tsx を使用している App.tsx が該当します。\n\nインテグレーションテストにおいては、バックエンドとの通信は模擬されますが、それ以外の要素はすべて実際のものです。ユニットテストではコンポーネント単体のみのテストでしたが、インテグレーションテストでは画面に表示される必要なコンポーネントが全て揃っています。そのため、コンポーネント間の連携を確認する目的で、ユーザー操作、すなわちインタラクションテストを行うことが効果的です。\n\nインタラクションテストには、Storybook を利用すると便利です。\n\nhttps://storybook.js.org/docs/react/writing-tests/interaction-testing\n\n従来はターミナルでインタラクション（クリックなど）のテストを行っていたと思いますが、Storybook を用いることで視覚的に確認しながらテストが作成できるため、非常に開発しやすくなります。\n\nそれでは、1 つの機能として提供されている App.tsx を対象に、インタラクションテストを作成してみましょう。\nまず、Storybook を作成すると、次のようなものができます。\n\n:::message\n今回紹介する Storybook のバージョンは 6.5 です。\n:::\n\n```typescript\n// src/components/App/App.stories.tsx\n\nimport { ComponentStoryObj, ComponentMeta } from \"@storybook/react\";\nimport { App } from \".\";\nimport { userEvent, within } from \"@storybook/testing-library\";\n\ntype Component = typeof App;\ntype Meta = ComponentMeta<Component>;\ntype Story = ComponentStoryObj<Component>;\n\nconst meta: Meta = {\n  component: App,\n};\nexport default meta;\n\nexport const AddTwoTodosAndCheckOneScenario: Story = {\n  play: async ({ canvasElement }) => {\n    const canvas = within(canvasElement);\n    await userEvent.type(canvas.getByRole(\"textbox\"), \"Write a blog post\", {\n      delay: 100,\n    });\n    await userEvent.keyboard(\"{enter}\", { delay: 100 });\n    await userEvent.type(canvas.getByRole(\"textbox\"), \"Develop sample app\", {\n      delay: 100,\n    });\n    await userEvent.keyboard(\"{enter}\", { delay: 100 });\n    await userEvent.click(canvas.getAllByRole(\"checkbox\")[1]);\n  },\n};\n```\n\nこのように、Storybook では、Story に play を記述することでインタラクションを表現できます。Storybook 上でインタラクションを確認することができます。\n\n[![storybook_interaction](https://res.cloudinary.com/silverbirder/image/upload/v1694336346/silver-birder.github.io/blog/97cc9410915a-20230423-png.png)](https://res.cloudinary.com/silverbirder/image/upload/v1693364075/silver-birder.github.io/blog/97cc9410915a-20230423.gif)\n\nそれでは、これをテストに活用しましょう。\n\n```typescript\n// src/components/App/App.test.tsx\n\nimport { render, screen } from \"@testing-library/react\";\nimport { composeStories } from \"@storybook/testing-react\";\nimport * as stories from \"./App.stories\";\n\nconst { AddTwoTodosAndCheckOneScenario } = composeStories(stories);\n\ndescribe(\"play AddTwoTodosAndCheckOneScenario\", () => {\n  it(\"renders two todos\", async () => {\n    // Arrange\n    const { container } = render(<AddTwoTodosAndCheckOneScenario />);\n\n    // Act\n    await AddTwoTodosAndCheckOneScenario.play({ canvasElement: container });\n\n    // Assert\n    const todos = screen.getAllByTestId(\"todo-title\");\n    expect(todos).toHaveLength(2);\n  });\n  it(\"checks one todo\", async () => {\n    // Arrange\n    const { container } = render(<AddTwoTodosAndCheckOneScenario />);\n\n    // Act\n    await AddTwoTodosAndCheckOneScenario.play({ canvasElement: container });\n\n    // Assert\n    const todoCheckboxes = screen.getAllByRole(\"checkbox\", { checked: true });\n    expect(todoCheckboxes).toHaveLength(1);\n  });\n});\n```\n\nこのように、Storybook の Story オブジェクトをテストコードに読み込み、play 関数を実行できます。したがって、Storybook で確認したインタラクションがそのままテストコードで動きます。後は、expect を書くだけです。\n\nインテグレーションテストは、ユニットテストよりも非常に価値があるテストを多く実施できます。その理由は、ユーザー目線のテストが可能となるからです。ユニットテストでは、関数やコンポーネントの詳細なテストは可能ですが、それは基本的にエンジニア目線のテストになります。\n\nユニットテストよりもインテグレーションテストが多くなっても問題ありません。ユニットテストとインテグレーションテストのテストが重なるコードがあるかもしれませんが、完璧な必要最小限な網羅的なテストメンテンナンスは現実的ではないため、また、重なっていても困ることもそう多くない場合、許容して良いと思っています。\n\n##### API 通信のモック\n\nフロントエンドは、バックエンドとの通信を発生させることは多々あります。インテグレーションテストやユニットテストでは、API 通信をモックすることがよくあります。通信をインターセプトして、固定データを返却する mswjs/msw が有名です。また、固定データではなく、動的にデータを返却できる mswjs/data というものも便利なので紹介です。\n\nhttps://github.com/mswjs/msw\nhttps://github.com/mswjs/data\n\n#### E2E テスト(システム)\n\nここでは、フロントエンドから API までを含んだ一気通貫のテストを作成します。E2E テストでは、一般的にヘッドレスブラウザを使用したテストが行われます。私は、Playwright を好んで使います。\n\nE2E テストの作成方法としては、エンジニア目線で細かいテストを行うよりも、ビジネス目線で要件を満たすかどうかを確認する受け入れテストを書くことが望ましいでしょう。そこで、ATDD として有名な[cucumber](https://github.com/cucumber/cucumber-js)を用いたサンプルを紹介します。\n\ncucumber では、受け入れのためのシナリオを BDD 形式の gherkin で記述します。また、[gherkin は markdown で作成すること](https://github.com/cucumber/gherkin/blob/main/MARKDOWN_WITH_GHERKIN.md)ができます。\n\nそれでは、簡単な受け入れテストのシナリオを作成してみましょう。以下のようなシナリオになります。\n\n```markdown\n## Feature: Todo App\n\n## Background: The Todo App is opened\n\n- Given the Todo App is opened\n\n## Rule: Adding new Todos\n\n### Scenario: Add a new Todo\n\n- When the user enters a \"new Todo\" and enter key\n- Then the \"new Todo\" is added to the list\n\n### Scenario: Attempt to add an empty Todo\n\n- When the user enters an empty Todo and clicks the Add button\n- Then the Todo is not added to the list and \"Not entered\" message is displayed\n```\n\nこのシナリオを参考にして、テストコードを作成してみましょう。次のようなテストコードを記述します。`World` は、Playwright を使用してヘッドレスブラウザを起動しているだけです。\n\n```typescript\n// features/step_definitions/steps.ts\n\nimport { Given, When, Then } from \"@cucumber/cucumber\";\nimport World from \"../support/World\";\nimport assert from \"assert\";\n\nGiven(\"the Todo App is opened\", async function (this: World) {\n  await this.page.goto(\"https://silverbirder-react-todo-mvc.vercel.app\");\n});\n\nWhen(\n  \"the user enters a {string} and enter key\",\n  async function (this: World, todo: string) {\n    const todoInput = await this.page.getByPlaceholder(\"what you need to do?\");\n    await todoInput.type(todo);\n    await this.page.keyboard.down(\"Enter\");\n  }\n);\n\nThen(\n  \"the {string} is added to the list\",\n  async function (this: World, todo: string) {\n    const todos = await this.page.getByText(todo);\n    assert((await todos.count()) === 1);\n  }\n);\n\nWhen(\n  \"the user enters an empty Todo and clicks the Add button\",\n  async function (this: World) {\n    const todoInput = await this.page.getByPlaceholder(\"what you need to do?\");\n    await todoInput.focus();\n    await this.page.keyboard.down(\"Enter\");\n  }\n);\n\nThen(\n  \"the Todo is not added to the list and {string} message is displayed\",\n  async function (this: World, message: string) {\n    const todos = await this.page.getByTestId(\"todo-title\");\n    assert((await todos.count()) === 0);\n    const messages = await this.page.getByText(message);\n    assert((await messages.count()) === 1);\n  }\n);\n```\n\n`cucumber-js` を実行すると、シナリオをもとにテストが実行されます。\n\n```bash\nnpx cucumber-js\n..........\n2 scenarios (2 passed)\n6 steps (6 passed)\n0m02.504s (executing steps: 0m02.476s)\n```\n\nこのテストをリリース前に実施することで、シナリオで記述された内容が保証されます。ぜひ、リリース前の受け入れテストの実施をご検討ください。\n\n※ Screenplay パターンと呼ばれる、Actor、Task、World についてもお話ししたいのですが、情報量が多くなるため、今回は割愛させていただきます。\n\n### 非機能テスト(Non-Functional)\n\nバックエンドではマシンリソースに対するパフォーマンステストが行われるように、フロントエンドでもブラウザに対するパフォーマンステストが実施されます。パフォーマンスは非機能要件の 1 つです。これから紹介する非機能要件は以下の通りです。\n\n- パフォーマンス\n- レジリエンス\n- ミューテーション\n- 互換性\n- ~~Security~~\n\n#### パフォーマンス\n\nフロントエンド開発では、パフォーマンス問題に直面することは避けられません。パフォーマンス問題が発生した際には、パフォーマンスチューニングが一般的に行われます。DevTool やプロファイラーを活用して問題を特定し、解決を図ります。\n\nしかし、問題解決だけで終わらせてしまうのは非常に勿体ないことです。同じような問題が再発しないように、パフォーマンスに関するテストコードが存在するとさらに良いでしょう。\n\n##### Profiler\n\nReact では、Profiler というツールが提供されており、これを Jest と組み合わせることで効果的にテストが可能です。\n\nhttps://ja.reactjs.org/docs/profiler.html\n\n例えば、TodoList の Todo が 100 個レンダリングされる場合の描画時間を、200ms 未満であることを確認するテストが作成できます。\n\n```typescript\n// src/components/TodoList/TodoList.perf.test.tsx\n\nimport { render } from \"@testing-library/react\";\nimport { TodoList } from \".\";\nimport { Todo } from \"../../types\";\nimport { Profiler } from \"react\";\n\ndescribe(\"TodoList\", () => {\n  it(\"renders with acceptable performance\", () => {\n    // Arrange\n    const onRender = jest.fn();\n    const todos: Todo[] = [...Array(100)].map((value, index) => {\n      return {\n        id: index.toString(),\n        title: \"title\",\n        completed: false,\n      };\n    });\n\n    // Act\n    render(\n      <Profiler id=\"PerformanceTestComponent\" onRender={onRender}>\n        <TodoList todos={todos} />\n      </Profiler>\n    );\n\n    // Assert\n    const [, , actualDuration, , , , ,] = onRender.mock.calls[0];\n    expect(actualDuration).toBeLessThan(200);\n  });\n});\n```\n\nこれは単純な例ですが、実際にはもっと複雑な操作が求められることがあります。パフォーマンスチューニング後に、描画時間などの要件が保証されるようにしましょう。\n\n##### PerformanceObserver\n\nレイアウトの再計算（reflow）が強制的に実行される場合、ブラウザのメインスレッドでの JS 実行時間が長く続く可能性があります。これにより、描画速度が遅れ、フレームレート（fps）が低下することがあります。\n\nこの問題に対処するために、Performance API の中にある、まだ実験段階の機能である PerformanceLongTaskTiming という指標を用いたテストコードを作成することができます。\n\n以下のリンクで Performance API および PerformanceLongTaskTiming に関する詳細情報を参照できます。\n\n- https://developer.mozilla.org/ja/docs/Web/API/Performance_API\n- https://developer.mozilla.org/ja/docs/Web/API/PerformanceLongTaskTiming\n\n具体的にテストコードを作成してみましょう。@playwright/test を利用してみます。\n\n```typescript\nimport { test, expect } from \"@playwright/test\";\n\ntest(\"no long tasks after button click\", async ({ page }) => {\n  // Navigate to the specified URL\n  await page.goto(\n    \"https://googlesamples.github.io/web-fundamentals/tools/chrome-devtools/rendering-tools/forcedsync.html\"\n  );\n\n  // Define a function to observe long tasks\n  const observeLongTasks = async (): Promise<number> => {\n    return await page.evaluate(() => {\n      return new Promise<number>((resolve) => {\n        let longTaskCount = 0;\n\n        // Create a PerformanceObserver to observe long tasks\n        const observer = new PerformanceObserver((entryList) => {\n          for (const entry of entryList.getEntries()) {\n            if (entry.entryType === \"longtask\") {\n              longTaskCount++;\n            }\n          }\n        });\n\n        // Start observing long tasks\n        observer.observe({ entryTypes: [\"longtask\"] });\n\n        // Click the button\n        const button = document.querySelector(\"button\");\n        button.click();\n\n        // Wait for a short time to allow long tasks to be recorded\n        setTimeout(() => {\n          // Stop observing and resolve the promise with the count of long tasks\n          observer.disconnect();\n          resolve(longTaskCount);\n        }, 3000);\n      });\n    });\n  };\n\n  // Observe long tasks after clicking the button\n  const longTaskCount = await observeLongTasks();\n\n  // Expect no long tasks to occur\n  expect(longTaskCount).toBe(0);\n});\n```\n\n以下のコマンドを使用してテストを実行することができます。\n\n```text\nnpx playwright test\n```\n\nこのテストコードによって、longTasks が発生しないことが保証されます。\n\nlongTasks は、50ms を超えるタスクが対象となります（[参照](https://w3c.github.io/longtasks/)）。その他の指標には、`paint`や`layout-shift`などが含まれます。指標の一覧は、[こちらのリンク](https://w3c.github.io/timing-entrytypes-registry/#registry)で確認できます。\n\n##### メモリリーク\n\nSPA のようなフロントエンドの場合、メモリリークが懸念されることがあります。この問題に対処するために、Meta 社が開発した Memlab というツールが便利です。Memlab は、Puppeteer を起動し、画面操作を行い、[V8 におけるヒープメモリのスナップショットを取得しています](https://github.com/facebook/memlab/blob/d93d724a95696ab013631bb86c42283303b7dcd1/packages/core/src/lib/NodeHeap.ts#L93)。\n\nここでは、簡単な Memlab を利用したテストコードを紹介します。\n\n```javascript\n// .memlab/scenario.js\n\n// initial page load's url\nfunction url() {\n  return \"https://silverbirder-react-todo-mvc.vercel.app\";\n}\n\n// action where you suspect the memory leak might be happening\nasync function action(page) {\n  await page.type(\".new-todo\", \"Hello World\");\n  await page.keyboard.press(\"Enter\");\n}\n\n// how to go back to the state before action\nasync function back(page) {\n  await page.hover(\".view\");\n  await page.click(\".destroy\");\n}\n\nmodule.exports = { action, back, url };\n```\n\n`url` は、ベースとなる URL へのアクセスであり、メモリの使用量を監視します。`action` でメモリリークが発生しそうな操作を記述し、`back` で元の状態に戻す操作を行います。\n\nMemlab の実行は、以下のコマンドです。\n\n```bash\nmemlab run --scenario .memlab/scenario.js\npage-load[1.4MB](baseline)[s1] > action-on-page[1.6MB](target)[s2] > revert[1.8MB](final)[s3]\n\ntotal time: 49.2s\nMemory usage across all steps:\n2.1 _________\n1.9 _________\n1.8 _________\n1.7 ______▄▄_\n1.5 ___▄▄_▄▄_\n1.4 ___▄▄_▄▄_\n1.3 ▄▄_▄▄_▄▄_\n1.1 ▄▄_▄▄_▄▄_\n1.0 ▄▄_▄▄_▄▄_\n    1  2  3\n\nNo leaks found\nMemLab found 0 leak(s)\n✨  Done in 51.69s.\n```\n\n#### レジリエンス\n\nフロントエンドでもカオスエンジニアリングテストが実施可能です。\n\nhttps://www.npmjs.com/package/chaos-frontend-toolkit\n\nブラウザの操作はユーザーによって多様です。例えば、以下のようなブラウザ操作が存在します。\n\n- 自由なブラウザバックやマウス、キーボード操作\n- シングルクリックではなくダブルクリック\n\nさらに、ブラウザが外部と通信することはよくあります。ネットワークに関しても、次のような状況が起こり得ます。\n\n- リクエストの失敗や遅延\n- プロキシ環境下でよくあるリクエストの遮断\n\nこのようなカオスを注入してもアプリケーションがクラッシュしないようにテストを書くことは有益であるかもしれません。\n\n例えば、Storybook 上でランダムなクリックを発生させるためのコードは、次のようになります。\n\n```typescript\n// src/components/App/App.stories.tsx\nimport { ComponentStoryObj, ComponentMeta } from \"@storybook/react\";\nimport { App } from \".\";\nimport chaosFrontendToolkit from \"chaos-frontend-toolkit\";\n\ntype Component = typeof App;\ntype Meta = ComponentMeta<Component>;\ntype Story = ComponentStoryObj<Component>;\n\nconst meta: Meta = {\n  component: App,\n};\nexport default meta;\n\nexport const Monkey: Story = {\n  decorators: [\n    (Story) => {\n      chaosFrontendToolkit.gremlins.start();\n      return <Story />;\n    },\n  ],\n};\n```\n\nその後、console.error を監視し、発生しないことを確認するテストコードを書くと良いでしょう。ただし、もしエラーが検出されたとしても、再現できなければ問題解決が難しいため、何らかの方法で追跡しやすいログを残すか、セッションリプレイのように記録するなどの工夫が必要です（シード値があればさらに良いですが）。\n\n#### ミューテーション\n\n突然変異テストという手法が存在します。\n\nhttps://stryker-mutator.io/\n\nこれは、フロントエンドという文脈ではありませんが、面白かったので紹介します。(笑)\n\nStryker は、プロダクションコードを書き換え（突然変異）する際に、テストコードも失敗することを期待するものです。つまり、テストコードのテストを行うイメージです。これにより、偽のテストカバレッジを見抜くことができます。Stryker の設定は、公式ページに従ってセットアップし、`stryker run` を実行するだけです。実際に動かしてみます。\n\n```bash\nstryker run\nINFO ProjectReader Found 4 of 63 file(s) to be mutated.\nINFO Instrumenter Instrumented 4 source file(s) with 47 mutant(s)\nINFO ConcurrencyTokenProvider Creating 2 checker process(es) and 2 test runner process(es).\nINFO DryRunExecutor Starting initial test run (jest test runner with \"off\" coverage analysis). This may take a while.\nINFO DryRunExecutor Initial test run succeeded. Ran 8 tests in 20 seconds (net 8004 ms, overhead 12326 ms).\nMutation testing  [=========================================] 100% (elapsed: ~2m, remaining: n/a) 47/47 Mutants tested (21 survived, 0 timed out)\n\nAll tests\n  ...\n  TodoItem/TodoItem.test.tsx\n    ✘ TodoItem renders todo title [line 18] (covered 0)\n    ✘ TodoItem toggles todo completion [line 30] (covered 0)\n    ✓ TodoItem deletes a todo [line 45] (killed 1)\n```\n\nTodoItem の中で、プロダクトコードを破壊したミュータント（👽）を検出し、対応するテストが失敗した（Killed）ものは、次の画像の通りです。\n\n![mutant_todo_item_1](https://res.cloudinary.com/silverbirder/image/upload/v1693364079/silver-birder.github.io/blog/ec63905e2231-20230423.png)\n\n一方、ミュータントが生き残って（Survived）しまった例として、例えば、className の箇所が挙げられます。\n\n![mutant_todo_item_2](https://res.cloudinary.com/silverbirder/image/upload/v1693364100/silver-birder.github.io/blog/81915c789ace-20230423.png)\n\nclassName は見た目に関わるため、後述するビジュアルリグレッションテストで検出したいところですね。\n\nこのように、ミュータントを見つけてテストの品質を向上させることは、効果的な手段の 1 つだと考えられます。\n\n#### 互換性\n\nフロントエンド開発では、サポート対象のブラウザで動作確認を行う必要があります。ブラウザごとに異なる JavaScript エンジンやレンダリングエンジンがあるため、各ブラウザにおける JavaScript の動作や見た目を確認することが必要です。\n\nクロスブラウザテストには、実機の購入、仮想サーバーの利用、BrowserStack のような SaaS を活用する、Playwright でのマルチブラウザ利用など、さまざまな方法が存在します。費用対効果に見合った選択を行うことが重要です。\n\n### UI/UX\n\nUI/UX は、フロントエンド開発において、切っても切り離せない重要なテーマです。今回は、テスト自動化が可能な非常に小さな部分だけを紹介します。UI/UX の範囲は、人の判断が多く求められる領域であるため、書く内容はあまり多くありません。\n\n#### ビジュアル\n\n見た目は、フロントエンド特有の非常に重要な要素です。レスポンシブデザイン、デスクトップ・モバイルのデバイス、Windows/Mac などの OS、ブラウザの外観に関する機能（ダークモード）など、見た目の変化をテストすることも重要です。\nビジュアルリグレッションテストという手法を開発サイクルに取り入れましょう。Lost Pixel や Chromatic など、様々な手段があるので試してみてください。\n\nhttps://storybook.js.org/docs/react/writing-tests/visual-testing\n\n#### アクセシビリティ\n\nアクセシビリティについては、人の判断が必要なケースもありますが、機械的にチェックできる要素も存在します。キーボード操作のみで機能が正常に動作するか確認するためには、インタラクションテストが必要です。VoiceOver の対応状況はいかがでしょうか？さらに、画像の alt 属性は適切に設定されていますか？文章の表現については人の目で判断が必要ですが、少なくとも入力されているかどうかはチェックできます。\n\nhttps://storybook.js.org/docs/react/writing-tests/accessibility-testing\n\n## その他\n\nテストの観点として、網羅的に知りたいと思いませんか？私は、自前で[point of view](https://docs.google.com/spreadsheets/d/e/2PACX-1vSpbSeaOPVSKyi36bwbBXQ56DbXNzLEp-anI4PHfXps4pa7gWUMDGHjNmVy1gl945o4aNGCszPWxcKm/pubhtml)というものを作成しました。これは、様々な観点の一覧表です。この一覧表から、何かインスパイアされるものを見つけるのが、楽しいですね。\n\n例えば、以下のようなことが考えられます。\n\n- 精度(precision)\n  - バックエンド側の数値は、フロントエンド側の数値の範囲に収まりますか？\n  - JavaScript の Integer の最大値は、9,007,199,254,740,991 です。\n- 耐障害性(fault tolerance)\n  - フロントエンドから、コアなデータ参照と、補助のデータ参照は分けていますか？\n  - 補助のデータ参照が失敗したとしても、アプリケーションが動作できる状態になっているのが良いでしょう。\n\n## 終わりに\n\nいかがでしたでしょうか。フロントエンドにおけるテストパターンは、まだまだ存在すると思います。もし他にもご存知のものがあれば、ぜひ教えてください。","publishedAt":"2023-04-28","slug":"web_frontend_test_pattern_guide","title":"Webフロントエンドにおける網羅的テストパターンガイド"},{"body":"zod の refine を使っていたのですが、path の使い方を全く理解できておらず、小一時間ほどハマってしまったことがあったので、備忘録として残しておきます。\n\n## 背景\n\nzod を使って、バリデーションロジックを書いていました。\nバリデーションで複数フィールドを参照する必要があったため、refine を使っていました。\n\nhttps://github.com/colinhacks/zod#refine\n\n## path\n\nサンプルコードを以下に示します。\n\n```javascript\nimport { z } from \"zod\";\n\nconst schema = z.object({\n  a: z\n    .object({\n      first: z.string(),\n    })\n    .refine(({ first }) => first === \"first\", {\n      path: [\"b\"],\n    }),\n});\n```\n\na というオブジェクトに refine を定義しました。refine の第 2 引数の path に `['b']` を定義しました。\n\nschema のテストをしてみます。\n\n```javascript\nimport test from \"tape\";\n\ntest(\"invalid\", (t) => {\n  // Act\n  const data = schema.safeParse({\n    a: {\n      first: \"BUG\",\n    },\n  });\n\n  // Assert\n  t.deepEqual(data.error.issues[0].path, [\"a\", \"b\"]);\n  t.end();\n});\n```\n\nエラー(issue)の path は、`['a', 'b']` になります。めちゃくちゃ当たり前なんですが、以上です。(笑)\n\nstackblitz にも残しておきました。\n\nhttps://stackblitz.com/edit/nodemon-fkzaw5?file=index.js\n\nzod の github にある path の説明は、`appended to error path` と書いています。","publishedAt":"2023-01-07","slug":"zod_refine_path","title":"zodのrefineにあるpathにハマった"},{"body":"あけまして、おめでとうございます。神社のおみくじで、人生はじめて大吉を引きました、silverbirder です。\n\n普段の業務で、Figma のデザイントークンや API のスキーマファイル、i18n のメッセージファイルなどを、フロントエンドへ同期するコミュニケーションが不毛に感じています。そこで、GitHub Actions と Pull Request を活用して、同期コミュニケーションを削減する仕組みを紹介します。\n\n目新しい情報はないかもしれませんが、同じお困りごとを持つ人へ助けになれば、幸いです。\n\n## GitHub Actions で使用するもの\n\n今回紹介する仕組みの核となるのが GitHub Actions の repository-dispatch トリガーです。\n\nhttps://docs.github.com/ja/rest/repos/repos?apiVersion=2022-11-28#create-a-repository-dispatch-event\n\nこのトリガーは、GitHub API を経由して、GitHub Actions のワークフローを起動することができます。そのため、次のように 異なるリポジトリでの GitHub Actions ワークフローを連携できます。\n\n[![efac2e9d6d0821370603fe52c9cac4017da30ca64df4949c264605124386e36d](https://res.cloudinary.com/silverbirder/image/upload/v1693362902/silver-birder.github.io/blog/efac2e9d6d0821370603fe52c9cac4017da30ca64df4949c264605124386e36d.png)](https://mermaid.live/edit#pako:eNp9kD1rwzAQhv-KuDmmuymeSrbSoaugXKRzLLA-erqDhJD_XslO6RCoBiGO59UrPTdw2ROMUOlbKTl6C3hmjDaZtlAlJ40nYpv2SUGW4ELBJOZDFmKD1ZyDLHr6Yiq5Bsl8fdVKnDDSS-7M9Jw9cm77_9m5M5T89Fu-FQ7TtIVHQxdyKmT-soMPtaC4Zec37pl3TCg0FF3Xgfu3q8ABInHE4JuKW09baGWRLIzt6GlGXcWCTfeGdi2f1-RgFFY6gBbfLnyYg3HGtbYp-f6m913vZvn-A1JSg1Q)\n\nrepository-dispatch と create-pull-request は、次の GitHub Actions です。\n\nhttps://github.com/peter-evans/repository-dispatch\nhttps://github.com/peter-evans/create-pull-request\n\n- respository-dispatch\n  - repository-dispatch-event を dispatch する Action\n- create-pull-request\n  - Pull Request を作成する Action\n\nこれらの GitHub Actions を使わずに `gh` などを使って代替できますが、便利なモノを使って楽をします。\n\n## GitHub リポジトリ以外からのトリガー\n\nGitHub のリポジトリ(username/other)からトリガーだけでなく、他のサービスからでもトリガーできます。例えば、Google Sheets からだと、Google Apps Script から GitHub API を呼べばよいです。\n\n[![207138540b3a001131d8bda0a09520285fb6b001d967242fbca20b8c8db88e0e](https://res.cloudinary.com/silverbirder/image/upload/v1693362926/silver-birder.github.io/blog/207138540b3a001131d8bda0a09520285fb6b001d967242fbca20b8c8db88e0e.png)](https://mermaid.live/edit#pako:eNplkMtqwzAQRX9l0DqmexMMgdK0i0IhW0OYSDexQK9Ko9IQ8u-V7ZYsqpU03Dm6nJvS0UD1quCzImg8W75k9mOgdrhKDNWfkMewThJnsdomDkKHCRDiQpcYLw7HMr_L_9xLjmHNWZnq6ZiRYrES83VbC3Jgj6fznEEww99HC7wbhmW5J83OkUygvZXXeqLdx9v2wemMLYlFTx2-EGSghvO0X2rRLqVCB51tkhW9IB9ofENXAekMFnSpOtfl2UYRtVEe2bM1zdBt3h5VK-Exqr5dDc5cnYxqDPcWnW0drkGrXnLFRtVkGvBXqOrP7EqbwsyV31fri_z7DxDMiec)\n\n他にも、Kibela の outgoing webhook を、Server が受けて、Server が GitHub API を呼び出す方法があります。\n\n[![e3da40e838b6c83226e0337b3e7e920b1eadb09c1be118fa6ab9087d0a5e35ba](https://res.cloudinary.com/silverbirder/image/upload/v1693362959/silver-birder.github.io/blog/e3da40e838b6c83226e0337b3e7e920b1eadb09c1be118fa6ab9087d0a5e35ba.png)](https://mermaid.live/edit#pako:eNplkVtrwzAMhf-K8XPD3k0JDMYujMFgr4ah2Gpi6ttsOVsp_e9z4oxC5wcjDudIH9KZq6CRC57xq6BX-GBgTOCkZ_VBoeCLGzBJ35QIiYwyETyxoxnQwn89Y5qXxK3-mEL9IbPR0FSGz4QxZEMhnfalZjw4vDssHvS6_xvYhnR93wrBStRAuOlMrXbKN-aGIDYUllChmTGz15YKhVRwzviRfeMwhXBs-Wav-RVVMAXWMpqQPRl6LgO7f3_ZX6k7bXIEUlOHc2XoW481em2BP6hK5VUJK3YXi7VdWnadie-4w-TA6Lr_85KWvA5zKLmopcYDFEuSS3-p1uUWHyevuKBUcMfbHrZzcXEAm6uKekF7azddT3v5BVs-q2Y)\n\nServer は、IFTTT や Zapier のようなサービスでも良いですし、自前のサーバーでも良いでしょう。\n\n## 自動 commit\n\nschema ファイルから、型を生成したい(yarn codegen)こともあると思います。そういうときは、次のフローを追加します。\n\n[![84bd13ddb0d7a355068241f2f6a56fad73521f96b19930891ace4a223c2aeee0](https://res.cloudinary.com/silverbirder/image/upload/v1693362977/silver-birder.github.io/blog/84bd13ddb0d7a355068241f2f6a56fad73521f96b19930891ace4a223c2aeee0.png)](https://mermaid.live/edit#pako:eNp9kU9rwzAMxb-K8WmDhNGOHhZGTmO3scOuhqHYSmqI_0yWYaH0u89OOnboqA_CiN-TeHonqYNB2cmEXxm9xhcLE4FTXpQHmYPPbkBSfutEILbaRvAs3vmIJCCJyfIxD5-EMSTLgZbnnJA8OHwIlemvta8USr2tHSuD3vS_y9eFbd-v4k7gN-rMKP60rbEpAuvjxq_cNa8JgbGNeZ5bqrYTbzyhZkHTcLd72jViv38s5XC4_3fYAuRFvd2E_ua2YrCtd2x1cK7-NdtwkRRzspEOyYE1JYRTbStZbDpUsitfgyPkmZVU_lzQOuhj8Vp2TBkbmaMpVi6ZyW6EOZUumnqNty3YNd_zD41uqeo)\n\ngit-auto-commit-action は、変更したファイルを git commit するだけの Action です。\n\nhttps://github.com/stefanzweifel/git-auto-commit-action\n\ncreate-pull-request だけでも、自動 commit することができます。私は、次のケースで使用しました。\n\n- Figma の[Design Tokens](https://github.com/lukasoppermann/design-tokens)で、Figma 上から Pull Request を作成する。\n  - GitHub Actions で、style dictionary の build したものを commit したい\n\n```yml\non:\n  pull_request:\n    types: [opened]\njobs:\n  update:\n    if: startsWith(github.head_ref, 'figma/')\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n      - run: npm ci\n      - run: npx style-dictionary build\n      - uses: stefanzweifel/git-auto-commit-action@v4\n```\n\n## Preview\n\nFigma のデザイントークンや、i18n のメッセージファイルを更新したとき、Preview できる仕組みがあると、画面の確認ができて、良いです。\n\n[![77341dff8054c17e4df812bd7d2bf51737cc4e3c3ce113168e878f8030b18a31](https://res.cloudinary.com/silverbirder/image/upload/v1693362979/silver-birder.github.io/blog/77341dff8054c17e4df812bd7d2bf51737cc4e3c3ce113168e878f8030b18a31.png)](https://mermaid.live/edit#pako:eNp9kUtLAzEUhf9KyEqhg7TShYPMqnQnLtwOSJqczgQmD29u1FL6301mFBcVs7iEw3fu8yx1MJCtTHjL8Bo7qwZSrveiPJU5-OwOoN4vSlTEVtuoPItnHkFCJTFYHvPhlRBDshzo9JgTyCuHu1CZ7tq7p1Di_95jZeBN91N8Lth03WxuBT6hM0P8ehtjU1Ssx4WfuWteExSjiXmaGqpjJ154gmZBw-Fm_bBeic3mvoTt9vbPZJHwbvEhdohTODl4TgtXGpYr6UBOWVMWe65yL0vrDr1sy9fgqPLEvez9paB1yS8nr2XLlLGSOZrS3vcdZHtUUyoqTJ3waTnWfLPLF6JHmvQ)\n\n例えば、vercel や chromatic の preview です。\n\nhttps://vercel.com/docs/concepts/deployments/preview-deployments\nhttps://www.chromatic.com/docs/review\n\n## サンプルコード\n\ni18n のメッセージファイルをフロントエンドへ同期する GitHub Actions を、紹介します。\n\n| repository        | やること                        |\n| ----------------- | ------------------------------- |\n| username/frontend | i18n のメッセージファイルを利用 |\n| username/message  | i18n のメッセージファイルを管理 |\n\n[![253d2d7c485f079449b9bf2b259f325d45156b1d538d78bda0c158049af50dfe](https://res.cloudinary.com/silverbirder/image/upload/v1693363954/silver-birder.github.io/blog/253d2d7c485f079449b9bf2b259f325d45156b1d538d78bda0c158049af50dfe.png)](https://mermaid.live/edit#pako:eNp9kk9LxDAQxb9KyGFR2CrepEgviuChJ68FmU1m22gziZNELct-d9M_6yKum0MIk_fLPCZvJ5XTKEsZ8D0hKXww0DLYhkRekKKjZDfIDS0VFR2LGkOAFmugvPN844GjUcYDRVELCKI1sUubF0bvgsnUcJcCMoHFazvz1V_ykV3ez9PbUYOkq4Op33aKqqrLkRfKWWviRfIaIgpzc0uHzlevwdGlWK0mnU-hW17K8GShFPiFKmXs6KDQJniIatFOuqN-ACbRIiHnZuXS56Ty8LJizNLCp74veBx_iCf1HkIQ90-n7xg_DH4Kjb53g0WK4Z-ZLIDqUL0JRz9kyDaQzkMWuUUxGhWLUbmWuWjB6Jyd3Ug3MnZosZFlPmrcQupjIxvaZ-mYo-eBlCwjJ1zL-UeWqMlyC33IVdTjmOs5j1Ms9987Oeuw)\n\n```yml\n## <username/message>/.github/workflows/main.yml\non:\n  push:\n    branches:\n      - main\n    paths:\n      - \"i18n/**\"\njobs:\n  dispath:\n    name: Setup\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: peter-evans/repository-dispatch@v1\n        with:\n          repository: username/frontend\n          token: ${{ secrets.PAT }}\n          event-type: create-pull-request-message\n          client-payload: '{\"ref\": \"${{ github.ref }}\"}'\n```\n\n```yml\n## <username/frontend>/.github/workflows/main.yml\non:\n  repository_dispatch:\n    types: [create-pull-request-message]\njobs:\n  createPullRequest:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/checkout@v3\n        with:\n          repository: username/message\n          ref: ${{ github.event.client_payload.ref }}\n          path: \"tmp/\"\n      - run: |\n          mv tmp/message.json src/message.json\n          rm -rf tmp\n      - uses: actions/setup-node@v3\n      - run: npm ci\n      - run: yarn generate:message\n      - uses: peter-evans/create-pull-request@v4\n```\n\n## 受け入れテストをマークダウンで管理\n\n安心してマージできるように、受け入れテストを整備しておきましょう。\n\n具体的には、[cucumber](https://cucumber.io/)で仕様書を[Markdown(MARKDOWN_WITH_GHERKIN)](https://github.com/cucumber/gherkin/blob/main/MARKDOWN_WITH_GHERKIN.md)で管理します。\n\n例えば、次のような仕様書です。\n\n```markdown\n## Feature: Staying alive\n\nThis is about actually staying alive,\nnot the [Bee Gees song](https://www.youtube.com/watch?v=I_izvAbhExY).\n\n## Rule: If you don't eat you die\n\n![xkcd](https://res.cloudinary.com/silverbirder/image/upload/v1693363969/silver-birder.github.io/blog/lunch_2x.png)\n\n`@important` `@essential`\n\n### Scenario Outline: eating\n\n- Given there are <start> cucumbers\n- When I eat <eat> cucumbers\n- Then I should have <left> cucumbers\n\n#### Examples:\n\n| start | eat | left |\n| ----- | --- | ---- |\n| 12    | 5   | 7    |\n| 20    | 5   | 15   |\n```\n\nこの Markdown も、GitHub Actions で Pull Request するフローに載せましょう。新しいシナリオが追加された場合、(cucumber のライブラリ上) テストコードが存在しないとエラーとなります。\n\n機能で担保したいシナリオを Markdown で管理していくことで、次のメリットがあります。\n\n- 仕様が明確になる\n- CI で受け入れテスト(cucumber)を動かし成功すると、仕様を満たす状態 となる\n\n## ハマったこと\n\n### GitHub Actions Bot の commit で、他のワークフローをトリガーできない\n\nhttps://github.com/orgs/community/discussions/27028\n\ntoken に、PAT を渡すように変更すれば解決します。\n\n他の解決策としては、workflow_run のトリガーを使えます。\n\nhttps://docs.github.com/ja/actions/using-workflows/events-that-trigger-workflows#workflow_run\n\nただし、デフォルトブランチでのみ動作します。\n\n### repository-dispatch の POST は、JSON で制限がある\n\nhttps://github.com/peter-evans/repository-dispatch#client-payload\n\n同期したいファイルを json に変換して、dispatch する event ペイロードに含めようと、当初考えていました。ただ、次の懸念があったため、却下しました。\n\n- json にしてしまうとコメントが消える\n- JSON のバイトサイズに上限がある\n\nそこで、同期したいリポジトリの github.ref を event ペイロードに含めて、event を受けた側がソースコードをチェックアウトして使う方針に切り替えました。\n\n## 終わりに\n\nGitHub Actions と Pull Request を活用することで、自動的にアプリケーションのソースコードを更新する仕組みを簡単に組み立てられます。\nこのような Ops があれば、Slack でのメッセージラリーをする回数が減らせられます。ぜひ、ご活用ください。","publishedAt":"2023-01-03","slug":"automated_synchronisation_using_github_actions_and_pull_requests","title":"GitHub ActionsとPull Requestを活用した、同期の自動化"},{"body":"2022 年の終わりに近づきました。今年の振り返りをしようと思います。\nこれは、自分のために書いていくので、文章の構造化とか不適当にやります。\n\n## 仕事\n\n今年の 1 月から、新しい職場で働き始めました。人生 2 回目の転職です。\n2 回目となると、転職関連の手続きは随分と慣れました。\n\n新しい職場では、Slack や Discord でコミュニケーションを取るのですが、ボケるコメントが多く、とても賑やかで楽しい職場です。クスっと笑えるので、居心地良い環境だなと思います。\n\n私はフルスタックなエンジニアリング力を経験してきたのですが、改めてフロントエンドエンジニア力を高めたいと思い(もともと IT 業界に入ったきっかけは Web フロントエンド)、転職してみました。\n\nただ、入社して半年ぐらいはドメインキャッチアップやバックエンド開発などをしていました。\n\n特別な領域のドメインのため、それの勉強や、バックエンドのプログラミング言語も馴染みがないものだったので、色々と一杯一杯でした。\n\n半年が経過したあたりから、フロントエンド開発に投資できるようになり、業務で初めて React や TypeScript を試すことができました。\n\n1 つの画面を React に置き換えるプロジェクトを終え、すごいインターン生のフロントエンドレビューをひたすらしたり、フロントエンド刷新プロジェクトにチャレンジして、フロントキャリアが長い方と数ヶ月一緒に仕事をして、ドンドンと右肩上がりに吸収できていると満足しています。\n\nまた、私は本来、React などのフレームワークよりもブラウザの仕組みや、HTML や WebAPI の仕様を読むという方が好きなので、それは継続していこうと思います。\n\n今年の 11 月から、名古屋拠点のメンバーと仕事をすることになり、私が住む大阪から新幹線通勤することになりました。そこでは、エッジなアーキテクチャを採用していて、それを楽しみに、今全力投球しています。\n\n## プライベート\n\nわたしは、妻と二人で暮らしています。僕ら二人の気持ちとしては、そろそろ子供がほしくなってきました。祖父母や両親に、僕らの子を見させてあげたいと思っています。\n\n妊活って、まったくわかりませんでした。\n自然妊娠がなかなかできずに、とても悩みました。\n職場の人から、不妊治療というのを教えてもらい、妻と相談し紆余曲折あって、不妊治療の検査に進むことができました。妻が保育士で多忙のため、なかなか検査にいく時間がないため、まだ検査は終わっていません。\n\n妊活を進めていく中で、妻に精神的な負荷がかかってしまい、つらいときがありました。最近は、『子供は授かりもの』と運だと割り切り、できたら良いよねと思い始めるようになりました。\n\n## お金と時間\n\n来年の 4 月ぐらいに、祖父母が所有する空き家を貰い住むことなりました。理由としては、空き家が実家の近くのため、両親の近くだと何かと安心できるから (子供の件で) です。\n祖父母としても、他界する前に相続でバタバタして貰いたくないので、空き家を誰かに貰って欲しかったとのことでした。僕らとしても、家賃を払わなくて済む (固定資産税は年 2,3 万程度 だけで良い) ので、引き受ける決意をしました。\n\nそうすると、支出がめちゃくちゃ抑えることができ、貯金も四捨五入したら 1000 万はあるため、妻には来年 4 月には働かず自由になって貰うつもりです。\n\nお金はいくらでも欲しくなるのですが、正直私としてはお金よりも家族との時間を優先したいと常々思っています。\n\nそのため、週 5 日の 8 時間勤務の正社員を継続するのか、もしくは契約社員やちょっとした副業でもやろうかと悩んでいます。\n\n副業だと、以前やっていたプログラミングを教えるサービスをもう一度やろうかなと思ったり。\n\nもしくは、人の写真を撮るのが好きで、写真って思い出にも残るし、いつか見返したときの温かい気持ちになれる素敵なアイテムだと思ってて、そういうのをちょっとした副業とかにもつなげてみるのも、面白そうだなと思います。\n\n## 来年の抱負\n\n仕事よりも、家族の時間を大切にしたいと思います。\n\nと言いつつも、モノづくりは結局楽しいので、趣味の範囲でワチャワチャしつつ、仕事でスキルアップしていこうと思います。\n\n## 過去の振り返り\n\n過去の振り返りを読んでみると、なんだかエモい気持ちになりました。\n\n- [2020 年の振り返り](https://silverbirder.github.io/blog/contents/2020_furikaeri/)\n- [2021 年の振り返り](https://silverbirder.github.io/blog/contents/2021_furikaeri/)\n\n結局、車の購入は見送りました。交通機関が充実してる地域に住んでいるため、まだデメリットが大きく感じました。","publishedAt":"2022-12-03","slug":"2022_furikaeri","title":"2022年の振り返り。転職と妊活"},{"body":"DAZN の Luca Mezzalira さんが書かれた[マイクロフロントエンド](https://www.oreilly.co.jp/books/9784814400027/) を読みました。簡単な書籍レビューを残しておこうかなと思います。\n\n## なぜマイクロフロントエンドを使うのか\n\n従来のモノリスなフロントエンドから、マイクロフロントエンドに置き換えることで、どういう価値があるのでしょうか。\n書籍に書いてある内容と、自身の意見を混ぜて以下に列挙します。\n\n- 機能開発のイテレーションが短くなる\n  - 1 チームに 1 サブドメインという小さなスコープのため\n- チーム内の意思決定がしやすい\n  - コードベースが小さいため\n- リリース速度が早い\n  - 各チームが独立しているため\n\n1 チームが小さなサブドメインで独立することで、開発やコミュニケーション、リリースなどのコスト低減ができます。\nこれは、最終的には顧客への価値提供するサイクルを短くすることに繋がります。\n\n## マイクロフロントエンドの導入方法\n\n書籍には、実例として既存アプリケーションをマイクロフロントエンドへマイグレーションする話があります。\nマイクロフロントエンドは、その設計の性質上、基本的に(既存アプリケーションからの)マイグレーションとセットです。\nそのため、マイグレーションをどのように進めるかというのは、とても重要です。\n\nその中で、マイクロフロントエンドへの最初の一歩として、次のパターンがあります。\n\n- 共有コンポーネントをマイクロフロントエンドとしてリリース\n- 新機能をマイクロフロントエンドとしてリリース\n- 既存アプリケーションの一部をマイクロフロントエンドとしてリリース\n\n要は、段階的に導入しましょうという話です。\nまた、マイクロフロントエンドには、従来の SPA 開発に似ている垂直分割という方法が最初の一歩としてお勧めのようです。\n\n- 垂直分割\n  - 1 つの画面に 1 つのマイクロフロントエンド\n- 水平分割\n  - 1 つの画面に複数のマイクロフロンエンド\n\nちなみに、マイクロフロントエンドとコンポーネントは、次のように区別します。\n\n- マイクロフロントエンド\n  - サブドメインのビジネス表現\n  - ロジックをカプセル化し、イベント通信\n- コンポーネント\n  - 再利用性の目的で使用される技術的ソリューション\n  - 拡張しやすく複数のプロパティを公開\n\n## 書籍にあった好きな言葉\n\n付録にある、New Relic で働かれている Erik Grijzen さんのインタビュー記事にて、\n\n- Q. マイクロフロントエンドを 3 語で表現すると\n- A. Scaling UI Development\n\nという回答がありました。\n`Scaling UI Development` という言葉、めちゃくちゃ好きになりました。\n\nマイクロフロントエンドは、フロントエンドをサブドメインで分割し、小さく独立した開発が可能となります。\n大規模な 1 つのアプリケーション開発や、1 つのブランド内の様々なプロダクトを提供するアプリケーション開発に対しては、マイクロフロントエンドは効果的だと思っています。\n\n## 終わりに\n\n余談ですが、ブログを書く時間が、徐々に減っています。\n1 年前とかは、1 日とか使っていたんですが、今日は 30 分とかです。\n効率化できている訳じゃなく、単純に時間がなくなってきたなと思います。","publishedAt":"2022-11-13","slug":"review_of_micro-frontends_book","title":"「マイクロフロントエンド」を読みました"},{"body":"WikiWikiWeb というコンセプトが好きで、そのコンセプトが含まれている Obsidian や Scrapbox が好きです。Obsidian には、[obsidian-git](https://github.com/denolehov/obsidian-git) という Git 連携のプラグインがあります。こちらには、デスクトップだけでなく、モバイルからでも Git Commit できます。\nそこで、私が持ってる iPhone を使って、Obsidian で Git Commit する手順を紹介します。\n\n## 手順\n\n1. iPhone から https://obsidian.md/ にアクセスし、アプリをダウンロード\n\n1. アプリを開いて、Create new vault をタップ\n\n![obsidian_1](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_1.png)\n\n1. Vault name に、適当な名前を入力 (後で変更可能)し、Create をタップ\n\n![obsidian_2](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_2.png)\n\n1. 左上のサイドバーアイコン → 設定アイコン → コミュニティプラグイン → コミュニティプラグインを有効化 の順でタップ\n\n![obsidian_3](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_3.png)\n\n1. コミュニティプラグインを閲覧 → Git を入力 → Obsidian Git をタップし、インストール → 有効化をタップ\n\n![obsidian_4](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_4.png)\n\n1. オプションをタップ\n\n![obsidian_5](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_5.png)\n\n1. Github のアカウント、[Personal Access Token](https://docs.github.com/ja/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token) (repo の権限があれば良い) を入力. バツボタンをタップし、4 の画面に戻る\n\n![obsidian_6](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_6.png)\n\n1. 下へスクロールして、コマンドパレットを表示 → Clone と入力し、表示された選択肢をタップ\n\n![obsidian_7](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_7.png)\n\n1. Clone したいリポジトリ URL を入力\n\n![obsidian_8](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_8.png)\n\n1. Vault Root をタップ\n\n![obsidian_9](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_9.png)\n\n1. NO をタップ (.obsidian フォルダが repository にあるなら YES)\n\n![obsidian_10](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_10.png)\n\n1. Clone が成功すると、リポジトリのファイルが閲覧できる\n\n1. Obisidian Git の Advanced に、Author name と Authr email を入力し、バツをタップ\n\n![obsidian_12](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_12.png)\n\n1. ファイルを適当に変更する\n\n1. 下へスクロールし、コマンドパレットを開く → Git Open source と入力し、表示された選択肢をタップ\n\n![obsidian_16](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_16.png)\n\n1. +ボタンで Stage、チェックボタンで Commit、アップロードボタンで Push できる\n\n![obsidian_15](https://res.cloudinary.com/silverbirder/image/upload/c_scale,w_400/v1666182104/silver-birder.github.io/blog/Obsidian_15.png)\n\n## 困ったこと\n\n- スマホから、ブランチを作成できるが Push できない\n- スマホから、ローカルには存在しないリモートブランチを(pull しても)Switch できない\n\n基本的には、スマホからの操作は、main ブランチでコミットプッシュするしかできなさそうです。\n\n## 終わりに\n\nこれから、スマホからいろいろメモを書いていこうかなと思います！","publishedAt":"2022-10-18","slug":"obsidian-git-muti-device","title":"ObsidianでiPhoneからGit Commitする"},{"body":"GraphQL Guild ってご存知ですか？\nGraphQL 界隈だと、Code Generator が有名と思いますが、GraphQL Guild は、それら GraphQL 関連の OSS を開発しているグループです。([詳しくは、こちら](https://the-guild.dev/about-us))\n\nGraphQL Guild のエコシステムって便利だな〜って感じたことがあったので、紹介します。\n試したソースコードは、こちらにあります。\n\n- https://github.com/silverbirder/playground/tree/main/node/supabase-graphql-guild-app\n\n## GraphQL Schema をダウンロードできる\n\nスキーマ駆動開発をすると、GraphQL のクライアントとサーバーのリポジトリ(GraphQL Schema が置いてある)が分かれることがあります。そうすると、クライアントのリポジトリに、サーバーのリポジトリにある GraphQL の Schema が欲しくなると思います。その状況では、次の解決手段が想像できると思います。\n\n- git submodule で、サーバーリポジトリをクライアントリポジトリに入れる\n- git clone で、GraphQL Schema ファイルをダウンロードするスクリプトを書く\n\ngit を扱うと、CI/CD のプロセスやいくつかの場面で、面倒なことがあります。\nそこで、GraphQL の SchemaURL を指定するだけで、Schema をダウンロードする機能が、`GraphQL CLI` にあります。\n\n- https://www.graphql-cli.com/introduction\n\n具体的には、`GraphQL Config` を作成し、`graphql codegen` と実行します。\n\n- https://the-guild.dev/graphql/config/docs\n\nSchema をダウンロードするために、GraphQL のエンドポイント URL を指定します。\n\nConfig ファイルの形式は、yml、json、js、ts のどれかを選べます。\n私の場合、(supabase を使っている関係で)GraphQL のエンドポイントへアクセスする認証情報を環境変数から読み込みたかったため、Typescript(ts)を選びました。\n\n具体的には、次の Config ファイルを生成します。\n\n```typescript\n// graphql.config.ts\nimport type { IGraphQLConfig } from \"graphql-config\";\nimport { config } from \"dotenv\";\n\nconfig();\n\n/** @type {import('graphql-config').IGraphQLConfig} */\nconst graphqlConfig: IGraphQLConfig = {\n  schema: [\n    {\n      [`${process.env.SUPABASE_URL}/graphql/v1`]: {\n        headers: {\n          apikey: process.env.SUPABASE_ANON_KEY || \"\",\n          authorization: `Bearer ${process.env.SUPABASE_ANON_KEY}`,\n        },\n      },\n    },\n  ],\n  extensions: {\n    codegen: {\n      generates: {\n        \"generated/schema.graphql\": {\n          plugins: [\"schema-ast\"],\n        },\n      },\n    },\n  },\n};\n\nexport default graphqlConfig;\n```\n\n必要なパッケージをインストールした状態で、`graphql codegen` と実行すると `generated/schema.graphql` が生成されます！\n\n## GraphiQL が Config だけで動く\n\nGraphQL を利用する側としては、どのようなクエリが書けるか試せす場所が欲しくなります。\nサーバー側から GraphiQL を用意頂くでも全然良いのですが、`GraphQL Yoga` というものを使えば簡単にできます。\n\n- https://the-guild.dev/graphql/yoga-server\n\n`yarn add graphql-yoga` したあとに、先程の `graphql.config.ts` が存在すれば、`yarn yoga` するだけで GraphiQL が手に入ります！一切、サーブするコードを書いていません。最高でした。\n\n## GraphQL CLI には色々便利な機能がある\n\n`GraphQL CLI` には、GraphQL 関連で便利な機能があります。\n\n- https://github.com/Urigo/graphql-cli\n\n具体的には、次の 3 つです。\n\n- `@graphql-cli/coverage`\n  - Document のオペレーションを元に、Schema がどれくらい使われているかわかる\n- `@graphql-cli/diff`\n  - ローカルとリモートの GraphQL Schema の違いを教えてくれる\n- `@graphql-cli/validate`\n  - Document のオペレーション が、GraphQL Schema 定義に反していないかチェックしてくれる\n\n## 終わりに\n\nGraphQL Guild は、GraphQL Config が中心になっている印象を受けました。\nConfig があれば、他のエコシステムはそれを見て機能が動くため、準備するものが少なくて済みます。\n\n関係ないですが、supabase で GraphQL を使うのもすごく簡単で、ありがたいです。","publishedAt":"2022-10-15","slug":"graphql_guild_ecosystem_is_useful","title":"GraphQL Guildのエコシステムって便利だね"},{"body":"スクレイピングしたいときって、あると思います。\nCrawlee という OSS が便利だったので、共有します。\n\n## 背景\n\nスクレイピングしようと思うと、得意な言語でクローリングプログラムを書いて、html をスクレイピングすると思います。\n私は、Node.js が得意なので、fetch + jsdom で書くことが多いです。ブラウザレンダリングが必要な場合、ヘッドレスブラウザを使うこともあります。\n毎回これを組み立てるのが、ちょっと面倒だなと思います。そういうときに、Crawle という OSS が便利でした。\n\n## Crawle\n\nhttps://crawlee.dev/ より引用します。\n\n> Crawlee is a web scraping and browser automation library.\n> It helps you build reliable crawlers. Fast.\n> Crawlee won't fix broken selectors for you (yet), but it helps you build and maintain your crawlers faster.\n\nCrawlee は壊れたセレクタを直せませんが、クローラーを素早く作ることができます。\n\n## Crawle の良いところ\n\nCrawle の良いなとおもった特徴を挙げます。\n\n### crawlee のテンプレートがある\n\ncrawlee は、`npx crawlee create` でコード生成できます。\n\n```bash\nnpx crawlee create my-crawler\n? Please select the template for your new Crawlee project (Use arrow keys)\n❯ Getting started example [TypeScript]\n  Getting started example [JavaScript]\n  CheerioCrawler template project [TypeScript]\n  PlaywrightCrawler template project [TypeScript]\n  PuppeteerCrawler template project [TypeScript]\n  CheerioCrawler template project [JavaScript]\n  PlaywrightCrawler template project [JavaScript]\n```\n\nTypeScript のサポートがあります。\nまた、Crawler はデフォルトで plain HTTP crawler である Cherrio を採用しています。\n必要に応じて、Playwright や Puppeteer を使うことができますし、Crawler の切り替えもインターフェースが揃っているため、簡単にできます。\n\n- https://crawlee.dev/docs/quick-start#choose-your-crawler\n\n### RequestQueue という仕組み\n\nクローラで、復数の URL にアクセスすることは、よくあると思います。\nリクエストは、RequestQueue というキューで管理され、自動的にクローラがアクセスしていきます。\nキューはユニークな URL で管理されるため、重複したアクセスはありません。\n\n- https://crawlee.dev/api/core/class/RequestQueue\n\nこの仕組みは、次のような簡単なコードで実現できます。\n\n```javascript\nimport { RequestQueue } from \"crawlee\";\nconst requestQueue = await RequestQueue.open();\nawait requestQueue.addRequest({ url: \"https://crawlee.dev\" });\n```\n\nさらに、enqueueLinks という機能があります。これは、アクセスしているページの anchor の URL を RequestQueue に追加します。\n次のコードが、enqueueLinks の例です。\n\n```javascript\nimport { CheerioCrawler } from \"crawlee\";\nconst crawler = new CheerioCrawler({\n  async requestHandler({ enqueueLinks }) {\n    await enqueueLinks();\n  },\n});\nawait crawler.run([\"https://crawlee.dev\"]);\n```\n\nenqueueLinks には、様々なオプションがあります。\n\n- https://crawlee.dev/api/core/function/enqueueLinks\n\n例えば、リンクを globs でフィルタリングしたり、anchor のセレクタを指定できたりします。\n\n### データは JSON で保存される\n\nスクレイピングで手に入れたデータは、json で保存できます。\n\n- https://crawlee.dev/docs/introduction/saving-data\n\n例えば、リクエストした URL を集めたいときは、次のようなコードです。\n\n```javascript\nimport { CheerioCrawler, Dataset } from \"crawlee\";\n\nconst crawler = new CheerioCrawler({\n  async requestHandler({ request }) {\n    await Dataset.pushData({ url: request.url });\n  },\n});\nawait crawler.run([\"https://crawlee.dev\"]);\n```\n\n保存先は、`{PROJECT_FOLDER}/storage/datasets/default/` になります。\nめちゃくちゃく簡単にデータが保存できます。\n\n## 終わりに\n\nCrawlee の SaaS として、Apify があります。これで気軽に試してみるのもありかもしれません。\n\n- https://apify.com/","publishedAt":"2022-09-14","slug":"crawlee-was-useful-for-crawling","title":"クローリングをシュッとやるのに、Crawleeが便利だった"},{"body":"vercel 製の turborepo という ビルドシステムが爆速なモノレポツールがあります。\n爆速にする機能の 1 つに、リモートキャッシュというものがあります。\nこの機能は vercel のキャッシュサーバを使うのですが、キャッシュサーバをセルフホストする方法もあります。\n今回は、それを紹介します。\n\n## なぜ、セルフホストしたいのか\n\nvercel のキャッシュサーバを使う場合、vercel のアカウントが必要です。\n[vercel の pricing](https://vercel.com/pricing)を見ると、個人利用(Hobby)では無料ですが、会社(Pro)で使うとすると、`$20 per user / month` という価格になります。費用対効果に見合うならそれで良いかもしれませんが、まだそれがわからない段階でコストをかけられない場面もあると思います。そこで、[公式にも書いてある](https://turborepo.org/docs/core-concepts/remote-caching#custom-remote-caches)とおり、キャッシュサーバをセルフホストする方法があります。\n\n## ローカルで、やってみた\n\n実際に試してみました。ソースコードは、次のリンクにあります。\n\n- https://github.com/silverbirder/turborepo-with-selfhost-remote-cache\n\n手元に Git clone して、README に従って動作確認できると思います。必要なソフトウェアは、Docker と Yarn です。\n\n### キャッシュサーバの準備\n\nセルフホストする場合、キャッシュサーバを建てる必要があります。\nキャッシュサーバは、https://github.com/fox1t/turborepo-remote-cache を使うと良いです。\nDocker イメージが公開されているので、それを使っても良いですし、自前で `docker build` しても良いです。\n\n- Docker イメージ\n  - https://hub.docker.com/r/fox1t/turborepo-remote-cache\n\nキャッシュサーバには、最低でも次の 2 つを環境変数を設定する必要があります。\n\n- TURBO_TOKEN\n  - turborepo と api を繋げるための TOKEN\n- STORAGE_PATH\n  - キャッシュオブジェクトを保存するパス\n  - STORAGE_PROVIDER が `s3` を指定する場合は、バケット名\n\n簡単にするため、次の.env ファイルを用意しました。\n\n```text\n## .env\nTURBO_TOKEN=mytoken\nSTORAGE_PATH=/storage/\n```\n\nあとは、キャッシュサーバを起動するために、docker-compose を書きます。\n\n```yml\n## docker-compose.yml\nservices:\n  remote-cache:\n    image: fox1t/turborepo-remote-cache:latest\n    env_file:\n      - .env\n    ports:\n      - \"3000:3000\"\n```\n\n次のコマンドで、キャッシュサーバを起動しましょう。\n\n```bash\ndocker-compose up -d\n```\n\nこれで、キャッシュサーバは PORT:3000 番 で起動します。\n\n### turbo build\n\nでは、実際に turborepo からつながるか、試してみます。\n\nturborepo は、`npx create-turbo@latest` で作成できます。\n作成後、作成したフォルダで次のコマンドを実行します。\n\n```bash\nyarn\nyarn turbo run build --team=\"team_myteam\" --token=\"mytoken\" --api=\"http://localhost:3000\"\n```\n\nturbo コマンドのオプションで、3 つ指定します。\n\n- team\n  - キャッシュを保存するときの名前空間の役割\n- token\n  - 先程定義した環境変数\n- api\n  - キャッシュサーバの URL\n\n実行すると次のログが表示されるはずです。\n\n```bash\nyarn run v1.22.19\nturbo run build --team=team_myteam --token=mytoken --api=http://localhost:3000\n• Packages in scope: docs, eslint-config-custom, tsconfig, ui, web\n• Running build in 5 packages\n• Remote computation caching enabled\nweb:build: cache miss, executing 082bae5de9b1745f\ndocs:build: cache miss, executing 5a55c6367c8caf01\n...\n```\n\n`Remote computation caching enabled` で、リモートキャッシュが有効となりました。\n初回の場合、cache miss となります。ハッシュ値は、`web: 082bae5de9b1745f` と `docs:5a55c6367c8caf01` になります。\nキャッシュがローカルに保存されるため、削除します。\n\n```bash\nrm -rf node_modules/.cache/turbo\n```\n\nではもう一度、turbo build してみましょう。\n\n```bash\nyarn turbo run build --team=\"team_myteam\" --token=\"mytoken\" --api=\"http://localhost:3000\"\nyarn run v1.22.19\n/Users/silverbirder/docker/node/turborepo-with-selfhost-remote-cache/node_modules/.bin/turbo run build --team=team_myteam --token=mytoken --api=http://localhost:3000\n• Packages in scope: docs, eslint-config-custom, tsconfig, ui, web\n• Running build in 5 packages\n• Remote computation caching enabled\ndocs:build: cache hit, replaying output 5a55c6367c8caf01\nweb:build: cache hit, replaying output 082bae5de9b1745f\n```\n\nどうでしょうか、`cache hit` と表示されています。手元にキャッシュがないのにも関わらず、リモートのキャッシュサーバにキャッシュがあるため、`cache hit` となります！\n\n### キャッシュオブジェクト\n\nキャッシュのオブジェクトは、ハッシュ値名で、アウトプット(file やログ)のバイナリになります。\nDocker コンテナ内で見ると、次のようなファイルが置かれています。\n\n```bash\nls -hl storage/team_myteam/\ntotal 5392\n-rw-r--r--  1 silverbirder  staff   1.3M Sep 11 16:20 082bae5de9b1745f\n-rw-r--r--  1 silverbirder  staff   1.3M Sep 11 16:20 5a55c6367c8caf01\n```\n\n--team オプションで指定した名前で、フォルダが作成されています。\nそのため、team 毎にキャッシュが作成されます。\n\n### キャッシュとは\n\nturborepo のキャッシュについては、[公式](https://turborepo.org/docs/core-concepts/caching) を読むと良いでしょう。\n\nざっくりいうと、次の流れで cache miss,cache hit になります。\n\n1. turbo build を実行\n1. turbo.json の`build`タスクの inputs(ソースコードなど)や環境変数をハッシュ化\n1. キャッシュが既にローカルまたはリモートに存在していなければ、cache miss\n1. turbo.json の`build`タスクの outputs(dist フォルダ、標準出力など)をバイナリ化し、ハッシュ名で保存\n\n3 の手順で、キャッシュが存在していれば、`cache hit` となり、outputs が復元します。\n\n## クラウドで、やってみた\n\nキャッシュサーバは、AWS や GCP などのクラウドベンダーにあるコンピューティングリソースへデプロイしましょう。\nDocker イメージがあるので、AppRunner や CloudRun が楽にできそうです。\n\nキャッシュストレージは、いまのところ AWS S3 のみ対応とのことです。\nAWS S3 のクライアントは、[S3Client を使っているため、GCS にも対応可能](https://zenn.dev/mizchi/articles/s3-compatible-client)です。まあ README に従うなら、S3 に配置するのがベターでしょう。コンピューティングリソースを動かす IAM は、ストレージリソースへの READ/WRITE 権限を足しましょう。\n\n## おわりに\n\nセルフホストして、リモートキャッシュが使えるようになりました。\nまだ運用したことがないので、課題を実感していません。引き続き、利用してみようと思います。","publishedAt":"2022-09-11","slug":"self-hosted_cache_server_with_turborepo-remote-cache","title":"turborepo-remote-cache でキャッシュサーバをセルフホストした"},{"body":"ERNIE-ViLG というのが、\"二次元キャラ\" に強いという記事を目にしました。\n実際に使ってみようと、次のページで試したんですが、レスポンスがイマイチでした。\n\n- https://huggingface.co/spaces/PaddlePaddle/ERNIE-ViLG\n\nそこで、[公式ページ](https://github.com/PaddlePaddle/PaddleHub/tree/develop/modules/image/text_to_image/ernie_vilg)を参考にして、ERNIE-ViLG を Google Colaboratory を書こうと思いました。\n\n## Google Colaboratory で動かす\n\n実際に作ったものは、次のモノです。\n\n- [DEMO_PaddlePaddle_PaddleHub_ERNIE_ViLG](https://colab.research.google.com/github/silverbirder/DEMO-PaddlePaddle-PaddleHub-ERNIE-ViLG/blob/main/src/DEMO_PaddlePaddle_PaddleHub_ERNIE_ViLG.ipynb)\n\n中身については、正直良くわかっていないですが([公式ページ](https://github.com/PaddlePaddle/PaddleHub/tree/develop/modules/image/text_to_image/ernie_vilg) 通りに試しただけ)、簡単に紹介しようと思います。\n\n## 準備\n\n次のコマンドを叩いて、ERNIE-ViLG の準備をします。(GPU 環境でないと動作しません)\n\n```bash\npip install paddlepaddle-gpu -U\npip install paddlehub==2.1.0\n```\n\n```python\nimport paddlehub\npaddlehub.server_check()\n```\n\n```bash\nhub install ernie_vilg\n```\n\n## ERNIE-ViLG を使う\n\n使うのは、2 つのパターンがあります。\n\n1. CLI で実行する(hub コマンド)\n1. Python で実行する(hub ライブラリ)\n\nCLI の場合は、次のとおりです。\n\n```bash\nhub run ernie_vilg --text_prompts \"宁静的小镇\" --style \"油画\" --output_dir ernie_vilg_out\n```\n\nPython の場合は、次のとおりです。\n\n```python\nimport paddlehub as hub\n\nmodule = hub.Module(name=\"ernie_vilg\")\ntext_prompts = [\"宁静的小镇\"]\nimages = module.generate_image(text_prompts=text_prompts, style='油画', output_dir='./ernie_vilg_out/')\n```\n\nオプションは、次の説明の通りです。\n\n- text_prompts\n  - 生成したい画像の内容を記述した入力文\n- style\n  - スタイルで画像を生成することが可能\n    - 油画 (油絵)\n    - 水彩 (水彩画)\n    - 粉笔画 (パステル)\n    - 卡通 (漫画, カートゥーン)\n    - 儿童画 (子供向け)\n    - 蜡笔画 (クレヨン)\n    - 探索无限 (無限大を探る)\n- topk\n  - 生成する画像数（最大 6 枚）\n- output_dir\n  - 保存先のディレクトリ (デフォルト:ernievilg_output)\n\n※ [ERNIE-ViLG#API](https://github.com/PaddlePaddle/PaddleHub/tree/develop/modules/image/text_to_image/ernie_vilg#3api)\n\ntext_prompts や style は、中国語で書く必要があります。\n\n## Google Colaboratory で 画像を簡単に見たい\n\nERNIE-ViLG を動かすと、出力ファイルが Google Colaboratory のフォルダに入ります。\n画像を見るためには、画像をダウンロードして、開くという手間があります。\n\n![download_image_on_browser](https://res.cloudinary.com/silverbirder/image/upload/v1662183656/silver-birder.github.io/blog/download_image_on_browser.png)\n\nそこで、フォルダを Google Drive と同期するという機能があります。\nこれを使えば、保存先を Google Drive にしておけば、Google Drive の UI 上から画像を見ることができます。\n\n![mount_google_drive](https://res.cloudinary.com/silverbirder/image/upload/v1662183656/silver-birder.github.io/blog/mount_google_drive.png)\n\nめちゃくちゃ便利なので、ぜひ使ってみてください。","publishedAt":"2022-09-03","slug":"ernie_vilg_demo","title":"ERNIE-ViLG を Google Colaboratory で動かしてみた"},{"body":"Stable Diffusion は、文章を渡すと画像を生成してくれる AI で OSS です。\nこれを自分の PC で動かそうとすると、GPU が必要になります。\n(CPU で動かせる[stable_diffusion.openvino](https://github.com/bes-dev/stable_diffusion.openvino) というのもあります)\n\nできれば、どの PC でも使えるように、かつ、Slack などサービスと連携できるよう API がほしいなと思いました。\nそこで、Stable Diffusion の API を開発しました。\n\n## 結論\n\nDreamStudio.ai の SDK、 [stability-sdk](https://github.com/Stability-AI/stability-sdk)を使いました。\n\n成果物は、次のリポジトリに置いています。\n\n- https://github.com/silverbirder/stable-diffusion-API\n\nローカル環境でも、Docker コンテナでも、動きます。\n\n動かすには、DreamStudio.ai の API Key が必要になります。\nDocker で動くので、Docker をデプロイできるサービスなら、どこでも動きます。(GPU は不要です)\n\n私は、GCP が好きなので、CloudRun というサービスにデプロイしました。\nAPI は、とりあえず、`<url>/?prompt=<text>` というパラメータを受け取り、画像を返却します。\n\nSlack で使ってみると、こんな感じになりました。\n\n![stable-diffusion-api-on-slack](https://res.cloudinary.com/silverbirder/image/upload/v1662177842/silver-birder.github.io/blog/stable-diffusion-api-on-slack.jpg)\n\nひとまず、API で Stable Diffusion を動かせました。\n\n## GPU と設計\n\n[stability-sdk](https://github.com/Stability-AI/stability-sdk)を使う前までは、自前で Stable Diffusion を動かす環境を用意しようと設計を考えました。設計の調査メモは、次のリンクにメモを残しています。\n\n- https://zenn.dev/silverbirder/scraps/3842c715662551\n\n具体的に、次のようなパターンを考えました。\n\n1. Google Colaboratory の GPU を使って Stable Diffusion を動かし、簡易な API で公開する\n1. サーバー(GCE や CloudRun など) で GPU を使って Stable Diffusion を動かし、簡易な API で公開する\n1. バッチ(Cloud Batch)で GPU を使って Stable Diffusion を動かし、必要なときに動かす。(API からバッチ処理をキックする)\n\n1 番目は、Google Colaboratory の利用は 12 時間制限というのがあり、そこを回避する何かが必要なります。ただし、本来の用途と外れていると思うので、却下しました。\n\n2 番目は、金銭的に数万~数十万円以上のランニングコストが発生するので却下です。\n\n3 番目は、一番最初の構想したものです。2 番目のような GPU のサーバを常時起動しているとめちゃくちゃもったいないので、\nバッチ処理として 3 番目の案を考えていました。3 番目で実際に構築してみると、(何が原因か深く調べていないですが) 起動に 30 分以上かかってしまい、使い物にならなさそうでした。\n\nで、悩んだ結果、[stability-sdk](https://github.com/Stability-AI/stability-sdk) がメンテナンスやランニングコストも不要で、シュッとできそうだったことに気づきました。\n\nもちろん、デメリットはあります。\n\n- SDK に依存するので、自身がコントロールできない(img2img できない)\n- 課金制\n\nしかし、個人レベルで利用するという前提でしたので、デメリットよりもメリットの方が大きいと判断しました。\n\n## stability-sdk\n\nDreamStudio.ai は、Stable Diffusion を使っています。\nAPI として、[stability-sdk](https://github.com/Stability-AI/stability-sdk) を公開しています。\n使うには、Python で書く必要があります。\nソースコードを読むと、gRPC を使っているため、別言語で SDK を書くのは比較的簡単だと思います。\n私は、Python でシュッと書けるので、flask と stability-sdk を使いました。\n\n- https://github.com/silverbirder/stable-diffusion-API\n\nひとまず、Prompt だけを受け付ける超絶シンプルな API を書きました。\n[stability-sdk](https://github.com/Stability-AI/stability-sdk)は、様々パラメータがあるので、それも受け付けられるようにしようかなと思ったり、Midjourney の discord のボットのようなモノを書いても面白そうだなと思いました。\n\n## 終わりに\n\nマークダウンで、画像を読み込むときに、今回開発した API を指定すると、マークダウンを開いたタイミングで画像が毎回変わります。\nprompt と seed を指定すれば固定できるんですけど、こういうのも面白いなと思っています。","publishedAt":"2022-09-03","slug":"using_stability_ai_API","title":"Stable Diffusion API 開発"},{"body":"Midjourney や StableDiffusion を使っていると、どういうフレーズを使えばよいかわからなくなります。\nそこで、フレーズ集を作って、Prompt で役立てたいなと思っています。\n\n## 練習場\n\nどこで Prompt の練習したら良いか悩むので、まとめておきました。\nお勧めは、DreamStudio.ai です。\n\n- Midjourney\n  - [Discord](https://discord.com/app/invite-with-guild-onboarding/midjourney)\n    - 課金制(無料枠あり)\n- StableDiffusion\n  - OSS\n    - [stable-diffusion](https://github.com/CompVis/stable-diffusion)\n  - Google Colab\n    - [text2img](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)\n    - [img2img](https://colab.research.google.com/github/cedro3/others2/blob/main/Stable_Diffusion2.ipynb)\n  - WebApp\n    - DreamStudio.ai\n      - 課金制(無料枠あり)\n        - API\n          - [stability-sdk](https://github.com/Stability-AI/stability-sdk)\n  - Docker\n    - [stable-diffusion-docker](https://github.com/fboulnois/stable-diffusion-docker)\n    - [stable-diffusion-nvidia-docker](https://github.com/NickLucche/stable-diffusion-nvidia-docker)\n\n## Prompt で入力する文章構成\n\nPrompt で入力する文章は、AI に理解しやすい構成である方が良いです。その方が欲しい画像を手に入れやすくなります。\n文章の構成は、次のフォーマットです。\n\n```text\n＜全体のフォーマット＞\n＜主題＞\n＜主題の補足＞\n＜作者＞\n＜全体の補足＞\n＜フレーバー＞\n\n例:\n＜全体フォーマット＞Detailing oil painting of\n＜主題＞The great white castle on deep forest landscape\n＜英霊＞by CASPAR DAVID FRIEDRICH and CLAUDE LORRAIN,\n＜全体の補足＞ perfect lighting, golden hour,\n＜フレーバー＞ taken with Canon 5D Mk4\n```\n\n※ [魔術として理解するお絵描き AI 講座](https://note.com/fladdict/n/n0f0be20e3e23) より引用\n\n各項目についてのフレーズを、まとめておきました。\n\n## 全体のフォーマット\n\n- Ancient of\n- Beautiful concept art of\n- Cartoon of\n- Concept art of\n- Detailed illustration of\n- Detailed water painting of\n- Detailing oil painting of\n- Futuristic of\n- Illustration of\n- Image of nightmare of\n- Logo about\n- Pencil sketch of\n- Photo of\n- Pop art of\n- Portrait of\n- Scene of graphic novel that\n- Scene of the movie that\n- Screenshot of UE5 of\n- Side profile of\n- Sketch of\n\n## 作者\n\n- by 作者\n- in 作者 style\n\n## 全体の補足\n\n- 8k\n- art\n- beautiful shadow\n- collection sheet\n- comic\n- golden hour\n- grid\n- kawaii\n- manga\n- perfect lighting\n- pixiv\n- realistic photo\n- unreal engine\n\n## フレーバー\n\n- 11mm\n- by Canon EOS 5D Mark4 and SIGMA Art Lens 35mm F1.4 DG HSM, F1.4, ISO 200 Shutter Speed 2000\n- EF11-24mm F4L USM\n- no background\n- taken with Canon 5D Mk4\n- white background\n\n## 終わりに\n\nフレーズをまとめておくと、Prompt で文章入力するときに、参考にできて便利でした。\n別件で、そもそも私には英語力がないため、Deepl を欠かせないことに気づきました...。\nでは、よい お絵かきライフを!","publishedAt":"2022-08-28","slug":"prompt_phrases_useful_in_Midjourney_StableDiffusion","title":"Midjourney, StableDiffusion で役立つPrompt フレーズ集"},{"body":"前々から気になっていた、CI/CD の非ベンダーロックインな Dagger というツールを試してみました。\n本記事では、試した内容について共有しようと思います。\n\n## CI/CD のパイプラインを書く\n\nDagger では、[CUE](https://cuelang.org/) という言語を使って CI/CD のパイプラインを書きます。\n[公式サイトのチュートリアル](https://docs.dagger.io/1200/local-dev)から、そのまま使ってみます。\nコードは、次のようなものになります。\n\n```go\npackage todoapp\n\nimport (\n \"dagger.io/dagger\"\n\n \"dagger.io/dagger/core\"\n \"universe.dagger.io/netlify\"\n \"universe.dagger.io/yarn\"\n)\n\ndagger.#Plan & {\n actions: {\n  source: core.#Source & {\n   path: \".\"\n   exclude: [\n    \"node_modules\",\n    \"build\",\n    \"*.cue\",\n    \"*.md\",\n    \".git\",\n   ]\n  }\n\n  build: yarn.#Script & {\n   name:   \"build\"\n   source: actions.source.output\n  }\n\n  test: yarn.#Script & {\n   name:   \"test\"\n   source: actions.source.output\n   container: env: CI: \"true\"\n  }\n\n  deploy: netlify.#Deploy & {\n   contents: actions.build.output\n   site:     string | *\"dagger-todoapp\"\n  }\n }\n}\n```\n\n見慣れない構文かもしれませんが、何をやっているかはなんとなく分かるんじゃないかなと思います。\nactions は、実行するものを定義していて、`dagger do <action名>` のようにして使います。\n上の定義にある`source: core.#Source` は、 `source` がアクション名で、`core` が実行するパッケージになります。\nパッケージは、次の 2 つに分類されます。\n\n- [dagger.io](https://github.com/dagger/dagger/tree/v0.2.0/pkg/dagger.io)\n  - 標準機能\n    - core\n- [universe.dagger.io](https://github.com/dagger/dagger/tree/v0.2.0/pkg/universe.dagger.io)\n  - 非標準機能\n    - yarn, netlify, aws, bash, etc\n\n## ローカル環境で Dagger を動かす\n\n実際にローカルで動かしてみます。\n\n```bash\ndagger do test\n[✔] actions.test.container                                                                                                                11.6s\n[✔] actions.test.install.container.script                                                                                                  0.1s\n[✔] actions.source                                                                                                                         0.5s\n[✔] actions.test.install.container                                                                                                         2.3s\n[✔] actions.test.container.script                                                                                                          0.1s\n[✔] actions.test.install.container.export                                                                                                  0.0s\n[✔] actions.test.container.export                                                                                                          0.2s\nField  Value\nlogs   \"\"\"\\n  yarn run v1.22.17\\n  $ react-scripts test\\n  Done in 6.78s.\\n\\n  \"\"\"\n```\n\n特に問題なく、PASS しています。`--log-format plain` をつけると、実行の詳細な情報が出力されます。\n\n```bash\ndagger do test --log-format plain\n8:06PM INFO  actions.test.install.container.script._write | computing\n8:06PM INFO  actions.test.container._image._dag.\"0\"._pull | computing\n8:06PM INFO  actions.test.install.container._image._dag.\"0\"._pull | computing\n8:06PM INFO  actions.test.container.script._write | computing\n8:06PM INFO  actions.source | computing\n...\n```\n\nちなみに、`actions.source` が実行されているのは、`actions.test`が`actions.source`に依存しているためと思います。\n\n```bash\nNETLIFY_TOKEN=**** USER=**** dagger do deploy\n[✔] actions.deploy.container.script                                                                                                        0.2s\n[✔] actions.build.install.container                                                                                                        3.8s\n[✔] client.env                                                                                                                             0.0s\n[✔] actions.source                                                                                                                         0.4s\n[✔] actions.build.install.container.script                                                                                                 0.2s\n[✔] actions.build.container                                                                                                               21.0s\n[✔] actions.build.container.script                                                                                                         0.2s\n[✔] actions.deploy                                                                                                                         4.8s\n[✔] actions.build.install.container.export                                                                                                 0.1s\n[✔] actions.build.container.export                                                                                                         0.1s\n[✔] actions.deploy.container                                                                                                              91.0s\n[✔] client.filesystem.\"./build\".write                                                                                                      0.3s\n[✔] actions.deploy.container.export                                                                                                        0.0s\nField      Value\nsite       \"****-dagger-todoapp\"\nurl        \"https://******-dagger-todoapp.netlify.app\"\ndeployUrl  \"https://xxxx--******-dagger-todoapp.netlify.app\"\nlogsUrl    \"https://app.netlify.com/sites/******-dagger-todoapp/deploys/xxxx\"\n```\n\nローカル環境で、CI/CD のパイプラインコードを動かくことができました。\n次は、CI と連携したいと思います。\n\n## CircleCI で Dagger を動かす\n\nまずは、CircleCI で Dagger を動かしてみます。\nCircleCI の yml ファイルは、次の定義になります。\n\n```yaml\n## .circleci/config.yml\nversion: 2.1\n\njobs:\n  install-and-run-dagger:\n    docker:\n      - image: cimg/base:stable\n    steps:\n      - checkout\n      - setup_remote_docker:\n          version: \"20.10.14\"\n      - run:\n          name: \"Install Dagger\"\n          command: |\n            cd /usr/local\n            wget -O - https://dl.dagger.io/dagger/install.sh | sudo sh\n            cd -\n      - run:\n          name: \"Update project\"\n          command: |\n            dagger project init\n            dagger project update\n      - run:\n          name: \"Testing\"\n          command: |\n            dagger do test --log-format plain\n      - run:\n          name: \"Deploy to Netlify\"\n          command: |\n            dagger do deploy --log-format plain\n\nworkflows:\n  dagger-workflow:\n    jobs:\n      - install-and-run-dagger\n```\n\nCircleCI の環境変数に、`NETLIFY_TOKEN`と`USER`を設定しておきます。\nこの定義ファイルは、Dagger をインストールして、先程ローカル環境で動かしていた `dagger do test` や `dagger do deploy` を実行しているだけです。\n\nこの定義は、CircleCI 上で PASS します。めちゃくちゃ簡単ですね。\n\n## GithubActions で Dagger を動かす\n\n次は、GithubActions で Dagger を動かしてみます。\nGithubActions の yml ファイルは、次の定義になります。\n\n```yaml\n## .github/workflows/todoapp.yml\nname: todoapp\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  dagger:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Clone repository\n        uses: actions/checkout@v2\n      - name: Update project\n        uses: dagger/dagger-for-github@v3\n        with:\n          version: 0.2\n          cmds: |\n            project init\n            project update\n      - name: Testing\n        uses: dagger/dagger-for-github@v3\n        with:\n          version: 0.2\n          cmds: |\n            do test\n      - name: Deploy to Netlify\n        uses: dagger/dagger-for-github@v3\n        with:\n          version: 0.2\n          cmds: |\n            do deploy\n        env:\n          USER: ${{ secrets.USER }}\n          NETLIFY_TOKEN: ${{ secrets.NETLIFY_TOKEN }}\n```\n\nここの定義も、CircleCI の定義とほとんど一緒だと思います。\nただ、少し違うのは、GithubActions では、`uses: dagger/dagger-for-github@v3` が使えるため、\n`cmds`が、`do test` や `do deploy` のように、`dagger`を書かなくて済むようになります。\n\nGithubActions の環境変数に、`NETLIFY_TOKEN`と`USER`を設定しておきます。\nそうすれば、このパイプラインも成功します。\n\n## 終わりに\n\nローカル環境で、CI/CD のパイプラインをテストできて、それをシュッと CI サービスに連携できました。\n今回は、チュートリアルのものをそのまま使っているので、テストやデプロイがシンプルな構成になっていましたが、\n実務になると、より複雑な構成になると思うので、手元で確認できるのは良いものと思いました。\nただし、`CUE`への学習コストがかかるため、導入する際は、そのあたりも含めて検討しましょう。","publishedAt":"2022-08-23","slug":"try_dagger","title":"CI/CDのDaggerで、GithubActionsとCircleCIにシュッと連携してみた"},{"body":"[connect-web の記事](https://future-architect.github.io/articles/20220819a/)が、はてブでトレンドになっていました。気になったので、試してみました。\n\nサンプルコードは、次のリポジトリに置いています。\n\n- https://github.com/silverbirder/playground/tree/main/node/connect-web-example/frontend\n\n## 前置き: gRPC と connect-web の雑な理解\n\nRPC (Remote Procedure Call) を実現するためのプロトコルとして、gRPC があります。\nこのプロトコルは、ブラウザ側からは使えない(?)ため、gRPC-Web というブラウザ向けの gRPC というものを使うことになります。\nその場合、ブラウザとサーバーとの間に、プロキシを建てる必要があるようです。(たぶん)\n\nそこで、Connect という gRPC 互換の HTTP API を構築するためのライブラリ群が開発されました。\nこれのおかげで、プロキシを建てる必要がなく、ブラウザ側から gRPC を使うことが可能になります。\n\n- https://connect.build/docs/introduction\n\n上記ページに、バックエンドは connect-go、フロントエンドは connect-web という項目があります。\nconnect-web は、ブラウザから RPC を動かすための小さなライブラリです。タイプセーフなライブラリなため、\n型補完が効きます。\nconnect-go は、go で Connect のサービスを作ることができます。\n\nそのため、フロントエンドの開発は、connect-web を使うことになります。\n以降は、フロントエンドの作業を、紹介します。ちなみに、React を使います。\n\n## やってみた\n\nフロントエンド側は、主に、次の 2 つの作業になります。\n\n1. Protocol Buffer スキーマから TypeScript ファイルを生成\n1. 生成された TypeScript ファイルから gRPC クライアントを実装\n\n## 1. Protocol Buffer スキーマから TypeScript ファイルを生成\n\ngRPC で通信するためのスキーマ、ProtocolBuffer スキーマが必要です。\nこれは、すでにあるものを使います。\n\n- https://buf.build/bufbuild/eliza\n\n具体的には、次のようなスキーマです。\n\n```protobuf\nsyntax = \"proto3\";\n\nservice ElizaService {\n  rpc Say(SayRequest) returns (SayResponse) {}\n}\n\nmessage SayRequest {\n  string sentence = 1;\n}\n\nmessage SayResponse {\n  string sentence = 1;\n}\n```\n\nTypeScript コードを生成するために、`buf` という CLI を使います。\nbuf で利用する、次の定義ファイルを書きます。\n\n```yaml\n## buf.gen.yaml\n\n## buf.gen.yaml defines a local generation template.\n## For details, see https://docs.buf.build/configuration/v1/buf-gen-yaml\nversion: v1\nplugins:\n  - name: es\n    path: node_modules/.bin/protoc-gen-es\n    out: gen\n    # With target=ts, we generate TypeScript files.\n    # Use target=js+dts to generate JavaScript and TypeScript declaration files\n    # like remote generation does.\n    opt: target=ts\n  - name: connect-web\n    path: node_modules/.bin/protoc-gen-connect-web\n    out: gen\n    # With target=ts, we generate TypeScript files.\n    opt: target=ts\n```\n\nこれは、後述する `buf generate` するときにどういう出力をするかの設定情報です。\ncodegen の yaml ファイルみたいなものかなと思います。\nこれを動かすために、次の module をインストールしましょう。\n\n```bash\n## plugin\nyarn add --dev @bufbuild/protoc-gen-connect-web @bufbuild/protoc-gen-es\n## runtime\nyarn add @bufbuild/connect-web @bufbuild/protobuf\n```\n\n- plugin\n  - protoc-gen-es\n    - リクエストやレスポンスメッセージのような基本型を生成\n  - protoc-gen-connect-web\n    - Protocol Buffer スキーマからサービスを生成\n- runtime\n  - bufbuild/connect-web\n    - Connect および gRPC-web プロトコルのクライアントを提供\n  - bufbuild/protobuf\n    - 基本型に対するシリアライズなどを提供\n\n次に、`buf`をインストールしましょう。\n私は、brew でインストールしました。\n\n```bash\nbrew install bufbuild/buf/buf\n## ref: https://github.com/bufbuild/buf#installation\n```\n\nでは、ProtocolBuffer スキーマから TypeScript ファイルを生成しましょう。\n\n```bash\nbuf generate --template buf.gen.yaml buf.build/bufbuild/eliza\n```\n\n成功すると、次の 2 つの TypeScript ファイルが生成されます。\n\n- gen/buf/connect/demo/eliza/v1/eliza_connectweb.ts\n- gen/buf/connect/demo/eliza/v1/eliza_pb.ts\n\n`eliza_connectweb.ts`は、次のコードが含まれています。\n\n```typescript\n// eliza_connectweb.ts\nimport { SayRequest, SayResponse } from \"./eliza_pb.js\";\nimport { MethodKind } from \"@bufbuild/protobuf\";\n\nexport const ElizaService = {\n  typeName: \"ElizaService\",\n  methods: {\n    say: {\n      name: \"Say\",\n      I: SayRequest,\n      O: SayResponse,\n      kind: MethodKind.Unary,\n    },\n  },\n} as const;\n```\n\n`eliza_pb.ts`は、次のコードが含まれています。\n\n```typescript\nexport class SayRequest extends Message<SayRequest> {\n  /**\n   * @generated from field: string sentence = 1;\n   */\n  sentence = \"\";\n\n  constructor(data?: PartialMessage<SayRequest>) {\n    super();\n    proto3.util.initPartial(data, this);\n  }\n\n  static readonly runtime = proto3;\n  static readonly typeName = \"buf.connect.demo.eliza.v1.SayRequest\";\n  # ... 省略 ...\n}\n\n/**\n * SayResponse describes the sentence responded by the ELIZA program.\n *\n * @generated from message buf.connect.demo.eliza.v1.SayResponse\n */\nexport class SayResponse extends Message<SayResponse> {\n  /**\n   * @generated from field: string sentence = 1;\n   */\n  sentence = \"\";\n\n  constructor(data?: PartialMessage<SayResponse>) {\n    super();\n    proto3.util.initPartial(data, this);\n  }\n\n  static readonly runtime = proto3;\n  static readonly typeName = \"buf.connect.demo.eliza.v1.SayResponse\";\n  # ... 省略 ...\n}\n```\n\nこれで、準備はできました。\n\n## 2. 生成された TypeScript ファイルから gRPC クライアントを実装\n\nでは、gRPC のクライアントを実装しましょう。\ngRPC のクライント生成は、`createPromiseClient` でできます。\n生成時の引数に、サービスとトランスポート(?)というものを渡す必要があります。\nコードを見たほうがわかりやすいと思うので、次のコードを見てください。\n\n```typescript\n// client.ts\nimport { useMemo } from \"react\";\nimport { ServiceType } from \"@bufbuild/protobuf\";\nimport {\n  createConnectTransport,\n  createPromiseClient,\n  PromiseClient,\n  Transport,\n} from \"@bufbuild/connect-web\";\n\nconst transport = createConnectTransport({\n  baseUrl: \"https://demo.connect.build\", # バックエンド側のURL\n});\n\nexport function useClient<T extends ServiceType>(service: T): PromiseClient<T> {\n  return useMemo(() => createPromiseClient(service, transport), [service]);\n}\n```\n\nこのクライアントを、使ってみましょう。\n\n```typescript\n// App.tsx\n\nimport { createConnectTransport, Interceptor } from \"@bufbuild/connect-web\";\nimport { ElizaService } from \"../gen/buf/connect/demo/eliza/v1/eliza_connectweb\";\nimport { useClient } from \"./client\";\n\nfunction App() {\n  const client = useClient(ElizaService);\n  client\n    .say({\n      sentence: \"hello\",\n    })\n    .then(({ sentence }) => {\n      console.log(sentence);\n    });\n  // ...\n}\n```\n\nこのように、ProtocolBuffers の ElizaService が、型補完として使えるようになります。\n良い感じです！\n\n## 終わりに\n\n意外とあっさり動いて、びっくりしました。","publishedAt":"2022-08-20","slug":"try_connect_web","title":"connect-webやってみた"},{"body":"GraphQL クライアントを使っていると、データ取得後にデータ変換がしたくなりませんか。私はしたくなります。\nGraphQL クライアントの urql で、データ変換するのに、exchanges が使えそうだったので、それを共有します。\n\nサンプルコードは、次のリポジトリに置いています。\n\nhttps://github.com/silverbirder/urql-exchange-transform\n\n## Exchanges\n\nExchanges とは、[公式ページ](https://formidable.com/open-source/urql/docs/architecture/#the-client-and-exchanges)より引用します。\n\n> The Client itself doesn't actually know what to do with operations. Instead, it sends them through \"exchanges\". Exchanges are akin to middleware in Redux and have access to all operations and all results. Multiple exchanges are chained to process our operations and to execute logic on them, one of them being the fetchExchange, which as the name implies sends our requests to our API.\n\nざっくりいうと、GraphQL の通信フロー(リクエスト/レスポンス)にアクセスできる機構です。レスポンスにアクセスできるため、\nデータ変換もできます。exchanges にデータ変換を一手に引き受けるため、useQuery などクエリ発行する側で、何度も変換コードを書く必要がなくなります。\n\n## Transform exchange\n\nサンプルコードを紹介する前に、GraphQL のデータソースとして Pokemon を使います。\nURL とクエリは、次のものを使います。\n\n- url\n  - `https://trygql.formidable.dev/graphql/basic-pokedex`\n\n```graphql\nquery Pokemons {\n  pokemons {\n    id\n    name\n  }\n}\n```\n\nデータ変換は、次のようなコードを書きます。\nmap の部分が、実際のデータ変換になります。今回は、name を`toLowerCase`しています。\n\n```javascript\nexport const transformExchange = ({ forward }) => {\n  return (ops$) =>\n    pipe(\n      ops$,\n      forward,\n      // Sample transform code\n      map((result) => {\n        const { data } = result;\n        if (!data || !data.pokemons) {\n          return result;\n        }\n        const { pokemons } = data;\n        result.data.pokemons = pokemons.map((pokemon) => {\n          pokemon[\"name\"] = pokemon.name.toLowerCase();\n          return pokemon;\n        });\n        return result;\n      })\n    );\n};\n```\n\ntransformExchange 関数を urql のクライアントに渡します。\n\n```javascript\nimport { createClient, fetchExchange } from \"urql\";\nimport { transformExchange } from \"./transformExchange\";\n\nclient = createClient({\n  url: \"https://trygql.formidable.dev/graphql/basic-pokedex\",\n  exchanges: [transformExchange, fetchExchange],\n});\n```\n\nexchanges は、何も指定しない場合、[defaultExchanges](https://formidable.com/open-source/urql/docs/api/core/#defaultexchanges)が使われます。今回、必要最低限の説明のために、[defaultExchanges](https://formidable.com/open-source/urql/docs/api/core/#defaultexchanges)の内の fetchExchange だけ使いました。\n\nあとは、次のコードのように useQuery でデータ取得すれば良いです。データ取得後のデータは、データ変換された結果になっています。\n\n```javascript\nimport { useQuery } from \"urql\";\n\nconst PokemonsQuery = `\n  query Pokemons {\n    pokemons {\n      id\n      name\n    }\n  }\n`;\n\nexport const Pokemons = () => {\n  const [result] = useQuery({\n    query: PokemonsQuery,\n  });\n\n  const { data, fetching, error } = result;\n\n  if (fetching) return <p>Loading...</p>;\n  if (error) return <p>Oh no... {error.message}</p>;\n\n  return (\n    <ul>\n      {data.pokemons.map((pokemon) => (\n        <li key={pokemon.id}>{pokemon.name}</li>\n      ))}\n    </ul>\n  );\n};\n```\n\npokemon.name が `toLowerCase` されています。\n\n## 終わりに\n\nurql の exchanges って、[wonka](https://github.com/kitten/wonka)という[Reason](https://reasonml.github.io/)言語で書かれたライブラリに依存しているので、調査するのが少し苦労しました。","publishedAt":"2022-08-10","slug":"urql_transform_exchange","title":"urqlでデータ変換(transform)してみた"},{"body":"GraphQL を業務で使い始めました。\nいつものように、GraphQL の歴史が気になったので、調べてみました。\n\n## 参考資料\n\nhttps://www.youtube.com/watch?v=VjHWkBr3tjI\n\nGraphQL の共同開発者で、GraphQL Foundation エグゼクティブディレクターである Lee Byron さんから、GraphQL の歴史について、紹介されています。\n\n次の資料も参考になります。\n\n- https://dev.to/tamerlang/a-brief-history-of-graphql-2jhd\n- https://levelup.gitconnected.com/what-is-graphql-87fc7687b042\n\n## GraphQL が生まれる前\n\nGraphQL が生まれる前の歴史を、簡単に要約しました。\n\n| 年   | 要約                                                                                                |\n| ---- | --------------------------------------------------------------------------------------------------- |\n| 2004 | ソーシャルメディア Web サイト「Thefacebook」が公開され、後に FaceBook になりました                  |\n| 2007 | iPhone の登場により、モバイルが急速に普及し始めましたが、FaceBook は HTML5 に賭けすぎて失敗しました |\n| 2012 | FaceBook はモバイル(iOS) のニュースフィードを REST API で開発し始めました                           |\n\n## REST API での開発における 3 つの課題\n\nREST API で開発を進めていくと、次の 3 つの課題を抱えてしまいました。\n\n- Slow on network\n  - 1 つの API から必要なデータが全て返ってこないため、複数のリクエストを何度も往復する必要がありました\n- Fragile client/server relationship\n  - API の変更を、クライアントコードに慎重に引き継がなければ、クラッシュしてしまいました\n- Tedious code & process\n  - クライアントの開発は、API のレスポンスに非常に連動しているので、API のレスポンスの変更があれば、クライアントも変更しなければなりません\n\nこれらの課題を解決すべく、FaceBook は、スーパーグラフと呼ばれるプロトタイプを開発しました。\nそのベストプラクティスを集めたものが、GraphQL となりました。\n\n### 例:複数のリクエストを何度も往復する\n\n複数のリクエストをする例が、次のページに書いています。\n\n- https://www.howtographql.com/basics/1-graphql-is-the-better-rest/\n\n例として、ユーザー情報、ユーザーが投稿したコンテンツ、ユーザーのフォロワーという 3 つの情報を取得するケースです。\n\nREST API の場合は、次の画像のように 3 往復することになります。\n\n![REST_API](https://res.cloudinary.com/silverbirder/image/upload/v1659191676/silver-birder.github.io/blog/rest_api_flow.png)\n\nGraphQL の場合は、1 回の往復だけでデータが取得できます。\n\n![GraphQL](https://res.cloudinary.com/silverbirder/image/upload/v1659191675/silver-birder.github.io/blog/graphql_flow.png)\n\n## REST API から GraphQL へ\n\nREST API から、GraphQL に切り替えた結果、次の 3 つのメリットを享受することができました。\n\n- Fast on network\n  - 必要なものだけを記述できるため、1 回のリクエストで十分です\n- Robust static types\n  - どのようなデータが利用可能か、どのような型か、クライアントは知ることができます\n- Empowering client evolution\n  - レスポンスのフォーマットはクライアントが制御できます。そのため、サーバーサイドはシンプルになり、メンテナンスも容易になります\n  - 古いフィールドを非推奨とし、機能は継続できます。この後方互換性によりバージョニング管理が不要になります\n\n## 3 つの課題を 改めて考える\n\nREST API の 3 つの課題を、2022 年の今、改めて考えてみます。\n\n- Slow on network\n  - 2012 年は、3G 回線が普及していた\n    - 複数リクエストや、API のペイロードが大きいと、ネットワークレイテンシに大きく影響していそう\n  - 2022 年は、5G 回線が普及している\n    - ネットワークレイテンシは、そこまでクリティカルな問題にはならないのでは\n    - もちろん、低ネットワークを利用するユーザーが多いプロダクトなら、考慮が必要かも\n  - 複数リクエストは、BFF のようなファザードを建てることで、解決できないか\n- Fragile client/server relationship\n  - バージョニングと後方互換性については、今の REST API も変わりなく課題の 1 つ\n- Tedious code & process\n  - スキーマ駆動な開発で、問題解決できるのではないか\n\n簡単に書いていますが、3 つの課題は、もっと深い・困難な話だったのかもしれません。\nですが、今の時代で考えてみると、GraphQL を使うユースケースは、エッジケースなのかなと思ってしまいました。\n本件の課題の根幹の 1 つは、ニュースフィードにおけるデータ構造の複雑さ(再帰的,ネスト)じゃないのかなと想像していました。\n\n### 参考リンク\n\n- https://www.apollographql.com/blog/graphql/basics/why-use-graphql/\n- https://wundergraph.com/blog/why_not_use_graphql\n\n## GraphQL の魅力\n\n### データの取捨選択\n\nGraphQL の必要なデータを記述できる機能は、魅力的と思います。\n従来の REST API の開発設計では、次のようなパターンを業務で経験してきました。\n\n- レスポンスデータのバリエーションをグループ分けするクエリパラメータ Response group\n  - Response group\n    - small\n      - 最小セット\n    - middle\n      - small と large の中間\n    - large\n      - 全てのフィールド\n\nResponse group での開発で、特に大きな課題と感じたことはありませんでした。\nデータの取捨選択は、API のスケールのしやすさがメリットのように思います。\n\n### データの階層構造\n\nGraphQL は、リクエスト・レスポンスのデータに、階層構造を表せます。\nこれも、魅力的です。\n\n従来の REST API では、リクエストのクエリパラメータは、フラットな形で送るしかありませんでした。リクエストボディを使って、JSON を送るという手段もあります。(まあ、これが GraphQL なんですが)\n\nREST API のリクエストに、階層構造を表せるのは、データの関係性を示せるため、柔軟性が高く良さそうです。\n\n## ただ、個人的な違和感\n\n### データ参照も POST\n\nREST API は、参照なら HTTP GET、更新なら HTTP POST を使うのが当たり前です。\nGraphQL は、参照も更新も HTTP POST を使います。これに違和感があります。\nquery は、HTTP GET、mutation は、HTTP POST で使い分けできるようにしたいです。\n\n## 終わりに\n\nGraphQL の歴史を簡単に紹介しました。\nまだそんなに使ったことがないので、良さ・悪さをしっかり理解していきたいと思います。","publishedAt":"2022-07-30","slug":"a_brief_history_of_graphql","title":"GraphQLの歴史"},{"body":"JavaScript の標準機能 `debugger` を使って、デバッグをしましょう。\n標準機能なので、React などのライブラリでも使えます。\n\n## Browser\n\n次の HTML ファイルを Chrome で開きます。\n\n```html\n<button>Button</button>\n<script>\n  document.querySelector(\"button\").addEventListener(\"click\", () => {\n    debugger;\n    alert(\"Hello World\");\n  });\n</script>\n```\n\n開いたページで、DevTools も開いておきます。\nその状態で、Button をクリックしましょう。\n\nそうすると、次の画像のようになります。\n\n![browser_debugger](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/browser_debugger.png)\n\n`debugger`と書いた箇所で、処理が停止されます。\nそのブレークポイントから、ステップイン、ステップアウト、ステップオーバーといった操作ができます。\nConsole タブで、変数や関数などの実行結果を確認できます。\n\nこのように、簡単にデバッグができるようになります。\n\n## Node.js\n\nNode.js でも、同様に `debugger` が使えます。\n次の JavaScript コードを用意します。\n\n```javascript\n// main.js\ndebugger;\nconsole.log(\"Hello World\");\n```\n\nこのファイルを次のコマンドで実行します。\n\n```bash\nnode --inspect-brk main.js\n```\n\n実行すると、次の画像のような出力になります。\n\n![node_debugger_1](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/node_debugger_1.png)\n\nその後、Chrome から `chrome://inspect` にアクセスしてください。\nアクセスすると、次の画像の画面になります。\n\n![node_debugger_2](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/node_debugger_2.png)\n\n`Open dedicated DevTools for Node` を Click したら、次の画像のようになります。\n\n![node_debugger_3](https://res.cloudinary.com/silverbirder/image/upload/v1657342289/silver-birder.github.io/blog/node_debugger_3.png)\n\nそうです、さきほどと同じように、`debugger` の箇所で、処理が停止されます。\n簡単ですね。\n\n## Jest\n\nテストフレームワークの Jest も、同じように `debugger` が使えます。\n次のテストコードを用意します。\n\n```javascript\n// main.test.js\ntest(\"1 equal 1\", () => {\n  debugger;\n  expect(1).toBe(1);\n});\n```\n\nこのファイルに対して、次のコマンドを実行します。\n\n```bash\n## mac\nnode --inspect-brk node_modules/.bin/jest --runInBand main.test.js\n## windows\nnode --inspect-brk ./node_modules/jest/bin/jest.js --runInBand main.test.js\n```\n\n実行すると、次の画像のような出力になります。\n\n![jest_debugger_1](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/jest_debugger_1.png)\n\nまた、同じく Chrome から`chrome://inspect` にアクセスすると、同様にデバッグできます。\n\n![jest_debugger_2](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/jest_debugger_2.png)\n\n![jest_debugger_3](https://res.cloudinary.com/silverbirder/image/upload/v1657342288/silver-birder.github.io/blog/jest_debugger_3.png)\n\nBrowser,Node.js と同じ使い方になります。\nわかりやすいですね。\n\n## 終わりに\n\nIDE やエディタでデバッグ設定することもできますが、こちらの方が断然楽ですね。\n\n## 参考\n\n- https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Statements/debugger\n- https://nodejs.org/ja/docs/guides/debugging-getting-started/\n- https://jestjs.io/ja/docs/troubleshooting","publishedAt":"2022-07-09","slug":"Lets_debug_with_JavaScript_debugger","title":"JavaScriptのdebuggerを使ってデバッグしよう (Browser/Node.js/Jest)"},{"body":"ブラウザのレンダリングエンジンにおけるレイアウトやペイントについて気になったので、調べました。\nその内容をまとめます。レンダリングエンジンは、Chrome の Blink を題材とします。\n\n## レンダリングエンジンの処理工程\n\nレンダリングエンジンの処理工程は、次の記事が参考になります。\n\n- https://web.dev/rendering-performance/\n- https://blog.leap-in.com/lets-learn-how-to-browser-works/\n- https://silver-birder.github.io/blog/contents/learning_browser_engine/\n- https://developer.chrome.com/blog/inside-browser-part3/\n\n![レンダリングエンジンの工程](https://res.cloudinary.com/silverbirder/image/upload/v1656816689/silver-birder.github.io/blog/browser_rendering_process.jpg)\n\n- (図には書いていないけど)Parse\n  - HTML と CSS をパース\n  - DOM Tree と Style Rules を生成\n- JavaScript\n  - 視覚的な操作を処理\n- Style\n  - HTML 要素が、どの CSS ルールが割り当たるかを決定\n  - DOM Tree と Style Rules を紐付けた Render Tree を生成\n- Layout\n  - HTML 要素の位置と大きさを決定\n  - Layout Tree を生成\n  - Reflow とも呼ぶ\n- Paint\n  - ブラウザに表示するピクセルを塗る\n  - レイヤーを分ける\n  - Draw とも呼ぶ\n- Composite\n  - 正しい順序で、レイヤーを重ねていく\n  - メインスレッドからコンポジットスレッド・ラスタースレッドに切り替わる\n    - コンポジットスレッドから、ページを各タイルに分割して、ラスタースレッドに送る\n    - ラスタースレッドは、ラスタライズして GPU に格納する\n\nこの工程が、実際に動いているところを見てみましょう。\n\n## DevTools でレンダリング工程を見てみる\n\n次のシンプルな HTML を Chrome で開いてみましょう。\n\n```html\n<div>Hello</div>\n```\n\n開いたページで DevTools を開き、Performance タブをクリックします。\n左上にある reload ボタンを押して、計測してみましょう。\n\n![devtools_performance](https://res.cloudinary.com/silverbirder/image/upload/v1656941210/silver-birder.github.io/blog/devtools_performance.png)\n\n計測の結果、 Main を見てみましょう。\n\n![devtools_performance_1](https://res.cloudinary.com/silverbirder/image/upload/v1656941719/silver-birder.github.io/blog/devtools_performance_1.png)\n\nさきほど説明したレンダリングエンジンの工程(色も一致)が、見えると思います。\n\n- 青色 `Parse HTML`\n- 紫色 `Recalculate Style`\n- 紫色 `Layout`\n- (黄色は JavaScript 関係)\n- (緑色は Paint/Composite 関係)\n\n視覚的に見やすい一方で、全体を網羅してみるのは難しいです。\nそこで、 `Event Log` を開きます。\n\n![devtools_performance_2](https://res.cloudinary.com/silverbirder/image/upload/v1656823105/silver-birder.github.io/blog/devtools_performance_2.png)\n\nレンダリングエンジンのイベントログが、色とともに表示されています。\nここには、さきほど見れなかった黄色や緑色のものもあります。\n\n### Tips: Performance タブに慣れよう\n\nPerformance タブには、様々な情報があります。\n\nいきなりプロダクションリリースされているものに対して、Performance 計測すると、何を見たらよいかわからなくなります。\n\nまずは、最小セットの HTML で見ていくと、情報量が絞られて、読みやすくなります。\n\nまた、計測の各場所には、工程の色が使われています。色も合わせて見ると、読みやすくなります。\n\n## ブラウザとリフレッシュレートと 60fps\n\nブラウザでアニメーションなど動きを出すときに、60fps を目標とすると良いです。\n\nhttp://jankfree.org/ というサイトから引用します。\n\n> Modern browsers try to refresh the content on screen in sync with a device's refresh rate. For most devices today, the screen will refresh 60 times a second, or 60Hz. If there is some motion on screen (such as scrolling, transitions, or animations) a browser should create 60 frames per second to match the refresh rate.\n\nブラウザは、リフレッシュレートと同期してコンテンツを更新します。\n最近のデバイスは、1 秒間に 60 回更新できるようです。そのため、ブラウザは 60fps で動作すべきと書いています。\n\nDevTools から、fps を確認できます。\nRendering タブにある `Frame Rendering Stats`にチェックを入れます。\n\n![devtools_fps_1](https://res.cloudinary.com/silverbirder/image/upload/v1656854862/silver-birder.github.io/blog/devtools_fps_1.png)\n\nそうすると、画面に次の画像が表示されます。\n\n![devtools_fps_2](https://res.cloudinary.com/silverbirder/image/upload/v1656854862/silver-birder.github.io/blog/devtools_fps_2.png)\n\n今、ブラウザは 18.6 fps のようです。\n\n---\n\nfps が少ないと、どうなるんでしょうか。ジャンクと呼ばれる現象が発生します。\n\n> Jank is any stuttering, juddering or just plain halting that users see when a site or app isn't keeping up with the refresh rate. Jank is the result of frames taking too long for a browser to make, and it negatively impacts your users and how they experience your site or app.\n\nリフレッシュレートに、画面が追いついていないと、ジャンクと呼ばれる滑らかではない動作になってしまいます。これは、ユーザーへの悪い体験をさせてしまいます。\n\nhttps://googlechrome.github.io/devtools-samples/jank/ が、まさにそのジャンクの体験ができます。\n\n## レイアウトスラッシング\n\nJavaScript や CSS を書いていると、DOM を追加してレイアウトが実行されたり、color を変えて、ペイントを実行されたりします。\nレンダリングエンジンは、シングルスレッドで動いているため、レイアウトの実行やペイントの実行をしていると、他の工程が動作されません。\n\n次のサイトにある JavaScript の関数を使うと、そのときのレイアウト情報を計算する必要があり、レイアウトが強制的に再計算されます。これがレイアウトスラッシングと呼ばれます。\nレイアウトスラッシングは、FPS の低下につながります。\n\n- https://gist.github.com/paulirish/5d52fb081b3570c81e3a\n  - 例えば、clientWidth\n\n例を示しましょう。ボタン要素にスタイル変更し、clientWidth を参照したコードです。\n\n```html\n<button>click</button>\n<script>\n  const b = document.querySelector(\"button\");\n  b.addEventListener(\"click\", () => {\n    b.setAttribute(\"style\", `width: 100px;`);\n    b.clientWidth;\n  });\n</script>\n```\n\nclientWidth を実行すると、そのときのレイアウト情報が必要になるため、強制的にレイアウトが実行されます。\n\n![layout_forced](https://res.cloudinary.com/silverbirder/image/upload/v1656941215/silver-birder.github.io/blog/layout_forced.png)\n\n強制レイアウトが発生しているのが、みてとれます。\n\n`b.clientWidth` をコメントアウトすれば、Layout Forced は発生しません。\nもっと、明らかに警告となるサンプルを用意しました。\n\n```html\n<button id=\"btn\">click</button>\n<div id=\"root\"></div>\n<template id=\"template\">\n  <div style=\"position: relative\">hello</div>\n</template>\n\n<script>\n  const root = document.getElementById(\"root\");\n  const template = document.getElementById(\"template\");\n  [...Array(100)].forEach(() =>\n    root.appendChild(template.content.cloneNode(true))\n  );\n\n  document.getElementById(\"btn\").addEventListener(\"click\", () => {\n    setInterval(() => {\n      document.querySelectorAll(\"div\").forEach((el) => {\n        el.style.left =\n          (Math.sin(el.offsetTop + Date.now() / 1000) + 1) * 500 + \"px\";\n      });\n    }, 100);\n  });\n</script>\n```\n\nDevTools の Performance タブから見ると、`forced reflow is likely a bottleneck` と警告が出ているのが分かります。\n\n![devtools_warn_forced_reflow](https://res.cloudinary.com/silverbirder/image/upload/v1656941719/silver-birder.github.io/blog/devtools_warn_forced_reflow.png)\n\n対策としては、次があげられます。\n\n- レイアウトスラッシングを発生させる関数を実行しない、もしくはキャッシュする\n- `Window.requestAnimationFrame()` を利用する\n\n参考までに\n\n- https://web.dev/avoid-large-complex-layouts-and-layout-thrashing/#avoid-forced-synchronous-layouts\n\nDEMO は、次のページにもあります。\n\n- https://googlesamples.github.io/web-fundamentals/tools/chrome-devtools/rendering-tools/forcedsync.html\n\n## Paint と Composite\n\nPaint もコストがかかります。そこで、Composite に任せることで、メインスレッドを開放し、パフォーマンスが良くなります。\n具体的には、コンポジットで動作する transform や opasity とかがあります。\n\n具体的な例を出しましょう。\n次の例は、四角のボックスを左右に動かすサンプルです。\n左右に動かす手段に、CSS の left のパターンと、transform のパターンを試してみます。\n\n```html\n<style>\n  @keyframes return {\n    50% {\n      left: 200px;\n    }\n    100% {\n      left: 0px;\n    }\n    /* 50% {\n      transform: translateX(200px);\n    }\n    100% {\n      transform: translateX(0px);\n    } */\n  }\n\n  .box {\n    position: relative;\n    width: 100px;\n    height: 100px;\n    left: 0px;\n    border: 1px solid black;\n  }\n  .trans {\n    animation-name: return;\n    animation-duration: 2s;\n    animation-iteration-count: infinite;\n    animation-timing-function: ease;\n  }\n</style>\n<div class=\"box trans\"></div>\n```\n\ntransform の場合は、left の部分をコメントアウトし、transform 部分をコメントアウトを外します。\n\nこのファイルをブラウザで開き、Performance タブで計測し、`Event Log` を確認します。\n\nleft の場合、layout,paint,composite が発生しています。\n\n![css_trigger_1](https://res.cloudinary.com/silverbirder/image/upload/v1656936814/silver-birder.github.io/blog/css_trigger_1.png)\n\ntransform の場合、composite のみ発生しています。\n\n![css_trigger_2](https://res.cloudinary.com/silverbirder/image/upload/v1656936814/silver-birder.github.io/blog/css_trigger_2.png)\n\nこのように、composite のみで動く CSS プロパティを選ぶと、軽量になります。\n次のサイトには、CSS のどのプロパティがレイアウト・ペイント・コンポジットどれを更新するのか分かります。\n\n- https://csstriggers.com/\n\nまた、DevTools の Layers タブを開くと、ペイントのカウント回数やレイアウトが見れます。\n\nleft の場合の Layers は、次の画像です。\n数秒経過しただけで、ペイントカウントが、数百を超えました。\n\n![devtools_layout_1](https://res.cloudinary.com/silverbirder/image/upload/v1656941210/silver-birder.github.io/blog/devtools_layout_1.png)\n\ntransform の場合の Layers は、次の画像です。\nペイントカウントが、たったの 2 回に留まりました。\n\n![devtools_layout_2](https://res.cloudinary.com/silverbirder/image/upload/v1656941210/silver-birder.github.io/blog/devtools_layout_2.png)\n\n## 終わりに\n\nレイアウトやペイントについて、調査をしていると、意図せずレイアウトやペイントを実行させていた人も、いるかもしれません。\nパフォーマンスは、必要になったときにチューニングすればよいと思いますが、基本知識として本記事についての情報は、知っておいて損はないと思います。\n\n## 参考\n\n- https://gist.github.com/paulirish/5d52fb081b3570c81e3a\n- https://dev.opera.com/articles/efficient-javascript/","publishedAt":"2022-07-03","slug":"know_your_browser_layout_and_paint","title":"ブラウザのレイアウトとペイントを知る"},{"body":"ミスタードーナツ、それは至高のドーナツを生み出すお店。\n私とミスタードーナツの出会い、別れ、そして再開について、話します。\n\n## ミスタードーナツとの出会い\n\n出会いは、私が高校生の頃、実家で暮らしていたときの朝食です。\n当時、私には大学生の姉がいて、姉がミスタードーナツでアルバイトとして働いていました。\nミスタードーナツを夜勤(ナイト)で、姉は働いていました。\n帰りに破棄前のドーナツをダース箱で貰っていました。\nそれを、実家に持ち帰り、私達の朝食になっていたのです。\n\n生クリームが詰まったエンゼルフレンチが大好きになりました。\nパンというより、デザート感覚で食べていました。\n\nそこから、沼にハマりました。\n\n## ミスタードーナツでアルバイト\n\n私が大学生になった頃、ミスタードーナツでアルバイトをしました。\n当時、アルバイトの周りの人は、女性ばかりで肩身が狭かった印象です。\nアルバイトのシフトは、もちろん、ナイト希望です。\n実際、ナイトで入らせて貰いました。\n\n働いていると、色々と大変だと思うことが多かったです。\n\n- ドーナツは、バーコードがついていないので、商品を覚えてレジ打ちをする\n  - 季節によって、どんどん商品が変わってくる\n- ラーメンやチャーハンなどの作る手順を、覚える必要がある\n- たまに、季節のコスプレをさせられる\n  - ハロウィンとか\n- おかわりコーヒーのために、店内を回らないといけない\n\nただ、その代わりに、廃棄前のドーナツをもらえることが最高でした。\n\n※ 昔も今も、\"廃棄前のドーナツをもらうこと\"は、タブーな話なのかもしれないです。\n\n## 社会人になりミスタードーナツと別れ\n\n社会人になると、ミスタードーナツを食べる機会が減りました。\nオフィスの近くに、ミスタードーナツがそもそもなかったり、\nあったとしても、業務多忙で、なかなかいけなかった記憶です。\n\n## リモートワーク普及によりミスタードーナツを再び食べる\n\nコロナの環境で、リモートワークが普及し始めた頃、引っ越しをしていました。\n引越し先の近くにミスタードーナツを発見しました。やったね。最高。\n\n## そして、いま\n\n購入履歴を見ると、週に 1 回は、ミスタードーナツに 500 円程度消費しているようです。\n\n![2021年6月から2022年6月までのミスタードーナツ購入履歴](https://res.cloudinary.com/silverbirder/image/upload/v1656509793/silver-birder.github.io/blog/202106_202206_md.png)\n\n## その他(食べ放題)\n\n食べ放題あるんですよ、ミスタードーナツ。\n\n- https://aumo.jp/articles/332895\n\n実際に行ってみたんですが、そんなに食べれなかったです。\nたまに、少し食べる程度がちょうどよいんだと、思いました。","publishedAt":"2022-06-30","slug":"this_body_is_made_of_ponderings","title":"この体はポンデリングで出来ている"},{"body":"学生時代、いろいろアルバイトをしました。忘れないように記録として残そうと思います。\n\n## 郵便局 年末年始のはがき\n\n- 種別\n  - 短期\n- 時期\n  - 高校生\n- 頻度\n  - 年末年始(2 週間程度)\n- 概要\n  - 年末年始のはがきの仕分け\n- 感想\n  - はじめてのアルバイト。有名人が近くに住んでいるのを知り驚いた。アルバイトの人によっては社員からお小遣いを貰っていた。仕分けが楽しかった。\n\n## ヤマザキパン工場\n\n- 種別\n  - 短期\n- 時期\n  - 大学生\n- 頻度\n  - 1 ヶ月(週 2,3 日)\n- 概要\n  - レールに乗っているパンの調整\n- 感想\n  - 時間の経過がめっちゃ長く感じて、暇だった。パンがレールにずーっと流れていて、定型作業をずっとする。お昼ごはんに菓子パンとお味噌汁が無料。4 食パンやスナックパン、ランチパックのちょっとした手伝いをした。\n\n## 市民プール 監視員\n\n- 種別\n  - 短期\n- 時期\n  - 大学生\n- 頻度\n  - 1 ヶ月(週 2,3 日)\n- 概要\n  - 市民プールの監視員\n- 感想\n  - 街の小さな市民プールでの監視員。定期的にプールに入れるのが楽しかった。眠くて監視台で寝そうになって怒られたのを覚えている。\n\n## 東急ハンズ\n\n- 種別\n  - 短期\n- 時期\n  - 大学生\n- 頻度\n  - 1 ヶ月(週 2,3 日)\n- 概要\n  - 東急ハンズの品出し、接客\n- 感想\n  - 倉庫から東急ハンズの商品を運んで、お店に陳列。お客さんに商品の案内。はじめて、お客さんと接する仕事をして、緊張した。\n\n## 個人書店\n\n- 種別\n  - 短期\n- 時期\n  - 大学生\n- 頻度\n  - 1 ヶ月(週 4,5 日)\n- 概要\n  - 私立中学向けの教材セットの準備・運搬\n- 感想\n  - めちゃくちゃコスパがよかった仕事。1 日 3~5 時間ぐらいで 8000 円ぐらい貰えて、アルバイト最終日にボーナス(数万)も貰えた。する仕事は、新学期の中学生向けの教材(国語,数学,etc)をセットで準備。中学校へ運搬。めっちゃ楽だった。\n\n## 美術館のモノ運搬\n\n- 種別\n  - 短期\n- 時期\n  - 大学生\n- 頻度\n  - 2 週間(週 3,4 日)\n- 概要\n  - ある美術館への美術品の運搬\n- 感想\n  - 重めの美術品を車から美術館へ運ぶ。純粋に力仕事でしんどかった。\n\n## ミスタードーナツ\n\n- 種別\n  - 長期\n- 時期\n  - 大学生\n- 頻度\n  - 6 ヶ月(週 3 日)\n- 概要\n  - 接客・レジ\n- 感想\n  - 姉がミスタードーナツで働いて、廃棄のドーナッツをダースの箱で持って帰ってくれたのをきっかけに、自分もアルバイトをはじめた。レジで、ドーナツを見てレジ打ちするのが、難しかった。ダース箱にうまくドーナツを入れるのも難しい。コーヒーのおかわりで、店内をウロウロするのが楽しい。女性のアルバイトが多く、肩身が狭かった。\n\n## ミドリ電化\n\n- 種別\n  - 長期\n- 時期\n  - 大学生\n- 頻度\n  - 6 ヶ月(週 3 日)\n- 概要\n  - 商品陳列・レジ\n- 感想\n  - クレジットカードでの支払いが多く、慎重にレジ打ちしていた。薄い記憶だが、店内の商品(乾電池)を、子供に盗ませて、お母さんが捕まったのが印象に残っている。\n\n## 塾講師\n\n- 種別\n  - 長期\n- 時期\n  - 大学生\n- 頻度\n  - 4 年(週 4,5 日)\n- 概要\n  - 小中高校生の塾講師\n- 感想\n  - 大学生の頃、一番働いた。複数の塾を掛け持ち。古参になった。1 対 2,3 人の形式が多く、1 コマの時間配分を工夫したり、生徒に合わせた伝え方を考えた。","publishedAt":"2022-06-29","slug":"part_time_jobs_I_had_as_a_student","title":"学生時代に経験したアルバイト"},{"body":"私は、これまでプライベートでしか React を使っていませんでした。\n最近、業務で React を使う機会が増えたので、学んだことを残そうと思います。\n\n## React の歴史\n\nなんで React って生まれたんだろうって気になりました。\n簡単ですが、ちょこっとだけ調べて、次の記事にまとめました。\n\n- [React を学ぶ前に歴史を知る](./know_the_history_before_learning_React)\n\nReact は、次の問題を解決したかったんだと思います。\n\n- DOM ツリーが大きくなるにつれて、下位の変更によるカスケード更新の負荷が大きくなる\n\nそこで、React は、この問題を解決するために、仮想 DOM という仕組みを作ったんだと思います。\n\n## 仮想 DOM、差分検出処理、そして Fiber\n\nReact は、直接 DOM を操作するのではなく、仮想 DOM に対して操作します。仮想 DOM は、名前の通り仮想的な DOM です。\n仮想 DOM を DOM へ反映するために、差分検出処理(reconciliation)というアルゴリズムがあったり、Fiber と呼ばれる、レンダリングの最適化(優先順位)を目的としたアルゴリズムもあるようです。これらのおかげで、レンダリング負荷が軽減されるんだと思います。(しらんけど)\n\nまだまだ理解が浅いので、これからもっと学んでいきたいと思います。\n\n- [仮想 DOM と内部処理 – React](https://ja.reactjs.org/docs/faq-internals.html)\n- [差分検出処理 – React](https://ja.reactjs.org/docs/reconciliation.html)\n- [acdlite/react-fiber-architecture: A description of React's new core algorithm, React Fiber](https://github.com/acdlite/react-fiber-architecture)\n- [React Fiber アーキテクチャについて | POSTD](https://postd.cc/react-fiber-architecture/)\n\nレンダリングのタイミングは、いつなんでしょうか。\n\n## レンダリングタイミング\n\n基本的に、React は、親コンポーネントをレンダリングすると、子コンポーネントもレンダリングされます。\n\n再レンダリングをキューイングする関数、setState や forUpdate などを呼ぶと、コンポーネントはレンダリングされることになります。\n\n- [Blogged Answers: A (Mostly) Complete Guide to React Rendering Behavior · Mark's Dev Blog](https://blog.isquaredsoftware.com/2020/05/blogged-answers-a-mostly-complete-guide-to-react-rendering-behavior/)\n\nコードベースが大きくなるにつれて、レンダリングのパフォーマンスが悪化していきます。\nそこで、パフォーマンスの最適化が求められます。\n\n## パフォーマンス最適化\n\n最初からパフォーマンス最適化をする必要はありませんが、要件によっては必要になることもあります。\n最適化の手段として、React にある、次の 3 つの関数が使えます。\n\n- [memo](https://ja.reactjs.org/docs/react-api.html#reactmemo)\n  - コンポーネントのレンダーをスキップできる\n    - 以前の props と現在の props で変更がなければ\n- [useMemo](https://ja.reactjs.org/docs/hooks-reference.html#usememo)\n  - 値を[メモ化](https://en.wikipedia.org/wiki/Memoization)できる\n- [useCallback](https://ja.reactjs.org/docs/hooks-reference.html#usecallback)\n  - 関数を[メモ化](https://en.wikipedia.org/wiki/Memoization)できる\n    - memo と併用して使う\n\n[パフォーマンス最適化 – React](https://ja.reactjs.org/docs/optimizing-performance.html)も参考になります。\n\n## 比較アルゴリズム\n\nReact では、コンポーネントや状態が変更されたかどうかの判定に、[Object.is()](https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Object/is) を使っているようです。\nObject.is のサンプルコードは、次のとおりです。\n\n```javascript\nObject.is(\"foo\", \"foo\"); // true\nObject.is(\"foo\", \"bar\"); // false\nObject.is([], []); // false\n\nvar foo = { a: 1 };\nvar bar = { a: 1 };\nObject.is(foo, foo); // true\nObject.is(foo, bar); // false\n```\n\nstring や integer のようなプリミティブな値は良いのですが、非プリミティブな値(Object)の場合の考慮が必要です。\n例えば、[memo](https://ja.reactjs.org/docs/react-api.html#reactmemo)の場合は、第二引数に比較関数を渡すことができます。\n例えば、次のような感じです。\n\n```javascript\nfunction MyComponent(props) {}\nfunction areEqual(prevProps, nextProps) {\n  return JSON.stringify(prevProps.foo) === JSON.stringify(nextProps.foo);\n}\nexport default React.memo(MyComponent, areEqual);\n```\n\n[公式ページにも書いています](https://ja.reactjs.org/docs/react-api.html#reactmemo)が、パフォーマンス最適化のみに使いましょう。\n\n### Tips\n\n`Object.is()` を使われている影響で、非プリミティブな値の状態更新に、工夫が必要です。\n\n```javascript\nconst [items, setItems] = useState([\"a\", \"b\"]);\n\n// NG\nitems.push(\"c\");\nsetItems(items); // 変更されない(Object.is()→true)\n\n// OK\nconst newItems = [...items, \"c\"];\nsetItems(newItems); // 変更される(Object.is()→false)\n```\n\nNG の方は、同じオブジェクトを使いまわしているのに対し、OK の方は、新しくオブジェクトを生成しています。\n\n## パフォーマンス調査\n\nトップダウンでパフォーマンス調査をするのが、ベターと思います。\n\n1. Chrome Developer Tools > Lighthouse を使い、performance score を確認\n1. Chrome Developer Tools > Performance を使い、処理に時間がかかっている箇所を見つける\n1. React Developer Tools > Profiler を使い、React コンポーネントのレンダリングで時間がかかっている箇所を調査\n\n## React コンポーネント デザインパターン\n\nReact でコンポーネントを実装していると、次の 3 つのパターンがあるようです。\n\n- Container and presentation\n  - ロジックと UI を分離\n  - XxxContainer, Xxx という命名が多い\n- Higher order component\n  - 高階コンポーネント\n  - withXxx という命名が多い\n- Function as child\n  - コンポーネントではなく関数を child として渡す\n\n### ロジックを独自フックとして切り出す\n\nテスタビリティや再利用性の観点より、ロジックを hooks として切り出すのが良さそうです。\n\n- [独自フックの作成 – React](https://ja.reactjs.org/docs/hooks-custom.html)\n\n命名は、use から始まることが多いです。\n\n## その他\n\n- コンポーネントコードと同じフォルダ内に、次のファイルを置きたい\n  - テストコード (test)\n    - 仕様を知る\n  - カタログコード(storybook)\n    - UI を見る\n  - スタイルコード (scss)\n- input 要素などの onChange には、debounce を使う\n  - onChange の処理が重たいときに","publishedAt":"2022-06-25","slug":"what_I_learned_when_I_started_using_React_in_my_work","title":"［覚書］Reactを業務で使い始めて知ったこと"},{"body":"Micro Frontends(以降、MFE)で組成するフラグメントを Web Components で定義して Module Federation で共有する方法を、ざっくり紹介します。\n\nサンプルコードは、次のリポジトリにあります。\n\n- https://github.com/silverbirder/playground/tree/main/node/web-components-is-api-for-micro-frontends\n\n※ MFE については、以下のブログ記事をお読みください。\n\nhttps://silverbirder.github.io/blog/contents/mfe/\n\n## 用語\n\n- フラグメント\n  - 各フロントエンドチームが提供する UI 部品(HTML,CSS,JS,etc)\n  - コンポーネントと言い換えても良いです\n- 組成\n  - フラグメントを使って、ページ全体を構築する\n\nMFE で有名な Michael Geers さんの記事より、次のサンプル図があります。\n\n[![[翻訳記事]マイクロフロントエンド > mfe-three-teams](https://micro-frontends-japanese.org/resources/three-teams.png)](https://micro-frontends-japanese.org/)\n\nこの例は、EC サイトのサンプルです。\nチェックアウトチームは React を使っていて、フラグメントは次の 2 つです。\n\n- 購入ボタン(`buy for 66.00`)\n- バスケット(`busket: 0 items(s)`)\n\n組成は、プロダクトチームが担っています。\n組成は調整の難しさがあるので、専任のチームがあっても良いかもと思います。\n\n## フラグメントを Web Components で定義\n\nフラグメントは、各フロントエンドチームが自由に定義できます。React で書いたり、Vue で書いたりできます。\nフラグメントを組成するチームからすると、フラグメントのインターフェースが揃っている方が使いやすいと思います。\nそこで、フラグメントを Web Components で定義しましょう。(定義の中身は React や Vue など自由です)\n\nこのやり方は、以下の MFE を実現する 3 つの設計パターンどれでも適用できると思います。\n\n- ビルドタイム組成パターン\n- サーバーサイド組成パターン\n- クライアントサイド組成パターン\n\n次に、サンプルコードを紹介します。\n\n## 検索ボタンのフラグメント\n\n検索ボタンのフラグメント(Web Components)を書きます。\nそれは、ボタンとクリックハンドラを定義した簡単なものです。\nフレームワークは、React を選択しました。\n\n```typescript\n// ./packages/team-search/src/components/SearchButton/SearchButton.tsx\nimport React, { createContext } from \"react\";\nimport ReactDOM from \"react-dom/client\";\nimport App from \"./App\";\n\nexport const CustomElementContext = createContext<HTMLElement>(\n  document.createElement(\"div\")\n);\n\nexport class SearchButton extends HTMLElement {\n  connectedCallback() {\n    const mountPoint = document.createElement(\"span\");\n    this.attachShadow({ mode: \"open\" }).appendChild(mountPoint);\n    ReactDOM.createRoot(mountPoint as HTMLElement).render(\n      <React.StrictMode>\n        <CustomElementContext.Provider value={this}>\n          <App />\n        </CustomElementContext.Provider>\n      </React.StrictMode>\n    );\n  }\n}\n```\n\n```typescript\n// ./packages/team-search/src/components/SearchButton/App.tsx\nimport { useContext } from \"react\";\nimport { CustomElementContext } from \"./SearchButton\";\n\nconst App = () => {\n  const customElement = useContext(CustomElementContext);\n  const onClick = () => {\n    customElement.dispatchEvent(\n      new CustomEvent(\"search\", { detail: { num: Math.random() } })\n    );\n  };\n  return <button onClick={onClick}>Search</button>;\n};\n\nexport default App;\n```\n\nこの Web Components は、`<search-button />` と書いて使います。\n\n他のフラグメントと連携する場合、カスタムイベントを使います。\nこの Web Components は、クリックボタンを押したら、`CustomEvent(\"search\", { detail: <object> })` というカスタムイベントを発火します。\n\n## JSON を表示するフラグメント\n\n次に、このイベントのデータ(`<object>`)を表示するフラグメント(Web Components)を書きます。\n与えられた json 文字列を表示するだけのシンプルなものです。\nWeb Components へデータを与える手段は 3 つあります。(さらにあるかもです)\n\n- HTML 属性 (ex. `<div attribute=\"value\">`)\n  - プリミティブな値(数値、文字など)で使う\n- イベントリスナー (`eventlistener`)\n  - 非プリミティブな値(配列など)で使う\n- Slot (`<slot name=\"xxx\">`)\n  - HTML 要素を差し込みたいときに使う\n\n今回は、HTML 属性を選択しました。\n\n```typescript\n// ./packages/team-content/src/components/JsonDiv/JsonDiv.tsx\nimport ReactDOM from \"react-dom/client\";\nimport App from \"./App\";\n\nexport class JsonDiv extends HTMLElement {\n  root: ReactDOM.Root | undefined;\n  static get observedAttributes() {\n    return [\"value\"];\n  }\n\n  attributeChangedCallback() {\n    const value = this.getAttribute(\"value\") || (\"{}\" as string);\n    const props = { json: value };\n    if (this.root) {\n      this.root.render(<App {...props} />);\n    }\n  }\n\n  connectedCallback() {\n    const value = this.getAttribute(\"value\") || (\"{}\" as string);\n    const props = { json: value };\n    const mountPoint = document.createElement(\"span\");\n    this.attachShadow({ mode: \"open\" }).appendChild(mountPoint);\n    this.root = ReactDOM.createRoot(mountPoint as HTMLElement);\n    this.root.render(<App {...props} />);\n  }\n}\n```\n\nこの Web Components は、`<json-div value=\"{}\" />` のように使います。\n\n```typescript\n// ./packages/team-content/src/components/JsonDiv/App.tsx\ntype AppProps = {\n  json: string;\n};\n\nconst App = (props: AppProps) => {\n  const { json } = props;\n  return <div>{json}</div>;\n};\n\nexport default App;\n```\n\n`App.tsx`は、与えられた json を`<div>`で表示しているだけです。\n\n## 組成\n\nこれまで紹介したフラグメントを組成します。\n組成するためには、フラグメントを提供する仕組みが必要です。\nそこで、Webpack の Module Federation を使います。\n\n※ Module Federation を採用すると、各フロントエンドチームのビルドシステムを Webpack で縛ってしまうデメリットがあります。\n\n※ 他の提供する仕組みとして、`importmap` が使えないかなと思ったんですが、未検証です。\n\n## Module Federation\n\nModule Federation は、Webpack@5 から導入された機能です。\n\n- https://webpack.js.org/concepts/module-federation/\n\n> Each build acts as a container and also consumes other builds as containers. This way each build is able to access any other exposed module by loading it from its container.\n\nModule Federation は、各ビルドをコンテナとして機能させ、他のコンテナを使うことができます。\n今回で言うと、Web Components の SearchButton と JsonDiv をコンテナ化し、組成のビルドでコンテナを参照します。\n\n具体的なコードを紹介します。\n\n### コンテナ化\n\n検索ボタンをコンテナ化してみます。(JSON を表示するフラグメントも同様のコードです)\n\n```typescript\n// .packages/team-search/src/remoteEntry.ts\nexport { SearchButton } from \"./SearchButton\";\n```\n\n何をコンテナとして提供するか export します。\n次に、webpack の plugins コードを定義します。\n\n```javascript\n// .packages/team-search/webpack.config.js\n...\nconst config = {\n  entry: \"./src/index\",\n  plugins: [\n    new ModuleFederationPlugin({\n      name: \"search\",\n      filename: \"remoteEntry.js\",\n      exposes: {\n        \"./App\": \"./src/remoteEntry\",\n      },\n      shared: {\n        react: {\n          singleton: true,\n          strictVersion: true,\n          requiredVersion: \"^18.0.0\",\n          eager: true,\n        },\n        \"react-dom\": {\n          singleton: true,\n          strictVersion: true,\n          requiredVersion: \"^18.0.0\",\n          eager: true,\n        },\n      },\n    }),\n  ]\n};\n...\n```\n\n先程の export したファイルを exposes で設定します。\nライブラリの重複ロードを防ぐために shared を設定します。\nこれで、SearchButton をコンテナ化し提供できるようになりました。\n\n### 組成 (2)\n\nでは、コンテナをロードする組成側のビルド(webpack)を見てみます。\n\n```javascript\n// ./webpack.config.js\nconst URL_MAP = {\n  content: process.env.CONTENT_URL || \"http://localhost:3001\",\n  search: process.env.SEARCH_URL || \"http://localhost:4001\",\n};\n\nconst config = {\n  entry: \"./src/index\",\n  plugins: [\n    new ModuleFederationPlugin({\n      name: \"all\",\n      remotes: {\n        content: `content@${URL_MAP.content}/remoteEntry.js`,\n        search: `search@${URL_MAP.search}/remoteEntry.js`,\n      },\n      shared: {\n        react: {\n          singleton: true,\n          strictVersion: true,\n          requiredVersion: \"^18.0.0\",\n        },\n        \"react-dom\": {\n          singleton: true,\n          strictVersion: true,\n          requiredVersion: \"^18.0.0\",\n        },\n      },\n    }),\n  ],\n};\n```\n\nremotes で、コンテナをロードする URL を設定します。\n次に、entry コードです。\n\n```typescript\n// ./src/index.ts\n// @see: https://webpack.js.org/concepts/module-federation/#uncaught-error-shared-module-is-not-available-for-eager-consumption\nimport(\"./bootstrap\");\nexport {};\n```\n\n`@see`を読むと分かりますが、entry コードは、`import`で動的ロードする必要があります。\n次に、bootstrap コードです。\n\n```typescript\n// ./src/bootstrap.tsx\nimport React from \"react\";\nimport ReactDOM from \"react-dom/client\";\nimport App from \"./App\";\n\nconst root = ReactDOM.createRoot(\n  document.getElementById(\"root\") as HTMLElement\n);\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n```\n\n```typescript\n// ./src/App.tsx\nimport { useEffect } from \"react\";\n\nconst App = () => {\n  useEffect(() => {\n    import(\"content/App\").then((module) => {\n      const { JsonDiv } = module;\n      if (customElements.get(\"json-div\") === undefined) {\n        customElements.define(\"json-div\", JsonDiv);\n      }\n    });\n    import(\"search/App\").then((module) => {\n      const { SearchButton } = module;\n      if (customElements.get(\"search-button\") === undefined) {\n        customElements.define(\"search-button\", SearchButton);\n      }\n      const SearchButtonElement = document.querySelector(\"search-button\");\n      SearchButtonElement?.addEventListener(\"search\", ((e: CustomEvent) => {\n        document\n          .querySelector(\"json-div\")\n          ?.setAttribute(\"value\", JSON.stringify(e.detail));\n      }) as EventListener);\n    });\n  }, []);\n\n  return (\n    <>\n      <search-button />\n      <json-div />\n    </>\n  );\n};\n\nexport default App;\n```\n\nここにある `import(\"content/App\")` や`import(\"search/App\")` がコンテナを動的ロードしているところです。\nロードするものは、Web Components なので`customElements.define`で定義します。\nまた、`search-button`の`search`イベントハンドラをリッスンし、イベントデータを`json-div`の`value`属性に設定する処理を書きます。\nこれで、組成が完了です。\n\n実際に、動きを見てみたい場合は、リポジトリの README.md を見て試してみてください。\n\n## この手法におけるメリット\n\nWeb Components をフラグメントとして使うメリット・デメリットは、次のとおりです。\n\n- メリット\n  - 適合性\n    - Web Components は、Web 標準技術なので、ライブラリとの適合は容易\n    - HTML タグを使うようにカスタム HTML タグを使えば良い\n  - 独立性\n    - Shadow DOM というサンドボックス環境で開発可能\n- デメリット\n  - Javascript が動く必要あり\n\n## 最後に\n\nMicro Frontends で組成するフラグメントを Web Components で定義して Module Federation で共有する方法を紹介しました。\n実運用の経験はないですが、アイデアとして使えるかもしれないと思いました。","publishedAt":"2022-05-28","slug":"fragments_to_be_composed_in_Micro_Frontends_are_defined_in_Web_Components_and_shared_in_Module_Federation","title":"Micro Frontendsで組成するフラグメントをWeb Componentsで定義してModule Federationで共有する"},{"body":"## 結論\n\n`iframe.contentWindow` から `twttr` オブジェクトを見つけて、`event.bind(\"rendered\", () => {})` の第二引数に、表示処理を書くことです。\n\n```javascript\niframe.addEventListener(\"load\", () =>\n  iframe.contentWindow.twttr.events.bind(\"rendered\", () =>\n    iframe.setAttribute(\"style\", \"opacity: 1;\")\n  )\n);\n```\n\n## 背景\n\n`https://twitter.com/openwc/status/1427617679427440643` のような URL から、埋め込みコンテンツをブログサイトなどに表示したいです。\n\n`https://publish.twitter.com/oembed?url=${URL}` のレスポンスの中の html が、埋め込みコンテンツになります。\nこれを iframe の srcdoc に設定することで、埋め込みコンテンツを表示することができます。\n\n```html\n<iframe></iframe>\n```\n\n```javascript\n/*\nconst url = \"https://twitter.com/openwc/status/1427617679427440643\";\nconst oembedUrl = `https://publish.twitter.com/oembed?url=${url}`;\n// response.html of `fetch(oembedUrl)` is html.\n*/\nconst html =\n  '<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">`npm init @‌open-wc` now supports lit v2!<br /><br />Give it a try and let us know what you think<a href=\"https://t.co/9191LFIYHZ\">https://t.co/9191LFIYHZ</a></p>&mdash; Open Web Components (@OpenWc) <a href=\"https://twitter.com/OpenWc/status/1427617679427440643?ref_src=twsrc%5Etfw\">August 17, 2021</a></blockquote>\\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\\n';\n\nconst iframe = document.querySelector(\"iframe\");\niframe.setAttribute(\"srcdoc\", html);\n```\n\n## 課題\n\niframe で srcdoc を読み込んだ後、埋め込みたい Tweet の文字列だけが、チラっと見えてしまいます。\n下の例であれば、`npm init @‌open-wc now supports lit v2!` がチラっと見えるはずです。reload をしてみると分かります。\n\n<iframe\n  src=\"https://codesandbox.io/embed/display-embedded-twitter-content-5tx92y?fontsize=14&hidenavigation=1&theme=dark\"\n  style={{\n    width: \"100%\",\n    height: \"24rem\",\n    border: \"0\",\n    borderRadius: \"4px\",\n    overflow: \"hidden\"\n  }}\n  title=\"Display embedded twitter content\"\n  allow=\"accelerometer; ambient-light-sensor; camera; encrypted-media; geolocation; gyroscope; hid; microphone; midi; payment; usb; vr; xr-spatial-tracking\"\n  sandbox=\"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts\"\n></iframe>\n\nチラっと見えてしまうのを阻止したいです。\n\n## 解決\n\n埋め込みコンテンツの描画後イベント `rendered` というものがあります。これを使います。\n\nhttps://developer.twitter.com/en/docs/twitter-for-websites/javascript-api/guides/javascript-api\n\n実装の順番は、次のとおりです。\n\n1. iframe から、`load` イベントを検知\n1. `iframe.contentWindow` から、`twttr` オブジェクトを見つける\n1. `twttr.events.bind(\"rendered\", () => {})` で、描画後の処理を書く\n\n実際に、コードを書くと、次のとおりです。\n\n```javascript\n/*\nconst url = \"https://twitter.com/openwc/status/1427617679427440643\";\nconst oembedUrl = `https://publish.twitter.com/oembed?url=${url}`;\n// response.html of `fetch(oembedUrl)` is html.\n*/\nconst html =\n  '<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">`npm init @‌open-wc` now supports lit v2!<br /><br />Give it a try and let us know what you think<a href=\"https://t.co/9191LFIYHZ\">https://t.co/9191LFIYHZ</a></p>&mdash; Open Web Components (@OpenWc) <a href=\"https://twitter.com/OpenWc/status/1427617679427440643?ref_src=twsrc%5Etfw\">August 17, 2021</a></blockquote>\\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\\n';\n\nconst iframe = document.querySelector(\"iframe\");\niframe.addEventListener(\"load\", () =>\n  iframe.contentWindow.twttr.events.bind(\"rendered\", () =>\n    iframe.setAttribute(\"style\", \"opacity: 1;\")\n  )\n);\n\niframe.setAttribute(\"srcdoc\", html);\n```\n\nhtml は、`style`で隠しておきます。(手段は問いません)\n\n```html\n<iframe style=\"opacity: 0;\"></iframe>\n```\n\n解決した結果が、こちらです。\n\n<iframe\n  src=\"https://codesandbox.io/embed/display-embedded-twitter-content-after-l6l3h7?fontsize=14&hidenavigation=1&theme=dark\"\n  style={{\n    width: \"100%\",\n    height: \"24rem\",\n    border: \"0\",\n    borderRadius: \"4px\",\n    overflow: \"hidden\"\n  }}\n  title=\"Display embedded twitter content after rendered event\"\n  allow=\"accelerometer; ambient-light-sensor; camera; encrypted-media; geolocation; gyroscope; hid; microphone; midi; payment; usb; vr; xr-spatial-tracking\"\n  sandbox=\"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts\"\n></iframe>\n\n`npm init @‌open-wc now supports lit v2!` のチラっとが見えなくなっているはずです。","publishedAt":"2022-05-22","slug":"how_to_display_embedded_twitter_content_after_rendering_on_iframe","title":"iframeでTwitterの埋め込みコンテンツの描画後に、画面表示する方法"},{"body":"次の 2 つの Web Components を作成しました。\n\n- https://www.webcomponents.org/element/Silver-birder/o-embed\n- https://www.webcomponents.org/element/Silver-birder/ogp-me\n\n## 背景\n\n自分のブログで、埋め込みコンテンツを表示したいな〜って思ってました。\niframely というサービスを使っていましたが、自前で作りたいなというモチベーションが生まれました。\nそこで、OEmbed と OGP の表示ができるように、Web Components を独自に作成しました。\n\n## o-embed\n\nhttps://twitter.com/silverbirder/status/1475262255818473473\n\n## ogp-me\n\nhttps://silverbirder.github.io/blog/contents/intro_rocket/\n\n## 終わりに\n\n自分のブログは、Rocket という Markdown と Web Components をシームレスに使える SSG を使っています。\nそのため、めっちゃ楽に、自分で公開した Web Components を組み込むことができました。\nいや〜、満足です。","publishedAt":"2022-04-11","slug":"publish_my_web_components","title":"OEmbedとOGPのWebComponentsを作ったので、自分のブログサイトに使う"},{"body":"WebComponents で、oEmbed コンポーネントを開発し、公開しました。\n\n- https://www.webcomponents.org/element/Silver-birder/o-embed\n- https://www.npmjs.com/package/@silverbirder/o-embed\n\n開発していく上で、学んだことを列挙しようと思います。\n\n## スターターキット\n\nWeb Components を開発する場合、次のどちらかのスターターキットを使うのが良さそうです。\n\n- [webcomponents.dev](https://webcomponents.dev/)\n- [open-wc](https://open-wc.org/)\n\nこれらを使わずとも、Web Components を開発できるのですが、Typescript で書いたり、テストをしたりするには、\nそれなりに準備が必要です。そのため、開発の初速を高めたいなら、スターターキットを使いましょう。\n\nもしくは、先にスターターキットを使わず素の Javascript だけで Web Components を作ってみて、その後にスターターキットを使うと良さを実感できるかもしれません。\n\n個人的に、open-wc をお勧めします。なぜなら、以下のツールが揃っているからです。\n\n- Testing\n- Demoing\n- Building\n- Linting\n\nもちろん、Typescript もサポートしています。\n\n## キャッチアップ\n\nWeb Components ってどういうものなのか、キャッチアップするには MDN のサイトが参考になります。\n\n- [ウェブコンポーネント | MDN](https://developer.mozilla.org/ja/docs/Web/Web_Components)\n\nまた、日本語で WebComponents(Custom Elements)の仕様書もあります。\n\n- [HTML Standard — Custom elements（日本語訳）](https://triple-underscore.github.io/HTML-custom-ja.html)\n\nChrome の中にある Chromium におけるレンダリングエンジン blink の実装コードも、公開されています。\n\n- [chromium/third_party/blink/renderer/core/html/custom/README.md](https://source.chromium.org/chromium/chromium/src/+/main:third_party/blink/renderer/core/html/custom/README.md)\n\n## ベストプラクティス\n\nGoogle より、Custom Elements のベストプラクティスが公開されています。\n\n[Custom Element Best Practices  |  Web Fundamentals  |  Google Developers](https://developers.google.com/web/fundamentals/web-components/best-practices)\n\n例えば\n\n> Always accept primitive data (strings, numbers, booleans) as either attributes or properties.\n\nにあるように、プリミティブなデータのみ HTML の属性に渡すようにしましょう。\nオブジェクトや配列のようなリッチなデータは、シリアル化する必要がありオブジェクト参照がなくなってしまう欠点があります。\n\n## テスト\n\nWeb Components のテストを書くには、Shadow DOM に対応する必要があります。\nJSDOM のように、ブラウザ API をラップするライブラリを使っても良いのですが、ヘッドレスブラウザを使ったほうが妥当です。\nそこで、[@web/test-runner](https://www.npmjs.com/package/@web/test-runner)が便利です。\nこのテストライブラリは、open-wc と同じ Modern Web というモノの 1 つです。\n@web/test-runner には、Puppeteer、Playwright、Selenium の 3 つをサポートしています。\n\n## Publish\n\n作成した Web Components を Publish したい場合、次の記事を読むと良いです。\n\n[Developing Components: Publishing: Open Web Components](https://open-wc.org/guides/developing-components/publishing/)\n\n特に、してはいけないことを読むと、なるほどな〜ってなります。\n\n> ❌ Do not optimize  \n> ❌ Do not bundle  \n> ❌ Do not minify  \n> ❌ Do not use .mjs file extensions  \n> ❌ Do not import polyfills\n\n詳しくは、上記の記事を読んでください。\n\n## 終わりに\n\nWeb Components をプロダクションレベルで使えるようになりたいなと思います。","publishedAt":"2022-03-25","slug":"what_i_learned_from_developing_o_embed_web_components","title":"WebComponentsでoEmbedのコンポーネントを開発して、学んだこと"},{"body":"2022 年 1 月より新しい職場で、はじめて Ruby on Rails(以下、Rails)を使うようになりました。\nこれまで、PHP の CakePHP、Node.js の Express、Python の Flask の経験がある私ですが、\nRails に、なかなか慣れない苦労がありました。ゆるく、言語化しようと思います。\nちなみに、Ruby もはじめて使いました。\n\n## Rails Doctrine\n\nRails という新しく Web フレームワークを学ぶので、どういう思想で作られたのか知りたいなと思いました。\nそこで、下記のページをざっくり読んでみました。\n\n- https://rubyonrails.org/doctrine\n\nPoLS や CoC といった原則により、プログラマは余計な悩み事が減って良いな〜と思います。\nDB のテーブルのカラム名で、post_id なのか postId なのかなんてどうだって良いのは、とても同感です。\nディレクトリ構成も、CoC で決まっているので、論争が生まれることが少ないのかなと思います。\n\n## 慣れないところ\n\nまず、前提として、私が Ruby、Rails どちらも知らないというのがあります。\n\n- 引数無し関数の括弧省略と、変数の見分けがつかない\n\nRuby の話で、よくある話と聞いています。\nこれは、コード読んで、悩みました。\n\n- Ruby の関数か、Rails の関数か、独自の関数か、分からない\n\n業務で Rails のコードを読んでいると、これは Ruby の関数なのか、\nRails の関数なのか、それとも、独自の関数なのか、いつもわからなくなります。\n\n- マイグレーションって、移行という言葉として思ってた\n\nRails の文脈だと、マイグレーションって DB 管理の Ruby コードを指すみたいです。\nDB マイグレーションって言わないのね〜って、違和感がありました。\n\n## 最後に\n\nrails って、色々よしなにやってくれて便利〜！と思うこともあれば、\nどう動いているんだっけ？と分からなくなることもあるなと思っています。\n\nトレードオフと思うんですが、まだまだ慣れない今日このごろでした。","publishedAt":"2022-03-24","slug":"started_using_ruby_on_rails_at_work.","title":"Ruby on Railsを業務で使って思ったこと"},{"body":"React は、どうして生まれたのか歴史について簡単に紹介します。(ちょっと調べただけ)\n\n## 背景\n\n最近、React を学び始めました。その過程で、どうして React って学ぶべきなのか、どういう特徴があるのか気になった次第です。\n\n## 歴史\n\n言語やフレームワーク問わず、何かしら学ぶ際には、学ぶ対象の歴史や背景を知ることは大切だと思います。\n\n対象ソフトウェアの公式ドキュメントに、`Background`や`Motivation`、`History`、`Under the roof` を読むと良いです。\n\nしかし、React の公式ドキュメントは、そのような情報を発見できませんでした。\n\nReact の作成者 Jordan Walke の[React についての記事](https://hackernoon.com/the-evolution-of-react-48409fac2efd)を発見したので、それを読みました。\n\nざっくり要約すると、\n\n1. Facebook の広告系のプロダクト(Ads)のコードベースが大きくなった\n1. コードベースツリー(DOM ツリー?CSSOM ツリー?)の下位の変更で、全体の再描画(カスケード更新)が必要になり、メンテナンスが大変になった\n1. Reactive 特性(状態変化に基づく自動更新) を活かした FaxJS (後の React)が誕生\n\n## カスケード更新\n\nカスケードとは、[カスケード（カスケーディング）とは - IT 用語辞典 e-Words](https://e-words.jp/w/%E3%82%AB%E3%82%B9%E3%82%B1%E3%83%BC%E3%83%89.html) より\n\n> カスケードとは、何段も連なった小さな滝のこと。転じて、同じものがいくつも数珠つなぎに連結された構造や、連鎖的あるいは段階的に物事が生じる様子を表す。\n> Web ページの見栄えを定義する CSS（Cascading Style Sheet）で、ある要素に適用されるスタイルを、大域的に定義されたものから局所的に定義されたものへと順番に引き継ぎながら適用していくことをカスケードあるいはカスケーディングという。\n\nブラウザにおける CSS や DOM の更新が、まさにカスケードです。\n例えば、DOM の場合、親 Node から子 Node へ(API 等で取得した)データを伝搬します(prop)。\nデータ変更があった場合、親 Node から子 Node を順々に、再描画されます。(レンダリングエンジンの処理に従い)\n\nCSS や DOM のツリーの縦横が大きくなるにつれて、カスケード更新が大変になるのは、想像しやすいと思います。\n\n## React の目的\n\nReact は、この**コードベース規模が肥大化**した際における**カスケード更新を簡単にできること**を目的としたフレームワークだと、私は思いました。\n\n逆を言えば、\n\n**Not コードベース規模が肥大化** OR **Not カスケード更新** ならば React は不要なのかなと思います。\n\n## 仮想 DOM と差分検出処理(reconciliation)\n\nDOM 自体のレンダリングは、ブラウザのレンダリングエンジンに依存します。\nReact は、DOM ではなく、仮想 DOM と呼ばれる概念を生み出しました。\n\n[仮想 DOM と内部処理 - React](https://ja.reactjs.org/docs/faq-internals.html) より\n\n> 仮想 DOM とは？\n> 仮想 DOM (virtual DOM; VDOM) は、インメモリに保持された想像上のまたは「仮想の」UI 表現が、ReactDOM のようなライブラリによって「実際の」DOM と同期されるというプログラミング上の概念です。このプロセスは差分検出処理 (reconciliation)と呼ばれます。\n> このアプローチにより React の宣言型 API が可能になっています。あなたは UI をどのような状態にしたいのか React に伝え、React は必ず DOM をその状態と一致させます。これにより、React なしではアプリケーションを構築するために避けて通れない属性の操作やイベントハンドリング、および手動での **DOM 更新が抽象化されます**。\n\nカスケード更新をブラウザに任せるというより、フレームワーク(React)で仮想 DOM を管理し、(全体の再描画する必要なく)必要箇所のみ DOM を更新(再描画)するのだと思います。\n\n## React とカスケード更新\n\nReact を学ぶ前には、この**カスケード更新という単語を脳の片隅に置いておく**のが、良いと思います。\n\n例えば、React.memo という関数が存在します。\n\n[React の最上位 API - React](https://ja.reactjs.org/docs/react-api.html#reactmemo)\n\n> もしあるコンポーネントが同じ props を与えられたときに同じ結果をレンダーするなら、結果を記憶してパフォーマンスを向上させるためにそれを React.memo でラップすることができます。つまり、React はコンポーネントのレンダーをスキップし、最後のレンダー結果を再利用します。\n\nこの関数も、React の目的であるカスケード更新を改善するための関数だと、思います。\n\n## 小話\n\n何かを学ぶ際に、次の 3 つの軸を考えると良いです。\n\n- 時間\n  - 過去、現在、未来\n    - どういう経緯で現在に至るのか。未来は、どうありたいか。\n- 周辺\n  - 類似するモノ、競合他社。\n    - React でいうと、Vue.js のようなコンポーネントベースのフレームワークとか。\n- 社会\n  - チーム、グループ、会社、社会。\n    - React は、チームでなぜ選ばれたか。組織的な理由(採用など)も、含まれる。","publishedAt":"2022-03-11","slug":"know_the_history_before_learning_React","title":"Reactを学ぶ前に歴史を知る"},{"body":"Web Components を人にお勧めしたいんです。メリット・デメリットをかんたんにまとめたいと思います。\n\n## Web Components is 何\n\nhttps://www.webcomponents.org/specs より引用します。\n\n> Web components is a meta-specification made possible by four other specifications:  \n> The Custom Elements specification  \n> The shadow DOM specification  \n> The HTML Template specification  \n> The ES Module specification\n\nWebComponents は、ブラウザの 4 つの API で実現可能となるメタ仕様です。\n\n> These four specifications can be used on their own but combined allow developers to define their own tags (custom element), whose styles are encapsulated and isolated (shadow dom), that can be restamped many times (template), and have a consistent way of being integrated into applications (es module).\n\ndiv や span といった HTML タグがブラウザ標準にありますが、WebComponents は、独自のタグを定義することができます。\n\n## メリット\n\n- 環境適合性\n  - フレームワークに依存しないので、Rails など Web フレームワークへの適用が容易です。\n- 軽量\n  - ブラウザ API のみ使用するので、ロードするアセットはありません。\n- シンプル\n  - HTML タグを使う要領で、WebComponents を使います。\n- サンドボックス\n  - Shadow DOM のおかげで、CSS のスタイルが独自のタグの外に漏れません。\n\n## デメリット\n\n- パフォーマンス\n  - React のような描画最適化は、ありません。\n- 機能性\n  - ブラウザ API の影響を、受けます。\n- SEO\n  - Web Components は Javascript 実行が必須です。そのため、SSR は実現できません。","publishedAt":"2022-03-01","slug":"the_goodness_of_web_components.","title":"Web Componentsの良さ"},{"body":"2022 年 1 月 24 日、オミクロン株に感染しました。知らないことが多かったので、分かったことを書こうと思います。\n\n※ あくまで、私が経験した内容であり、一般的な内容かどうかは、知りません。\n\n## 結論\n\n- オミクロン株は、本当に感染しやすい\n  - (感染した)私\n    - ワクチン 2 回摂取\n    - フルリモートワーク\n    - 基礎疾患なし\n    - 手洗い・マスクの徹底\n    - 会食なし\n  - 感想\n    - 感染するかどうかは、運がかなり大きい気がする。\n    - コロナウィルス(デルタ株など)は、感染しないための対策が大切と思ってたけど、オミクロンに限っては、感染後の準備も大切だなと思う。\n- 喉(中咽頭)が、**めっっっちゃ痛い**\n  - オミクロン株の特徴の 1 つ\n  - 感想\n    - 唾液を飲み込むと、痛みが走る。\n      - 特に夜中は、**激痛になる**。\n      - 飲み込み動作を避けるために、唾液を溜めたり、ティッシュで捨てたりする。(ティッシュは袋に入れて、ちゃんと締める)\n    - 喉を潤わせることが大切\n      - マスク、のど飴 大事。\n- 症状が、インフルエンザに近い症状\n  - 症状\n    - 喉の痛み、高熱\n    - その他なし (嗅覚・味覚障害なし)\n  - **重症化なし**\n  - 感想\n    - 高熱は、内科で処方して貰ったお薬(葛根湯,カロナール)で充分治る。\n    - カロナール、ありがとう。\n\n## 体調変化の時系列\n\n| 日付                | 体温 | 症状             | 行動                   |\n| ------------------- | ---- | ---------------- | ---------------------- |\n| 2022 年 01 月 24 日 | 37.5 | なし             | 内科へ受診             |\n| 2022 年 01 月 25 日 | 39.1 | 喉(中咽頭)の炎症 | 内科で PCR 検査        |\n| 2022 年 01 月 26 日 | 38.0 | 喉(中咽頭)の炎症 | なし                   |\n| 2022 年 01 月 27 日 | 37.2 | 喉(中咽頭)の炎症 | PCR 検査より陽性と判明 |\n| 2022 年 01 月 28 日 | 36.4 | 喉(中咽頭)の炎症 | なし                   |\n\n熱は、平熱に戻りましたが、喉がまだ治りません。\n\n## 終わりに\n\nまだ保健所から電話がかかってきません。日に日に感染者数が増加してて、保健所は相当忙しいんでしょうね...、お疲れさまです。","publishedAt":"2022-01-28","slug":"covid-19-omicron-knowledge","title":"オミクロン株に感染したので、分かったことを書く"},{"body":"皆さん、Chrome 拡張機能をご存知ですか？\nChrome 拡張機能は、Chrome ブラウザをカスタマイズするための機能です。\n\n私は、Chrome 拡張機能を過去(数年前)に 2 つ作っていて、その当時は、Chrome 拡張機能の仕様である Manifest V2 に従っていました。\nそして、今再び、Chrome 拡張機能で作りたいものができたので、久々に作ろうと決意しました。\n作ろうと思ったものの、どうやら今の Chrome 拡張機能の仕様は Manifest V3 を推奨しているようです。\nそこで、今回、開発した際に知ったことをまとめようと思います。\n\nちなみに、実際に作ったものは次のものです。\n\n- https://github.com/silverbirder/chrome-extensions-tiktok-scraping-downloader\n  - 上にある図が、この Chrome 拡張機能の設計図になります\n\n※ Chrome 拡張機能の概要について詳しく知りたい方は、[What are extensions? - Chrome Developers](https://developer.chrome.com/docs/extensions/mv3/overview/)をご覧ください。\n\n## Chrome Extensions Components\n\nChrome 拡張機能は、主に次の 4 つのコンポーネントが存在します。\n\n- [Background Scripts](https://developer.chrome.com/docs/extensions/mv3/service_workers/)\n  - サービスワーカー上で動作し、ブラウザ上のイベント駆動(ページ遷移やブックマーク差所など)で反応します。\n  - [manifest](https://developer.chrome.com/docs/extensions/mv3/manifest/)の `background`フィールドで設定します。\n- [Content Scripts](https://developer.chrome.com/docs/extensions/mv3/content_scripts/)\n  - Web ページのコンテキスト上で動作し、DOM へアクセスできます。\n  - [manifest](https://developer.chrome.com/docs/extensions/mv3/manifest/)の `content_scripts`フィールドで設定します。\n- [UI Elements](https://developer.chrome.com/docs/extensions/mv3/user_interface/)\n  - URL バーの右側にあるボタンを押した(Action)際に表示される UI です。\n  - ブラウザ体験を損なわさない最低限の機能だけの提供を推奨されています。\n  - [manifest](https://developer.chrome.com/docs/extensions/mv3/manifest/)の `action`フィールドで設定します。\n- [Options Page](https://developer.chrome.com/docs/extensions/mv3/options/)\n  - Chrome 拡張機能アイコンを右クリックして、オプションを選択すると表示される UI です。\n  - Chrome 拡張機能をカスタマイズしたい設定ページに使います。\n  - [manifest](https://developer.chrome.com/docs/extensions/mv3/manifest/)の `options_page`フィールドで設定します。\n\n私なりに、これらのコンポーネントの使い分けを考えると、次になります。\n\n- DOM へアクセスする必要がある\n  - Content Scripts を使う\n- ページに依存しない処理がある\n  - Background Scripts を使う\n- 環境変数の設定が必要\n  - Option Page\n\nUI Elements は、基本的に必要ないのかなと思いました。\n\n## Debug\n\nデバッグって、どうやるんでしょうか。\n\n- [Debugging extensions - Chrome Developers](https://developer.chrome.com/docs/extensions/mv3/tut_debugging/)\n\nこちらにやり方が書いてありました。\n私なりに解釈した結果、次の 2 つで使い分けるのかなと思います。\n\n---\n\n- ① そもそも、Chrome 拡張機能がロードできない場合\n\nmanifest.json ファイルに記述で誤りがあるなどで、Chrome 拡張機能がロードできない場面があります。\nそういうときは、次の手順を実行します。\n\n1. `chrome://extensions` へアクセス\n1. 次の図にあるような ERROR ボタンをクリック\n\n![chrome extensions debug](https://res.cloudinary.com/silverbirder/image/upload/v1642325181/silver-birder.github.io/blog/chrome_extensions_debug.png)\n\n恐らく、何かしらエラーメッセージが出力されていると思います。\nそれを解決しましょう。\n\n---\n\n- ② ① 以外の場合\n\nChrome 拡張機能はロードできるが、期待通りに動作しない場面があると思います。\nそういうときは、DevTools を開きましょう。\n\n- Background Scripts の場合\n  - `chrome://extensions` へアクセスし、`inspect views`の右にあるリンクをクリック。(上図)\n    - DevTools が開きます。\n- Content Scripts, UI Elements, Options Page の場合\n  - UI 上で右クリックして `Inspect` をクリック\n    - DevTools が開きます。\n\nDevTools には、console タブがあるはずです。そこのログメッセージを確認しましょう。\n\n## Message Passing\n\n各コンポーネント間で、通信するのは、どうしたら良いのでしょうか。\n例えば、Content Scripts から Background Scripts へデータを渡したいときなどです。\n次の資料が、参考になります。\n\n- [Message passing - Chrome Developers](https://developer.chrome.com/docs/extensions/mv3/messaging/)\n\n資料を読むと、次のようなパターンの通信ができるようです。\n\n- 各コンポーネント間の通信\n  - Background Scripts ⇔ Content Scripts など\n- Chrome 拡張機能間の通信\n  - A Chrome 拡張機能 ⇔ B Chrome 拡張機能\n  - Chrome 拡張機能の ID を使って通信します\n- Web ページからの通信(Sending messages from web pages)\n  - Web ページ ⇔ Chrome 拡張機能のコンポーネント\n\n通信の具体的なコードは、`chrome.runtime.sendMessage`メソッドを使います。\nBackground Scripts から Content Scripts へ通信する場合、どの Chrome タブに送信するか`chrome.tabs.query`で事前に id を見つけておく必要があります。\n\nまた、後で紹介しますが、`Web Accessible Resources`でアクセス可能な Javascript を Web ページへ Inject(`document.querySelector('body').append()`)した場合、その Javascript と Content Scripts の通信は、`window.postMessage`と`window.addEventListener`を使いましょう。\n`chrome.runtime`が使えないので。\n\n## Web Accessible Resources\n\nContent Scripts から Web ページの DOM へアクセスできますが、window オブジェクトにある変数へアクセスすることができません。\n\n- ['javascript - Can the window object be modified from a Chrome extension? - Stack Overflow'](https://stackoverflow.com/questions/12395722/can-the-window-object-be-modified-from-a-chrome-extension)\n\nwindow オブジェクトへアクセスするには、Web Accessible Resources を使う方法があります。\n\n- [Manifest - Web Accessible Resources - Chrome Developers](https://developer.chrome.com/docs/extensions/mv3/manifest/web_accessible_resources/)\n\n---\n\n具体的にコードで説明しましょう。\n\nmanifest.json で必要なフィールドの例は、次のとおりです。\n\n```json\n{\n  \"manifest_version\": 3,\n  \"content_scripts\": [\n    {\n      \"js\": [\"content-script.js\"],\n      \"matches\": [\"https://*/*\"]\n    }\n  ],\n  \"web_accessible_resources\": [\n    {\n      \"resources\": [\"web_accessible_resources.js\"],\n      \"matches\": [\"https://*/*\"]\n    }\n  ]\n}\n```\n\nContent Scripts と Web Accessible Resources の Javascript は次のとおりです。\n\n```javascript\n// content-script.js\nconst injectScript = (filePath, tag) => {\n  var node = document.getElementsByTagName(tag)[0];\n  var script = document.createElement(\"script\");\n  script.setAttribute(\"type\", \"text/javascript\");\n  script.setAttribute(\"src\", filePath);\n  node.appendChild(script);\n};\ninjectScript(chrome.runtime.getURL(\"web_accessible_resources.js\"), \"body\");\n```\n\n```javascript\n// web_accessible_resources.js\nconsole.log(window[\"hoge\"]);\n// Content Scriptsへ通信する場合は、window.postMessageを使います。\n```\n\nこのように、web_accessible_resources.js を Web ページの body タグへ append します。\nその web_accessible_resources.js では、window オブジェクトにアクセスすることができます。\n\n## chrome.webRequest API\n\nChrome ブラウザでネットワークトラフィックを監視する Chrome 拡張機能の API があります。\nそれが、`chrome.webRequest`です。\n\n- [chrome.webRequest - Chrome Developers](https://developer.chrome.com/docs/extensions/reference/webRequest/)\n\nこれがあれば、Web ページでどういうリクエストが発生しているか分かるようになります。\nmanifest.json のフィールドで、`host_permissions`の設定が必要です。\n\n---\n\nサンプルで、Background Scripts のコードを紹介します。\nまず、manifest.json の必要なフィールドを書きます。\n\n```json\n{\n  \"manifest_version\": 3,\n  \"host_permissions\": [\"https://*/*\"],\n  \"background\": {\n    \"service_worker\": \"background.js\"\n  }\n}\n```\n\n次に、Web ページからリクエストが完了(onCompleted)したイベントを監視するコードを書きます。\n\n```javascript\n// background.js\nchrome.webRequest.onCompleted.addListener(\n  async (details) => {\n    console.log(`request url is ${details.url}`);\n  },\n  {\n    urls: [\"https://*/*\"],\n  },\n  [\"responseHeaders\"] // responseHeadersをdetailsオブジェクトに含めることができます。\n);\n```\n\nこの details にはリクエストの URL が含まれています。さらに詳しく知りたい人は、[こちら](https://developer.chrome.com/docs/extensions/reference/webRequest/#event-onCompleted)をご確認ください。\n\n## 最後に\n\nChrome 拡張機能、久々に開発してみると、進化しすぎていてキャッチアップに苦労しました。\n私と同じような方の助けになれば、幸いです。","publishedAt":"2022-01-16","slug":"chrome_extension_development_feedback","title":"Chrome拡張機能(Manifest V3)の開発で知ったこと"},{"body":"Markdown でブログやドキュメントを書いていますか？\n執筆活動に集中したいのに、Markdown だけだとかゆいところに手が届かないもどかしさ、感じたことありませんか？\n\nそんな方に、Markdown と WebComponents がシームレスに統合できる静的サイトジェネレータ(以降、SSG と呼ぶ)、Rocket をおすすめします。\n\n## 対象読者\n\n- (ブログなど)執筆活動に集中したい人\n  - 執筆に、Markdown を利用している\n- 執筆したコンテンツを SSG で公開している人\n- SSG の移行コストを極力減らしたい人\n\n## そもそも、Markdown って何\n\nMarkdown は、Qiita や Zenn、はてなブログなどの各サービス(以降、執筆サービスと呼ぶ)、に使われていたり、Git リポジトリの説明書として README.md を書いたりしますよね。\n\nその Markdown ですが、どういう目的で作られたモノなのでしょうか。\n\n[Daring Fireball: Markdown](https://daringfireball.net/projects/markdown/) から引用します。\n\n> Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML).\n\nMarkdown は、**Web ライター**向けに開発された PlainText から HTML へ変換するためのツールです。\nまた、Markdown には**書きやすさ、読みやすさが大切**です。\n\nWeb ライターは、ブログ記事やネット広告の文章など、Web 向けコンテンツを執筆する人です。\nそう、**執筆**です。Markdown は、執筆のための道具です。\n\nそのため、ブログ記事や Git リポジトリの説明書に Markdown を用いるのは、目的に合っています。\n逆に、構造的な特徴を利用して、一種のデータファイルとして Markdown を使ったり、ショッピングやゲームといったアプリケーションに Markdown を使うのは、目的に反します。\n\n## Markdown と HTML\n\nMarkdown には、見出しや箇条書き、テーブルなどの記法(シンタックス)があります。\nこれらの記法を用いて、構造的に記事を書くことができます。\n\n執筆で欲しい記法がなかった場合は、どうしたら良いでしょうか。\n\n[Daring Fireball: Markdown Syntax Documentation](https://daringfireball.net/projects/markdown/syntax) より引用します。\n\n> For any markup that is not covered by Markdown’s syntax, you simply use HTML itself. There’s no need to preface it or delimit it to indicate that you’re switching from Markdown to HTML; you just use the tags.\n\nMarkdown には HTML が使えます。執筆サービスの Markdown で、HTML を書いてみると、恐らく使えるはずです。\n\nMarkdown は HTML へ変換するという目的を考えると、HTML が使用できるというのは納得できると思います。\nただし、**HTML を使用することで、読みやすさや書きやすさは少し悪くなってしまうため、多用は避けなければいけません**。\n\n## HTML では物足りない\n\n執筆サービスを使ってみるとわかると思いますが、おおよそ次の機能が提供されています。\n\n- 埋め込み(Embed)コンテンツ\n  - URL を書くと、Description やタイトル、画像を表示してくれる\n- 目次(TOC)生成\n  - 文章の見出しを収集し、目次を生成してくれる\n\nこれらの機能によって、執筆したコンテンツが読みやすくなったり、執筆の効率性が向上したりします。\n当たり前ですが、Markdown には、そのような機能が存在しません。\nMarkdown は、記法を定義しているだけなので、Markdown に機能拡張を望んでいる訳ではありません。\n\nしかし、執筆をしていくと、それらの機能が**どうしても欲しくなってきます**。\n機能がなくても、Markdown 記法を駆使すれば、埋め込みコンテンツっぽく表示できますし、目次も手動で生成できます。\nただ、本来執筆に集中したいのに、見出しが増えるたびに、目次を手動更新するというのは、非効率的です。\n\nその非効率、どうしたら良いでしょうか。\n\n### 案 1. Markdown から HTML への変換処理で、機能拡張する\n\nMarkdown から HTML への変換処理で、埋め込みコンテンツや目次生成といった機能を拡張します。\n具体的な話をした方が分かりやすいと思うので、目次生成を例にして、説明します。\n\n説明しやすいために自前で変換処理を書きますが、本来は、Hugo や GatsbyJS、MDX などを想定しています。\n\n[Markdown を HTML に変換する · JavaScript Primer #jsprimer](https://jsprimer.net/use-case/nodecli/md-to-html/) がちょうど分かりやすかったので参考にします。\n\nMarkdown と変換処理の transform.js を、次のものとします。\n\n```markdown\n## Header1\n\nHello, World\n```\n\n```javascript\n// transform.js\nconst fs = require(\"fs\");\nconst { marked } = require(\"marked\"); // markdownをhtmlへ変換してくれる\n\nconst markdown = fs.readFileSync(\"README.md\", { encoding: \"utf-8\" });\nconst html = marked(markdown);\nconsole.log(html);\n```\n\ntransform.js は、とてもシンプルです。README.md を html に変換して標準出力するだけです。\n実行してみましょう。\n\n```bash\nnode transform.js\n<h1 id=\"header1\">Header1</h1>\n<p>Hello, World</p>\n```\n\n期待通り、HTML が出力されました。次は、目次生成です。\nはてなブログでは、目次生成に `[:contents]` というマーカーを書くと、そこが目次となります。\n脱線ですが、[remark](https://github.com/remarkjs/remark) という、Markdown に変換処理をしてくれるツールがあります。\n\n目次生成のサンプルコードを書いていきます。\n\n```markdown\n[:contents]\n\n## Header1\n\nHello, World\n```\n\n```javascript\n// transform.js\nconst fs = require(\"fs\");\nconst { marked } = require(\"marked\"); // markdownをhtmlへ変換してくれる\n\nconst markdown = fs.readFileSync(\"README.md\", { encoding: \"utf-8\" });\nreMarkdown = markdown\n  // TODO: replaceの第2引数の固定を動的に設定\n  .replace(/\\[:contents\\]/g, '<div id=\"toc\"><ul><li>Header1</li></ul></div>');\nconst html = marked(reMarkdown);\nconsole.log(html);\n```\n\nとても馬鹿げているコードだと思いますが、伝えたいことが書けているので、これで良いです。\n実行してみます。\n\n```bash\nnode transform.js\n<div id=\"toc\"><ul><li>Header1</li></ul></div>\n\n<h1 id=\"header1\">Header1</h1>\n<p>Hello, World</p>\n```\n\n期待通り、Markdown の目次が生成されています。\nこれは簡単な例ですが、機能拡張していくと、transform.js の処理が増えたり、README.md にマーカーがたくさん書かれていきます。\n\nこのように変換処理に機能拡張するのは、変換処理に機能を一任できるというメリットがあります。\nですが、**Markdown が変換処理に依存してしまう**こととなってしまいます。\nこれは、変換処理を違うものへ移行するときに**移行コスト**が発生してしまいます。\n\nまた、Markdown 自体に、**Markdown 記法や HTML でもないマーカーを埋める**というのも、ちょっと違和感を感じます。\n\n### 案 2. WebComponents で、機能拡張する\n\nWebComponents は、Web 標準技術の 1 つで、HTML 要素を独自にカスタマイズできる機能(Custom Elements)があります。\n例えば、目次生成するための HTML 要素、`<generate-toc>`を WebComponents で開発したとします。\nこの HTML 要素は、全ての見出しテキストを収集し、箇条書きで表示するだけの WebComponents だとします。\n\nMarkdown のイメージは、次のとおりになります。\n\n```markdown\n<generate-toc />\n\n## Header1\n\nHello, World\n```\n\nこの Markdown を、任意の HTML 変換処理(さきほどの transform.js でも可)をすると、次の結果になります。\n\n```html\n<generate-toc />\n\n<h1 id=\"header1\">Header1</h1>\n<p>Hello, World</p>\n```\n\nMarkdown は HTML を許容するため、`<generate-toc />`が、そのまま HTML 出力されます。\nこのままだと、ブラウザが `generate-toc` を識別できません。そのため、`generate-toc`を定義したコード、つまり WebComponents を読み込む必要があります。\n例えば、次のようなコードを読み込みます。\n\n```html\n<script>\n  class GenerateToc extends HTMLElement {\n    constructor() {\n      super();\n      const shadow = this.attachShadow({ mode: \"open\" });\n      // TODO: 見出しを収集し、箇条書きのHTMLを構築する処理\n      shadow.innerHTML = `<div id=\"toc\"><ul><li>Header1</li></ul></div>`;\n    }\n  }\n  customElements.define(\"generate-toc\", GenerateToc);\n</script>\n```\n\nこれで、ブラウザは `generate-toc`を識別できるようになったため、期待通り目次が表示されます。\n\nWebComponents を利用するメリットは、**変換処理に依存せず WebComponents に依存します**。ブラウザの標準技術に依存するというのは、全く問題ありません。\n変換処理の移行をしても、WebComponents のコードがあれば、同じ動作が実現できます。\n\nまた、再掲ですが、Markdown に次の文章があったとしても、Markdown の仕様に反しません。\n\n```markdown\n<generate-toc />\n\n## Header1\n\nHello, World\n```\n\nMarkdown の目的や仕様、Web というプラットフォームを考慮すると、Markdown と WebComponents の組み合わせは、相性が良いと思います。\n\n## ようやく登場、Rocket\n\nお待たせしました、ようやく Rocket の登場です。\n\nRocket は、Markdown と WebComponents をシームレスに統合できる SSG です。\nModern Web と呼ばれる Web 標準技術の開発支援を行うプロジェクトがあり、その中のサブプロジェクトとして[rocket](https://rocket.modern-web.dev/)があります。\n他のサブプロジェクトとして、[テストランナー](https://modern-web.dev/docs/test-runner/overview/)と[開発サーバー](https://modern-web.dev/docs/dev-server/overview/)の[modern-web](https://modern-web.dev/)、WebComponents の開発、テスト、リンターなどの[open-wc](https://open-wc.org/)があります。\n\nRocket の事例は、次のものがあります。\n\n- https://modern-web.dev/\n- https://rocket.modern-web.dev/\n- https://open-wc.org/\n- https://apolloelements.dev/\n\nRocket は、技術的には、Eleventy という SSG の Wrapper になります。\nEleventy は、Markdown を HTML へ変換してくれます。Rocket は、その Eleventy に Modern Web の技術(WebComponents,TestRunner,DevServer)を混ぜています。\n\n### Modern Web って\n\nJavascript を使って開発すると、Babel のトランスパイラ、ESLint のリンター、Jest のテスター、Webpack のビルダーなど、扱うツールが多く、必要以上に複雑になり、開発者は疲弊してしまいます。\n本来、開発に注力すべきなのに、それらの複雑さによって、アジリティ低下につながることを、開発者は知っています。\n\nそこで、WebComponents や、ESModules といった Web 標準技術で開発することで、複雑さといったものを軽減していく狙いが、Modern Web にはあります。\n\n※ JSDOM のようなブラウザ API をモックすることでテストするのではなく、本来動いているブラウザでテストするテストランナーもあります。\n\nModern Web は、そういった Web 標準技術の開発を支援します。\n\n## Rocket の特徴\n\n[Rocket のホームページ](https://rocket.modern-web.dev/)に、Rocket の特徴を 6 つ書いてあります。\nしかし、本記事の流れ的に Markdown と WebComponents の統合についてを説明すべきだと思うので、次の 1 つだけ特徴を紹介して、その他は割愛します。\n\n- Meta Framework\n  - Build on top of giants like Eleventy, Rollup, and Modern Web.\n\nEleventy や(話題にしていませんでしたが)Rollup、Modern Web という巨人の肩に乗ることで、Rocket の魅力があると思っています。\n\nこれまでの話で、『Eleventy で Markdown を HTML に変換して、WebComponents を読み込ませればよいでしょ？Rocket 必要？』と思う方がいるかもしれません。実際、その 2 つだけあれば充分だと思います。\n\nただ、Modern Web というプロジェクト支援があると、開発アジリティは向上します。\n具体的には、Markdown や Javascript 変更による自動リロード、[Eleventy の画像変換処理](https://www.11ty.dev/docs/plugins/image/)、[Markdown のリンク先チェック](https://rocket.modern-web.dev/tools/check-html-links/overview/)などがあります。\nまあ、必須ではないので Eleventy と WebComponents でも良いと思いますが、私は Rocket を使います。\n\n## Markdown Javascript\n\nMarkdown と WebComponents の統合について説明します。\n\nRocket には、Markdown Javascript という機能があります。これは内部的に MDJS というライブラリを使っています。\n以下に、MDJS についての InfoQ の記事がありますので、よければご参照ください。\n\n- [新しい MDJS マークアップ言語により JavaScript を Markdown に追加してインタラクティブなドキュメント作成が可能に](https://www.infoq.com/jp/news/2020/08/mdjs-markdown-web-components/)\n\nMarkdown Javascript は、Markdown に Javascript を記入でき、インタラクティブに実行できる機能を備えています。\n例えば、次のような Markdown を書いたとします。\n\n````markdown\n```js script\nconsole.log(\"Hello, World\");\n```\n````\n\nこれを書いて、Rocket で実行すると、ブラウザの開発ツールのコンソール画面に `Hello, World`と表示されます。\nこれを応用して、WebComponents を定義することもできます。\n\n````markdown\n```js script\nclass MyDiv extends HTMLElement {\n  constructor() {\n    super();\n    const shadow = this.attachShadow({ mode: \"open\" });\n    shadow.innerHTML = `Hello, World`;\n  }\n}\n\ncustomElements.define(\"my-div\", MyDiv);\n```text\n\n<my-div></my-div>\n````\n\nこれを Rocket で実行すると、画面に `Hello World` と表示されます。\nこのように、Markdown 上に WebComponents を定義し、インタラクティブに実行されるため、**即座に WebComponents を使うことができます**。\n\n使い捨ての WebComponents であればこれで良いのですが、使いまわしたいときがあると思います。\nそういう場合は、共通する箇所に WebComponents を定義するのが良いでしょう。\nNumjucks の script ヘッダに、共通化したい WebComponents を書いてあげると、どの Markdown からでも定義した WebComponents を使えます。\n\n### Bare Import のサポート\n\nRocket は、Modern Web の[開発サーバー](https://modern-web.dev/docs/dev-server/overview/)を内部で使用しています。開発サーバーには、[Bare Import をサポートしています](https://modern-web.dev/blog/introducing-modern-web/#highlights-1)。\n\nBare Import の例を示します。\n事前に `npm install canvas-confetti` インストールしていることを前提とした場合、次の Markdown は`confetti()`が実行されます。\n\n````markdown\n```js script\nimport confetti from \"canvas-confetti\";\nconfetti();\n```\n````\n\nこのように、相対パスや絶対パスを意識せず Bare で指定できるようになります。\n\n### WebComponents のコミュニティからライブラリを使う\n\n独自に WebComponents を書かなくても、次の WebComponents のコミュニティサイトから良さそうなものを使うこともできます。\n\n- [webcomponents.org](https://www.webcomponents.org/)\n\n例えば、[emoji-picker-element](https://www.webcomponents.org/element/emoji-picker-element)という WebComponents を使ってみたいとします。emoji-picker-element は、絵文字キーボードの UI に似ています。Mac なら、command + control + スペースキー で表示されます。\n\n使い方は、簡単です。\n先ほどと同じく、`npm install emoji-picker-element` でインストールしておけば、次の Markdown を書くだけで `<emoji-picker-element>`が使えます。\n\n````markdown\n```js script\nimport \"emoji-picker-element\";\n```text\n\n<emoji-picker></emoji-picker>\n````\n\n## 宣伝\n\nWebComponents についての入門書を Amazon で、500 円で販売しています。\n今回の Rocket については書いていませんが、[open-wc](https://open-wc.org/)のテストについて触れています。\n\n- [はじめての Web Components 入門: 4 つの基本機能から関連ライブラリまで](https://www.amazon.co.jp/gp/product/B08CY2QCFV/)\n\nまた、私のポートフォリオページを Rocket で作成しています。このブログも Markdown で執筆しています。よければご覧ください。\n\n- [silverbirder's page](https://silverbirder.github.io/)\n  - このブログの Markdown ファイルは、[こちら](https://github.com/silverbirder/silverbirder.github.io/blob/main/docs/blog/contents/intro_rocket.md)\n\n## 終わりに\n\nRocket の紹介が、随分と後ろの方になってしまいました。前置きが長すぎたかもしれません。\n少しでも誰かのお役に立てればと思います。","publishedAt":"2021-12-24","slug":"intro_rocket","title":"Markdownで執筆するなら、WebComponentsが使えるSSG、Rocketがオススメ！"},{"body":"この度、私のポートフォリオページを刷新致しました。本記事では、\n刷新することになった動機から、刷新内容、今後について紹介したいと思います。\n\n## 動機\n\n元々、私のポートフォリオページは、静的ページジェネレーターである Hugo を使って\n構築していました。\n\nhttp://kohki.hatenablog.jp/entry/hugo-portfolio\n\nこちらの記事を参考にして、Hugo でポートフォリオページを作りました。\nその当時、なぜポートフォリオを作ったのかというと、確か次の 3 つの思いがありました。\n\n- 私がどういった人かを知ってもらいたい\n- 自分のサイトを持ちたい\n- 静的ページジェネレーターを使ってみたい\n\nHugo で記事を管理する対象は、Markdown であるため、エンジニアにとって書きやすいです。\nまた、デザインテーマは、公開されているテーマがあるので、好きなものを選びます。\n\n導入当初は、とても快適でした。手軽にオシャレなポートフォリオサイトを公開できて満足でした。\nしかし、ずっと使っていると、かゆいところに手が届ないもどかしさを感じるようになりました。\nこれは、便利さとのトレードオフだと思いますが、下記のようなデメリットがあると認識し始めました。\n\n- Javascript で技術的な挑戦が難しい\n- デザインテーマのカスタマイズが難しい\n- SEO のチューニングが難しい\n\n便利さというメリットよりも、デメリットの方が大きいように思い始めました。\nそのため、独自にポートフィリオサイトを作成することにしました。\n\n## やったこと\n\nAMP を存分に使ったポートフォリオサイトを作成しました。全体像は、下記のとおりです。\n\n![overview](https://res.cloudinary.com/silverbirder/image/upload/v1640068525/silver-birder.github.io/blog/silverbirder_portfolio_amp_overview.png)\n\n[AMP Optimizer](https://www.npmjs.com/package/@ampproject/toolbox-optimizer)を中心とした構成です。\nソースコードは、下記のリポジトリにあります。\n\nhttps://github.com/silverbirder/silverbirder.github.io\n\n## 技術選択\n\n今回のポートフォリオサイトに、必要以上の機能を持つ Web フレームワーク(e.g. Next.js)を使うのは、メンテナンスコストが高くなるので、却下としました。\nまた、静的ページジェネレーター(e.g. Gatsby)も、動機の理由より却下としました。\nそのため、必要最小限な構成を目指しました。結果、次のような流れとなりました。\n\n1. コンテンツを用意する(Markdown,HTML,JSON)\n1. 1 をインプットとして[AMP Optimizer](https://www.npmjs.com/package/@ampproject/toolbox-optimizer)で AMP 化する\n\nこれらの順序を制御するタスクランナーとして、[Gulp](https://www.npmjs.com/package/gulp) を採用しました。\n[AMP Optimizer](https://www.npmjs.com/package/@ampproject/toolbox-optimizer)は、NPM でインストールするので、Node.js と相性が良いタスクランナーを求めました。\nその選択肢として、Grunt や Gulp があったのですが、[AMP の公式サイトでは Gulp を紹介されていた](https://amp.dev/documentation/guides-and-tutorials/optimize-and-measure/amp-optimizer-guide/node-amp-optimizer/)ので、Gulp を選択しました。\n\n大きな技術選択としては、これくらいです。他の細かい所は、下記のとおりです。\n\n- highlightjs\n  - プログラムコードのハイライト機能\n- jsdom\n  - html の各処理\n    - h1~h6 タグの Anchor 設定(anchorJS 風)\n    - HTML のテンプレートとメインコンテンツの Mix\n    - ...etc\n- ampcssframework\n  - Dark Theme や Grid 機能が欲しかった\n- Cloudinary\n  - 画像管理 SaaS。OGP などに利用\n- SEO 向け\n  - Google search console\n  - Google analytics\n\n## ポートフォリオコンテンツ\n\nポートフォリオサイトにどういったコンテンツを用意しようか悩みました。\n[AMP Optimizer に Markdown オプション](https://github.com/ampproject/amp-toolbox/tree/main/packages/optimizer#markdown)があります。\nこれは、HTML だけではなく、Markdown も(HTML 経由で)AMP 化することができるようです。\nそのため、ブログのようなコンテンツもポートフォリオページに加えることができそうと気づきました。\nまた、これまで私が書いたブログコンテンツは、Markdown で管理していたので、ちょうど使えそうでした。\n\n結果、次のようなコンテンツを用意しました。\n\n- 自己紹介\n- ブログ\n- 持っている本検索\n- 買ったものリスト\n  - アマゾンで買ったもの、サブスク\n- ウォッチ\n  - チェックしてる RSS\n- プロジェクト\n  - 作ったものの紹介\n\nウォッチページで、RSS の WebPush 機能を追加しようとしましたが、Push する側である Server が必要となり、開発が伸びそうだったのでやめておきました。\n\n## 刷新してどうだったか\n\n想定通り、Hugo ではできなかったような様々なポートフォリオサイトの機能拡張ができるようになりました。\n\n- Javascript で技術的な挑戦が難しい\n  - AMP や、Web Worker(amp-script)を試せた\n- デザインテーマのカスタマイズが難しい\n  - CSS フレームワークや、CSS のチューニングができた\n- SEO のチューニングが難しい\n  - SearchConsole や GoogleAnalytics が使えた\n  - sitemap や meta タグのチューニングができた\n\n想定通りにできなかったのは、AMP の制約なのですが、WebComponents のような amp-script 上で動かせない技術もあるということでした。\nまた、WebWorker(amp-script)上で、ES Module([skypack](https://skypack.dev/))を Import しようとしても、Safari が未対応だったりで、断念したりもしました。\n\nただ、最終的な感想としては、HTML を柔軟に処理できるようになったので、AMP 上でできることは何でもできるようになり、刷新してよかったと思います。\n\n## 学んだこと\n\n経験学習モデルより、簡単に振り返ります。(はじめて)\n\n| 経験                                                 | 省察                                                                                                       | 概念化                                                 | 試行                                         |\n| ---------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ | -------------------------------------------- |\n| AMP を初めて使ってみた                               | AMP 使ったことなかったけど、思っていたより課題は少なかった。 / しかし、想定していなかった課題もあった。 | 使ったことがない技術要素の課題は、想定していても未知数 | 未知数な技術は、軽く試してみる               |\n| Next.js や Gatsby など、フレームワークを使わなかった | シンプルな構成にしたかった。 / 必要以上に機能が多いフレームワークを入れたくなかった。                   | 保守性を担保するため、最小限の機能で構成               | 大掛かりな技術の選択は、保守性と天秤にかける |\n\n## 終わりに\n\nポートフォリオ刷新をしました。これまで 1 から Web サイトを作ったことがなかったので、\nsitemap や JSON-LD など全て手作りで開発したので、良い勉強になりました。\nまだまだポートフォリオの課題は山積みですが、少しずつ改善していきたいと思います。","publishedAt":"2021-12-23","slug":"replace_my_portfolio_v2","title":"silverbirderのポートフォリオページ刷新(v2)"},{"body":"2021 年も、もう残りわずかになりました。今年も、振り返りをブログに残そうと思います。\n\n## 技術\n\n### フルスタックエンジニアリング\n\n今年は、業務でフルスタックな開発を多く経験できました。\n昨年までは、Web アプリケーションの開発が多かったのですが、今年はクラウドインフラやデータ構築の業務が多かったです。\nまた、ゼロベースで構築したプロダクトの運用も経験したことで、去年に比べて幅広いエンジニアリング力を身につけられたなと思いました。\n\n具体的に経験したソフトウェアは、[Resume##Career](../.././resume)に書いていますので、ご参照ください。ざっくり言うと、クラウドインフラは GCP/Terraform, データ構築は BigQuery と Digdag です。\n\n### 転職\n\n現職が 2 社目になります。\n1 社目が SIer で、2 社目が自社サービス会社で勤務していました。\n1 社目から 2 社目は、(諸事情により)転職活動をせずに、転職していました。\nそのため、3 社目の転職は、カジュアル面談や自己分析などといった転職活動をはじめて経験しました。\n\nその転職活動については、[カジュアル面談を 10 社受けた感想](./my_feedback_after_taking_casual_interviews_with_10_companies_in_2_months) で触れています。\n\n転職活動することで、次のようなことを考えるようになりました。\n\n- 私のキャリア形成\n- 私の市場価値\n- 私のできること・やりたいこと・すべきこと\n\n## 生活\n\n### 結婚記念写真\n\n結婚式は、コロナの収束が見えない状況だったため、まだ挙げていません。\nコロナの収束を待っていては、何も予定が決められないため、結婚記念写真だけでも撮ろうと決断しました。\n撮影当日を、2021 年 3 月中旬ぐらいに設定したため、桜の綺麗な景色をバックに写真を撮ろうと計画しました。\n\n例えば、次のようなことを考えました。\n\n- 大阪城のチャペルを貸し切る\n- プロのカメラマンに撮影頂く\n- 和装・洋装どちらも着る\n\n最後の\"和装・洋装どちらも着る\"は、衣装替えによってタイトなスケジュールになってしまうため、洋装のみとしました。\n\n撮影当日は、曇りの天候でしたが、場を和ませてくれるカメラマンさんや、チャペルスタッフの方々のおかげで、とても晴れやかな雰囲気で撮影できました。\n私と妻の両家の両親へ写真を共有し、とても喜んでくれました。\n\n### 新婚旅行\n\n新婚旅行に行ってきました。\n当初、海外を考えていましたが、感染リスクを考えると国内にしようと話になりました。\nそこで、ハレクラニ沖縄というハネムーンに最適なリゾート地に向かい、そこから 4 泊 5 日のスケジュールを考えました。\n\n普段、あまり経験しないようなことをしようということで、SUP やクルーズなどを調べていました。\n妻と予定を考えるのが楽しかったり、意見が衝突してケンカしたりと、良い思い出になりました。\n\nまたしても、新婚旅行の天候は芳しくなく、いくつか予定変更を余儀なくされましたが、\nこのような事態を何度も経験しているたためか、臨機応変に予定を組み直し、自由気ままに遊んで満喫しました。\n\n竹富島の中心部から船乗り場まで、全力で走ったのは、その場のノリでやりすぎたなとも思っています。(笑)\n\n## 来年の抱負\n\n来年は、今年以上に忙しくなりそうです。\n技術面では、来年 1 月 4 日より新たな職場で勤務することとなるので、環境の変化で疲弊しそうです。\n生活面では、車や家といった大きな買い物を検討するのと、子作りも頑張らねばいけません。(妻の事情で、解禁)\n\nそのため、来年の抱負は **挑戦と健康のバランスを保つ** です。\nまだ 20 代なので、何事にも失敗を恐れず挑戦していきたいと思っています。\n例えば、Web フロントエンドの専門的な領域を探求したり、OSS コミッター活動を頑張ったりです。\n他には、ペーパードライバーの私が、子供と遠出しやすいよう、車の運転に慣れるよう努力したいです。\n\nただ、挑戦し続けると疲労し、ストレスが蓄積しやすくなります。\n今年、何度か妻とケンカをしてしまったのですが、原因の多くは、私の未熟さだと思っています。\n喧嘩の例を挙げると、親切心で家事(料理,掃除,etc)をしていたのですが、感謝を妻に求めてしまい喧嘩になることが多かったです。(≠ 親切心)\n当たり前ですが、行動や態度で気持ちを伝えるのではなく、ちゃんと会話して気持ちを伝えるように心がけようと思います。\n特に『一緒にやる or お願いする』や『妻のタイミングで』をできるようになりたいです。\n\n※ 妻とは 9 年ぐらいの付き合いなので、言わなくても通じることが多いです。\n\n※ 私は、一人でなんでもやろうとする人で、几帳面な性格も相まって、完璧にこなそうとする癖があるようです。\n\n## 終わりに\n\nエンジニアとして、また、人として成長できるよう、来年も多くの経験を積んでいきたいと思います！","publishedAt":"2021-12-21","slug":"2021_furikaeri","title":"2021年の振り返り。"},{"body":"みなさん、ご自身のプロフィール画像ってどう管理していますか？例えば、zenn のプロフィール画像って、更新していますか？ 私は、プロフィール画像の更新は面倒なので、放置することが多いです。(Gravatar みたいな SaaS が使えたら良いのに...)\n\n最近、自身の[ポートフォリオページ](https://silverbirder.github.io/)刷新を検討しており、プロフィール画像をどうするか悩みました。ポートフォリオのベースドキュメントは、Markdown を採用しています。\n\nプロフィール画像を固定で保持させず、API 経由でプロフィール画像を設定できないかと思い、今回、**Google アカウント画像を返却するだけの API、Google Account Photo API**を作成しました。\n\nAPI のソースコードは、[こちら(Github)](https://github.com/silverbirder/Google-Account-Photo-API)です。1 時間程度で作ったので、正常パターンしか見ていません。(笑) ご了承ください。\n\n## Google アカウント画像ってどれ\n\nGoogle のアカウント画像は、[www.google.com](https://www.google.com/) で表示されている右上の画像です。(ログインしている方のみ)\n\n![Google Chrome Home Page](https://github.com/silverbirder/Google-Account-Photo-API/blob/main/assets/i_want_to_that_image.png?raw=true)\n\n## API の使い方\n\nAPI を呼び出すために、あなたの Google アカウント ID というものを用意する必要があります。\n\n## Google アカウント ID の調べ方\n\nあなたの Google アカウント ID は、[Google People API の Explorer を実行](https://developers.google.com/people/api/rest/v1/people/get?apix_params=%7B%22resourceName%22%3A%22people%2Fme%22%2C%22personFields%22%3A%22photos%22%7D) するだけで分かります。\n\n実行すると、`resourceName(ex. people/<account_id>)` というフィールドが返却されるので、そこに書いてある account_id が、あなたのモノになります。\n\n## API を呼び出す\n\nAPI は、次の URL に GET 呼び出しします。YOUR_ACCOUNT_ID は、さきほど手に入れた account_id になります。\n\n```text\nhttps://google-account-photo.vercel.app/api/?account_id=YOUR_ACCOUNT_ID\n```\n\n呼び出すと、画像を返却されます。私の場合は、次の画像が返却されます。\n\n![my google account image](https://google-account-photo.vercel.app/api/?account_id=101722346324226588907)\n\n## Markdown で活用する\n\nこの API を活用すれば、次のような Markdown を書くだけでプロフィール画像を表示することができます！\n\n```text\n![google account image](https://google-account-photo.vercel.app/api/?account_id=YOUR_ACCOUNT_ID)\n```\n\nこれだけだと、ちょっと味気ないので、Cloudinary を使います。Cloudinary は、URL のパラメータを設定するだけで、画像を加工できます。例えば、画像を円にする場合は、次の URL を書きます。\n\n```text\n![circle google account image](https://res.cloudinary.com/demo/image/fetch/r_max/https%3A%2F%2Fgoogle-account-photo.vercel.app%2Fapi%2F%3Faccount_id%3DYOUR_ACCOUNT_ID)\n```\n\nCloudinary についての説明は、割愛します。\n\n私の場合は、次のような画像が表示されます。\n\n![my_google_account_image_circle](https://res.cloudinary.com/demo/image/fetch/r_max/https%3A%2F%2Fgoogle-account-photo.vercel.app%2Fapi%2F%3Faccount_id%3D101722346324226588907)\n\nCloudinary について、詳しくは次の URL を確認ください。\n\n- [Deliver remote media files | Cloudinary](https://cloudinary.com/documentation/fetch_remote_images)\n- [Image transformations | Cloudinary](https://cloudinary.com/documentation/image_transformations)\n\n## 終わりに\n\nサクッと API を構築できちゃうのって、便利な世の中だな〜と思いました。","publishedAt":"2021-12-20","slug":"intro_google_account_photo_api","title":"Googleアカウント画像を返却するだけのAPIを作った"},{"body":"BigQuery、皆さん使っていますか？\n私は、業務で BigQuery を使ったデータ構築をしています。\n品質担保のため、BigQuery の SQL に対してテストをしたいと考えています。\n本記事では、BigQuery だけで完結し、かつ、Mock データを差し替え可能なユニットテスト手法について、紹介します。\n\n## 動機\n\n端的に言うと、BigQuery の SQL 改修時にデグレが発生していないか確認したいです。\n\n業務で BigQuery の SQL を書いているのですが、それに対するユニットテストがありません。\n\nPython や Javascript のような言語でアプリケーション開発する場合、XUnit 等のユニットテストフレームワークでユニットテストを書くのは、よくあると思います。\nしかし、SQL に対するユニットテストというのは、(私の観測範囲上) あまり聞いたことがありません。\n\ndbt(Data Build Tool)というツールを使えば、SQL へユニットテストをかけるようですが、私はそれの良さ・悪さを知りません。(興味本位で、試してみたい)\n\nそれよりも、新しいライブラリ・ツールを覚えるのではなく、その言語の**標準的な技術**を用いて、SQL のユニットテストが書けないかと悩みました。\n\nそこで、私なりに BigQuery の SQL に対するユニットテスト方法を考えてみました。\n\n## xUnit\n\nxUnit は、ユニットテストのためのフレームワークです。\n\n> xUnit is the collective name for several unit testing frameworks that derive their structure and functionality from Smalltalk's SUnit.\n\n※ https://en.wikipedia.org/wiki/XUnit\n\nxUnit は、各プログラミング言語に影響を与えました。\nJava なら JUnit、Python なら unittest(厳密には JUnit から触発)のユニットテストができます。\n\n## xUnit x Python\n\nBigQuery の前に、まず Python を使ったユニットテストを紹介します。\n\n『100 円未満の果物を取得する』関数、`get_less_than`があったとします。\n\n```python\n## fruits.py\nclass Fruits(object):\n    def _get_fruits(self):\n        return [\n            {\"price\": 130, \"name\": \"apple\"},\n            {\"price\": 120, \"name\": \"banana\"},\n            {\"price\": 110, \"name\": \"grape\"},\n            {\"price\": 100, \"name\": \"lemon\"},\n            {\"price\": 90, \"name\": \"orange\"},\n        ]\n\n    def get_less_than(self, price):\n        fruits = self._get_fruits()\n        return list(filter(lambda x: x[\"price\"] < price, fruits))\n```\n\n`_get_fruits`関数は、簡易的なモノで、実際には実データを参照する箇所になります。\n\n`get_less_than`関数に対してユニットテストを書くとすれば、次のコードになります。\n\n```python\n## test_fruits.py\nimport unittest\nfrom unittest.mock import patch\n\nfrom fruits import Fruits\n\n\nclass TestFruits(unittest.TestCase):\n    @patch(\"fruits.Fruits._get_fruits\")\n    def test_get_less_than(self, mock_get_fruits):\n        # Arrange\n        mock_get_fruits.return_value = [\n            {\"price\": 110, \"name\": \"apple\"},\n            {\"price\": 100, \"name\": \"banana\"},\n            {\"price\": 90, \"name\": \"orange\"},\n        ]\n        fruits = Fruits()\n\n        # Act\n        actual = fruits.get_less_than(price=100)\n\n        # Assert\n        assert len(actual) == 1\n```\n\n[単体テストを記述するためのベストプラクティス#テストの配置](https://docs.microsoft.com/ja-jp/dotnet/core/testing/unit-testing-best-practices#arranging-your-tests)にあるように、ユニットテストは、次の 3 段階で分けて書くと、分かりやすいです。\n\n1. Arrange: 配置, 準備\n1. Act: 実行\n1. Assert: 検証\n\nユニットテストは、次のコマンドで実行できます。\n\n```shell\npython -m unittest test_fruits\n.\n----------------------------------------------------------------------\nRan 1 test in 0.001s\n\nOK\n```\n\nテストは成功しました。今度は、失敗させてみましょう。\nfruits.py のコードにある `get_less_than`のロジックを誤ったものに変更します。\nコードは、次のとおりです。\n\n```python\n## fruits.py\nclass Fruits(object):\n    ...\n    def get_less_than(self, price):\n        fruits = self._get_fruits()\n        # return list(filter(lambda x: x[\"price\"] < price, fruits))\n        return list(filter(lambda x: x[\"price\"] <= price, fruits))\n```\n\nこの状態で、さきほどのユニットテストを実施してみます。\n\n```shell\npython3 -m unittest test_fruits\nF\n======================================================================\nFAIL: test_get_less_than (test_fruits.TestFruits)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/unittest/mock.py\", line 1348, in patched\n    return func(*newargs, **newkeywargs)\n  File \"test_fruits.py\", line 22, in test_get_less_than\n    assert len(actual) == 1\nAssertionError\n\n----------------------------------------------------------------------\nRan 1 test in 0.005s\n\nFAILED (failures=1)\n```\n\n期待通り、失敗しました。\n**ロジックを誤る**というのは、保守を続けていくと、**ほぼ間違いなく発生**します。\nその際、**ロジックが誤っている** と気付ける、つまりデグレを気づける事が大切です。\nユニットテストを書くメリットの 1 つは、この **デグレを検知できるところ** だと思っています。\n\n## xUnit x BigQuery\n\nBigQuery の場合、どのようにテストすればよいのでしょうか。\nまず、BigQuery の SQL を書くために元データを用意します。\n\n```sql\n-- fruits_ct.sql\n-- destination:\n--   dataset: shop\n--   table: fruits\nCREATE OR REPLACE TABLE\n  shop.fruits AS\nSELECT\n  price,\n  name\nFROM (\n  SELECT\n    130 AS price,\n    \"apple\" AS name\n  UNION ALL\n  SELECT\n    120 AS price,\n    \"banana\" AS name\n  UNION ALL\n  SELECT\n    110 AS price,\n    \"grape\" AS name\n  UNION ALL\n  SELECT\n    100 AS price,\n    \"lemon\" AS name\n  UNION ALL\n  SELECT\n    90 AS price,\n    \"orange\" AS name )\n```\n\nshop.fruits テーブルから、先程の Python コードにあった`get_less_than`関数相当の SQL を用意します。\n\n```sql\n-- fruits_less_than_100.sql\n-- destination\n--   dataset: shop\n--   table: fruits_less_than_100\nSELECT\n  price,\n  name\nFROM\n  shop.fruits\nWHERE\n  price < 100\n```\n\n出力された`fruits_less_than_100`テーブルに対して、ユニットテストを書いてみます。\n\n```sql\n-- test_fruits_less_than_100.sql\nASSERT\n  (\n  SELECT\n    COUNT(name) = 1\n  FROM\n    shop.fruits_less_than_100) AS \"There's one fruit less than 100.\"\n```\n\nこのテストにより `fruits_less_than_100`テーブルに対して、次のことを保証できました。\n\n- price が 100 未満の fruit は 1 つ\n\nただし、これは実データ(shop.fruits テーブル)を参照して生成されたデータです。\nそのため、次の問題があります。\n\n- 実データを参照しているため、テストが不安定になる\n  - 実データに`orange`がなくなると、テストが失敗する\n- フィードバックサイクルが長い\n  - 実データが多くなると、テスト実行時間が長くなる\n\nそこで、テーブル関数というものを活用し、実データをモックデータに差し替えるようにします。\n\n## テーブル関数とは\n\nBigQuery の公式ページより、テーブル関数について、次のことが書かれています。\n\n> テーブル関数（テーブル値関数、TVF とも呼ばれます）は、テーブルを返すユーザー定義関数です。テーブル関数は、テーブルを使用できる場所であればどこでも使用できます。テーブル関数はビューと似ていますが、テーブル関数ではパラメータを取得できます。\n\n※ [テーブル関数|BigQuery|Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/table-functions)\n\nテーブル関数の定義は、次のようなサンプルコードがあります。\n\n```sql\n-- names_by_year.tvf.sql\nCREATE OR REPLACE TABLE\n  FUNCTION mydataset.names_by_year(y INT64) AS\nSELECT\n  year,\n  name,\n  SUM(number) AS total\nFROM\n  `bigquery-public-data.usa_names.usa_1910_current`\nWHERE\n  year = y\nGROUP BY\n  year,\n  name\n```\n\n特徴は、`CREATE OR REPLACE TABLE FUNCTION` です。関数を定義し、テーブル情報を返り値とします。今回のケースでは、`year, name, total` のフィールドを持つテーブルです。\n\n定義したテーブル関数は、次のように使います。\n\n```sql\n-- names_by_year.sql\nSELECT\n  *\nFROM\n  mydataset.names_by_year(1950)\nORDER BY\n  total DESC\nLIMIT\n  5\n```\n\nテーブル関数は、`FROM句`に使えます。私は、ここに着目しました。\nFROM 句で関数呼び出しする際、モックデータを返却できるようにできないかと考えました。\n\nそこで、次の章にある手段を発見しました。\n\n## xUnit x BigQuery (Mock)\n\nどのように差し替えるかというと、次の 2 つの順番にテーブル関数化していきます。\n\n1. 元データを Mock 差し替えできるように、テーブル関数化\n1. ロジックを含んだ SQL の FROM 句を、① のテーブル関数に差し替えて、テーブル関数化\n\n順を追って説明します。\n\n---\n\n① 番目は、`元データをMock差し替えできるように、テーブル関数化` です。\n\n元データは、今回`shop.fruits`テーブルですので、Mock で差し替えられるようにテーブル関数化します。\n次のコードが、Mock 差し替え可能なテーブル関数です。\n\n```sql\n-- fruits_tvf.sql\n--   function:\n--    - shop.fruits_inject()\n--    - shop.fruits(is_test BOOL)\nCREATE OR REPLACE TABLE\n  FUNCTION shop.fruits_inject() AS\nSELECT\n  *\nFROM (\n  SELECT\n    130 AS price,\n    \"apple\" AS name )\nWHERE\n  1 <> 1;\nCREATE OR REPLACE TABLE\n  FUNCTION shop.fruits(is_test BOOL) AS\nSELECT\n  name,\n  price\nFROM\n  shop.fruits\nWHERE\n  NOT is_test\nUNION ALL\nSELECT\n  name,\n  price\nFROM\n  shop.fruits_inject()\nWHERE\n  is_test\n```\n\nこの SQL には、2 つのステートメントがあります。\n\n1. テーブル関数 shop.fruits_inject の定義\n1. テーブル関数 shop.fruits の定義\n\n1 つ目は、後で Mock 差し替え(上書き)するための関数です。\n\n2 つ目は、`is_test BOOL` という値を引数とした関数で、次の条件分岐があります。\n\n- is_test が True の場合\n  - モックデータ(shop.fruits_inject)を返却\n- is_test が False の場合\n  - 実データ(shop.fruits)を返却\n\nプロダクションコード時は、is_test を False とし、テストコード時は、is_test を True として使う想定です。\n\n---\n\n② 番目は、`ロジックを含んだSQLのFROM句を、①のテーブル関数に差し替えて、テーブル関数化` です。\n\nロジックを含んだ SQL、今回は、`fruits_less_than_100`テーブルを関数化します。\n次のコードが、① のテーブル関数で差し替えたテーブル関数です。\n\n```sql\n-- fruits_less_than_tvf.sql\n--  function:\n--    - shop.fruits_less_than(is_test BOOL, p INT)\nCREATE OR REPLACE TABLE\n  FUNCTION shop.fruits_less_than(is_test BOOL,\n    p INT) AS\nSELECT\n  price,\n  name\nFROM\n  shop.fruits(is_test)\nWHERE\n  price < p\n```\n\nFROM 句に、先程 ① 番で定義した shop.fruits テーブル関数を呼び出します。\nshop.fruits テーブル関数の引数は、shop.fruits_less_than 関数から渡ってくる`is_test BOOL`をそのままセットします。\nまた、shop.fruits_less_than 関数には、`p INT`という引数も持ち、less_than の price を柔軟に対応できるようにします。\n\n---\n\nこれにて、テーブル関数化を終えました。次は、プロダクトコードとテストコードを紹介します。\n\nでは、まずプロダクションコードを書きます。\n\n```sql\n-- fruits_less_than_100.sql\n-- destination\n--   dataset: shop\n--   table: fruits_less_than_100\nSELECT\n  price,\n  name,\nFROM\n  shop.fruits_less_than(False, 100)\n```\n\n取り上げて重要なことは、ありません。プロダクションコードは、is_test を False とします。\n\n次が、本記事のメインである、**BigQuery の SQL に対するユニットテストコード**です。\n\n```sql\n-- test_fruits_less_than_100.sql\n-- arrange\nCREATE OR REPLACE TABLE\n  FUNCTION shop.fruits_inject() AS\nSELECT\n  110 AS price,\n  \"grape\" AS name\nUNION ALL\nSELECT\n  100 AS price,\n  \"lemon\" AS name\nUNION ALL\nSELECT\n  90 AS price,\n  \"orange\" AS name;\n-- act\n  CREATE TEMP TABLE fruits_less_than_100 AS\nSELECT\n  price,\n  name,\nFROM\n  shop.fruits_less_than(True,\n    100);\n-- assert\nASSERT\n  (\n  SELECT\n    COUNT(name) = 1\n  FROM\n    fruits_less_than_100) AS \"There's one fruit less than 100.\"\n```\n\nこの SQL は、3 つのステートメントがあります。\n\n1. shop.fruits_inject 関数の上書き(**モックの差し込み**)\n1. shop.fruits_less_than 関数で、is_test=True として生成し、一時テーブルで保存\n1. ② の一時テーブルに対してアサーション\n\n重要なのが、① 番です。shop.fruits_inject 関数を上書きします。\nそうすると、shop.fruits 関数で参照する shop.fruits_inject 関数結果が、上書きされたものに切り替わります。\n\n後は、② 番で shop.fruits_less_than 関数を呼んで一時テーブル保存し、③ 番でアサーションします。\n\nでは、テストを失敗させてみましょう。ロジックを含んでいる shop.fruits_less_than 関数を、次のように書き換えます。\n\n```sql\n-- fruits_less_than_tvf.sql\n--  function:\n--    - shop.fruits_less_than(is_test BOOL, p INT)\nCREATE OR REPLACE TABLE\n  FUNCTION shop.fruits_less_than(is_test BOOL,\n    p INT) AS\nSELECT\n  price,\n  name\nFROM\n  shop.fruits(is_test)\nWHERE\n  -- price < p\n  price <= p\n```\n\nWHERE 句の price が 100 未満ではなく、100 以下になっているので、`orange`と`lemon`の 2 つが抽出されます。\n\nこの関数を再度定義し、もう一度テストを実行してみましょう。\nそうすると、次のようなメッセージが出力されます。\n\n```text\nQuery error: There's one fruit less than 100. at [25:1]\n```\n\n期待通り、テストは失敗しました！🎉\n\n---\n\nBigQuery のユニットテストができるようになれば、次は CI に組み込みたいと思うはずです。\nBigQuery は、GCP のサービスなので、GCP の CI サービスとして有名な Cloud Build を活用しようと思います。\nCloud Build の定義ファイルを、次に示します。\n\n```yaml\n-- cloudbuild.yaml\nsteps:\n  # If you want to receive notifications from Slack, uncomment it.\n  # Then follow the README.md at the following URL to set it up.\n  # https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/slackbot\n  # - name: \"gcr.io/$PROJECT_ID/slackbot\"\n  #   id: \"WATCH\"\n  #   args: [\n  #     \"--build\", \"$BUILD_ID\",\n  #     \"--webhook\", \"$_SLACK_WEB_HOOK\"\n  #   ]\n  - name: gcr.io/cloud-builders/gcloud-slim\n    id: fruits_ct\n    entrypoint: 'bash'\n    args: ['run_query.sh', 'fruits_ct.sql']\n  - name: gcr.io/cloud-builders/gcloud-slim\n    id: fruits_tvf\n    entrypoint: 'bash'\n    args: ['run_query.sh', 'fruits_tvf.sql']\n    waitFor:\n      - fruits_ct\n  - name: gcr.io/cloud-builders/gcloud-slim\n    id: fruits_less_than_tvf\n    entrypoint: 'bash'\n    args: ['run_query.sh', 'fruits_less_than_tvf.sql']\n    waitFor:\n      - fruits_tvf\n  - name: gcr.io/cloud-builders/gcloud-slim\n    id: test_fruits_less_than_100\n    entrypoint: 'bash'\n    args: ['run_query.sh', 'test_fruits_less_than_100.sql']\n    waitFor:\n      - fruits_less_than_tvf\n```\n\n```shell\n#!/bin/bash\n## run_query.sh\nif [ $# -eq 0 ]; then\n  echo \"No arguments supplied\"\nfi\nbq query --use_legacy_sql=false < $1\n```\n\nCloud Build を Github 等の Git プラットフォームと連携すれば、Git のイベント毎(Push,Merge,etc)にユニットテストを動かすことができます。\n\n※ サンプルの cloudbuild.yaml にある、`id:fruits_ct`や`id:fruits_tvf`、`id:fruits_less_than_tvf`は何度も実行するものではないのですが、\n記事をわかりやすくするために書いています。\n\n## xUnit x BigQuery メリット・デメリット\n\nBigQuery の Mock を差し替え可能なユニットテストについて、メリット・デメリットを列挙します。\n\n- メリット\n  - BigQuery だけ学習すればよい\n    - BigQuery の標準機能だけで、完結しているため\n  - フィードバックサイクルが短い\n    - 実データを参照するのではなく、モックデータを参照しているため\n  - テストが安定する\n    - 実データを参照するのではなく、モックデータを参照しているため\n- デメリット\n  - BigQuery の SQL 実行順序を制御する必要あり\n    - 今回でいうと、次の順番でクエリ実行する必要がある\n      1. fruits_tvf.sql\n      1. fruits_less_than_tvf.sql\n      1. test_fruits_less_than_100.sql\n    - 回避案\n      - BigQuery の Scripting を利用\n      - Cloud Build の`waitFor`を利用\n  - 並列実行すると、予期せぬ動作になる\n    - テーブル関数は、`CREATE OR REPLACE TABLE FUNCTION`で定義\n      - shop.fruits_inject 関数が、何度も再定義されている\n    - `CREATE TEMP TABLE FUNCTION` は未サポート\n    - 回避案\n      - BigQuery のトランザクションを利用\n        - テーブル関数は未サポート\n  - 汎用性がない\n    - 他のデータベースエンジン(MySQL,PostgreSQL,etc)に、同じ手法(テーブル関数)は使えない\n      - 回避案\n        - dbt の利用(多分)\n\n## 終わりに\n\n今回、この手法を使うことで、BigQuery の SQL に対してユニットテストを書けることがわかりました。\nこれにより、データに対する品質を一定担保しながら、安全に開発できるようになります。\n\n他にも、次のようなテスト手法についても検討して良いかもしれません。\n\n- dbt によるデータモデルテスト\n- Open Policy Agent(OPA)によるポリシーテスト\n  - SQL を AST 分解 →JSON 化し、OPA でテスト\n- BigQuery のクライアントライブラリを使った、ユニットテスト\n\n## P.S\n\ndbt を試したいと思っています。","publishedAt":"2021-11-26","slug":"a_mockable_unit_testing_method_that_can_be_completed_only_with_big_query","title":"BigQueryだけで完結するモック可能なユニットテスト手法"},{"body":"[100 日後に退職する 47 歳さんのお話](https://twitter.com/i/events/1418432177168031749)が、Twitter 上で話題ですね。\nその投稿が続いている裏で、私は、転職活動をしていました。\nその活動内容や感想について、かんたんにまとめておきたいと思います。\n\n## 自己紹介\n\n私は、関西に住む 20 代の Web エンジニアです。\n2020 年ぐらいから、転職はふんわり考えていて、訳あって 2021 年 8 月末から 10 月末まで本格的に活動していました。\n\n## 転職活動\n\nスカウト式の転職サイトを使い、カジュアル面談をして頂きました。\n\n転職サイトは、次の 2 つを使いました。\n\n- [ビズリーチ](https://www.bizreach.jp/)\n- [Findy](https://findy-code.io/)\n\nどちらも、企業側から転職希望者へスカウトする転職サイトになります。\n\n転職希望者は、事前に職務経歴書や転職希望条件などを転職サイトに登録しておきます。\n当初、(CM でよく目にしていた)ビズリーチで転職先を探していたのですが、次の理由で使うのを諦めました。\n\n- 登録したい情報に、私の成果物をリンクできない\n  - [Github](https://github.com/silverbirder)\n  - [ポートフォリオ](https://silverbirder.github.io)\n  - [職務経歴書](https://silverbirder.github.io/resume/)\n    - 必要に応じて PDF 化\n\nそこで、Github と連携が可能な Findy というサービスに乗り換えました。\n\n最終的に、ビズリーチで 1 社、Findy で 9 社のカジュアル面談をして頂きました。\n\n※ ちなみに、SNS の DM で連絡頂く人もいましたが、胡散臭い感じが強くあったので無視しました。\n\n## Findy での進め方\n\n次の流れで、カジュアル面談まで進めました。\n\n1. 企業側の担当者が、転職希望者へ\"いいね\"を送る\n1. \"いいね\"が、転職希望者へ通知される(メール, Line)\n1. 転職希望者が、求人内容を確認する ([例](https://findy-code.io/companies/685/jobs/oBsGg3cfPWoiY))\n1. 転職希望者が、企業へ\"いいかも\"を送る\n1. 企業側の担当者と転職希望者が、メッセージのやりとりをする\n1. 企業側の担当者が、カジュアル面談を設定する\n\nFindy では、[掲載企業一覧](https://findy-code.io/companies)に書いてある通りの企業から、\"いいね\"を頂けることがあります。\n\n> エンジニア・プログラマーが最新技術を試せる職場、ホワイト企業、日系大手、外資系、急成長ベンチャー企業など、様々なおすすめテック企業を厳選して掲載しています。ご登録いただくと、これらの企業からスキル偏差値を元にオファーが届くようになります。\n\nメルカリやサイボウズ、(アンジャッシュ児島さんの CM で有名な STORES の)Hey などの企業から\"いいね\"を頂きました。\n\n## カジュアル面談での進め方\n\nこの世の中、リモートでのカジュアル面談が当たり前になりました。\nそのため、平日の勤務後(18 時以降)に、Zoom や Teams を使ってカジュアル面談して頂くことになります。\n\nカジュアル面談の流れは、次のとおりです。\n\n1. 自己紹介\n1. 採用ピッチを使った会社紹介 (適宜質問)\n   1. ビジネスの話(プロダクト、サービス)\n   1. 会社の話(ミッション、ビジョン、バリュー、カルチャー)\n   1. 現場の話(開発、技術、体制)\n1. 次のアクション(別メンバーとの MTG、選考進める、保留)\n\nカジュアル面談に来て頂く人は、次の構成が多かったです。\n\n- グループリーダークラスの人\n- 人事担当者\n- グループリーダークラスの人 + 人事担当者\n\n中には、CTO とカジュアル面談して頂いたことがあったのですが、とても緊張して情報交換が一方通行(CTO→ 私)となってしまいました...。\n\n## カジュアル面談で思ったこと\n\n## カジュアル面談前のメッセージ内容で、モチベーションが変わる\n\nカジュアル面談を進める前に、企業側の担当者から、(ありがたいことに)メッセージを頂けます。\nそのメッセージの中には、Github やポートフォリオの感想を書いて頂けることがあります。\nそういうメッセージは、『私を見て頂いているんだな』と思い、カジュアル面談への意思表示を強く示すことが多いです。\n\n## 情報交換を円滑に進めるため、基本的なコミュニケーションを心がけて\n\nまず、次のことは絶対はやめてほしいと思いました。\n\n- 話す内容が聞こえない\n  - 話し方が早口\n  - 声が聞こえにくい・小さい\n- 相手の表情が読めない\n  - (Zoom や Teams で)顔を出さない\n  - 表情が暗い・笑わない\n\n1 つ目は、情報交換ができていないので、絶対にやめてほしいところです。\n2 つ目は、できればやめてほしいのですが、会話するときは、営業スマイルでも良いので、明るい人と話したいです。\n\n## カジュアル面談の参加者は、転職希望者と近い距離にある人が良い\n\nカジュアル面談に来て頂く方は、転職希望者と一緒に働くかもしれないぐらいの役職にある人が良いなと思いました。\n例えば、私の場合は、グループやチームのリーダーが良いと思いました。\nそのような人とカジュアル面談すると、働く現場の話や、課題感についての認識を持ちやすくなるからです。\n\n## コロナ禍からフルリモート可になった企業は、避けた\n\nカジュアル面談時に、多くの企業が、フルリモート可能になったという話を聞きました。\n関西在住だと、関東の企業で働ける機会が増えて、嬉しい反面、コロナ収束後に、フルリモートがなくなるのではないかと危惧しました。\nそのため、そういう企業は避けるようにしました。\n\n## 求人に悩んだら、オープンポジションを提案する\n\n求人内容が、私に適切なのかどうか分からないときは、\"オープンポジション\"という選考を提案することにしました。\n私の場合は、Web フロントエンドの求人に応募することが多いのですが、それとは別の求人も良さそうと悩むことがあります。\nそういったときに、\"オープンポジション\"で選考をお願いできないか提案しました。\nどちらの求人枠の方が、私の強みを活かせられるのか、企業側に考えて貰いたいのです。\n\n## 最後に\n\n転職活動らしい活動は、今回がはじめてでした。\n転職活動を進めていくと、色々と考えさせられて、良い機会だなと思いました。\n\n- 企業選びは、何を基準として考えるか\n  - ビジネスへの共感は前提\n  - 給与、働き方、技術、etc\n- 私は、どういった人物なのか\n  - 強み・弱み\n  - 経験・性格\n  - できないこと・できること・やりたいこと\n- どういったキャリアを積み上げたいのか\n  - 数年先は、どういう人物になりたいか\n  - マイルストーンをどう刻むのか\n\n良い機会ですが、転職活動すると、色々クタクタになるので、またしたいとは思いませんでした...。","publishedAt":"2021-11-12","slug":"my_feedback_after_taking_casual_interviews_with_10_companies_in_2_months","title":"カジュアル面談を10社受けた感想"},{"body":"コンパイラ基盤であるLLVMについて、全く知識がない私が、\njavascriptソースコードをパースしLLVMでコンパイルできるようになりました。\n\nLLVMの記事は数多くありますが、初心者向けの記事が少なく感じたため、\n本記事では、できる限り分かりやすくLLVMについて紹介できる記事を書こうと思います。\n\nソースコードは、こちらに置いています。\n\nhttps://github.com/silverbirder/rustscript\n\n## 自己紹介\n\nふだん、javascriptやpythonなどインタプリタ言語を使うエンジニアです。\nLLVMについて、全く知識がなかった人間です。\n\n## 背景\n\n過去に、おもちゃのブラウザ自作をやってみました。\n\nhttps://silverbirder.github.io/blog/contents/learning_browser_engine\n\nHTMLとCSSを解析し、レンダリングするところを書き、基本的な動作を知ることができました。\nHTMLとCSSとくれば、次はJSだと思い、JSを実行するエンジンを書いてみたくなりました。\nただし、WebブラウザのAPIとJS実行エンジンをバインディングする箇所(EX.DOM操作)は難しいので、\nまずは、単純な処理、四則演算やfizzbuzzが処理できるものを作ろうと思いました。\n\n## コンパイラとは\n\nコンパイラとは、\n\n> compiler is a computer program that translates computer code written in one programming language (the source language) into another language (the target language). The name \"compiler\" is primarily used for programs that translate source code from a high-level programming language to a lower level language (e.g. assembly language, object code, or machine code) to create an executable program.\n\n※ [https://en.wikipedia.org/wiki/Compiler](https://en.wikipedia.org/wiki/Compiler)\n\nに書かれている通り、あるコードを別のコードに変換するプログラムのことをコンパイラと指します。\n主に、高級言語(ex. javascript)から低級言語(ex. アセンブリ言語)への変換という意味でコンパイラが使われます。\n\n---\n\nプログラムをコンパイルするというのは、主に次の順番で処理されます。\n\n![plantuml](https://www.plantuml.com/plantuml/svg/SoWkIImgAStDuIfAJIv9p4lFILLutBJtSVEUnqqx7pTj1Z6QEv4adwwT_hH_wOlbYv_Dcu0a_6nvzxDfxJY4dyrPWIJsPCVQbzCclrZHy6BLF1HRePOzdpB_MSS4BYvCPoZesg7QZym1IQAu0fc3a0Iv1Su22QCu1va3aaHtb4DgNWemi000)\n\n---\n\n字句解析 ~ 構文木は、lexやyaccというソフトウェアが有名だと思います。\n今回は、swc_ecma_parserというものを使います。swc_ecma_parserは、[swc](https://github.com/swc-project/swc)で使われるパーサです。\n\n> EcmaScript/TypeScript parser for the rust programming language.\nPasses almost all tests from tc39/test262.\n\n※ [swc_ecma_parser](https://rustdoc.swc.rs/swc_ecma_parser/)\n\ntc39/test262のテストケースをほとんどパスしているようです。\n[tc39/test262](https://github.com/tc39/test262)は、次の仕様動作を保証するテストスイートです。\n\n```text\nECMA-262, ECMAScript Language Specification\nECMA-402, ECMAScript Internationalization API Specification\nECMA-404, The JSON Data Interchange Format (pdf)\n```\n\n実際のテストコードは、[tc39/test262/test](https://github.com/tc39/test262/tree/main/test)にあります。\n\n---\n\nパーサ部分を自作しようか悩みました。\n自作するには、次の手順を踏むことになります。\n\n1. 言語文法の理解\n1. パース処理の実装\n    1. BNFやPEGからパース自動生成も可\n\n①番の言語文法について知るために、ecmascriptのBNFってどれだろうなと調べていました。\nそうすると、私の調べた範囲では、次のページにたどり着きました。\n\nhttps://tc39.es/ecma262/#sec-grammar-summary\n\nこれは、先程の[swc_ecma_parser](https://rustdoc.swc.rs/swc_ecma_parser/)のテストスイート対象[tc39/test262/test](https://github.com/tc39/test262/tree/main/test)であったので、あえて再構築する気になれず、自作は諦めました。\n\n---\n\n中間言語 ~ コード生成については、LLVMというコンパイル基盤を使おうと思います。\n\n## LLVMとは\n\nLLVMとは、公式ページより、\n\n> The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.\n\n※ [ttps://llvm.org/](https://llvm.org/)\n\nLLVMプロジェクトとは、再利用性が高いコンパイラとツールチェイン技術の総称です。\nLLVMは、次の特徴があります。\n\n> LLVM is a set of compiler and toolchain technologies, which can be used to develop a front end for any programming language and a back end for any instruction set architecture. LLVM is designed around a language-independent intermediate representation (IR) that serves as a portable, high-level assembly language that can be optimized with a variety of transformations over multiple passes.\n\n※ [https://en.wikipedia.org/wiki/LLVM](https://en.wikipedia.org/wiki/LLVM)\n\nLLVMは、任意のフロントエンド言語(コンパイラという文脈でいう変換前の言語)から任意の命令セットアーキテクチャ(以下、ISA)バックエンドへ変換できます。\n\n---\n\nISAは、次の意味になります。\n\n> 命令セットとは、あるマイクロプロセッサ（CPU/MPU）を動作させるための命令語の体系。プロセッサが直に解釈して実行できる機械語（マシン語）の仕様を定めたもの。\n\n※ [https://e-words.jp/w/命令セット.html](https://e-words.jp/w/命令セット.html)\n\nプロセッサを動作させるための命令は、例えばLoad(LDR)とStore(STR)です。Loadは、メモリからレジスタへセットし、Storeは、その逆です。\n(Rust:inkwellのリファレンスですが)[こちら(Instruction)](https://thedan64.github.io/inkwell/inkwell/builder/struct.Builder.html)に一覧があります。\n\n---\n\nまた、非言語依存な中間言語(以下、IR)を中心として設計されています。\n\n![Retargetablity - The Architecture of Open Source Applications: LLVM](https://res.cloudinary.com/silverbirder/image/upload/v1693376952/silver-birder.github.io/blog/RetargetableCompiler.png)\n\n---\n\n今回、LLVMのフロントエンド言語は、タイトルにある通り、Rustで書こうと思います。\n単にRustでやってみたかっただけです。\nLLVMライブラリとして、[inkwell](https://github.com/TheDan64/inkwell)を使用します。\nこれは、LLVMのC APIを安全に使えるようにする薄いラッパーライブラリです。\n\n---\n\nLLVMのバックエンドは、ローカルマシンで動かすこととします。\n具体的には、`x86_64-apple-darwin20.6.0` になります。\n\n試していないですが、WASMもバックエンドとして選択できるようです。\nというのも、過去の記事([WebAssemblyに正式対応した「LLVM 8.0」がリリース － Publickey](https://www.publickey1.jp/blog/19/webassemblyllvm_80.html))ですが、LLVMがバックエンドとしてWebAssembly(以下,WASM)をサポートしました。\n\n* [Target initialize_webassembly](https://thedan64.github.io/inkwell/inkwell/targets/struct.Target.html#method.initialize_webassembly)\n\nちなみに、WASMは、仮想的なISAとして設計されています。\n\n> WebAssembly, or \"wasm\", is a general-purpose virtual ISA designed to be a compilation target for a wide variety of programming languages.\n\n[WebAssembly Reference Manual](https://github.com/sunfishcode/wasm-reference-manual/blob/master/WebAssembly.md)\n\n## LLVM開発で、知っておくべきこと\n\nLLVMでは、IRを生成します。\nそのIRでは、`Module ⊇ Function ⊇ Block ⊇ Instruction(Builder)` という構成になっています。\nこれを知っていないと、LLVMのコードを見ても、理解しにくいと思います。(自身が持つ言葉で解釈して誤った理解になりかねません)\n\n小さなC言語コードとIRで例を示します。\nRustじゃなく、Cを選んだのは、clangから手軽にIRを出力できるからです。\n\n```c\n// if.c\n#include <stdio.h>\n#include <stdlib.h>\n\nint main(void)\n{\n    int i = rand();\n    if (i == 1)\n    {\n        printf(\"i is one.\");\n    }\n    return 0;\n}\n```\n\nこれをIRに変換\n\n```shell\nclang -S -emit-llvm -O3 if.c\n```\n\n出力されたファイルは、`if.ll`というIRファイルです。\nそこから、`@main`コードを見ます。\n\n```text\n@.str = private unnamed_addr constant [10 x i8] c\"i is one.\\00\", align 1\n\ndefine i32 @main() local_unnamed_addr #0 {\n  %1 = tail call i32 @rand() #3\n  %2 = icmp eq i32 %1, 1\n  br i1 %2, label %3, label %5\n\n3:                                                ; preds = %0\n  %4 = tail call i32 (i8*, ...) @printf(i8* nonnull dereferenceable(1) getelementptr inbounds ([10 x i8], [10 x i8]* @.str, i64 0, i64 0))\n  br label %5\n\n5:                                                ; preds = %3, %0\n  ret i32 0\n}\n\ndeclare i32 @rand() local_unnamed_addr #1\n\ndeclare noundef i32 @printf(i8* nocapture noundef readonly, ...) local_unnamed_addr #2\n```\n\nIRをModule,Function,Block,Instructionで区切って見ると、次の画像のとおりです。\n\n![sample_llvm_code](https://res.cloudinary.com/silverbirder/image/upload/v1633770792/silver-birder.github.io/blog/sample_llvm_code.png)\n\nそれぞれ、どういうものか簡単に説明します。\n\n### Module\n\n> LLVM programs are composed of Module’s, each of which is a translation unit of the input programs.\n\n※ [https://llvm.org/docs/LangRef.html#module-structure](https://llvm.org/docs/LangRef.html#module-structure)\n\nモジュールは、入力プログラムの変換単位になります。\nモジュールには、関数、グローバル変数、シンボルテーブルエントリを持ちます。\n\n### Function\n\n> LLVM function definitions consist of the “define” keyword.\nA function definition contains a list of basic blocks.\n\n※ [https://llvm.org/docs/LangRef.html#functions](https://llvm.org/docs/LangRef.html#functions)\n\n関数は、複数のブロック(Block)を持ちます。\n\n### Block\n\n> Each basic block may optionally start with a label (giving the basic block a symbol table entry), contains a list of instructions, and ends with a terminator instruction (such as a branch or function return).\n\n※ [https://llvm.org/docs/LangRef.html#functions](https://llvm.org/docs/LangRef.html#functions)\n\nブロックは、ラベルから始まり、複数の命令(Instruction)を持ちます。\n\n### Instruction\n\n> The LLVM instruction set consists of several different classifications of instructions: terminator instructions, binary instructions, bitwise binary instructions, memory instructions, and other instructions.\n\n※ [https://llvm.org/docs/LangRef.html#instruction-reference](https://llvm.org/docs/LangRef.html#instruction-reference)\n\n命令は、バイナリ命令やメモリ命令など、様々な命令があります。\n\n### 参考資料\n\n参考になる資料たちは、次のとおりです。\n\n* チュートリアル\n  * C++ [Kaleidoscope](https://llvm.org/docs/tutorial/)\n  * Rust [Kaleidoscope](https://github.com/jauhien/iron-kaleidoscope)\n    * codegenが動かないため、途中までしか使えません\n  * Rust + inkwell [Kaleidoscope](https://github.com/TheDan64/inkwell/blob/master/examples/kaleidoscope)\n* LLVMリファレンス\n  * [LLVM Language Reference Manual](https://llvm.org/docs/LangRef.html)\n\n## LLVMをやってみよう\n\n前置きが長くなりましたが、実際にLLVMをやっていきたいと思います。\n\n### 開発環境\n\n私の環境(Mac)はこちらです。\n\n```shell\n$ sw_vers \nProductName:    macOS\nProductVersion: 11.6\nBuildVersion:   20G165\n$ cargo --version && rustc --version\ncargo 1.56.0-nightly (18751dd3f 2021-09-01)\nrustc 1.56.0-nightly (50171c310 2021-09-01)\n```\n\nllvmのインストールは、Macユーザなので、[brewからllvm](https://formulae.brew.sh/formula/llvm)をインストールします。\n[公式ページからダウンロード](https://releases.llvm.org/download.html)もできるようです。\n\nインストールが完了すると、clangやllcといったツールが使えます。\n\n```shell\n$ clang --version\nHomebrew clang version 13.0.0\nTarget: x86_64-apple-darwin20.6.0\nThread model: posix\nInstalledDir: /usr/local/opt/llvm/bin\n$ llc -version\nHomebrew LLVM version 12.0.1\n```\n\nMacにはXcodeにclangが含まれているようです。こちらを使っても問題ありません。\n(ただ、xcodeのclangには、[wasmには対応していないです](https://github.com/WebAssembly/wasi-sdk/issues/172#issuecomment-772399153))\n\n```shell\n# xcode付属のclangの場合\n$ clang --version\nApple clang version 12.0.5 (clang-1205.0.22.9)\nTarget: x86_64-apple-darwin20.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n```\n\nCargo.tomlの`dependencies`は、次のとおりです。\n\n```toml\n[dependencies]\ninkwell = { git = \"https://github.com/TheDan64/inkwell\", branch = \"master\", features = [\"llvm12-0\"] }\nswc_ecma_parser = \"0.73.0\"\nswc_common = { version = \"0.13.0\", features=[\"tty-emitter\"] }\nswc_ecma_ast = \"0.54.0\"\n```\n\n### \"Hello World\" を出力\n\nまずは、Hello World を出力します。\nRustのコードは、次のものになります。\n\n```rust\nextern crate inkwell;\n\nuse inkwell::context::Context;\nuse inkwell::OptimizationLevel;\n\nfn main() {\n    let context = Context::create();\n    let i32_type = context.i32_type();\n    let i8_type = context.i8_type();\n    let i8_ptr_type = i8_type.ptr_type(inkwell::AddressSpace::Generic);\n\n    // Module\n    let module = context.create_module(\"main\");\n\n    // Function\n    let printf_fn_type = i32_type.fn_type(&[i8_ptr_type.into()], true);\n    let printf_function = module.add_function(\"printf\", printf_fn_type, None);\n    let main_fn_type = i32_type.fn_type(&[], false);\n    let main_function = module.add_function(\"main\", main_fn_type, None);\n\n    // Block\n    let entry_basic_block = context.append_basic_block(main_function, \"entry\");\n\n    // Instruction(Builder)\n    let builder = context.create_builder();\n    builder.position_at_end(entry_basic_block);\n    let hw_string_ptr = builder.build_global_string_ptr(\"Hello, world!\\n\", \"hw\");\n    builder.build_call(printf_function, &[hw_string_ptr.as_pointer_value().into()], \"call\");\n    builder.build_return(Some(&i32_type.const_int(0, false)));\n\n    let execution_engine = module.create_jit_execution_engine(OptimizationLevel::Aggressive).unwrap();\n    unsafe {\n        execution_engine.get_function::<unsafe extern \"C\" fn()>(\"main\").unwrap().call();\n    }\n}\n```\n\n実行してみます。\n\n```shell\n$ cargo run\nHello, world!\n```\n\nLLVMのJITコンパイラで実行できました。\nちなみに、IRがどんなものか確認したい場合は、`module.print_to_file` を使いましょう。\n実際に出力してみると、次の結果になります。\n\n```text\n; ModuleID = 'main'\nsource_filename = \"main\"\n\n@hw = private unnamed_addr constant [15 x i8] c\"Hello, world!\\0A\\00\", align 1\n\ndeclare i32 @printf(i8*, ...)\n\ndefine i32 @main() {\nentry:\n  %call = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @hw, i32 0, i32 0))\n  ret i32 0\n}\n```\n\nRustの`execution_engine.get_function::<unsafe extern \"C\" fn()>(\"main\").unwrap().call();`は、IRの`@main`関数を実行しています。\n`@main`関数では、`@printf`関数を実行していますが、それは、C言語の`printf`になります。\n\nIRのコードに関する調査は、[LLVM Language Reference Manual](https://llvm.org/docs/LangRef.html) が重宝します。\n`getelementptr`を調査してみると面白いです。\n\n### SUM\n\n次は、3つの数値を引数とし、足し算した結果を返す関数SUMを作成してみます。\nRustのコードは、次のものになります。\n\n```rust\nextern crate inkwell;\n\nuse inkwell::OptimizationLevel;\nuse inkwell::context::Context;\nuse std::error::Error;\n\nfn main() -> Result<(), Box<dyn Error>> {\n    let context = Context::create();\n    let i64_type = context.i64_type();\n    let fn_type = i64_type.fn_type(&[i64_type.into(), i64_type.into(), i64_type.into()], false);\n\n    // Module\n    let module = context.create_module(\"main\");\n    let builder = context.create_builder();\n\n    // Function\n    let function = module.add_function(\"sum\", fn_type, None);\n\n    // Block\n    let basic_block = context.append_basic_block(function, \"entry\");\n\n    // Instruction(Builder)\n    builder.position_at_end(basic_block);\n    let x = function.get_nth_param(0).unwrap().into_int_value();\n    let y = function.get_nth_param(1).unwrap().into_int_value();\n    let z = function.get_nth_param(2).unwrap().into_int_value();\n    let sum = builder.build_int_add(x, y, \"sum\");\n    let sum = builder.build_int_add(z, sum, \"sum\");\n    builder.build_return(Some(&sum));\n\n    let execution_engine = module.create_jit_execution_engine(OptimizationLevel::None)?;\n\n    unsafe { \n        let x = 1u64;\n        let y = 2u64;\n        let z = 3u64;\n        let r = execution_engine.get_function::<unsafe extern \"C\" fn(u64, u64, u64)-> u64>(\"sum\")?.call(x, y , z);\n        println!(\"{:?}\", r);\n    };\n    Ok(())\n}\n```\n\n実行してみます。\n\n```shell\n$ cargo run\n6\n```\n\n見事、`1 + 2 + 3`の足し算ができました。\nちなみに、IRも出力しておきます。\n\n```text\n; ModuleID = 'main'\nsource_filename = \"main\"\ntarget datalayout = \"e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\n\ndefine i64 @sum(i64 %0, i64 %1, i64 %2) {\nentry:\n  %sum = add i64 %0, %1\n  %sum1 = add i64 %2, %sum\n  ret i64 %sum1\n}\n```\n\n前回同様、Rustの`execution_engine.get_function::<unsafe extern \"C\" fn(u64, u64, u64)-> u64>(\"sum\")?.call(x, y , z);`は、IRの`@sum`関数に該当します。\n足し算の`Instruction`が使えました。\n\n### FizzBuzz\n\nでは、次はFizzBuzzをしてみます。割り算やifの命令が新しく使います。\nRustのコードは、次のものになります。\n\n```rust\nextern crate inkwell;\n\nuse inkwell::context::Context;\nuse inkwell::IntPredicate::EQ;\nuse inkwell::OptimizationLevel;\nuse std::error::Error;\n\nfn main() -> Result<(), Box<dyn Error>> {\n    let context = Context::create();\n    let i64_type = context.i64_type();\n    let void_type = context.void_type();\n    let i8_type = context.i8_type();\n\n    let i8_ptr_type = i8_type.ptr_type(inkwell::AddressSpace::Generic);\n    let fn_type = i64_type.fn_type(&[i64_type.into()], false);\n    let null = i8_ptr_type.const_null();\n\n    // Module\n    let module = context.create_module(\"fizz_buzz\");\n\n    // Function\n    let printf_fn_type = void_type.fn_type(&[i8_ptr_type.into()], true);\n    let printf_function = module.add_function(\"printf\", printf_fn_type, None);\n    let fizz_buzz_function = module.add_function(\"fizz_buzz\", fn_type, None);\n\n    // Block\n    let block = context.append_basic_block(fizz_buzz_function, \"entry\");\n\n    // Instruction\n    let builder = context.create_builder();\n    builder.position_at_end(block);\n\n    let fizz_buzz_string_ptr = builder.build_global_string_ptr(\"FizzBuzz\\n\", \"fizz_buzz\");\n    let fizz_string_ptr = builder.build_global_string_ptr(\"Fizz\\n\", \"fizz\");\n    let buzz_string_ptr = builder.build_global_string_ptr(\"Buzz\\n\", \"buzz\");\n\n    let param_0 = fizz_buzz_function\n        .get_nth_param(0)\n        .unwrap()\n        .into_int_value();\n\n    let rem_divied_by_3 =\n        builder.build_int_signed_rem(param_0, i64_type.const_int(3, false), \"rem_3\");\n    let rem_divied_by5 =\n        builder.build_int_signed_rem(param_0, i64_type.const_int(5, false), \"rem_5\");\n    let rem_divied_by15 =\n        builder.build_int_signed_rem(param_0, i64_type.const_int(15, false), \"rem_15\");\n\n    let comp_that_is_divisible_by_3 = builder.build_int_compare(\n        EQ,\n        rem_divied_by_3,\n        i64_type.const_int(0, false),\n        \"if_can_divide_by_3\",\n    );\n    let comp_that_is_divisible_by_5 = builder.build_int_compare(\n        EQ,\n        rem_divied_by5,\n        i64_type.const_int(0, false),\n        \"if_can_divide_by_5\",\n    );\n    let comp_that_is_divisible_by_15 = builder.build_int_compare(\n        EQ,\n        rem_divied_by15,\n        i64_type.const_int(0, false),\n        \"if_can_divide_by_15\",\n    );\n\n    // Block\n    let fizz_buzz_block = context.append_basic_block(fizz_buzz_function, \"fizz_buzz\");\n    let fizz_block = context.append_basic_block(fizz_buzz_function, \"fizz\");\n    let buzz_block = context.append_basic_block(fizz_buzz_function, \"buzz\");\n    let num_block = context.append_basic_block(fizz_buzz_function, \"num\");\n    let else_1_block = context.append_basic_block(fizz_buzz_function, \"else_1\");\n    let else_2_block = context.append_basic_block(fizz_buzz_function, \"else_2\");\n    let end_block = context.append_basic_block(fizz_buzz_function, \"end_block\");\n\n    // Instruction\n    builder.build_conditional_branch(comp_that_is_divisible_by_15, fizz_buzz_block, else_1_block);\n    builder.position_at_end(fizz_buzz_block);\n    builder.build_call(\n        printf_function,\n        &[fizz_buzz_string_ptr.as_pointer_value().into()],\n        \"print_fizz_buzz\",\n    );\n    builder.build_unconditional_branch(end_block);\n\n    // Instruction\n    builder.position_at_end(else_1_block);\n    builder.build_conditional_branch(comp_that_is_divisible_by_3, fizz_block, else_2_block);\n    builder.position_at_end(fizz_block);\n    builder.build_call(\n        printf_function,\n        &[fizz_string_ptr.as_pointer_value().into()],\n        \"print_fizz\",\n    );\n    builder.build_unconditional_branch(end_block);\n\n    // Instruction\n    builder.position_at_end(else_2_block);\n    builder.build_conditional_branch(comp_that_is_divisible_by_5, buzz_block, num_block);\n    builder.position_at_end(buzz_block);\n    builder.build_call(\n        printf_function,\n        &[buzz_string_ptr.as_pointer_value().into()],\n        \"print_buzz\",\n    );\n    builder.build_unconditional_branch(end_block);\n\n    // Instruction\n    builder.position_at_end(num_block);\n    builder.build_call(\n        printf_function,\n        &[buzz_string_ptr.as_pointer_value().into()], // TODO: Print input num.\n        \"print_num\",\n    );\n    builder.build_unconditional_branch(end_block);\n\n    // Instruction\n    builder.position_at_end(end_block);\n    builder.build_return(Some(&null));\n\n    let e = module.create_jit_execution_engine(OptimizationLevel::None)?;\n    unsafe {\n        let x = 15u64;\n        e.get_function::<unsafe extern \"C\" fn(u64) -> ()>(\"fizz_buzz\")?\n            .call(x);\n    }\n    Ok(())\n}\n```\n\nif文では、`build_conditional_branch`と`build_unconditional_branch`がどうやら使うそうです。\n[inkwell/examples/kaleidoscope/main.rs](https://github.com/TheDan64/inkwell/blob/master/examples/kaleidoscope/main.rs)で書いてありましたので、使ってみました。\n実行してみます。15を引数として呼んでいます。\n\n```shell\n$ cargo run\nFizzBuzz\n```\n\n成功です！\nちなみに、IRも出力しておきます。\n\n```text\n; ModuleID = 'fizz_buzz'\nsource_filename = \"fizz_buzz\"\n\n@fizz_buzz.1 = private unnamed_addr constant [10 x i8] c\"FizzBuzz\\0A\\00\", align 1\n@fizz = private unnamed_addr constant [6 x i8] c\"Fizz\\0A\\00\", align 1\n@buzz = private unnamed_addr constant [6 x i8] c\"Buzz\\0A\\00\", align 1\n\ndeclare void @printf(i8*, ...)\n\ndefine i64 @fizz_buzz(i64 %0) {\nentry:\n  %rem_3 = srem i64 %0, 3\n  %rem_5 = srem i64 %0, 5\n  %rem_15 = srem i64 %0, 15\n  %if_can_divide_by_3 = icmp eq i64 %rem_3, 0\n  %if_can_divide_by_5 = icmp eq i64 %rem_5, 0\n  %if_can_divide_by_15 = icmp eq i64 %rem_15, 0\n  br i1 %if_can_divide_by_15, label %fizz_buzz, label %else_1\n\nfizz_buzz:                                        ; preds = %entry\n  call void (i8*, ...) @printf(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @fizz_buzz.1, i32 0, i32 0))\n  br label %end_block\n\nfizz:                                             ; preds = %else_1\n  call void (i8*, ...) @printf(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @fizz, i32 0, i32 0))\n  br label %end_block\n\nbuzz:                                             ; preds = %else_2\n  call void (i8*, ...) @printf(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @buzz, i32 0, i32 0))\n  br label %end_block\n\nnum:                                              ; preds = %else_2\n  call void (i8*, ...) @printf(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @buzz, i32 0, i32 0))\n  br label %end_block\n\nelse_1:                                           ; preds = %entry\n  br i1 %if_can_divide_by_3, label %fizz, label %else_2\n\nelse_2:                                           ; preds = %else_1\n  br i1 %if_can_divide_by_5, label %buzz, label %num\n\nend_block:                                        ; preds = %num, %buzz, %fizz, %fizz_buzz\n  ret i8* null\n}\n```\n\nBlockがめちゃくちゃ増えました。それはFizzBuzzのif,elseが多いからですね。\nLLVMについて、少し自信がついてきました。\nこれまで`中間言語 ~ コード生成`をLLVMでやってみました。\n少し戻って、`字句解析 ~ 構文木`の部分、つまりパース処理をやってみます。\n\n### 四則演算するJavascriptをパース\n\njavascriptをパースしてみます。[swc_ecma_parser](https://rustdoc.swc.rs/swc_ecma_parser/)を使います。\nパースするjavascriptは、次のものになります。\n\n```javascript\n// ./src/test.js\n20 / 10\n```\n\nRustのコードは、次のものになります。\n\n```rust\n#[macro_use]\nextern crate swc_common;\nextern crate swc_ecma_ast;\nextern crate swc_ecma_parser;\n\nuse std::path::Path;\n\nuse swc_common::sync::Lrc;\nuse swc_common::{\n    errors::{ColorConfig, Handler},\n    SourceMap,\n};\nuse swc_ecma_parser::{lexer::Lexer, Parser, StringInput, Syntax};\n\nfn main() {\n    let cm: Lrc<SourceMap> = Default::default();\n    let handler = Handler::with_tty_emitter(ColorConfig::Auto, true, false, Some(cm.clone()));\n\n    let fm = cm\n        .load_file(Path::new(\"./src/test.js\"))\n        .expect(\"failed to load test.js\");\n    let lexer = Lexer::new(\n        Syntax::Es(Default::default()),\n        // JscTarget defaults to es5\n        Default::default(),\n        StringInput::from(&*fm),\n        None,\n    );\n\n    let mut parser = Parser::new_from(lexer);\n\n    for e in parser.take_errors() {\n        e.into_diagnostic(&handler).emit();\n    }\n\n    let _module = parser\n        .parse_module()\n        .map_err(|mut e| e.into_diagnostic(&handler).emit())\n        .expect(\"failed to parser module\");\n\n    println!(\"{:?}\", _module);\n}\n```\n\n実行してみます。\n\n```shell\n$ cargo run\nModule { span: Span { lo: BytePos(0), hi: BytePos(8), ctxt: #0 }, body: [Stmt(Expr(ExprStmt { span: Span { lo: BytePos(0), hi: BytePos(8), ctxt: #0 }, expr: Bin(BinExpr { span: Span { lo: BytePos(0), hi: BytePos(7), ctxt: #0 }, op: \"/\", left: Lit(Num(Number { span: Span { lo: BytePos(0), hi: BytePos(2), ctxt: #0 }, value: 20.0 })), right: Lit(Num(Number { span: Span { lo: BytePos(5), hi: BytePos(7), ctxt: #0 }, value: 10.0 })) }) }))], shebang: None }\n```\n\nそれっぽい結果(20.0や10.0、`op: \"/\"`)が出力されましたね！\n\n### 四則演算するJavascriptをLLVMで実行\n\n最後に、swc_ecma_parserとLLVMを組み合わせて、`字句解析 ~ 構文木`と`中間言語 ~ コード生成`を繋げ、四則演算するJSをパースし、LLVMで実行してみます。\n\nパースするjavascriptは、次のものになります。\n\n```javascript\n// ./src/test.js\n20 / 10;\n```\n\nRustのコードは、次のものになります。\n\n```rust\nextern crate inkwell;\nextern crate swc_common;\nextern crate swc_ecma_ast;\nextern crate swc_ecma_parser;\n\nuse inkwell::context::Context;\nuse inkwell::OptimizationLevel;\nuse std::error::Error;\nuse std::path::Path;\nuse swc_common::sync::Lrc;\nuse swc_common::{\n    errors::{ColorConfig, Handler},\n    SourceMap,\n};\nuse swc_ecma_ast::Lit::Num;\nuse swc_ecma_parser::{lexer::Lexer, Parser, StringInput, Syntax};\n\nfn main() -> Result<(), Box<dyn Error>> {\n    let cm: Lrc<SourceMap> = Default::default();\n    let handler = Handler::with_tty_emitter(ColorConfig::Auto, true, false, Some(cm.clone()));\n\n    let fm = cm\n        .load_file(Path::new(\"./src/test.js\"))\n        .expect(\"failed to load test.js\");\n    let lexer = Lexer::new(\n        Syntax::Es(Default::default()),\n        Default::default(),\n        StringInput::from(&*fm),\n        None,\n    );\n    let mut parser = Parser::new_from(lexer);\n    for e in parser.take_errors() {\n        e.into_diagnostic(&handler).emit();\n    }\n    let _module = parser\n        .parse_module()\n        .map_err(|e| e.into_diagnostic(&handler).emit())\n        .expect(\"failed to parser module\");\n\n    let context = Context::create();\n    let module = context.create_module(\"main\");\n    let builder = context.create_builder();\n    for b in _module.body {\n        if b.is_stmt() {\n            let stmt = b.stmt().unwrap();\n            if stmt.is_expr() {\n                let expr_stmt = stmt.expr().unwrap();\n                let expr = expr_stmt.expr;\n                if expr.is_bin() {\n                    let bin_expr = expr.bin().unwrap();\n                    let left_expr = bin_expr.left;\n                    let right_expr = bin_expr.right;\n                    let binary_op = bin_expr.op;\n                    if left_expr.is_lit() && right_expr.is_lit() {\n                        let left_lit = left_expr.lit().unwrap();\n                        let right_lit = right_expr.lit().unwrap();\n                        let left_value = match left_lit {\n                            Num(n) => n.value,\n                            _ => 0f64,\n                        };\n                        let right_value = match right_lit {\n                            Num(n) => n.value,\n                            _ => 0f64,\n                        };\n                        let i64_type = context.i64_type();\n                        let void_type = context.void_type();\n                        let fn_type = void_type.fn_type(&[], false);\n                        let function = module.add_function(\"main\", fn_type, None);\n                        let basic_block = context.append_basic_block(function, \"entry\");\n                        builder.position_at_end(basic_block);\n                        let x = i64_type.const_int(left_value as u64, true);\n                        let y = i64_type.const_int(right_value as u64, true);\n                        let result = match binary_op {\n                            swc_ecma_ast::BinaryOp::Add => builder.build_int_add(x, y, \"main\"),\n                            swc_ecma_ast::BinaryOp::Sub => builder.build_int_sub(x, y, \"main\"),\n                            swc_ecma_ast::BinaryOp::Div => {\n                                builder.build_int_signed_div(x, y, \"main\")\n                            }\n                            swc_ecma_ast::BinaryOp::Mul => builder.build_int_mul(x, y, \"main\"),\n                            _ => i64_type.const_int(0u64, true),\n                        };\n                        builder.build_return(Some(&result));\n                        let e = module.create_jit_execution_engine(OptimizationLevel::None)?;\n                        unsafe {\n                            let r = e\n                                .get_function::<unsafe extern \"C\" fn() -> u64>(\"main\")?\n                                .call();\n                            println!(\"{:?}\", r);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    Ok(())\n}\n```\n\n実行してみます。\n\n```shell\n$ cargo run\n2\n```\n\n`20 / 10`つまり、`2`が出力されました！やった！\n\n## 終わりに\n\nこれにて、簡単なjavascriptコードをパースし、LLVMで実行できるところまでたどり着きました。\n当初、LLVMの使い方って全然わからなかったのですが、段階的にできる部分が増えると、分かる領域が増えて、モチベーションが高まります。\nLLVMの勉強をされている方、参考にしてみてください。","publishedAt":"2021-09-04","slug":"intro_to_LLVM-JIT_compilation_of_javascript_with_LLVM_Rust_inkwell","title":"LLVM入門 - javascriptをLLVM(Rust:inkwell)でJITコンパイルするまで"},{"body":"TikTok へスクレイプするバッチを GCP 上で構築しました。\nGCP 構築のシステム設計話と、その構築時に、ハマったことを共有します。\n\n## きっかけ\n\n2020 年、最もダウンロードされたアプリが Facebook を抜いて**TikTok**が一位になったそうです。\n\nhttps://gigazine.net/news/20210811-tiktok-overtakes-facebook/\n\n私も TikTok を利用しています。\n\nネットサーフィンをしている時に、[tiktok-scraper](https://www.npmjs.com/package/tiktok-scraper)というライブラリを[cloudflare のサイト](https://workers.cloudflare.com/works)で発見しました。これを使って、TikTok の情報収集できるんじゃないかなと思い始めましたのがきっかけです。\n\n※ スクレイプは私的利用であることが前提です。また、TikTok へ負荷をかけないようスクレイプ間隔に配慮しましょう。\n\n## tiktok-scraper\n\nhttps://www.npmjs.com/package/tiktok-scraper\n\n> Scrape and download useful information from TikTok.\n> No login or password are required.\n> This is not an official API support and etc. This is just a scraper that is using TikTok Web API to scrape media and related meta information.\n\n上記とおり、TikTok の WebAPI を通してスクレイプします。\nライブラリでは、特定の TikTok 動画をダウンロードすることができますが、次の切り口で、TikTok 動画を一括ダウンロードすることもできます。\n\n- ユーザー\n- ハッシュタグ\n- トレンド\n- 音楽\n\n![動画をダウンロード](https://res.cloudinary.com/silverbirder/image/upload/v1630224934/silver-birder.github.io/blog/tiktok_scraper_doc1.png)\n\n![様々な切り口で、動画をダウンロード](https://res.cloudinary.com/silverbirder/image/upload/v1630224935/silver-birder.github.io/blog/tiktok_scraper_doc2.png)\n\n加えて、メタ情報(フォロワー数やいいね数など)も手に入ります。\n\n中には、ユーザー画像や動画カバー画像などの TikTok CDN へのリンクもあります。(`https://p16-sign-va.tiktokcdn.com`)\n\nリンクには、有効期限を示す文字が含まれており、一定の時間が経過すると `Access Denied` となります。\n\n![様々な切り口で、メタ情報をダウンロード](https://res.cloudinary.com/silverbirder/image/upload/v1630224935/silver-birder.github.io/blog/tiktok_scraper_doc3.png)\n\n手に入れられない情報は、**ログインが必要なもの**です。\n例えば、私がフォローしているユーザーとかです。\nその情報が欲しかったので、どうにかして手に入れました。(詳細は省きます)\nそのユーザー情報を使って、先程のユーザーという切り口で TikTok の動画やメタ情報を収集するバッチを作ろうと考えました。\n\n※ WebAPI を叩きすぎると、TikTok 側のブラックリストに追加され、アクセス拒否されます。\n\n## システム設計\n\nバッチを動かす環境ですが、プライベートでよく使っている GCP 上で構築しようと思いました。\nバッチで収集したデータを閲覧する Web アプリケーションも作ろうと考え、Netlify と React で動かすことにしました。\n\n![Webアプリケーション UI](https://res.cloudinary.com/silverbirder/image/upload/v1630404283/silver-birder.github.io/blog/tiktok_scraper_web_app_sample.png)\n\n## 目的\n\n私がフォローしているユーザーの TikTok 動画やメタ情報を集めること。\n\n## I/O\n\n- インプット\n  - ユーザー情報\n- アウトプット\n  - TikTok 動画\n  - メタ情報\n\n## GCP リソース選定\n\n- TikTok 動画\n  - Cloud Storage へ保存\n- メタ情報\n  - Cloud SQL へ保存\n- コンピューティングリソース\n  - Cloud Run\n\n## 設計図\n\n実際に構築した GCP のシステム設計図が、次の画像のとおりです。\n\n![tiktok scrape platform overviews](https://res.cloudinary.com/silverbirder/image/upload/v1630160345/silver-birder.github.io/blog/tiktok_scrape_platform_overviews.png)\n\nGCP リソースの用途は、次のとおりです。\n\n| GCP リソース    | 用途                           |\n| --------------- | ------------------------------ |\n| Cloud Scheduler | バッチ起動のスケジュールを管理 |\n| Cloud Worlflows | バッチのワークフローを制御     |\n| Cloud Run       | 役割に応じて処理               |\n| PubSub          | Cloud Run を繋げる             |\n| Cloud Storage   | 動画を保存                     |\n| AutoML Vision   | 動画のカバー画像をラベル検出   |\n| Cloud SQL       | 全てのメタ情報を管理           |\n\n各 Clour Run の役割は、次のとおりです。\n\n| Cloud Run 名 | 役割                                             |\n| ------------ | ------------------------------------------------ |\n| Loader       | ユーザー情報を読み込む                           |\n| Processor    | 一連の処理を行む                                 |\n| Scraper      | TikTok へスクレイプする                          |\n| Storer       | 渡された情報を保存する                           |\n| Uploader     | 動画をダウンロードし、Storage へアップロードする |\n| Visioner     | 画像を(Vision API を通して)ラベル情報を抽出する  |\n| API          | Cloud SQL とのインターフェース                   |\n\n## ハマったこと\n\n## Cloud Workflows の制限が厳しい\n\n当初、PubSub は使わずに、Cloud Run の連携は Cloud Workflows で行おうと考えていました。\nPubSub でワークフローを制御するよりも、Cloud Workflows の yaml でワークフローを制御した方が分かりやすいと思ったからです。\n具体的には、Cloud Run へ HTTP リクエストし、HTTP レスポンスに応じて、次の Cloud Run を呼び出そうと考えていました。\n\nただ、Cloud Workflows には、次のページに書いてあるとおり、いくつかの制限があります。\n\nhttps://cloud.google.com/workflows/quotas?hl=ja\n\n特に困ったのが、全ての変数のメモリ合計が、**64kb** だということです。\nHTTP レスポンスの Body を変数保持する構成を取ると、そのサイズを考慮しなければいけません。\nいくつかやり方を見直してみたのですが、思うような形に仕上げることができず、断念しました。\n結果、PubSub を使って Cloud Run を連携することになりました。\nCloud Workflows は、バッチのキック、通知などをすることとなりました。\n\n## Firestore のページカーソルに ±2 ページ以降への移動が難しい\n\nGCP でデータストレージで、無料枠がある Firestore を当初使っていました。\n理由は、単純に GCP 無料枠として Firestore があったからです。\n\n当初、Firestore を使って、バッチと Web アプリを書いていました。\nWeb アプリには、バッチで収集した TikTok の動画を一覧表示する View を用意しました。\n\n閲覧する TikTok 動画が多くなると、ページネーションが欲しくなりました。\nそこで、Firestore でページネーションの実現方法を調べてみると、次の資料を発見しました。\n\nhttps://firebase.google.com/docs/firestore/query-data/query-cursors?hl=ja\n\nこれを見ると、ページネーションは、現在位置から ±1 ページの移動は簡単です。\n資料にあるサンプルコードのように、`startAfter`を使えばよいだけです。\n\n```javascript\nvar first = db.collection(\"cities\").orderBy(\"population\").limit(25);\n\nreturn first.get().then((documentSnapshots) => {\n  // Get the last visible document\n  var lastVisible = documentSnapshots.docs[documentSnapshots.docs.length - 1];\n  console.log(\"last\", lastVisible);\n\n  // Construct a new query starting at this document,\n  // get the next 25 cities.\n  var next = db\n    .collection(\"cities\")\n    .orderBy(\"population\")\n    .startAfter(lastVisible)\n    .limit(25);\n});\n```\n\nしかし、現在位置から ±2 ページ目以降への遷移がしたい場合は、どうすれば良いでしょうか。\n上記のサンプルコードで言えば、`first`をコピペして`second`変数を生成するのでしょうか。\nそれよりも、`offset`メソッドがほしいところです。\nしかし、次の資料を発見し、諦めることになります。\n\nhttps://firebase.google.com/docs/firestore/best-practices?hl=ja\n\n> オフセットは使用しないでください。その代わりにカーソルを使用します。オフセットを使用すると、スキップされたドキュメントがアプリケーションに返されなくなりますが、内部ではスキップされたドキュメントも引き続き取得されています。スキップされたドキュメントはクエリのレイテンシに影響し、このようなドキュメントの取得に必要な読み取りオペレーションは課金対象になります。\n\nという訳で、クエリカーソルを推奨されています。\n\n解決策としては、順序を示すフィールドがあれば、解決するかもしれません。\n例えば、`order`というフィールドを用意し、1,2,3 とインクリメントしたデータがあれば、クリアできるかもしれません。\n`startAfter`の引数は document オブジェクトだけではなく、orderBy 句で指定したフィールドの変数を含めることができます。\n\n```javascript\nvar next = db.collection(\"cities\").orderBy(\"order\").startAfter(50).limit(25);\n```\n\nこれだと、1 ページ 25 個のデータを表示するならば、3 ページ目(51~75)を取得できます。(`startAfter`は開始点を含めません)\n\nhttps://cloud.google.com/nodejs/docs/reference/firestore/latest/firestore/query\n\nそもそも、ドキュメントベースの設計よりも、RDB の設計に慣れていた私は、\nFirestore よりも、Cloud SQL の方が扱いやすいと思いました。\nそこで、データストレージを Firestore から Cloud SQL へ切り替えることとしました。\n改修自体、Cloud Run の役割が明確に分離されていたので、一部の処理を書き換えるだけで、簡単にできました。\n\n## Eventac のリソース選択が物足りない\n\nCloud Run と PubSub の連携には、Eventac を使用します。\n\nhttps://cloud.google.com/blog/ja/products/serverless/eventarc-unified-eventing-experience-google-cloud\n\n> 昨年 10 月、60 を超える Google Cloud ソースから Cloud Run にイベントを送信できる新しいイベント機能、Eventarc を発表いたしました。Eventarc は、さまざまなソースから監査ログを読み取り、それらを CloudEvents 形式のイベントとして Cloud Run サービスに送信します。また、カスタム アプリケーションの Pub/Sub トピックからイベントを読み取ることもできます。\n\nこの Eventarc のソースとして、Cloud Storage の Object.create をトリガーとして設計を考えていました。\nしかし、そのイベントをフィルタリングする選択肢は、2 つしかありません。\n\nhttps://cloud.google.com/blog/ja/products/serverless/demystifying-event-filters-eventarc\n\nできるのは、執筆時点(2021 年 8 月)で、次の 2 つです。\n\n- All resource\n- Specific resource\n\nAll resource は、Cloud Storage の全てのバケットにおける Object.create イベントがトリガーとなります。\nSpecific resource は、特定の Obeject 名が Object.create された場合のみ、トリガーとなります。\n欲しいなと思ったのは、Specific resouce の正規表現によるフィルタリング、任意のバケットやフォルダの配下で限定など\nのフィルタリングです。例えば、`gs://bucket/folder/*.json` のような形式です。現状は、`gs://bucket/folder/A.json`とするしかありません。\n\n今回は、PubSub のイベントのみでトリガーするようにしました。\n\n## PubSub をトリガーとする CloudRun で HTTP レスポンス 500 を返却すると、PubSub が再試行される\n\nCloud Run で、5XX 系のエラーとなった場合、PubSub の再試行されます。\n\nhttps://cloud.google.com/pubsub/docs/admin?hl=ja#using_retry_policies\n\n何度も PubSub が実行されると、Cloud Run のコンピューティングリソースが消費され続けます。\nそうすると、課金が発生するので、対策が必要です。\n\n## Cloud Workflows の処理は、あまりカスタマイズできない\n\nCloud Workflows は、あくまでワークフローの管理です。\n変数処理などは、基本的に使わず、ワークフローのタスクを連結するだけにした方が良いです。\n次の資料には、Cloud Workflows で使える標準機能です。\n\nhttps://cloud.google.com/workflows/docs/reference/stdlib/overview\n\nワークフローのタスクを並列処理する機能は、まだ実験段階なので、本番環境は使えないようです。\n\nhttps://cloud.google.com/workflows/docs/reference/stdlib/experimental.executions/map\n\n## 終わりに\n\nシステム設計変更が度々変更がありつつも、目的とする TikTok 動画やメタ情報を収集することは達成できました。\n変更があったとしても、役割をできる限り小さく保つことで、変更に柔軟に対応することができます。\nまた、実際に動かすことで、気付けるポイントもあるので、フィードバックサイクルを短くすることも大切です。\n\nまだまだ改善する余地はあります。ユーザー情報という切り口で情報収集していましたが、トレンドやハッシュタグなどからも\n取得できるようにしたいです。また、ユーザーの RSS を作ることで、金銭的な節約もしてみたいと思っています。","publishedAt":"2021-08-28","slug":"learn_point_from_building_tiktok_scrape_platform_on_gcp","title":"TikTokスクレイプ基盤をGCP上で構築してハマったこと"},{"body":"Web フロントエンジニアたるもの、**ブラウザの仕組みに興味を持つのは自然の摂理**です。本記事では、私がブラウザの仕組みを学んでいく過程を備忘録として残します。\n\n## みんな大好き Chrome\n\nWeb フロントエンジニアに愛されているブラウザといえば、~~IE~~Chrome ですよね。\nブラウザで HTML,CSS,JS の動作確認するのは、日常茶飯事です。\nブラウザによって動作が異なることは、Web フロントエンジニアなら周知の事実です。\nじゃあ、なんで動作が違うのかというと、\n\n- 「レンダリングエンジンが違うから〜」\n- 「Javascript エンジンが違うから〜」\n\nぐらいは知っているんじゃないかなと思います。\nじゃあ、そのレンダリングエンジンってどういう仕組みで動いているのでしょうか。\n気になりますよね。\n\n## Chromium について\n\nChromium も、たぶんご存じの方多いのかなと思いますので、簡単に説明します。\n\nChromium は、オープンソースのプロジェクト名であり、ブラウザ名でもあります。\nChrome は、Chromium を元に開発されています。\n詳しい説明は[Chromium - Wiki](<https://en.wikipedia.org/wiki/Chromium_(web_browser)>)を見てください。\n\nオープンソースってことは、ソースコードが誰でも読めちゃうってことですよね。\nだったら、ブラウザの動作を知ることができちゃうじゃないですか！\nわーい！😎\n\n## Chromium のリバースエンジニアリング\n\nではさっそく、Chromium のソースコードを見ていきましょう。\n\nこれです。\n\n[![chromium/src](https://res.cloudinary.com/silverbirder/image/upload/v1622126149/silver-birder.github.io/blog/chromium_src.png)](https://source.chromium.org/chromium/chromium/src)\n\n[Chromium - Wiki](<https://en.wikipedia.org/wiki/Chromium_(web_browser)>)によれば、Chromium のソースコードは約 3,500 万行あるそうです。\nしかも、言語は C++。私はあまりそれを詳しくないのです 😞。\n\n実際にソースコードをローカルマシン(Macbook Air)へチェックアウトし、ビルドをしてみました。\nマシンが貧弱だというのもあるんですが、ビルドに半日ぐらいかかってしまいました。ヘトヘトです。\nこれじゃあさすがに、手軽にブラウザの動作確認はできそうにないです。\n\n## ブラウザの仕組み資料を読む\n\nちょっと趣向を変えて、次のような資料を読むことにしました。\n\n- [ブラウザの仕組み: 最新ウェブブラウザの内部構造](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n  - 記事の公開日が 2011 年 8 月 5 日なので、色々古いかもしれません。\n\nでは、さっそく見ていきます。\n最初に目につくのが、ブラウザの主な構成要素です。\n\n[![ブラウザの主な構成要素](https://res.cloudinary.com/silverbirder/image/upload/v1656253204/silver-birder.github.io/blog/%E3%83%95%E3%82%99%E3%83%A9%E3%82%A6%E3%82%B5%E3%82%99%E3%81%AE%E6%A7%8B%E6%88%90%E8%A6%81%E7%B4%A0.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\n構成要素の内、ユーザーインターフェース、ブラウザエンジン、レンダリングエンジンに着目します。\nそれぞれ、次の役割があります。\n\n- ユーザーインターフェース\n  - アドレスバーや戻る/進むボタンのような UI を担当\n- ブラウザエンジン\n  - UI とレンダリングエンジンの間の処理を整理\n- レンダリングエンジン\n  - 要求されたコンテンツ(HTML など)の表示を担当\n\nちなみに、Chromium のレンダリングエンジンには、webkit を使っていましたが、blink に変わりました。\n\n- [webkit](https://webkit.org/)\n- [blink](https://www.chromium.org/blink)\n\nブラウザの基本的なフローは、次の図の通りです。\n\n[![レンダリングの基本的なフロー](https://res.cloudinary.com/silverbirder/image/upload/v1656253204/silver-birder.github.io/blog/%E3%83%AC%E3%83%B3%E3%82%BF%E3%82%99%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%99%E3%82%A8%E3%83%B3%E3%82%B7%E3%82%99%E3%83%B3%E5%9F%BA%E6%9C%AC%E3%83%95%E3%83%AD%E3%83%BC.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\n[![Webkitのメインフロー](https://res.cloudinary.com/silverbirder/image/upload/v1656253203/silver-birder.github.io/blog/Webkit%E3%81%AE%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%95%E3%83%AD%E3%83%BC.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\n1. Parsing HTML to construct the DOM tree\n1. Render tree construction\n1. Layout of the render tree\n1. Painting the render tree\n\nそれぞれ見ていきます。\n\n---\n\n① Parsing HTML to construct the DOM tree\n\n1 は、HTML をレキサ(字句解析. ex:flex)・パーサ(構文解析. ex:bison)を使って DOM ツリーを構築します。\n\nレキサでは、ステートマシンによって読み込み状態を管理しつつトークンを識別します。空白とかコメントなどは削除されます。\n\nレキサから識別されたトークンをパーサに渡し、構文解析していきます。\nHTML は DTD（Document Type Definition）で文脈自由文法なため、機械的に解析できます。\nただ、HTML は寛大な仕様で、次のようなパターンも許容するようになっています。\n\n- `<br />`の代わりの`</br>`\n- 迷子のテーブル\n- 入れ子のフォーム要素\n- 深すぎるタグ階層\n- 配置に誤りのある html または body 終了タグ\n\nパーサから DOM（Document Object Model）を構築します。\nDOM は、これまでの単なるテキストから、API を持たせたオブジェクトモデルを作ることで、\n以降は DOM を使って処理しやすくなります。\n\n[![サンプル マークアップのDOMツリー](https://res.cloudinary.com/silverbirder/image/upload/v1656253203/silver-birder.github.io/blog/%E3%82%B5%E3%83%B3%E3%83%95%E3%82%9A%E3%83%AB%E3%83%9E%E3%83%BC%E3%82%AF%E3%82%A2%E3%83%83%E3%83%95%E3%82%9A%E3%81%AEDOM%E3%83%84%E3%83%AA%E3%83%BC.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\nこれまでは HTML の話をしていましたが、HTML と並行して CSS も同様に処理していきレンダーオブジェクトというオブジェクトを作っていきます。これは、スタイル情報を付与したオブジェクトになります。\n基本的に、CSS と HTML は互いに独立しているので、並列処理が可能です。例えば、CSS を処理したことで、HTML が変化することはないはずです。\n\n[![CSSの解析](https://res.cloudinary.com/silverbirder/image/upload/v1656253203/silver-birder.github.io/blog/CSS%E3%81%AE%E8%A7%A3%E6%9E%90.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\nただ、Javascript は話が違うので、Javascript が読み込まれた時点で HTML のパースを中断して Javascript のパースが開始されます。\nまた、Javascript が、まだ読み込まれていないスタイルシートの影響を受けそうな特定のスタイルプロパティにアクセスした場合、Javascript はブロックされます。\n\n---\n\n② Render tree construction\n\n① の DOM とレンダーオブジェクトから、レンダーツリーを構築します。\nDOM とレンダーオブジェクトは、1 対 1 という訳ではなく、例えば head 要素や、`display:none;`の要素もレンダーツリーに含まれません。\nレンダーツリーの更新は、DOM ツリーが更新される度に行われます。\n\n[![レンダーツリーと対応するDOMツリー](https://res.cloudinary.com/silverbirder/image/upload/v1656253203/silver-birder.github.io/blog/%E3%83%AC%E3%83%B3%E3%82%BF%E3%82%99%E3%83%BC%E3%83%84%E3%83%AA%E3%83%BC%E3%81%A8%E5%AF%BE%E5%BF%9C%E3%81%99%E3%82%8BDOM%E3%83%84%E3%83%AA%E3%83%BC.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\nレンダーオブジェクトからスタイルを計算するのですが、ちょっと複雑です。\n詳しくは、[スタイルの計算](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/#Style_Computation)を見てください。\n\n---\n\n③ Layout of the render tree\n\nレンダーツリーから、レイアウト情報を計算していきます。\nレイアウト情報とは、位置(x,y)とサイズ(width,height)です。\n\nレンダーツリーのルートから再帰的にレイアウト情報を計算(layout メソッド)していきます。\n\n1. 親レンダラーが自身の幅を決定します。\n1. 親が子を確認して、\n   1. 子レンダラーを配置します（x と y を設定します）。\n   1. 必要な場合は子の layout メソッドを呼び出します。これにより、子の高さを計算します。\n1. 親は子の高さの累積、マージンの高さ、パディングを使用して、自身の高さを設定します。この高さは親レンダラーのさらに親によって使用されます。\n\n※ [レイアウト処理](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/#The_layout_process) 参考\n\nCSS ボックスモデルの図を参考までに共有しておきます。\n\n[![CSS 基本ボックスモデル](https://res.cloudinary.com/silverbirder/image/upload/v1693363991/silver-birder.github.io/blog/boxmodel.png)](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_Box_Model/Introduction_to_the_CSS_box_model)\n\n---\n\n④ Painting the render tree\n\nようやく描画します。\nどこに描画するかという配置方法について考えることになります。\n大きく分けて、3 つに分かれます。\n\n- 通常\n  - オブジェクトはドキュメント内の場所に従って配置されます。つまり、レンダーツリー内の場所は DOM ツリー内の場所と同様になり、ボックスの種類や寸法に従ってレイアウトされます。\n    - position:static,relative\n- フロート\n  - オブジェクトは最初に通常のフローのようにレイアウトされてから、左右のできるだけ遠くに移動されます。\n    - float:right,left\n- 絶対\n  - オブジェクトはレンダーツリー内で DOM ツリーとは異なる場所に配置されます。\n    - position:absolute,fixed\n\n※ [配置方法](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/#Positioning_scheme)\n\n配置方法が分かれば、今度は描画する形について考えます。ブロックボックスとインラインボックスです。\n\n[![ブロックとインラインの配列](https://res.cloudinary.com/silverbirder/image/upload/v1656253203/silver-birder.github.io/blog/%E3%83%95%E3%82%99%E3%83%AD%E3%83%83%E3%82%AF%E3%81%A8%E3%82%A4%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%AE%E9%85%8D%E5%88%97.png)](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/)\n\nブロックボックスは、短形の形であり垂直に並びます。\nインラインボックスは、独自の形を持たず水平に並びます。\n\nz-index のようなプロパティでは、スタッキングコンテキストという概念を知る必要があります。\n詳しくは、[重ね合わせコンテキスト - developer.mozilla.org](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context) をご確認ください。\n\n---\n\n## ブラウザを自作してみる\n\n前章では、資料を通してブラウザの動作が理解できました。\n読むだけじゃなく、動かして理解してみたいとは思いませんか？\nそうです、自作してみましょう。\n\nRust 製の Servo というブラウザエンジンを開発している人が書いた、次のブラウザ自作に関する記事がとても分かりやすいです。\n\n- [Let's build a browser engine! Part 1: Getting started](https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html)\n  - [mbrubeck/robinson](https://github.com/mbrubeck/robinson)\n    - Toy ブラウザエンジン(mbrubeck)\n    - Rust 製\n\nToy ブラウザエンジン(mbrubeck)のメインフローが、これまでの話ととても似ています。\n\n[![Toyブラウザエンジン(mbrubeck)のメインフロー](https://res.cloudinary.com/silverbirder/image/upload/v1622034177/silver-birder.github.io/blog/mbrubeck_toy-layout-engine-7-painting.png)](https://limpet.net/mbrubeck/2014/11/05/toy-layout-engine-7-painting.html)\n\nStyle tree は、これまでの話でいうと Render tree だと思います。\nToy ブラウザエンジン(mbrubeck)に、次の HTML と CSS を読み込ませると、下記の画像のようなアウトプットになります。\n\n```html\n<html>\n  <head>\n    <title>Test</title>\n  </head>\n  <div class=\"outer\">\n    <p class=\"inner\">Hello, <span id=\"name\">world!</span></p>\n    <p class=\"inner\" id=\"bye\">Goodbye!</p>\n  </div>\n</html>\n```\n\n```css\n* {\n  display: block;\n}\n\nspan {\n  display: inline;\n}\n\nhtml {\n  width: 600px;\n  padding: 10px;\n  border-width: 1px;\n  margin: auto;\n  background: #ffffff;\n}\n\nhead {\n  display: none;\n}\n\n.outer {\n  background: #00ccff;\n  border-color: #666666;\n  border-width: 2px;\n  margin: 50px;\n  padding: 50px;\n}\n\n.inner {\n  border-color: #cc0000;\n  border-width: 4px;\n  height: 100px;\n  margin-bottom: 20px;\n  width: 500px;\n}\n\n.inner#bye {\n  background: #ffff00;\n}\n\nspan#name {\n  background: red;\n  color: white;\n}\n```\n\n[![Toyブラウザエンジン(mbrubeck)のアウトプット](https://res.cloudinary.com/silverbirder/image/upload/v1622034247/silver-birder.github.io/blog/mbrubeck_robinson_output.png)](https://github.com/mbrubeck/robinson)\n\n次のリンクにある自作ブラウザエンジンは、[mbrubeck/robinson](https://github.com/mbrubeck/robinson)を参考にして作られたものだそうです。\n\n- [askerry/toy-browser](https://github.com/askerry/toy-browser)\n  - Toy ブラウザエンジン(askerry)\n  - C++製\n\nToy ブラウザエンジン(askerry)に、次の HTML と CSS を読み込ませると、下記の画像のようなアウトプットになります。\n見たら分かると思いますが、とても高機能です。\n\n```html\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n  <head>\n    <title>Browser Test</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n    <link rel=\"stylesheet\" href=\"demo.css\" />\n  </head>\n\n  <body>\n    <div id=\"page\">\n      <header class=\"header\">\n        <h1>Toy Browser Engine</h1>\n      </header>\n      <div id=\"main\">\n        <div id=\"navbar\">\n          <a href=\"#\" class=\"navitem\"> Home </a>\n          <a href=\"#\" class=\"navitem\"> About </a>\n          <a href=\"#\" class=\"navitem\"> Some random stuff </a>\n          <a href=\"#\" class=\"navitem\"> Conclusion </a>\n          <img class=\"img\" src=\"images/otters.jpg\" />\n        </div>\n        <div id=\"content\">\n          <h2>What is this?</h2>\n          This is a <b>toy</b> browser engine, implemented for\n          <span>fun </span> <img class=\"icon\" src=\"images/fun.png\" /> and\n          <span>glory <img class=\"icon\" src=\"images/glory.png\" /></span>.\n          <h2>Why would anyone do this?</h2>\n          This seems pretty pointless! But I had a few goals:\n          <ul>\n            <li>Something to build to learn C++</li>\n            <li>Learn more about how browsers work</li>\n            <li>Make something I've never made before</li>\n          </ul>\n          <h2>What can it do?</h2>\n          <p>\n            Currently, the engine can parse a subset of HTML and build a DOM\n            tree. It can also parse a small subset of CSS (sometimes\n            incorrectly) and use simple selector matching to apply styles to\n            elements.\n          </p>\n          <p>\n            It supports <em>very basic</em> rendering of boxes, images, and text\n            with simple block and inline layouts.\n          </p>\n        </div>\n      </div>\n    </div>\n  </body>\n</html>\n```\n\n```css\n/* https://github.com/askerry/toy-browser/blob/master/examples/demo.css */\nbody {\n  font-family: Arial, sans-serif;\n  background-color: #bfc0c0;\n  color: #253237;\n  font-size: 16px;\n}\n#page {\n  padding: 20;\n  /* width: 800px; */\n  margin: auto;\n}\n\nheader {\n  padding: 10px;\n  padding-left: 20px;\n  background-color: #434371;\n  color: #4acebd;\n}\n\nspan {\n  color: #4acebd;\n}\n\n#main {\n  background-color: white;\n  display: flex;\n}\n\n#navbar {\n  width: 180px;\n  padding: 30px;\n  background-color: #4acebd;\n  height: 500px;\n}\n\n.navitem {\n  display: block;\n  text-align: center;\n  background-color: #434371;\n  color: #4acebd;\n  margin-top: 5px;\n  margin-bottom: 5px;\n  padding: 10px;\n  border-radius: 4px;\n  border-style: solid;\n  border-width: 2px;\n  border-color: #253237;\n}\n\n#content {\n  padding: 20px;\n  width: 500;\n}\n\n.img {\n  width: 180px;\n}\n\n.icon {\n  width: 2em;\n}\n\nh2 {\n  color: #434371;\n}\n\nli {\n  margin-bottom: 5px;\n}\n```\n\n[![Toyブラウザエンジン(askerry)のアウトプット](https://res.cloudinary.com/silverbirder/image/upload/v1693364002/silver-birder.github.io/blog/demo.png)](https://github.com/askerry/toy-browser)\n\n私としては、こちらの方が興味があるので、まずこちらを知り、それを Rust 版で作り直したいなと思います。\n\n## C++ を学ぶ\n\nさて、C++を学ぶために、次のサイトをざっと眺めてみます。\n\n- [C++入門 - www.asahi-net.or.jp](http://www.asahi-net.or.jp/~yf8k-kbys/newcpp0.html)\n- [C++入門 - wisdom.sakura.ne.jp](http://wisdom.sakura.ne.jp/programming/cpp/)\n- [C++入門 - kaitei.net](http://kaitei.net/cpp/)\n\n## 自作ブラウザのソースコード\n\n[askerry/toy-browser](https://github.com/askerry/toy-browser)のメインコード(main.cc)を載せます。\n\n```c\n/* https://github.com/askerry/toy-browser/blob/master/src/main.cc */\nnamespace {\n\nvoid renderWindow(int width, int height, const style::StyledNode &sn,\n                  sf::RenderWindow *window) {\n  layout::Dimensions viewport;\n  viewport.content.width = width;\n  viewport.content.height = height;\n  // Create layout tree for the specified viewport dimensions.\n  std::unique_ptr<layout::LayoutElement> layout_root =\n      layout::layout_tree(sn, viewport);\n  // Paint to window.\n  paint(*layout_root, viewport.content, window);\n}\n\nint windowLoop(const style::StyledNode &sn) {\n  // Create browser window.\n  std::unique_ptr<sf::RenderWindow> window(new sf::RenderWindow());\n  window->create(sf::VideoMode(FLAGS_window_width, FLAGS_window_height),\n                 \"Toy Browser\", sf::Style::Close | sf::Style::Resize);\n  window->setPosition(sf::Vector2i(0, 0));\n  window->clear(sf::Color::Black);\n  // Render initial window contents.\n  renderWindow(FLAGS_window_width, FLAGS_window_height, sn, window.get());\n  // Run the main event loop as long as the window is open.\n  while (window->isOpen()) {\n    sf::Event event;\n    while (window->pollEvent(event)) {\n      switch (event.type) {\n        case sf::Event::Closed:\n          window->close();\n          break;\n\n        case sf::Event::KeyPressed:\n          logger::debug(\"keypress: \" + std::to_string(event.key.code));\n          break;\n\n        case sf::Event::Resized:\n          logger::debug(\"new width: \" + std::to_string(event.size.width));\n          logger::debug(\"new height: \" + std::to_string(event.size.height));\n          window->clear(sf::Color::Black);\n          renderWindow(event.size.width, event.size.height, sn, window.get());\n          break;\n\n        case sf::Event::TextEntered:\n          if (event.text.unicode < 128) {\n            logger::debug(\n                \"ASCII character typed: \" +\n                std::to_string(static_cast<char>(event.text.unicode)));\n          }\n          break;\n\n        default:\n          break;\n      }\n    }\n  }\n  return 0;\n}\n}  // namespace\nint main(int argc, char **argv) {\n  gflags::ParseCommandLineFlags(&argc, &argv, true);\n\n  // Parse HTML and CSS files.\n  const std::string source = io::readFile(FLAGS_html_file);\n  std::unique_ptr<dom::Node> root = html_parser::parseHtml(source);\n  const std::string css = io::readFile(FLAGS_css_file);\n  const std::unique_ptr<css::StyleSheet const> stylesheet = css::parseCss(css);\n\n  // Initialize font registry singleton.\n  text_render::FontRegistry *registry =\n      text_render::FontRegistry::getInstance();\n\n  // Align styles with DOM nodes.\n  std::unique_ptr<style::StyledNode> styled_node =\n      style::styleTree(*root, stylesheet, style::PropertyMap());\n\n  // Run main browser window loop.\n  windowLoop(*styled_node);\n\n  // Delete styled node and clear font registry.\n  styled_node.reset();\n  registry->clear();\n  return 0;\n}\n```\n\n次のとおり、これまで学んできたメインフローと、C++がとても似ていることが分かります。\n\n1. HTML と CSS をパース\n\n```c\n// Parse HTML and CSS files.\nconst std::string source = io::readFile(FLAGS_html_file);\nstd::unique_ptr<dom::Node> root = html_parser::parseHtml(source);\nconst std::string css = io::readFile(FLAGS_css_file);\nconst std::unique_ptr<css::StyleSheet const> stylesheet = css::parseCss(css);\n```\n\n1. 1 の結果から Style tree(Render tree)を構築\n\n```c\n// Align styles with DOM nodes.\nstd::unique_ptr<style::StyledNode> styled_node =\n    style::styleTree(*root, stylesheet, style::PropertyMap());\n```\n\n1. 2 の結果から Layout tree を構築\n\n```c\n// Create layout tree for the specified viewport dimensions.\nstd::unique_ptr<layout::LayoutElement> layout_root =\n    layout::layout_tree(sn, viewport);\n```\n\n1. 3 を paint という描画\n\n```c\n// Paint to window.\npaint(*layout_root, viewport.content, window);\n```\n\n## Re: ブラウザの仕組み資料を読む\n\nもう一度、[ブラウザの仕組み: 最新ウェブブラウザの内部構造](https://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/) を読むと、初めて読んだときに比べて、深く理解できるんじゃないかなと思います。\n\n## 最後に\n\nブラウザの動作について資料や自作を通して理解を深めました。\n\nブラウザの動作が分かれば、ブラウザに優しい Web フロントエンド開発ができると思います。\n\n(今度こそ Chromium のリバースエンジニアリングができるかもしれません。)\n\n## その他\n\nChromium のアドベントカレンダーがありました。参考までにざっと見てみると良いでしょう。\n[Chromium Browser Advent Calendar 2017](https://qiita.com/advent-calendar/2017/chromium)","publishedAt":"2021-05-24","slug":"learning_browser_engine","title":"ブラウザの仕組みを学ぶ"},{"body":"リモートワークが普及しつつある今、オンラインでの仕事に慣れているエンジニアも多いのではないでしょうか。\n私も、そのエンジニアの一人であり、約 1 年はリモートワークしています。\nそんな中、久々に会社へ出社すると、**気軽に話しかける楽さ** を実感しました。この体験について、深堀りしたいと思います。\n\n## リモートワーク前\n\n元々、コロナが流行り出す前(2020 年 2 月以前)は、会社に出社して仕事をしていました。\n当時、同じグループやチームなどと一緒に仕事をしていまして、なにか気になることがあれば、\n近くの席で座っている人に話しかけることをしていましたし、事務関係で他部門の方へ質問するときも、\nちょこっとオフィスを歩き回る程度(数メートルの距離)の近くにいるので、気軽に話しかけていました。\n\n## リモートワークが普及し始める\n\n2020 年 3 月ぐらいからコロナ騒動となり、いつの間にかリモートワークする回数が増えていきました。\nそして、緊急事態宣言があったりとで会社へ出社する回数が極端に減りました。\n出社するとしても、出社する人の人数制限されている状況です。\n\n## 久々のオフィス出勤と、気づき\n\nそして現在(2021 年 3 月)、関西に住むエリアでは緊急事態宣言が解除されました。\nその影響で、会社へ出社することになり、密にならない程度に、オフィスで仕事する機会も増えました。\nそんな中、オフィスで仕事をしていると、**誰かとすぐ気軽に口頭で相談すること(話しかけること)が楽** と感じるようになりました。\nなんでそう思うんだろうって、少し考えるようになりました。\n\n## オンラインでも気軽に相談できるんじゃ\n\nオンラインでも気軽に相談できると思いますが、オフラインほど気軽じゃないと思います。\nオンラインだと、例えば、次のような手順を踏むことがあると思います。\n\n1. 相談したい相手のカレンダーで予定が空いているか確認する\n1. チャットツールで相手に相談したい旨を連絡する\n1. ビデオ会議の仮想部屋を用意する\n1. 相談相手との予定を合わせる\n1. 相談する\n\nどれもちゃちゃっとすれば、数分も掛からないと思いますし、いくつか上の手順を省略しても良いと思います。\nしかし、オフラインで人の話しかける場合は、例えば、次の手順ぐらいかなと思います。\n\n1. 相談したい人をオフィス内で探す\n1. 相談する\n\n何が言いたいかというと、オンラインに比べて、オフラインで相談する方が **調整毎が少ない** んです。\n\n## 口頭じゃなくて、テキストでも相談できるでしょ\n\nわざわざ口頭じゃなくて、テキストで伝えれば良いじゃん？って思ったりもするのですが、それも気軽じゃないです。\n確かに、チャットツールでちゃんと 話したい内容や背景、目的をテキスト化に落とし込むのは、ログが残ります。\nそうすると、後々言った言わないみたいな話にならずに済むので、良いところもあります。\n\nが、テキスト化することは、気軽さから外れます。\nテキスト化するのが難しい場面(e.g. 分からないことが分からない場面など)だってあるはずで、\nそれを無理にテキスト化するのは、やっぱり大変です。\n\nテキスト化するのは、やれば良いかもしれませんが、**気軽さの障壁が高くなります** 。\n\n## すぐにって重要\n\n気軽さを求めているのは、すぐ聞きたいときが多いんです。すぐじゃないなら、\n自分で社内資料を漁ったり、コードを読んだりで、自分なりに調査をします。\nが、そういう手間が、人に教えてもらえるだけで不要になるなら、人に聞いて知った方が効率的と思います。\n\nすぐに聞きたいときって、オンラインだと、カレンダーの予定からしか相手の状況が見えないので、チャットツールでメンションすることってありますよね。\nでも、そういう行為は、相手の仕事を妨害しちゃいます。オフラインだと、相手の仕事姿を傍から見て、あ、今なら話しかけても大丈夫そうだなみたいな状況が分かります。\n\n※ 『質問される側は、作業中断しちゃうんだけど！』はい、そ、そうですね。すみません。\n\n## 気軽さを追求するには\n\n例えば、カレンダー・チャットツール・ビデオ会議ツールが全て連動して、\n1 クリックだけで、相手に相談できるようになる Web アプリを社内で開発・導入したとして、\nこれがあれば、オンラインでも気軽に話せる場面が増えるかもしれません。\n\nけど、面倒だと思うのは、相談したいときにわざわざその Web アプリを起動する面倒さがちょこっとありそうです。\n何が言いたいかというと、常時、気軽に話しかけれる環境下で仕事をしたいなと思っています。\n所謂 **バーチャルオフィスツール** (Remotty,Sococo,etc)を常時使っていれば、気軽に話せる状態になれるのかなと思ったりしました。\nそのツールだと、さっきの『すぐにって重要？』で話したようなカレンダーからの状況だけだと相手の状況が適切に見えない問題を解決してくれたりします。\n\n## バーチャルオフィスツール使えば、全て解決\n\nそのバーチャルオフィスツールを社内で導入したとしても、\n\n- 利用者が少ない\n  - → 相談したい人がいない\n    - → 利用しなくなる\n- 利用ルールが整備されていない\n  - → 離席しているかどうかのルールが徹底されていない\n    - → 信頼できなくなる\n- 利用する時間帯が限らている\n  - → 相談したいときに、相手がバーチャルオフィスから退出している\n\nなどの課題があるかもしれません。バーチャルオフィスツールを導入したものの、イマイチ良い効果が生まれなかったかもしれません。\n私は、その経験がありますが、今になってやっぱりバーチャルオフィスツールって必要かもと思ったりします。\nそれは、 **リモートワークを経験した今だからこそ** バーチャルオフィスツールの便利さが分かるのかもしれません。\nが、ツールを導入したところで、そのツールを活かす文化(ex.上で示したような課題を解決する)が整っていないと、結局、気軽に話し始めるのは難しいんじゃないですかね。\n\n## 結局、何が言いたかったのか\n\n気軽に話すというのは、オフラインだと意識したことがなかったのですが、\nオンラインでの仕事を経験することで、気軽さについて考えるようになりました。\n\n気軽さというのは、**本当に繊細で、細かいところの配慮** がないと、いけないなと思います。\nそもそも、チャットツールで気軽に相談できるないのか！っと言われると、あ、すみませんってなるのですが、\n人それぞれ個性があって、それを強制するのは、強制された側のストレスが貯まります。\n\n人によって『気軽さ』ってそれぞれだと思うので、各企業は、そのことをしっかり分析してみてはいかがでしょうか。\nその上で、バーチャルオフィスツールを試してみてはどうでしょうか。","publishedAt":"2021-03-10","slug":"good_and_bad_in_offline_and_online","title":"リモートワークになってから『気軽にすぐ聞く』ことが難しくなった"},{"body":"2021 年、あけましておめでとうございます。本年も宜しくおねがいします。最近、体重が増えてしまったため、有酸素運動を頑張っています。\n\n本記事は、昨年の冬あたりから検証していた クライアントサイド統合での Micro Frontends について話そうと思います。検証したソースコードは、次のリポジトリにあります。\n\nhttps://github.com/silverbirder/micro-frontends-sample-code-6\n\n## 概要\n\n全体設計イメージ図は、次のとおりです。\n\n![overview](https://res.cloudinary.com/silverbirder/image/fetch/f_auto/https://raw.githubusercontent.com/silverbirder/micro-frontends-sample-code-6/main/overview.svg)\n\nサーバーサイドは静的コンテンツを返すだけとし、クライアントサイドでアプリケーションを構築します。\n\n構築手段は、ブラウザ標準である ES Module Import を使用し、アプリケーションに必要な Javascript(index.js, bootstrap 用)を load します。\n\nUI に必要な各 Team の Component は、API 経由で取得し、レンダリングする構成になります。\n\n## Javascript Module\n\nJavascript(index.js)には、次の Module を含めようと考えていました。\n\n- DOM Parser\n  - 任意の要素の情報を取得する\n- Imorter\n  - 任意の Module を取得する\n- Router\n  - Web アプリケーション全体の Routing を管理する\n- Worker\n  - バックグランドで実行する処理を管理する\n- EventHub\n  - Module 間の通信を制御する\n\nこれらをざっと考えていた訳ですが、結局実装したのは Importer と Router ぐらいです (笑)。力尽きてしまいました。\n\nまた、前提として可能な限り各 Team の依存関係を独立するよう心がけます。Micro Frontends では、独立できてこそのメリットが享受できるため、できる限り各 Team の共通化は避けるようにします。\n\n## Javascript Importer\n\n全体設計イメージ図にも書いていますが、Javascript の Importer は、Component Discovery API を通して、各 Team の Component を Import します。この構成は、Microservices の Service Discovery Patterns に似せています。この構成を取ることで、各チーム同士は独立(非依存)することができます。\n\n## Javascript Router\n\nRouter は、アプリケーション全体の Routing を管理します。例えば、`/` は Top ページ、 `/s` は検索ページといった具合です。\nRouter には、後ほど説明する WebComponents との相性が良い vaadin/router を使用しました。\n\nhttps://vaadin.com/router\n\nvaadin/router では、WebComponents を指定して Routing するため、指定された WebComponents は、Importer より取得します。\n\n## Component\n\nComponent は LitElement という WebComponents ベースのライブラリを使用しています。各 Team の Component(LitElement のライブラリ込)を Import していると、重複した load となりパフォーマンスがよろしくありません。共通ライブラリを事前に load (import map とかで)することをお勧めします。\n\nWebComponents ということなので、Shadow DOM でレンダリングすることになります。CSS のスコープが独立できるため、他へ影響することはありません。ただ、全体的なブランドカラーを統一したい等 Design System がある場合、Component の共通化のやり方を(慎重に)考える必要があります。\n\n## Build Package, Design System, Performance Metrics\n\n各 Team を独立したいといっても、共通化しないといけないことがあると考えています。私が想定しているものは、次のとおりです。\n\n- Design System\n  - Component 全体のデザインを統一する\n- Performance Metrics\n  - 計測指標のルールを全体で統一する\n    - Rendering Time\n    - Response Time\n    - etc\n- Build Package\n  - ライブラリの扱い方を統一する\n    - External\n    - ECM Version\n    - etc\n\nと書いているだけで、実際に試した訳ではありません(笑)。\n\n## 所感\n\nMicro Frontends のサーバーサイド統合でもそうでしたが、Component を集約・提供するサービスは、クライアントサイド統合でも必要になりました。今回でいうと、Component Discovery API です。これは、Component 間の依存度を下げるためのレイヤーであり、Micro Frontends では、ほぼ必須の要素なのではないかと思います。\n\n## 最後に\n\nMicro Frontends は、統合パターンも大切ですが、もっと大切なのは、ドメインをどう分解するかだと思います。この分割が適切ではないとどうしても共通化しなければならないケースが誕生し、Micro Frontends のメリットが活かせないと思います。そろそろ、プロダクションレベルで検証したいと思いますが、中々重い腰を上げらない今日このごろです。","publishedAt":"2021-01-16","slug":"client_microfrontends","title":"クライアントサイド(ES Module)でMicro Frontends"},{"body":"2020 年も、もう残りわずかになりました。今年の振り返りをはじめてブログに残そうと思います。\n\n## 技術\n\n### UseCotlin\n\n2020 年 3 月より、自前で作ったツール [Cotlin](https://github.com/silverbirder/Cotlin) で技術キャッチアップをはじめました。このツールは、Twitter に投稿された技術資料(ex.speakerdeck,slideshare)を収集するだけのツールです。日本だと、技術勉強会の資料は Twitter で投稿する習慣が（私の観測範囲では）あるため\n、この習慣を利用して、様々な技術資料を広く発見できることができます。\n\n下記のスプレッドシートに、技術資料リンクを自動登録しています。\n\n[UseCotlin (github.com/silverbirder/Cotlin)](https://docs.google.com/spreadsheets/d/1IaJOw9-GdoHhz3D0CzvJfFitrmEN8KpgIleer9rmxiw/edit)\n\n日本だけじゃなく、海外の技術資料も発見できるので、色々な観点の技術を知ることができました。例えば、テスト手法、アーキテクチャの考え方、働き方の考え方などです。これを毎日欠かさずキャッチアップし続けていました。\n\n### Github Contribution\n\nUseCotlin は、主に技術のインプットばかりで、アウトプットができていません。インプットのし過ぎで、頭でっかちにならないよう、毎日アウトプットを心がけていました。\n\n![Github Contribution](https://res.cloudinary.com/silverbirder/image/upload/v1614431446/silver-birder.github.io/blog/Github_Contribution.png)\n\nほぼ毎日、contribute するようにしました。Input と Output のバランスは難しいですが、取り組んで良かったです。\n\n## Twitter Follower\n\n（思いつきで）Twitter のフォロワーを増やしてみようと思い、Twitter の Follower を自動的に増やす仕組みを構築しました。2020 年 9 月ぐらいからはじめて、フォロワー 1000 人ぐらいだったものがもうすぐ 3000 人ぐらいになります。\n\nhttps://twitter.com/silverbirder/status/1318861346327252993\n\n## 生活\n\n### 結婚\n\n11 月 22 日、26 歳で、はじめて結婚しました。\n奥さんは、大学時代からお付き合いしていた人で、一度別れたりと紆余曲折ありましたが、私の方からプロポーズしまして、結婚することになりました。仕事を早く終わらせて、プライベートがとても充実しています。\n\n### 在宅勤務と IoT\n\nコロナの影響で、在宅勤務が当たり前になりました。今年買った IoT で良かったものを紹介します。\n\n- スマートエナジーハブ Nature Remo E lite\n  - 家の電力使用量をリアルタイムに可視化\n- NETATMO ウェザーステーション\n  - 家の室温、湿度、Co2 をリアルタイムに可視化\n- Arlo カメラ\n  - 玄関前やベランダをカメラで可視化\n- Withings Sleep&体重計\n  - 睡眠時間や体重を計測し、スマホからデータを可視化\n\n## 来年の抱負\n\nこれまでは、技術をガンガンキャッチアップしていましたが、2021 年は、技術とプライベートのバランスを取ろうと思います。\n\n## 終わりに\n\nコロナコロナと、今年は騒ぎ立てていましたが、来年はもっと楽しい話題で盛り上がりたいなと思います。","publishedAt":"2020-12-30","slug":"2020_furikaeri","title":"2020年の振り返り。結婚と継続力"},{"body":"2020 年 3 月頃からコロナが流行りだし、もう 12 月になります。働き方が大きく変わり、リモートワークが当たり前の時代となりました。\nエンジニアの働き方も同様に変わりました。そこで、今回は Cloud IDE というものを紹介しようと思います。\n\n## リモートワークと DaaS\n\nリモートワークが増えると、DaaS のようなサービスを利用する企業が増えたのではないでしょうか。\nDaaS の簡単な説明を引用しますと、次のとおりです。\n\n> DaaS とは、“Desktop as a Service”の頭文字を取った略語で「ダース」と読みます。\n> 普通ならば個人の PC にデスクトップは存在し、データは個人の PC 内に保存されていますが、DaaS においては個人のデスクトップがクラウド上に構築され、ネットワークを通じてそのデスクトップを呼び出して利用することになります。\n> ここでは、DaaS とはどういう仕組みなのかを説明し、その必要性、メリットについて詳しく述べていきます。\n> DaaS はクラウドサービスの一種で、特定のソフトウェアを端末にインストールすることなく、ネットワークを通じて利用できるという特徴があります。\n> クラウド上にあるデスクトップ環境を呼び出して利用できるため、個人の PC はディスプレイとキーボードなど必要最低限の機能があれば良いので、テレワークをするために高いスペックの PC を用意する必要はありません。\n\n※ [https://www.ascentech.co.jp/solution/column/daas.html](https://www.ascentech.co.jp/solution/column/daas.html)\n\n例えば、クラウド上で開発環境(お気に入りのエディタ, プログラミング言語, 使い慣れたツール, etc)を構築して、そこにアクセスして仕事をするようになります。アクセス元は、私物の PC や会社から支給されている PC などが多いと思います。\n\n## Cloud IDE\n\nCloud IDE は、クラウドにある統合開発環境(IDE)のことで、主にブラウザから操作できるようなものが多いです。\nざっと有名なものをリストアップしてみました。\n\n| 提供元                | IDE 名                   |\n| --------------------- | ------------------------ |\n| Microsoft Azure       | Visual Studio Codespaces |\n| Github                | Codespaces               |\n| Amazon Web Services   | Cloud9                   |\n| Google Cloud Platform | Cloud Shell Editor       |\n| Coder                 | Coder                    |\n| OSS                   | Gitpod                   |\n\nブラウザで見ると、どんな UI でしょうか。いくつか例を載せておきます。\n\n[![visual studio codespaces](https://res.cloudinary.com/silverbirder/image/upload/v1693376916/silver-birder.github.io/blog/codespaces-vs.png)](https://github.co.jp/features/codespaces)\n\n[![cloud shell editor](https://res.cloudinary.com/silverbirder/image/upload/v1693376917/silver-birder.github.io/blog/Cloud_shell_editor.max-2000x2000.png)](https://cloud.google.com/blog/ja/products/application-development/introducing-cloud-shell-editor)\n\n[![gitpod](https://res.cloudinary.com/silverbirder/image/upload/v1693376919/silver-birder.github.io/blog/gitpod-editor.jpg)](https://www.gitpod.io)\n\nCloud Shell Editor や Gitpod は、OSS の **Theia** というものを使っています。\nまた、全体的に UI がとても似ていますよね。これは、次の記事でわかりやすく説明されていますので、ご興味があればお読みください。\n\nhttps://qiita.com/monamour555/items/f93287c273a388261968\n\nこれらの Cloud IDE は、ここ最近 Publickey でよく目にします。記事と投稿日時をまとめてみました。\n\n- [https://www.publickey1.jp/blog/20/visual_studio_codeeclipse_theia_10vs_codeweb.html](https://www.publickey1.jp/blog/20/visual_studio_codeeclipse_theia_10vs_codeweb.html)\n  - 2020 年 4 月 3 日 投稿\n- [https://www.publickey1.jp/blog/20/githubwebidecodespacesgithub.html](https://www.publickey1.jp/blog/20/githubwebidecodespacesgithub.html)\n  - 2020 年 5 月 7 日 投稿\n- [https://www.publickey1.jp/blog/20/webidevisual_studio_codespaecsgithub_codespaces.html](https://www.publickey1.jp/blog/20/webidevisual_studio_codespaecsgithub_codespaces.html)\n  - 2020 年 9 月 7 日 投稿\n- [https://www.publickey1.jp/blog/20/githubgitlabwebidegitpodgithub_codespaces.html](https://www.publickey1.jp/blog/20/githubgitlabwebidegitpodgithub_codespaces.html)\n  - 2020 年 9 月 11 日 投稿\n- [https://www.publickey1.jp/blog/20/googlevscodeeclipse_theiagoogle_cloud_shell.html](https://www.publickey1.jp/blog/20/googlevscodeeclipse_theiagoogle_cloud_shell.html)\n  - 2020 年 11 月 10 日 投稿\n\n稚拙な推測ですが、リモートワークが普及し、働く環境も変化したためかなと思っています。\n物理的な PC で開発するのではなく、クラウド上にある PC で開発する、それが当たり前になるのかなと。\n\n## Theia\n\nTheia とは何か、Github の about より引用します。\n\n> Eclipse Theia is a cloud & desktop IDE framework implemented in TypeScript\n\n※ [https://github.com/eclipse-theia/theia](https://github.com/eclipse-theia/theia)\n\nこの OSS の興味深いところの 1 つに、設計書が公開されているところです。\n\nhttps://docs.google.com/document/d/1aodR1LJEF_zu7xBis2MjpHRyv7JKJzW7EWI9XRYCt48\n\nTheia は、ローカルで動かすことができます。Web アプリだけじゃなく、ネイティブアプリ(Electron)もあります。\n\nhttps://github.com/eclipse-theia/theia/blob/master/doc/Developing.md#quick-start\n\nまた、Docker コンテナも公開されています。\n\nhttps://github.com/theia-ide/theia-apps\n\nベンダーニュートラルなので、VM インスタンスに Theia を入れて独自に運用するなど、ベンダーに依存しません。\n\n## 個人的な話\n\n個人的に、Gitpod を使いたいのですが無料だと月 50 時間までしか使えません。\n\nhttps://www.gitpod.io/pricing/\n\n\"Professional Open Source\" というものを応募したところ、[Gitpod の組織](https://github.com/gitpod-io) へ招待頂き、公開リポジトリの無制限利用ができるようになりました。\n\n## Gitpod を使い続けて思うこと\n\nGitpod は、.gitpod.yml というファイルで環境構築されます。\n\nhttps://www.gitpod.io/docs/configuration/\n\nベースとなる Docker イメージを指定して、必要なライブラリを事前にインストールできたりします。\n公式ブログに、Gitpod の完全ガイドがあります。\n\nhttps://www.gitpod.io/blog/gitpodify/\n\nまた、様々な OSS を Gitpod で簡単に動作確認できます。\n\n[https://contribute.dev/](https://contribute.dev/)\n\n実際に Gitpod を使ってみると、確かに便利です。\nアクセス元の PC は、非力なノート PC でも良く、Github の Repository 毎に Gitpod のコンテナがあるため、相互に影響しません。\nただ、ネットワーク遅延でちょっと待ったり、Gitpod のショートカットキーより、ブラウザのショートカットキーが上書きされて困ることが多少あります。\n\n## 終わりに\n\nブラウザ上で開発するのって、昔からあったように思いますが、あんまり注目されていなかったのでしょうか（私が無知なだけかもしれません）。\nAWS や GCP、Github など各社が積極的に手を出しているところを見ると、これからますます期待できる分野なのだと思います。","publishedAt":"2020-12-12","slug":"cloud_ide","title":"コロナ禍におけるエンジニアのためのCloud IDE"},{"body":"ArchUnit をというものを最近知りました。依存関係のテストができるそうです。さっそく試してみたいと思いますので、その備忘録として残しておきます。\n\n## ArchUnit\n\nhttps://www.archunit.org/\n\n> ArchUnit is a free, simple and extensible library for checking the architecture of your Java code using any plain Java unit test framework. That is, ArchUnit can check dependencies between packages and classes, layers and slices, check for cyclic dependencies and more. It does so by analyzing given Java bytecode, importing all classes into a Java code structure.\n\nJava のアーキテクチャをテストできるライブラリで、パッケージやクラス、レイヤー、スライス（？）の依存関係をテストできるそうです。\nそこで、親の顔よりも見たこの図をテストしたいと思います。\n\n[![Clean Coder Blog > The Clean Architecture](https://res.cloudinary.com/silverbirder/image/upload/v1693376915/silver-birder.github.io/blog/CleanArchitecture.jpg)](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)\n\n## Typescript でも ArchUnit したい\n\nArchUnit は Java 製です。私は Typescript の ArchUnit がしたいです。\nそこで、良さげなライブラリを発見しました。\n\nhttps://github.com/MaibornWolff/ts-arch\n\n特に拘りなく、アーキテクチャのテストができれば何でも良いかなと思います。\n極端な話、ソースコードを AST パースし、依存関係を抽出できれば自作できるんじゃないかと思います。\n\n## 試してみた\n\n試したソースコードは、下記に置いています。ご参考下さい。\n\nhttps://github.com/silverbirder/try-archunit\n\n全体のソースコードツリーは次の構成です。\n\n```text\nsrc\n└ 1_enterprise_business_rules\n  └ entities\n    └ Entity.ts\n└ 2_application_business_rules\n  └ use_cases\n    └ UseCase.ts\n└ 3_interface_adapters\n  └ controllers\n    └ Controller.ts\n  └ gateways\n    └ Gateway.ts\n  └ presenters\n    └ Presenter.ts\n└ 4_frameworks_and_drivers\n  └ web\n    └ Web.ts\n└ clean_architecture.puml\n└ clean_architecture.test.ts\n```\n\n各プロダクトコードは、下の階層のファイルを import しているだけとします。\n\n```typescript\n// src/4_frameworks_and_drivers/web/Web.ts\nimport \"../../3_interface_adapters/gateways/Gateway\";\nimport \"../../3_interface_adapters/controllers/Controller\";\nimport \"../../3_interface_adapters/presenters/Presenter\";\n```\n\n```typescript\n// src/3_interface_adapters/controllers/Controller.ts\nimport \"../../2_application_business_rules/use_cases/UseCase\";\n```\n\n```typescript\n// src/2_application_business_rules/use_cases/UseCase.ts\nimport \"../../1_enterprise_business_rules/entities/Entity\";\n```\n\n```typescript\n// src/1_enterprise_business_rules/entities/Entity.ts\n```\n\n下記ファイルにある UML のコンポーネント図で依存関係を表します。\n\n```text\n## clean_architecture.puml\n@startuml\n  component [4_frameworks_and_drivers] #Blue\n  component [3_interface_adapters] #Green\n  component [2_application_business_rules] #Red\n  component [1_enterprise_business_rules] #Yellow\n\n  4_frameworks_and_drivers --> 3_interface_adapters\n  3_interface_adapters --> 2_application_business_rules\n  2_application_business_rules --> 1_enterprise_business_rules\n@enduml\n```\n\nUML を可視化すると、下記の図のとおりです。\n\n![clean_architecture.puml](https://res.cloudinary.com/silverbirder/image/upload/v1614430164/silver-birder.github.io/blog/clean_architecture.puml.png)\n\nテストコードは、下記のとおりです。\n\n```typescript\n// clean_architecture.test.ts\ndescribe(\"architecture\", () => {\n  it(\"Check dependency\", async () => {\n    const architectureUml = path.resolve(__dirname, \"clean_architecture.puml\");\n    const violations = await slicesOfProject()\n      .definedBy(\"src/(**)/\")\n      .should()\n      .adhereToDiagramInFile(architectureUml)\n      .check();\n    await expect(violations).toEqual([]);\n  });\n});\n```\n\nこのテストケースは PASS します。\n\n![src/clean_architecture.test.ts > architecture > Check dependency #Succeed](https://res.cloudinary.com/silverbirder/image/upload/v1614430233/silver-birder.github.io/blog/src_clean_architecture_test_ts_architecture_check_dependency_succeed.png)\n\nでは、違反コードを書いてみます。\n\n```typescript\n// src/3_interface_adapters/controllers/Controller.ts\nimport \"../../2_application_business_rules/use_cases/UseCase\";\nimport \"../../4_frameworks_and_drivers/web/Web\";\n```\n\n3 レイヤーが上位の 4 レイヤーを使用しています。この状態でテストを実行すると、\n\n![src/clean_architecture.test.ts > architecture > Check dependency #Failed](https://res.cloudinary.com/silverbirder/image/upload/v1614430292/silver-birder.github.io/blog/src_clean_architecture_test_ts_architecture_check_dependency_failed.png)\n\n見事 Failed となりました。つまり、依存関係の誤りを自動的に検出することができます。\n\n## 最後に\n\n規模が大きなプロジェクトほど、依存関係が複雑になりがちです。(Java でいう) パッケージやクラスの依存関係を適切に設計できていたとしても、誰かが壊しかねません。せっかく設計したのに壊されるのは、とても残念なので、テストコードで守ってあげましょう！","publishedAt":"2020-11-28","slug":"arch-unit","title":"TypescriptでArchUnitしてみた"},{"body":"## Micro Frontends とは?🤔\n\n皆さん、**Micro Fronends**(以下、MFE)をご存知でしょうか。説明をざっくりしますと、Microservices の考え方をフロントエンドまで拡張した考え方です。Microservices は、バックエンド側で適用される事例をよく耳にしますが、フロントエンドでの適用事例は、あまり聞いたことがありません。\n\n従来、Web サービス開発ではモノリスな構成からスタートします。そこから、規模が拡大するにつれて様々な理由により、フロントエンドとバックエンドの分離、バックエンドの Microservices 化が行われます。\n\n[![[翻訳記事]マイクロフロントエンド > monolith-frontback-microservices](https://micro-frontends-japanese.org/resources/monolith-frontback-microservices.png)](https://micro-frontends-japanese.org/)\n\nMicroservices 化によって、Scalability、Agility、Independency、Availability の大幅な向上が期待できます。しかし、依然フロントエンドはモノリスなままです。そこで、次の画像のように、Microservices と同様にフロントエンドも縦(専門領域)に分割します。\n\n[![[翻訳記事]マイクロフロントエンド > verticals-headline](https://micro-frontends-japanese.org/resources/verticals-headline.png)](https://micro-frontends-japanese.org/)\n\nただし、全ての Web サービスを MFE にする必要はありません。先程の説明にもあった通り、規模が拡大した際に MFE を検討する必要があるため、小・中規模の Web サービスでは時期尚早です。また、次の画像にもある通り、静的ページ(Web サイト,Web ドキュメント)や動的ページ(Web アプリ)の両極端に位置する Web サービスは MFE の適用するのには不向きです(と書いています)。両方の要素が求められる Web サービスに MFE が役立ちます。MFE の適用される Web サービス事例では、EC サイトが挙げられます。\n\n[![Microfrontends: An approach to building Scalable Web Apps](https://res.cloudinary.com/silverbirder/image/upload/v1613832627/silver-birder.github.io/blog/mfe-web-document-to-web-app.png)](https://www.linkedin.com/pulse/microfrontends-approach-building-scalable-web-apps-vinci-rufus)\n\n※ MFE という言葉は、[Micro frontends | Technology Radar | ThoughtWorks](https://www.thoughtworks.com/radar/techniques/micro-frontends) の記事より生まれたみたいです。\n※ [Micro Frontends in Action](https://www.manning.com/books/micro-frontends-in-action)にも記載されていますが、この考え方は Web サービスを対象としており、ネイティブアプリは対象としていません。\n\n## 導入企業 👨‍💼👩‍💼\n\n実績企業としては、IKEA、DAZN、Spotify などが挙げられます。他の例は、[Micro Frontends を調べたすべて](./think_micro_frontends) にリストアップしていますので、興味がある方はご覧ください。\n\n## メリット・デメリット 🔍\n\nMFE を導入することによるメリット・デメリットについて、(プロダクション導入経験無しの私が偏見で)簡単に紹介します。Microservices のメリット・デメリットと似ていると思います。\n\n私が思う最大のメリットは、**Agility**と思います。規模が中・大規模な Web サービスとなると、様々な業務ドメインが詰め込まれます。先程の MFE の例(EC サイト)でいうと、推薦(inspire)、検索(search)、商品(product)、注文(checkout)などにあたります。これらを 1 つのフロントエンドで構築すると、ドメイン設計を適切に分離できたとしても、**開発者の業務ドメイン知識が追いつかず、開発スピードが低下してしまいます**。結果、特定の開発者の属人化が加速し、ボトルネックとなります。\nそこで、それぞれ**業務ドメインを分割することで、開発者はそこだけにフォーカスできます。結果、開発スピードは維持できるはずです**。\n\n私が思う最大のデメリットは、**Independency の難しさ**だと思います。例えば、UI/UX の指針となるデザインシステムが Web サービスにあったとして、それをすべてのフロントエンドへ適用しなければいけません。そのため、全体を通した**一貫性のある UI/UX であるかどうか**の品質担保が難しいです。\n他には、あるチームのビルドツールを改善したとしても、他のチームではその恩恵を受けれなかったり、アプリケーション設計における全体共通(アクセス履歴、イベント管理、状態管理など)部分を、どうするか考える必要があります。\n\nこちら [Micro Frontends を調べたすべて#ProsCons](./think_micro_frontends#proscons) にも簡単にメリット・デメリットを書いていますので、気になる方はご覧ください。\n\n## 統合パターン 🔮\n\nMFE では、各フロントエンドのフラグメント(HTML)を、どのタイミングで統合するのかが重要です。今回はその統合パターンをざっくり紹介します。\n例えば、次の MFE の例で言えば、Team-Product、Team-Checkout、Team-Inspire の 3 つのフロントエンドフラグメント(HTML)があります。これらをどのタイミングで統合するのかがポイントです。\n\n[![[翻訳記事]マイクロフロントエンド > mfe-three-teams](https://micro-frontends-japanese.org/resources/three-teams.png)](https://micro-frontends-japanese.org/)\n\n詳しくは、[Micro Frontends を調べたすべて#統合パターン](./think_micro_frontends) をご覧ください。\n\n## ビルド時統合パターン\n\nビルド時統合とは、Web サービスを Publish する前の Build の段階で統合するパターンです。このパターンは、[bit.dev](https://bit.dev)がよく使われます。\n\n[![bit.dev](https://res.cloudinary.com/silverbirder/image/upload/v1693376955/silver-birder.github.io/blog/e74w0sjnj1r0zpzvd5xfvsk7k1bd.png)](https://bit.dev/)\n\nフラグメントを Packaging し、Packaging したライブラリを import させて build(統合)します。あとは、build した静的コンテンツを Publish させるだけになります。\n\n## サーバーサイド統合パターン\n\nサーバーサイド統合とは、Web サーバー側の HTML 構築段階で統合するパターンです。このパターンは、SSI や ESI、Podium、Tailor、Ara-Framework などが使われます。\n\n[![Server-side includes (SSI)](https://res.cloudinary.com/silverbirder/image/upload/v1693376958/silver-birder.github.io/blog/ssi1.jpg)](https://www.st-andrews.ac.uk/itsnew/web/ssi/index.shtml)\n\nフラグメントを提供するサーバーを準備し、それらからフラグメント情報を収集し、全体のページ HTML を構築します。それを SSR としてユーザーへ提供します。\n\n[![cloudflare-worker](https://res.cloudinary.com/silverbirder/image/upload/v1693376972/silver-birder.github.io/blog/overview.svg)](https://github.com/silverbirder/micro-frontends-sample-code-5)\n\nサーバーサイドのサンプルコードは、次にまとめています。\n\n- [Micro Frontends を学んだすべて](./microfrontends)\n- [Ara-Framework で Micro Frontends with SSR](./ara-framework)\n- [Zalando tailor で Micro Frontends with ( LitElement & etcetera)](./tailor)\n\nまた、サーバーサイドというより Edge での統合パターンを下記リンクで紹介しています。\n\n- [Cloudflare Workers (Edge Workers) で Micro Frontends](./cloudflare_workers_mfe)\n\n※ リッチなインタラクション UI を表現したいなら、サーバーサイドとクライアントの Hydration をする必要があります。\n\n## クライアントサイド統合パターン\n\nクライアントサイド統合とは、ブラウザ側レンダリングの段階で統合するパターンです。このパターンは、iframe や WebComponents などが使われます。\n\niframe を使ったページ(フラグメント)埋め込み、全体のページ HTML を統合させたり、WebComponents のようにカスタムエレメントを定義した HTML タグでページを構成したりします。\n\n[![Micro Frontends – The Missing Piece Of The Puzzle In Feature Teams | BlueSoft](https://res.cloudinary.com/silverbirder/image/upload/v1693376976/silver-birder.github.io/blog/Micro-Frontends-11.jpg)](https://bluesoft.com/micro-frontends-the-missing-piece-of-the-puzzle-in-feature-teams/)\n\n## 終わりに 👨‍💻👩‍💻\n\nMFE のアプローチを実際に導入した企業は、国内だとまだ比較的少なく、どういった場面で役立つのかあまり明確ではありません。また、書籍や知見も多くはないため、未知な領域と思います。\n\nただ、依然フロントエンドがモノリスな、中・大規模な Web サービスを運用するならば、特に進化が激しいフロントエンド界隈の中で、サービス提供の速度、品質を維持するのは難しいと思います。フロントエンドも Microservices 化する場面が訪れるかもしれません。そんなときに、この記事を思い出して頂ければ幸いです。\n\n※ 独り言ですが、MFE の構築アプローチとして、Edge Worker + Web Components の組み合わせが最近好みです。\n\n## 関連リンク 🔗\n\n私が書いた MFE 関連の記事です。もしよければご覧ください。\n\n- [Micro Frontends を学んだすべて](./microfrontends)\n- [Micro Frontends を調べたすべて](./think_micro_frontends)\n- [MFE 関連資料リンク集](https://github.com/silverbirder/think-micro-frontends/blob/master/research/docs/read.md)\n- [Ara-Framework で Micro Frontends with SSR](./ara-framework)\n- [Zalando tailor で Micro Frontends with ( LitElement & etcetera)](./tailor)\n- [Cloudflare Workers (Edge Workers) で Micro Frontends](./cloudflare_workers_mfe)\n- [github.com/silverbirder/micro-frontends-on-kubernetes](https://github.com/silverbirder/micro-frontends-on-kubernetes)\n- [speakerdeck.com/silverbirder/micro-frontends-on-kubernetes-trial](https://speakerdeck.com/silverbirder/micro-frontends-on-kubernetes-trial)\n- [github.com/silverbirder/think-micro-frontends](https://github.com/silverbirder/think-micro-frontends)\n- [github.com/silverbirder/micro-frontends-sample-code](https://github.com/silverbirder/micro-frontends-sample-code)\n- [github.com/silverbirder/micro-frontends-sample-code-2](https://github.com/silverbirder/micro-frontends-sample-code-2)\n- [github.com/silverbirder/micro-frontends-sample-code-3](https://github.com/silverbirder/micro-frontends-sample-code-3)\n- [github.com/silverbirder/micro-frontends-sample-code-4](https://github.com/silverbirder/micro-frontends-sample-code-4)\n- [github.com/silverbirder/micro-frontends-sample-code-5](https://github.com/silverbirder/micro-frontends-sample-code-5)","publishedAt":"2020-11-19","slug":"mfe","title":"［覚書］ Micro Frontends"},{"body":"今回、また Micro Frontends の構築を試みようと思います。構築パターンの内、サーバーサイド統合パターン、特にエッジサイド統合を試しました。\nその内容を紹介します。サンプルコードは、下記に残しています。\n\nhttps://github.com/silverbirder/micro-frontends-sample-code-5/\n\n## Edge Side Include (ESI)って\n\nhttps://www.w3.org/TR/esi-lang/\n\nESI は、SSI と似たようなもので、サーバーサイド側でコンテンツを挿入する仕組みの 1 つです。ESI の場合、挿入するコンテンツ(ページフラグメント)が Edge 側にあると理解しています。\nそのため、Edge キャッシュをコンテンツ毎に効かせれるメリットがあります。\n現状、ESI 言語仕様は W3C へ提出していますが、承認が降りていない状況です。Akamai などの CDN 企業や、Varnish などのキャッシュプロキシサーバは、ESI を一部実装しています。\n\n個人で試すのに、Akamai は金銭的に厳しいですし、varnish の VCL を記述したくない(好き嫌い)です。\nそこで、Edge Worker と呼ばれる仕組みを試そうと思います。\n\n次の引用は Akamai ブログからです。\n\n> EdgeWorkers は、世界中に分散配置された Akamai の Edge サーバー上で、カスタムしたプログラムコードを実行できるようになる新しいサービスです\n\n※ [https://blogs.akamai.com/jp/2019/10/edgeworker.html](https://blogs.akamai.com/jp/2019/10/edgeworker.html)\n\n要は、Edge Workers とは CDN が提供するプラットフォーム上で、プログラムコード、例えば Javascript などが実行できるサービスです。\n\n## Edge Workers\n\n個人で使える Edge Workers だと、[fly.io](https://fly.io)や[Cloudflare Workers](https://developers.cloudflare.com/workers/) があります。後者の Cloudflare Workers には、[HTMLRewriter](https://developers.cloudflare.com/workers/runtime-apis/html-rewriter) という HTML を書き換える機能があり、Micro Frontends に使えそうだったため、今回は Cloudflare Workers を使用します。\n\n## 構成\n\n次のような構成を考えてみました。\n\n![Cloudflare worker + Micro Frontends](https://res.cloudinary.com/silverbirder/image/upload/v1614430655/silver-birder.github.io/blog/cloudflare_worker_micro_frontends.png)\n\n※ [Podium](https://podium-lib.io/)と[Ara-Framework](https://ara-framework.github.io/website/) に影響されています。  \n※ [draw.io](https://draw.io/)の sketch style で書きました。\n\nそれぞれのブロックが Cloud Workers となります。\n\n簡単に、図の左から右の順に説明していきます。\nRouter で、Web アプリケーションのルーティングを管理します。\nルーティングでは、HTTP リクエストの内容に基づいて、どのページか振り分けます。\n振り分けられたページでは、後述するフラグメントを含めて HTML を構築します。\nその HTML を HTMLRewiter で処理し、Proxy に存在するフラグメントがあれば、フラグメントの HTML へ置換されます。\nフラグメントでは、HTML,CSS,JS を取得する PATH を JSON 形式で返却するようにします。\nJSON を返す URL は、/manifest.json と統一しています。\n\nこのような構成を取ることで、担当領域を分割することができます。\n例えば、フラグメント A とページ X をチーム 1 が管理し、フラグメント B、C、ページ Y をチーム 2 が管理するなどです。\n\nまた、Rust の WebAssembly を下記のようなテンプレートで組み込むことができます。\n\nhttps://github.com/cloudflare/rustwasm-worker-template\n\n特定の重い処理を Rust の WebAssembly で処理するようなフラグメントをページに混ぜることができます。\n\n## 構築して困ったこと\n\n## 同一ドメイン内での Edge Workers 通信が不可\n\nCloudflare Workers は、任意のドメインで動かすことになります。\n例えば、ドメイン A 内に複数の Cloudflare Workers X と Y があったとすると、\nX から Y への通信ができないです。\n\nhttps://community.cloudflare.com/t/issue-with-worker-to-worker-https-request/94472/37\n\nそのため、複数の Cloudflare Workers を使用する場合は 複数のドメインが必要になります。\n先程の例なら、ドメイン A に属する Cloudflare Workers X からドメイン B に属する Cloudflare Workers Y へ通信することができます。\n私は、freenom の tk ドメイン(無料)を複数購入しました。\n\nhttps://freenom.com/\n\n## 直接 IP アドレスへリクエストできない\n\nローカル開発時に困ったことがあります。\nCloudflare Workers をローカル開発する場合、[wrangler:dev](https://github.com/cloudflare/wrangler#-dev) というコマンドで検証します。\n検証中に、他の Cloudflare Workers の URL(localhost:XXXX)へアクセスしようとしても、直接 IP となるため失敗します。\n\nhttps://support.cloudflare.com/hc/ja/articles/360029779472-Cloudflare-1XX-%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%AE%E3%83%88%E3%83%A9%E3%83%96%E3%83%AB%E3%82%B7%E3%83%A5%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0#error1003\n\nそのため、下記のようなサービスを使って、私は解決させました。\n\nhttps://ngrok.com/\n\nhttps://github.com/localtunnel/localtunnel\n\n## Cloudflare Workers による制約が大きい\n\nCloudflare のプラットフォーム上では、下記のランタイム API が使用できます。\n\nhttps://developers.cloudflare.com/workers/runtime-apis\n\nCloudflare Workers の仕組みを把握していないのですが、この提供されている API 以外は、\n確か使えなかったような気がします。\n\n## 最後に\n\nEdge って、私の印象では、単なる静的コンテンツを置くだけのものと考えていました。\nそれが、動的なコンテンツ、つまり Edge Workers のような存在を知り、Edge の世界が広がったように感じます。\nWeb アプリケーションを、よりユーザーに近い Edge へ配置するようにすれば、レスポンス速度改善が期待できます。\n\nMicro Frontends というより、Edge Workers の話が多かったですね。(笑)","publishedAt":"2020-11-15","slug":"cloudflare_workers_mfe","title":"Cloudflare Workers (Edge Worker) で Micro Frontends"},{"body":"私は、現在 26 歳の Web エンジニアです。これまでの技術に対する学び方と、これからの技術に対する学び方について、少し考えたいと思っています。\n\n## これまでの 20 代前半\n\n新卒入社した当時の私は、業務上、PHP + MySQL on AWS の組み合わせで Web アプリケーション開発を学んでいました。\nそれとは別に、プライベートでは、Node.js + MongoDB on SAKURA レンタルサーバで Web アプリケーション開発もしていました。\n\n当時、Web アプリケーション開発のフロントエンドとバックエンドをなんとなく動かせる程度で満足していたのですが、\n先輩や同僚のエンジニアや、お勧めされた書籍から影響を受け、あらゆるものに興味を示しました。\n\n- SQL や正規表現、文字コードといったエンジニアにとって欠かせない技術\n- sed や awk, make といった shellscript の扱い方\n- 手続き型、オブジェクト指向、関数型といった考え方のパラダイムシフトを発生するような考え方\n- MVC, MVVM, CleanArchtecture などのアプリケーション設計\n- ユニットテストや E2E テストなどを使った TDD 開発\n- CI/CD を活用した DevOps 開発\n- インフラやミドルウェアの自動構築\n- CloudNative なアプリケーション開発\n- SSR や SPA、SEO といった Web 設計\n- インタプリタ言語やコンパイラ言語\n- コンポーネントベースのフロントエンド開発\n- Web ゲーム開発\n- ビッグデータを扱う技術\n- 様々なクラウドサービス技術\n- 強化学習\n- Bot 開発やスクレイプ技術、GAS などの業務改善\n\nWeb アプリケーションに関する幅広い領域をあらゆる角度で学んでいったのかなと思います。\n\n## これからの 20 代後半\n\nこれからも、興味を持った分野を見つけて、手あたり次第学んでいくのも 1 つのキャリアだと思います。\nただ、自信過剰という訳じゃないですが、多分やればある程度できるようになれると自負しています。\n\nしかし、私としては、そろそろ広く浅くから、狭く深く学ぶ領域(専門性)を見つけたいと思っています。\nどういった領域を突き詰めたいか、考える時がきたのかもしれません。\n\n## 何を突き詰めたいか\n\n単純にソフトウェア技術を突き詰め、テックリードを目指すか、\nプロジェクトマネージャーやエンジニアリングマネージャーといった管理職を目指すか。\nそれでいうと、前者を目指したい。具体的には、Web に関わる専門性を突き詰めたいなと。\nまた、アーキテクトのような職業に憧れています。\n\nVue や React など言語は違えど、Web アプリケーションの成果物はそう変わりません。\nだとすると、あまり似たようなベクトルの言語を学んだところで、面白みが薄いのではと思っています。\n\nそれよりも、どのレイヤーにどういう役割を持たせるか、クラスをどのように設計するか、レスポンス速度をより早くするためにはどのようなシステム構成にすべきなのか、そういった視点を考える方が楽しいと最近感じています。\n\nまた、アーキテクト的な視点以外に、Web の Native(標準)部分の話やブラウザの話、W3C の動向など、これからの Web についてキャッチアップし続けることにも、力を注ぎたいと思っています。\n\nそれらを踏まえると、『Web の専門性が高いアーキテクト』のような立ち位置を目指したいと思います。\n\n## 最後に\n\nポエムみたいな話になってしまいました。以上、最近の悩み事でした。","publishedAt":"2020-10-29","slug":"20_study_enginner","title":"20代後半エンジニアである私がこれから学ぶべきこと"},{"body":"エンジニアは、普段様々なところから技術をキャッチアップすると思います。それは、SNS であったり、ブログであったり、動画であったりです。\nそこで、私の技術をキャッチアップするためのアンテナの張り方について、紹介しようと思います。\n\n## RSS\n\nRSS は、良いです。不定期にお気に入りの企業やサービスのテクニカルな情報を知ることができます。\n特に、大手の企業のブログや、自分自身の関心を持っているサービスの RSS がオススメです。\n\n## Tech Blog\n\n- [airbnb-engineering](https://medium.com/feed/airbnb-engineering)\n- [blog.twitter.com](https://blog.twitter.com/engineering/en_us/blog.rss)\n- [eng.uber.com](https://eng.uber.com/feed/)\n- [engineering.atspotify.com](https://engineering.atspotify.com/feed/)\n- [engineering.fb.com](https://engineering.fb.com/feed/)\n- [engineering.linkedin.com](https://engineering.linkedin.com/blog.rss.html)\n- [github.blog](https://github.blog/feed/)\n- [instagram-engineering.com](https://instagram-engineering.com/feed)\n- [medium.engineering](https://medium.engineering/feed)\n- [netflixtechblog.com](https://netflixtechblog.com/feed)\n- [slack.engineering](https://slack.engineering/feed/)\n\n## Web\n\n- [blog.chromium.org](http://blog.chromium.org/atom.xml)\n- [blog.google/products/chrome](https://blog.google/products/chrome/rss)\n- [blog.whatwg.org](https://blog.whatwg.org/feed)\n- [discourse.wicg.io/latest](https://discourse.wicg.io/latest.rss)\n- [discourse.wicg.io/posts](https://discourse.wicg.io/posts.rss)\n- [tools.ietf.org](https://tools.ietf.org/tools/atomfeed.xml)\n- [www.w3.org](https://www.w3.org/blog/news/feed)\n\n## CDN\n\n- [blog.cloudflare.com](https://blog.cloudflare.com/rss/)\n- [www.fastly.com](https://www.fastly.com/blog_rss.xml)\n\n## BBS\n\n- [dev.to](https://dev.to/feed)\n- [hnrss.org](https://hnrss.org/newest)\n\n## Book\n\n- [www.oreilly.co.jp](https://www.oreilly.co.jp/catalog/soon.xml)\n\n## News\n\n- [feed.infoq.com](https://feed.infoq.com/jp)\n- [www.publickey1.jp](https://www.publickey1.jp/atom.xml)\n\n## Twitter\n\nTwitter の公式アカウントをフォローするのも良いです。\nまた、特定分野に長けているエンジニアの方であったり、コミュリティアカウントもフォローすると良いでしょう。\n\n例えば、私の場合は、次のアカウントをフォローしていたりします。\n\n- [https://twitter.com/naltatis](https://twitter.com/naltatis)\n  - Micro Frontends in Action の著者\n- [https://twitter.com/tech_slideshare](https://twitter.com/tech_slideshare)\n  - 日本における勉強会のスライド収集 Bot\n- [https://twitter.com/wicg\\_](https://twitter.com/wicg_)\n  - Web Incubator のコミュニティ\n\n## UseCotlin\n\n私の独自ツールです。TwitterAPI を使って、Speakerdeck や GoogleSlides などの技術スライドを Spreadsheet に収集しています。\n勉強会やカンファレンスが開催されると、Twitter で宣伝されることが多いため、こちらのツールで自動的にキャッチアップできます。\nまた、日本だけではなく、世界各国のプレゼンテーションを知ることができます。\n\n- [https://docs.google.com/spreadsheets/d/1IaJOw9-GdoHhz3D0CzvJfFitrmEN8KpgIleer9rmxiw/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1IaJOw9-GdoHhz3D0CzvJfFitrmEN8KpgIleer9rmxiw/edit?usp=sharing)\n\n## Medium\n\nMedium の有料会員です。Medium は、Tech 系の質の高い投稿が多く充実できます。\n無料会員だと、一日の閲覧回数に制限があるため、ちょっとストレスに感じ、有料会員になりました。\n\n- [https://medium.com/](https://medium.com/)\n\n## Hatena Blog\n\n今日のホットエントリを見て、何が流行りなのか、どういう分野に関心があるのかざっとななめ読みしています。\n\n- [https://b.hatena.ne.jp/hotentry/it](https://b.hatena.ne.jp/hotentry/it)\n\nまた、テクノロジだけではなく、総合分野を見ていたりします。\n\n## 最後に\n\nこのネタを思いついたので、勢いで投稿してみました。\nもしどなたかの参考になれば、幸いです。","publishedAt":"2020-10-16","slug":"tech_antena","title":"技術におけるアンテナの張り方 (巨人の肩に乗れ!)"},{"body":"Micro Frontends に関わる記事を 100 件以上読みました(参考記事に記載しています)。そこから得た Micro Frontends についてこの投稿に記録します。\nまた、調査メモについて、次のリポジトリに残しています。\n\nhttps://github.com/silverbirder/think-micro-frontends\n\n## 発端\n\nhttps://www.thoughtworks.com/radar/techniques/micro-frontends\n\n## 実績企業\n\n- Airbnb\n- Allegro\n- Amazon\n- Beamery\n- Bit.dev\n- BuzzFeed\n- CircleCI\n- DAZN\n- Elsevier\n- Entando\n- Facebook\n- Fiverr\n- Hello Fresh\n- IKEA\n- Klarna\n- Microsoft\n- Open Table\n- OpenMRS\n- Otto\n- Paypal\n- SAP\n- Sixt\n- Skyscanner\n- Smapiot\n- Spotify\n- Starbucks\n- Thalia\n- Upwork\n- Zalando\n- ZEISS\n\n## ProsCons\n\n## Pros\n\n| 観点   | 内容                                                                                                                                                                                                                                                                                                                                                                                |\n| ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 独立性 | ・任意のテクノロジーと任意のチームで開発可能 /                                                                                                                                                                                                                                                                                                                                   |\n| 展開   | ・特定の機能をエンドツーエンド(バック、フロント、デプロイ）で確実に実行可能                                                                                                                                                                                                                                                                                                         |\n| 俊敏性 | ・特定のドメインについて最高の知識を持つチーム間で作業を分散すると、リリースプロセスが確実にスピードアップして簡素化される。 / ・フロントエンドとリリースが小さいということは、リグレッションテストの表面がはるかに小さいことを意味する。リリースごとの変更は少なく、理論的にはテストに費やす時間を短縮できる。 / ・フロントエンドのアップグレード/変更にはコストが小さくなる |\n\n## Cons\n\n| 観点           | 内容                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| -------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 独立性         | ・独立できず、相互接続しているチームが存在しがち / ・多くの機能で複数のマイクロフロントエンドにまたがる変更が必要になり、独立性や自律性が低下 / ・ライブラリを共有すること自体は問題ないが、不適切な分割によって作成された任意の境界を回避するための包括的な場所として使用すると、問題が発生する。 / ・コンポーネント間の通信の構築は、実装と維持が困難であるだけでなく、コンポーネントの独立性が取り除かれる / ・横断的関心事への変更ですべてのマイクロフロントエンドを変更することは、独立性が低下する |\n| 展開           | ・より大きな機能の部分的な実装が含まれているため、個別にリリースできない / ・サイト全体の CI / CD プロセス                                                                                                                                                                                                                                                                                                                                                                                                        |\n| 俊敏性         | ・重複作業が発生する / ・検出可能性が低下した結果、一部の標準コンポーネントを共有できず、個別のフロントエンド間で実装が重複してしまう。 / ・共有キャッシュがないと、各コンポーネントは独自のデータセットをプルダウンする必要があり、大量の重複呼び出しが発生する。                                                                                                                                                                                                                                             |\n| パフォーマンス | ・マイクロフロントエンドの実装が不適切な場合、パフォーマンスが低下する可能性がある。                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n\n## 統合パターン\n\nhttps://bluesoft.com/micro-frontends-the-missing-piece-of-the-puzzle-in-feature-teams/\n\n| 統合               | 選択基準                                                                                                                    | 技術                                                                                                                               |\n| ------------------ | --------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| サーバーサイド統合 | 良好な読み込みパフォーマンスと検索エンジンのランキングがプロジェクトの優先事項であること                                    | ・Podium / ・Ara-Framework / ・Tailor / ・Micromono / ・PuzzleJS / ・namecheap/ilc                                  |\n| エッジサイド統合   | サーバーサイド統合と同じ                                                                                                    | ・Varnish EDI  / ・Edge Worker /  / CDN / ・ Akamai / ・ Cloudfront / ・ Fastly / ・CloudFlare / ・ Fly.io |\n| クライアント統合   | さまざまなチームのユーザーインターフェイスを 1 つの画面に統合する必要があるインタラクティブなアプリケーションを構築すること | ・Ajax / ・Iframe / ・Web Components / ・Luigi / ・Single-Spa / ・FrintJS / ・Hinclude / ・Mashroom           |\n| ビルド時統合       | 他の統合が非常に複雑に思われる場合に、 / 小さなプロジェクト（3 チーム以下）にのみ使用すること                            | ・ Bit.dev / ・ Open Components / ・ Piral                                                                                   |\n\n## 機能\n\n## コミュニケーション\n\nhttps://developer.mozilla.org/ja/docs/Web/API/CustomEvent\n\nhttps://github.com/postaljs/postal.js\n\n## データ共有\n\n- ストレージ\n  - URL\n  - Cookie\n  - Local Storage/Session Storage\n\n## モジュール共有\n\n- webpack\n\nhttps://webpack.js.org/concepts/module-federation/\n\nhttps://webpack.js.org/configuration/externals/\n\nhttps://webpack.js.org/plugins/dll-plugin/\n\n## ルーティング\n\nVaddin router\n\nhttps://vaadin.com/router\n\n## キャッシュ\n\nhttps://developer.mozilla.org/ja/docs/Web/API/Service_Worker_API\n\nhttps://developer.mozilla.org/ja/docs/Web/API/IndexedDB_API\n\n## 認証\n\n- JWT\n\nhttps://jwt.io/\n\n## 計測\n\n- Google Analytics\n- Navigation Timing API\n- Resource Timing API\n- High Resolution Time API\n- User Timing API\n- Frame Timing API\n- Server Timing API\n- Performance Observer\n\n### Real User Monitoring\n\n- SpeedCurve\n- Catchpoint\n- New Relic\n- Boomerang.js\n- Parfume.js\n- sitespeed.io\n\n### Synthetics Monitoring\n\n- Lighthouse\n- WebpageTest\n\n## アクセス履歴\n\nhttps://developer.mozilla.org/ja/docs/Web/API/History_API\n\n## 分割ポリシー\n\nフロントエンドを分割する方針について\n\n- 水平分割\n  - 画面内にある要素で分割\n  - ビジネス上の機能\n- 垂直分割\n  - 画面毎に分割\n\n## Web サイト ⇔Web アプリ\n\n[![Microfrontends: An approach to building Scalable Web Apps](https://res.cloudinary.com/silverbirder/image/upload/v1614412210/silver-birder.github.io/blog/microfrontends-document-application.png)](https://www.linkedin.com/pulse/microfrontends-approach-building-scalable-web-apps-vinci-rufus)\n\nマイクロフロントエンドは、かなりのオーバーラップがあるバンドの中央部分の大部分に最も適しています。バンドの両極端に該当するプロジェクトにマイクロフロントエンドアーキテクチャを実装しようとすると、生産性に反するそうです。\n\n## リポジトリ\n\n| パターン   | Pros                                                                                                         | Cons                                                                                                                                           | 技術                  |\n| ---------- | ------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------- | --------------------- |\n| モノリポ   | コードベース全体に簡単にアクセスできる。 /  (検出可能性が高い)                                            | モノリポジトリは、特に大規模なチームで作業しているときに、 / 動作が遅くなる傾向があり、バージョン管理下のコミットとファイルの数が増加する。 | ・nx.dev / ・lerna |\n| マルチリポ | ・マルチリポジトリは、非常に大規模なプロジェクトと / それに取り組む非常に大規模なチームがある場合に最適。 | マルチリポジトリ環境では、各マイクロアプリを / 個別にビルドする必要がある。                                                                 |                       |\n\n## 他アーキテクチャ\n\n| アーキテクチャ名                             | 関係リンク                                                                                                                                                                                                                                                                              |\n| -------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Modular Monolith                             | ・[Deconstructing the Monolith – Shopify Engineering](https://engineering.shopify.com/blogs/engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity) / ・[kgrzybek/modular-monolith-with-ddd](https://github.com/kgrzybek/modular-monolith-with-ddd) |\n| Enterprise Architecture (Clean Architecture) | ・[Building an Enterprise Application with Vue](https://medium.com/javascript-in-plain-english/building-vue-enterprise-application-part-0-overture-6d41bea14236) / ・[soloschenko-grigoriy/vue-vuex-ts](https://github.com/soloschenko-grigoriy/vue-vuex-ts/)                        |\n| Jam Stack                                    | [Jam Stack](https://jamstack.org/)                                                                                                                                                                                                                                                      |\n| App Shell                                    | [App Shell モデル](https://developers.google.com/web/fundamentals/architecture/app-shell?hl=ja)                                                                                                                                                                                         |\n\n## 書籍\n\nhttps://www.manning.com/books/micro-frontends-in-action\n\n## 参考記事\n\n- [https://blog.bitsrc.io/communication-between-micro-frontends-67a745c6cfbe](https://blog.bitsrc.io/communication-between-micro-frontends-67a745c6cfbe)\n- [https://medium.com/swlh/luigi-micro-fronteds-orchestrator-8c0eca710151](https://medium.com/swlh/luigi-micro-fronteds-orchestrator-8c0eca710151)\n- [https://medium.com/swlh/micro-frontends-in-action-221d4ed81c35](https://medium.com/swlh/micro-frontends-in-action-221d4ed81c35)\n- [https://medium.com/swlh/problems-with-micro-frontends-8a8fc32a7d58](https://medium.com/swlh/problems-with-micro-frontends-8a8fc32a7d58)\n- [https://levelup.gitconnected.com/podium-easy-server-side-micro-frontends-385f3a4cd346](https://levelup.gitconnected.com/podium-easy-server-side-micro-frontends-385f3a4cd346)\n- [https://levelup.gitconnected.com/micro-frontend-curry-506b98a4cfc0](https://levelup.gitconnected.com/micro-frontend-curry-506b98a4cfc0)\n- [https://medium.com/javascript-in-plain-english/demystify-micro-frontends-using-component-libraries-53aa9a33cf5b](https://medium.com/javascript-in-plain-english/demystify-micro-frontends-using-component-libraries-53aa9a33cf5b)\n- [https://medium.com/@areai51/microfrontends-an-approach-to-building-scalable-web-apps-e8678e2acdd6](https://medium.com/@areai51/microfrontends-an-approach-to-building-scalable-web-apps-e8678e2acdd6)\n- [https://medium.com/@shubhranshutiwari07/micro-frontend-microfe-is-superman-part-1-basic-understanding-architectures-21970d3fc218](https://medium.com/@shubhranshutiwari07/micro-frontend-microfe-is-superman-part-1-basic-understanding-architectures-21970d3fc218)\n- [https://medium.com/better-programming/5-steps-to-turn-a-random-react-application-into-a-micro-frontend-946718c147e7](https://medium.com/better-programming/5-steps-to-turn-a-random-react-application-into-a-micro-frontend-946718c147e7)\n- [https://medium.com/@lucamezzalira/micro-frontends-decisions-framework-ebcd22256513](https://medium.com/@lucamezzalira/micro-frontends-decisions-framework-ebcd22256513)\n- [https://medium.com/hacking-talent/two-years-of-micro-frontends-a-retrospective-522526f76df4](https://medium.com/hacking-talent/two-years-of-micro-frontends-a-retrospective-522526f76df4)\n- [https://medium.com/@sagiv.bengiat/integrate-react-with-other-applications-and-frameworks-94d443e3cc3f](https://medium.com/@sagiv.bengiat/integrate-react-with-other-applications-and-frameworks-94d443e3cc3f)\n- [https://medium.com/js-dojo/serverless-micro-frontends-using-vue-js-aws-lambda-and-hypernova-835d6f2b3bc9](https://medium.com/js-dojo/serverless-micro-frontends-using-vue-js-aws-lambda-and-hypernova-835d6f2b3bc9)\n- [https://medium.com/swlh/micro-frontend-using-web-components-e9faacfc101b](https://medium.com/swlh/micro-frontend-using-web-components-e9faacfc101b)\n- [https://medium.com/@tomsoderlund/micro-frontends-a-microservice-approach-to-front-end-web-development-f325ebdadc16](https://medium.com/@tomsoderlund/micro-frontends-a-microservice-approach-to-front-end-web-development-f325ebdadc16)\n- [https://medium.com/@PepsRyuu/micro-frontends-341defa8d1d4](https://medium.com/@PepsRyuu/micro-frontends-341defa8d1d4)\n- [https://medium.com/hepsiburadatech/hepsiburada-micro-frontend-d%C3%B6n%C3%BC%C5%9F%C3%BCm%C3%BC-4c2f26b8dcae](https://medium.com/hepsiburadatech/hepsiburada-micro-frontend-d%C3%B6n%C3%BC%C5%9F%C3%BCm%C3%BC-4c2f26b8dcae)\n- [https://medium.com/javascript-in-plain-english/create-micro-frontends-using-web-components-with-support-for-angular-and-react-2d6db18f557a](https://medium.com/javascript-in-plain-english/create-micro-frontends-using-web-components-with-support-for-angular-and-react-2d6db18f557a)\n- [https://medium.com/hackernoon/understanding-micro-frontends-b1c11585a297](https://medium.com/hackernoon/understanding-micro-frontends-b1c11585a297)\n- [https://medium.com/javascript-in-plain-english/micro-frontends-made-easy-e49acceea536](https://medium.com/javascript-in-plain-english/micro-frontends-made-easy-e49acceea536)\n- [https://itnext.io/building-micro-frontend-applications-with-angular-elements-34483da08bcb](https://itnext.io/building-micro-frontend-applications-with-angular-elements-34483da08bcb)\n- [https://blog.pragmatists.com/independent-micro-frontends-with-single-spa-library-a829012dc5be](https://blog.pragmatists.com/independent-micro-frontends-with-single-spa-library-a829012dc5be)\n- [https://blog.bitsrc.io/state-of-micro-frontends-9c0c604ed13a](https://blog.bitsrc.io/state-of-micro-frontends-9c0c604ed13a)\n- [https://medium.com/stepstone-tech/microfrontends-extending-service-oriented-architecture-to-frontend-development-part-1-120b71c87b68](https://medium.com/stepstone-tech/microfrontends-extending-service-oriented-architecture-to-frontend-development-part-1-120b71c87b68)\n- [https://medium.com/bb-tutorials-and-thoughts/6-different-ways-to-implement-micro-frontends-with-angular-298bc8d79f6b](https://medium.com/bb-tutorials-and-thoughts/6-different-ways-to-implement-micro-frontends-with-angular-298bc8d79f6b)\n- [https://medium.com/@benjamin.d.johnson/exploring-micro-frontends-87a120b3f71c](https://medium.com/@benjamin.d.johnson/exploring-micro-frontends-87a120b3f71c)\n- [https://medium.com/hacking-talent/using-micro-frontends-to-permanently-solve-the-legacy-javascript-problem-5fba18b0ceac](https://medium.com/hacking-talent/using-micro-frontends-to-permanently-solve-the-legacy-javascript-problem-5fba18b0ceac)\n- [https://medium.com/dazn-tech/micro-frontends-the-future-of-frontend-architectures-5867ceded39a](https://medium.com/dazn-tech/micro-frontends-the-future-of-frontend-architectures-5867ceded39a)\n- [https://medium.com/swlh/build-micro-frontends-using-angular-elements-the-beginners-guide-75ffeae61b58](https://medium.com/swlh/build-micro-frontends-using-angular-elements-the-beginners-guide-75ffeae61b58)\n- [https://medium.com/dazn-tech/adopting-a-micro-frontends-architecture-e283e6a3c4f3](https://medium.com/dazn-tech/adopting-a-micro-frontends-architecture-e283e6a3c4f3)\n- [https://codeburst.io/breaking-a-large-angular-app-into-microfrontends-fb8f985d549f](https://codeburst.io/breaking-a-large-angular-app-into-microfrontends-fb8f985d549f)\n- [https://medium.com/dazn-tech/orchestrating-micro-frontends-a5d2674cbf33](https://medium.com/dazn-tech/orchestrating-micro-frontends-a5d2674cbf33)\n- [https://tech.buzzfeed.com/micro-frontends-at-buzzfeed-b8754b31d178](https://tech.buzzfeed.com/micro-frontends-at-buzzfeed-b8754b31d178)\n- [https://blog.bitsrc.io/serverless-microfrontends-in-aws-999450ed3795](https://blog.bitsrc.io/serverless-microfrontends-in-aws-999450ed3795)\n- [https://medium.com/dazn-tech/identifying-micro-frontends-in-our-applications-4b4995f39257](https://medium.com/dazn-tech/identifying-micro-frontends-in-our-applications-4b4995f39257)\n- [https://medium.com/@gilfink/avoiding-the-framework-catholic-wedding-using-stencil-compiler-3c2aa55bcaca](https://medium.com/@gilfink/avoiding-the-framework-catholic-wedding-using-stencil-compiler-3c2aa55bcaca)\n- [https://medium.com/@lucamezzalira/building-micro-frontends-the-book-a2b531d0279a](https://medium.com/@lucamezzalira/building-micro-frontends-the-book-a2b531d0279a)\n- [https://blog.bitsrc.io/tools-and-practices-for-microfrontends-dab0283393f2](https://blog.bitsrc.io/tools-and-practices-for-microfrontends-dab0283393f2)\n- [https://medium.com/better-programming/thoughts-about-micro-frontends-in-2020-dd95eb7216f](https://medium.com/better-programming/thoughts-about-micro-frontends-in-2020-dd95eb7216f)\n- [https://medium.com/@rangleio/five-things-to-consider-before-choosing-micro-frontends-f685e71bdd76](https://medium.com/@rangleio/five-things-to-consider-before-choosing-micro-frontends-f685e71bdd76)\n- [https://blog.bitsrc.io/how-we-achieved-smooth-navigation-across-micro-frontends-42130577924d](https://blog.bitsrc.io/how-we-achieved-smooth-navigation-across-micro-frontends-42130577924d)\n- [https://eng.collectivehealth.com/gracefully-scaling-web-applications-with-micro-frontends-part-i-162b1e529074](https://eng.collectivehealth.com/gracefully-scaling-web-applications-with-micro-frontends-part-i-162b1e529074)\n- [https://eng.collectivehealth.com/gracefully-scaling-web-applications-with-micro-frontends-part-ii-8fa730d05b14](https://eng.collectivehealth.com/gracefully-scaling-web-applications-with-micro-frontends-part-ii-8fa730d05b14)\n- [https://medium.com/bb-tutorials-and-thoughts/should-we-frameworks-for-micro-frontends-35f9f15b7821](https://medium.com/bb-tutorials-and-thoughts/should-we-frameworks-for-micro-frontends-35f9f15b7821)\n- [https://medium.com/javascript-in-plain-english/microfrontends-bringing-javascript-frameworks-together-react-angular-vue-etc-5d401cb0072b](https://medium.com/javascript-in-plain-english/microfrontends-bringing-javascript-frameworks-together-react-angular-vue-etc-5d401cb0072b)\n- [https://medium.com/@_rchaves_/building-microfrontends-part-i-creating-small-apps-710d709b48b7](https://medium.com/@_rchaves_/building-microfrontends-part-i-creating-small-apps-710d709b48b7)\n- [https://blog.bitsrc.io/6-patterns-for-microfrontends-347ae0017ec0](https://blog.bitsrc.io/6-patterns-for-microfrontends-347ae0017ec0)\n- [https://medium.jonasbandi.net/frontend-monoliths-run-if-you-can-voxxed-day-zuerich-2019-d8d714ff361a](https://medium.jonasbandi.net/frontend-monoliths-run-if-you-can-voxxed-day-zuerich-2019-d8d714ff361a)\n- [https://medium.com/@gilfink/why-im-betting-on-web-components-and-you-should-think-about-using-them-too-8629396e27a](https://medium.com/@gilfink/why-im-betting-on-web-components-and-you-should-think-about-using-them-too-8629396e27a)\n- [https://medium.com/@ScriptedAlchemy/webpack-5-module-federation-stitching-two-simple-bundles-together-fe4e6a069716](https://medium.com/@ScriptedAlchemy/webpack-5-module-federation-stitching-two-simple-bundles-together-fe4e6a069716)\n- [https://medium.com/passionate-people/my-experience-using-micro-frontends-e99a1ad6ed32](https://medium.com/passionate-people/my-experience-using-micro-frontends-e99a1ad6ed32)\n- [https://engineering.contaazul.com/evolving-an-angularjs-application-using-microfrontends-2bbcac9c023a](https://engineering.contaazul.com/evolving-an-angularjs-application-using-microfrontends-2bbcac9c023a)\n- [https://blog.bitsrc.io/11-popular-misconceptions-about-micro-frontends-d5daecc92efb](https://blog.bitsrc.io/11-popular-misconceptions-about-micro-frontends-d5daecc92efb)\n- [https://medium.com/js-dojo/micro-frontends-using-vue-js-react-js-and-hypernova-af606a774602](https://medium.com/js-dojo/micro-frontends-using-vue-js-react-js-and-hypernova-af606a774602)\n- [https://medium.com/linedevth/micro-frontends-the-new-era-of-front-end-edge-technology-cb981ad26eae](https://medium.com/linedevth/micro-frontends-the-new-era-of-front-end-edge-technology-cb981ad26eae)\n- [https://blog.bitsrc.io/sharing-dependencies-in-micro-frontends-9da142296a2b](https://blog.bitsrc.io/sharing-dependencies-in-micro-frontends-9da142296a2b)\n- [https://medium.com/@pyaesonenyein/micro-frontends-part-one-95ea3d939bc6](https://medium.com/@pyaesonenyein/micro-frontends-part-one-95ea3d939bc6)\n- [https://medium.com/outbrain-engineering/micro-front-ends-doing-it-angular-style-part-1-219c842fd02e](https://medium.com/outbrain-engineering/micro-front-ends-doing-it-angular-style-part-1-219c842fd02e)\n- [https://levelup.gitconnected.com/brief-introduction-to-micro-frontends-architecture-ec928c587727](https://levelup.gitconnected.com/brief-introduction-to-micro-frontends-architecture-ec928c587727)\n- [https://itnext.io/prototyping-micro-frontends-d03397c5f770](https://itnext.io/prototyping-micro-frontends-d03397c5f770)\n- [https://blog.bitsrc.io/mini-web-apps-a-bounded-context-for-microfrontends-with-microservices-f1482af9276f](https://blog.bitsrc.io/mini-web-apps-a-bounded-context-for-microfrontends-with-microservices-f1482af9276f)\n- [https://medium.com/trendyol-tech/micro-frontends-how-it-changed-our-development-process-a5cf667356da](https://medium.com/trendyol-tech/micro-frontends-how-it-changed-our-development-process-a5cf667356da)\n- [https://medium.embengineering.com/micro-front-end-and-web-components-ce6ae87c3b7f](https://medium.embengineering.com/micro-front-end-and-web-components-ce6ae87c3b7f)\n- [https://medium.com/@witek1902/ui-in-microservices-world-micro-frontends-pattern-and-web-components-23607a569363](https://medium.com/@witek1902/ui-in-microservices-world-micro-frontends-pattern-and-web-components-23607a569363)\n- [https://medium.com/stepstone-tech/microfrontends-part-2-integration-and-communication-3385bc242673](https://medium.com/stepstone-tech/microfrontends-part-2-integration-and-communication-3385bc242673)\n- [https://blog.bitsrc.io/building-react-microfrontends-using-piral-c26eb206310e](https://blog.bitsrc.io/building-react-microfrontends-using-piral-c26eb206310e)\n- [https://medium.com/js-dojo/implementing-microfrontends-in-nuxt-js-using-svelte-and-ara-framework-8c06b683472c](https://medium.com/js-dojo/implementing-microfrontends-in-nuxt-js-using-svelte-and-ara-framework-8c06b683472c)\n- [https://itnext.io/implementing-microfrontends-in-gatsbyjs-using-ara-framework-a95ee79cc0e7](https://itnext.io/implementing-microfrontends-in-gatsbyjs-using-ara-framework-a95ee79cc0e7)\n- [https://itnext.io/strangling-a-monolith-to-micro-frontends-decoupling-presentation-layer-18a33ddf591b](https://itnext.io/strangling-a-monolith-to-micro-frontends-decoupling-presentation-layer-18a33ddf591b)\n- [https://itnext.io/page-building-using-micro-frontends-c13c157958c8](https://itnext.io/page-building-using-micro-frontends-c13c157958c8)\n- [https://medium.com/notonlycss/micro-frontends-architecture-1407092403d5](https://medium.com/notonlycss/micro-frontends-architecture-1407092403d5)\n- [https://medium.com/soluto-nashville/not-so-micro-frontends-building-a-reverse-proxy-f41ab5cde81c](https://medium.com/soluto-nashville/not-so-micro-frontends-building-a-reverse-proxy-f41ab5cde81c)\n- [https://medium.com/@armand1m\\_/why-micro-frontends-might-not-work-for-you-5a810b4687b0](https://medium.com/@armand1m_/why-micro-frontends-might-not-work-for-you-5a810b4687b0)\n- [https://medium.embengineering.com/micro-front-ends-webpack-manifest-b05fc63a0d53](https://medium.embengineering.com/micro-front-ends-webpack-manifest-b05fc63a0d53)\n- [https://medium.com/better-programming/you-dont-have-to-lose-optimization-for-micro-frontends-60a63d5f94fe](https://medium.com/better-programming/you-dont-have-to-lose-optimization-for-micro-frontends-60a63d5f94fe)\n- [https://medium.com/wix-engineering/3-ways-micro-frontends-could-improve-your-life-dev-velocity-and-product-97ff611881b5](https://medium.com/wix-engineering/3-ways-micro-frontends-could-improve-your-life-dev-velocity-and-product-97ff611881b5)\n- [https://medium.com/oracledevs/microservice-approach-for-web-development-micro-frontends-1cba93d85021](https://medium.com/oracledevs/microservice-approach-for-web-development-micro-frontends-1cba93d85021)\n- [https://medium.com/@miki.lombi/micro-frontends-from-the-00s-to-20s-19b37efece6d](https://medium.com/@miki.lombi/micro-frontends-from-the-00s-to-20s-19b37efece6d)\n- [https://medium.com/@soroushchehresa/deep-dive-into-the-micro-frontends-approach-c2ba1e5cd689](https://medium.com/@soroushchehresa/deep-dive-into-the-micro-frontends-approach-c2ba1e5cd689)\n- [https://medium.embengineering.com/micro-front-ends-server-side-rendering-2b515220a56e](https://medium.embengineering.com/micro-front-ends-server-side-rendering-2b515220a56e)\n- [https://medium.com/wehkamp-techblog/sharing-server-code-between-micro-sites-4f23359101e5](https://medium.com/wehkamp-techblog/sharing-server-code-between-micro-sites-4f23359101e5)\n- [https://medium.com/@mikkanthrope/sso-with-jwt-and-react-micro-frontends-811f0fcc4121](https://medium.com/@mikkanthrope/sso-with-jwt-and-react-micro-frontends-811f0fcc4121)\n- [https://itnext.io/the-micro-frontends-journey-tech-agnostic-principle-b61414b19505](https://itnext.io/the-micro-frontends-journey-tech-agnostic-principle-b61414b19505)\n- [https://medium.com/@singh.architsinghaim/micro-front-ends-dc105f5c0fea](https://medium.com/@singh.architsinghaim/micro-front-ends-dc105f5c0fea)\n- [https://medium.embengineering.com/micro-front-ends-76171c02ab17](https://medium.embengineering.com/micro-front-ends-76171c02ab17)\n- [https://medium.com/codingtown/micro-frontends-mystery-8b51b6e2f7f9](https://medium.com/codingtown/micro-frontends-mystery-8b51b6e2f7f9)\n- [https://medium.com/rangle-io/micro-frontends-and-the-rise-of-federated-applications-265171bcb346](https://medium.com/rangle-io/micro-frontends-and-the-rise-of-federated-applications-265171bcb346)\n- [https://medium.com/@felipegaiacharly/the-micro-frontends-journey-tech-agnostic-principle-b61414b19505](https://medium.com/@felipegaiacharly/the-micro-frontends-journey-tech-agnostic-principle-b61414b19505)\n- [https://medium.com/better-practices/how-postman-engineering-does-microservices-aa026a3d682d](https://medium.com/better-practices/how-postman-engineering-does-microservices-aa026a3d682d)\n- [https://medium.com/ergonode/create-your-own-vue-micro-frontend-architecture-with-vuems-library-f054233b97cb](https://medium.com/ergonode/create-your-own-vue-micro-frontend-architecture-with-vuems-library-f054233b97cb)\n- [https://blog.bitsrc.io/how-to-develop-microfrontends-using-react-step-by-step-guide-47ebb479cacd](https://blog.bitsrc.io/how-to-develop-microfrontends-using-react-step-by-step-guide-47ebb479cacd)\n- [https://medium.com/jit-team/microfrontends-should-i-care-12b871f70fa3](https://medium.com/jit-team/microfrontends-should-i-care-12b871f70fa3)\n- [https://medium.com/mailup-group-tech-blog/micro-frontends-in-the-mailup-console-82a81e712cfe](https://medium.com/mailup-group-tech-blog/micro-frontends-in-the-mailup-console-82a81e712cfe)\n- [https://towardsdatascience.com/looking-beyond-the-hype-is-modular-monolithic-software-architecture-really-dead-e386191610f8](https://towardsdatascience.com/looking-beyond-the-hype-is-modular-monolithic-software-architecture-really-dead-e386191610f8)\n- [https://medium.com/swlh/developing-and-deploying-micro-frontends-with-single-spa-c8b49f2a1b1d](https://medium.com/swlh/developing-and-deploying-micro-frontends-with-single-spa-c8b49f2a1b1d)\n- [https://levelup.gitconnected.com/easy-svelte-micro-frontends-with-podium-34aa949bed02](https://levelup.gitconnected.com/easy-svelte-micro-frontends-with-podium-34aa949bed02)\n- [https://medium.com/swlh/react-vue-svelte-on-one-page-with-micro-frontends-f740b3ee6979](https://medium.com/swlh/react-vue-svelte-on-one-page-with-micro-frontends-f740b3ee6979)\n- [https://blog.bitsrc.io/using-es-modules-with-dynamic-imports-to-implement-micro-frontends-7c840a38890e](https://blog.bitsrc.io/using-es-modules-with-dynamic-imports-to-implement-micro-frontends-7c840a38890e)\n- [https://medium.com/@jh.rossa/micro-frontend-federation-today-and-tomorrow-4eda3ab69409](https://medium.com/@jh.rossa/micro-frontend-federation-today-and-tomorrow-4eda3ab69409)\n- [https://medium.com/design-and-tech-co/modular-monoliths-a-gateway-to-microservices-946f2cbdf382](https://medium.com/design-and-tech-co/modular-monoliths-a-gateway-to-microservices-946f2cbdf382)\n- [https://medium.com/swlh/implementing-micro-frontends-using-react-8d23b7e0a687](https://medium.com/swlh/implementing-micro-frontends-using-react-8d23b7e0a687)\n- [https://medium.com/javascript-in-plain-english/javascript-monorepo-with-lerna-5729d6242302](https://medium.com/javascript-in-plain-english/javascript-monorepo-with-lerna-5729d6242302)\n- [https://levelup.gitconnected.com/a-micro-frontend-solution-for-react-1914b19663b](https://levelup.gitconnected.com/a-micro-frontend-solution-for-react-1914b19663b)\n- [https://medium.com/@lucamezzalira/i-dont-understand-micro-frontends-88f7304799a9](https://medium.com/@lucamezzalira/i-dont-understand-micro-frontends-88f7304799a9)\n- [https://floqast.com/engineering-blog/post/implementing-a-micro-frontend-architecture-with-react/](https://floqast.com/engineering-blog/post/implementing-a-micro-frontend-architecture-with-react/)\n- [https://blog.bitsrc.io/how-we-build-micro-front-ends-d3eeeac0acfc](https://blog.bitsrc.io/how-we-build-micro-front-ends-d3eeeac0acfc)\n- [https://medium.com/upwork-engineering/modernizing-upwork-with-micro-frontends-d5be5ec1d9a](https://medium.com/upwork-engineering/modernizing-upwork-with-micro-frontends-d5be5ec1d9a)\n- [https://blog.bitsrc.io/implementing-micro-front-end-with-single-spa-and-react-eeb4364100f](https://blog.bitsrc.io/implementing-micro-front-end-with-single-spa-and-react-eeb4364100f)\n- [https://www.redhat.com/en/blog/5-benefits-using-micro-frontends-build-process-driven-applications](https://www.redhat.com/en/blog/5-benefits-using-micro-frontends-build-process-driven-applications)\n- [https://medium.com/swlh/cross-app-bundling-a-different-approach-for-micro-frontends-e4f212b6a9a](https://medium.com/swlh/cross-app-bundling-a-different-approach-for-micro-frontends-e4f212b6a9a)\n- [https://www.esentri.com/composing-micro-frontends-server-side](https://www.esentri.com/composing-micro-frontends-server-side)\n- [https://dev.to/dabit3/building-micro-frontends-with-react-vue-and-single-spa-52op](https://dev.to/dabit3/building-micro-frontends-with-react-vue-and-single-spa-52op)\n- [https://dev.to/florianrappl/11-popular-misconceptions-about-micro-frontends-463p](https://dev.to/florianrappl/11-popular-misconceptions-about-micro-frontends-463p)\n- [https://dev.to/rsschouwenaar/thoughts-about-micro-frontends-in-2020-39ed](https://dev.to/rsschouwenaar/thoughts-about-micro-frontends-in-2020-39ed)\n- [https://dev.to/onerzafer/understanding-micro-frontends-1ied](https://dev.to/onerzafer/understanding-micro-frontends-1ied)\n- [https://dev.to/aregee/breaking-down-the-last-monolith-micro-frontends-hd4](https://dev.to/aregee/breaking-down-the-last-monolith-micro-frontends-hd4)\n- [https://dev.to/thejoin95/micro-frontends-from-the-00s-to-20s-5a2](https://dev.to/thejoin95/micro-frontends-from-the-00s-to-20s-5a2)\n- [https://dev.to/florianrappl/communication-between-micro-frontends-41fe](https://dev.to/florianrappl/communication-between-micro-frontends-41fe)\n- [https://dev.to/phodal/micro-frontend-architecture-in-action-4n60](https://dev.to/phodal/micro-frontend-architecture-in-action-4n60)\n- [https://dev.to/jondearaujo/the-approaches-and-challenges-of-micro-frontends-a-theoretical-introduction-176](https://dev.to/jondearaujo/the-approaches-and-challenges-of-micro-frontends-a-theoretical-introduction-176)\n- [https://dev.to/scriptedalchemy/micro-frontend-architecture-replacing-a-monolith-from-the-inside-out-3ali](https://dev.to/scriptedalchemy/micro-frontend-architecture-replacing-a-monolith-from-the-inside-out-3ali)\n- [https://dev.to/abhinavnigam2207/an-approach-to-micro-frontend-architecture-mvp-with-nextjs-2l84](https://dev.to/abhinavnigam2207/an-approach-to-micro-frontend-architecture-mvp-with-nextjs-2l84)\n- [https://dev.to/jamesmh/using-micro-uis-to-extend-legacy-web-applications-166](https://dev.to/jamesmh/using-micro-uis-to-extend-legacy-web-applications-166)\n- [https://dev.to/jonisar/11-must-know-frontend-trends-for-2020-13e1](https://dev.to/jonisar/11-must-know-frontend-trends-for-2020-13e1)\n- [https://dev.to/manfredsteyer/6-steps-to-your-angular-based-microfrontend-shell-1nei](https://dev.to/manfredsteyer/6-steps-to-your-angular-based-microfrontend-shell-1nei)\n- [https://dev.to/coroutinedispatcher/working-on-modularising-android-app-314c](https://dev.to/coroutinedispatcher/working-on-modularising-android-app-314c)\n- [https://dev.to/remast/my-software-architecture-resources-g38](https://dev.to/remast/my-software-architecture-resources-g38)\n- [https://dev.to/open-wc/open-wc-scoped-elements-3e47](https://dev.to/open-wc/open-wc-scoped-elements-3e47)\n- [https://medium.com/cdiscount-engineering/microservices-frontend-module-federation-an-handsome-promise-3b309944c215](https://medium.com/cdiscount-engineering/microservices-frontend-module-federation-an-handsome-promise-3b309944c215)\n- [https://medium.com/@infoxicator/what-is-holocron-224255625241](https://medium.com/@infoxicator/what-is-holocron-224255625241)\n- [https://medium.com/paypal-engineering/how-micro-frontend-has-changed-our-team-dynamic-ba2f01597f48](https://medium.com/paypal-engineering/how-micro-frontend-has-changed-our-team-dynamic-ba2f01597f48)\n- [https://dev.to/kleeut/how-do-you-share-authentication-in-micro-frontends-5glc](https://dev.to/kleeut/how-do-you-share-authentication-in-micro-frontends-5glc)\n- [https://github.com/ChristianUlbrich/awesome-microfrontends](https://github.com/ChristianUlbrich/awesome-microfrontends)\n- [https://github.com/rajasegar/awesome-micro-frontends](https://github.com/rajasegar/awesome-micro-frontends)\n- [https://github.com/MPankajArun/awesome-micro-frontends](https://github.com/MPankajArun/awesome-micro-frontends)\n- [https://github.com/phodal/microfrontends](https://github.com/phodal/microfrontends)\n- [https://martinfowler.com/articles/micro-frontends.html](https://martinfowler.com/articles/micro-frontends.html)\n- [https://thenewstack.io/microfrontends-the-benefits-of-microservices-for-client-side-development](https://thenewstack.io/microfrontends-the-benefits-of-microservices-for-client-side-development)\n- [https://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html](https://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html)\n- [https://engineering.hellofresh.com/front-end-microservices-at-hellofresh-23978a611b87](https://engineering.hellofresh.com/front-end-microservices-at-hellofresh-23978a611b87)\n- [http://tech.opentable.co.uk/blog/2016/04/27/opencomponents-microservices-in-the-front-end-world/](http://tech.opentable.co.uk/blog/2016/04/27/opencomponents-microservices-in-the-front-end-world/)\n- [http://tech.opentable.co.uk/blog/2015/02/09/dismantling-the-monolith-microsites-at-opentable/](http://tech.opentable.co.uk/blog/2015/02/09/dismantling-the-monolith-microsites-at-opentable/)\n- [https://medium.com/@matteofigus/5-years-of-opencomponents-3114e6d6a35b](https://medium.com/@matteofigus/5-years-of-opencomponents-3114e6d6a35b)\n- [https://blog.senacor.com/microfrontends/](https://blog.senacor.com/microfrontends/)\n- [https://www.infoq.com/news/2018/08/experiences-micro-frontends/](https://www.infoq.com/news/2018/08/experiences-micro-frontends/)\n- [https://dzone.com/articles/building-micro-frontends-with-single-spa-and-react](https://dzone.com/articles/building-micro-frontends-with-single-spa-and-react)\n- [https://www.agilechamps.com/microservices-to-micro-frontends/](https://www.agilechamps.com/microservices-to-micro-frontends/)\n- [https://gustafnk.github.io/microservice-websites/](https://gustafnk.github.io/microservice-websites/)\n- [https://hub.packtpub.com/what-micro-frontend/](https://hub.packtpub.com/what-micro-frontend/)\n- [https://www.thoughtworks.com/de/radar/techniques/micro-frontends](https://www.thoughtworks.com/de/radar/techniques/micro-frontends)\n- [http://blog.wolksoftware.com/microlibraries-the-future-of-web-development](http://blog.wolksoftware.com/microlibraries-the-future-of-web-development)\n- [https://xebia.com/blog/the-monolithic-frontend-in-the-microservices-architecture/](https://xebia.com/blog/the-monolithic-frontend-in-the-microservices-architecture/)\n- [https://x-team.com/blog/micro-frontend/](https://x-team.com/blog/micro-frontend/)\n- [https://menelaos.dev/devweek-sf-2020/](https://menelaos.dev/devweek-sf-2020/)\n- [https://www.infoq.com/news/2020/07/microfrontends-vue-yoav-yanovski/](https://www.infoq.com/news/2020/07/microfrontends-vue-yoav-yanovski/)\n- [https://www.infoq.com/articles/microfrontends-business-needs](https://www.infoq.com/articles/microfrontends-business-needs)\n- [https://www.infoq.com/articles/architecture-trends-2020/](https://www.infoq.com/articles/architecture-trends-2020/)\n- [https://www.infoq.com/news/2018/08/experiences-micro-frontends/](https://www.infoq.com/news/2018/08/experiences-micro-frontends/)\n- [https://www.infoq.com/news/2020/01/strategies-micro-frontends/](https://www.infoq.com/news/2020/01/strategies-micro-frontends/)\n- [https://speakerdeck.com/kimh/k8stotraefikdetukurumaikurohurontoendo](https://speakerdeck.com/kimh/k8stotraefikdetukurumaikurohurontoendo)","publishedAt":"2020-10-07","slug":"think_micro_frontends","title":"Micro Frontends を調べたすべて"},{"body":"Zalando 社が開発した Tailor を使って、サンプル Web アプリを Micro Frontends で構築してみました。Tailor はサーバーサイドで統合するアーキテクチャです。クライアントサイドは、Web Components で作られている Lit Element を使って統合しました。どういった内容か、ここに投稿しようと思います。\n\n作ったリポジトリは、下記に残しています。\nhttps://github.com/silverbirder/micro-frontends-sample-code-4\n\n## 全体構成\n\n![アプリケーション構成](https://res.cloudinary.com/silverbirder/image/upload/v1614430036/silver-birder.github.io/blog/tailor_and_application_configuration.png)\n\nざっくり説明すると、HTML から Tailor に対してフラグメント(コンポーネント)を取得・返却するようにします。各フラグメントは、LitElement で WebComponents を定義させた Javascript を指します。フラグメントを読み込むだけで、カスタムエレメントを使えるようになります。\n\n## Tailor\n\n![image](https://res.cloudinary.com/silverbirder/image/upload/v1693364018/silver-birder.github.io/blog/68747470733a2f2f7261776769746875622e636f6d2f7a616c616e646f2f7461696c6f722f6d61737465722f6c6f676f2f7461696c6f722d6c6f676f2e737667.svg)\n\nhttps://github.com/zalando/tailor\n\n> A streaming layout service for front-end microservices\n\ntailor は、ストリーミングレイアウトサービスというだけあって、fragment の load をストリーミングするそうです。(こちらのライブラリは、Facebook の[BigPipe](https://www.facebook.com/notes/facebook-engineering/bigpipe-pipelining-web-pages-for-high-performance/389414033919/) に影響されたそう)\n\nまず、tailor.js の HTML テンプレートは次のとおりです。\n\ntemplates/index.html\n\n```html\n<body>\n  <div id=\"outlet\"></div>\n  <fragment src=\"http://localhost:7000\" defer></fragment>\n  <fragment src=\"http://localhost:8000\" defer></fragment>\n  <fragment src=\"http://localhost:9000\" defer></fragment>\n</body>\n```\n\nこれらの fragment の取得は、tailor.js を経由します。\n\ntailor.js\n\n```javascript\nconst http = require(\"http\");\nconst Tailor = require(\"node-tailor\");\nconst tailor = new Tailor({\n  templatesPath: __dirname + \"/templates\",\n});\n\nhttp\n  .createServer((req, res) => {\n    req.headers[\"x-request-uri\"] = req.url;\n    req.url = \"/index\";\n    tailor.requestHandler(req, res);\n  })\n  .listen(8080);\n```\n\nx-request-uri は、後ろのフラグメントに URL を引き継ぐためのようです。\nそして、フラグメントサーバーは、次のとおりです。\n\nfragments.js\n\n```javascript\nconst http = require(\"http\");\nconst url = require(\"url\");\nconst fs = require(\"fs\");\n\nconst server = http.createServer((req, res) => {\n  const pathname = url.parse(req.url).pathname;\n  const jsHeader = { \"Content-Type\": \"application/javascript\" };\n  switch (pathname) {\n    case \"/public/bundle.js\":\n      res.writeHead(200, jsHeader);\n      return fs.createReadStream(\"./public/bundle.js\").pipe(res);\n    default:\n      res.writeHead(200, {\n        \"Content-Type\": \"text/html\",\n        Link: '<http://localhost:8000/public/bundle.js>; rel=\"fragment-script\"',\n      });\n      return res.end(\"\");\n  }\n});\n\nserver.listen(8000);\n```\n\nfragments.js は、Response Header に Link ヘッダを追加するようにします。Tailor は、このヘッダの Javascript を読み込むことになります。\nさらに、fragments.js は、Link ヘッダで指定されたリクエストを `return fs.createReadStream('./public/bundle.js').pipe(res)` でストリームのパイプを返すそうです。\n\n## Lerna\n\n![lerna](https://res.cloudinary.com/silverbirder/image/upload/v1614430061/silver-birder.github.io/blog/Lerna.png)\n\nそれぞれのフラグメントを Lerna で管理するようにします。\n私は、下記のような packages 分けをしました。\n\n- common\n  - 共通する変数・ライブラリ\n- fragment\n  - LitElement のカスタムエレメント定義\n- function\n  - フラグメントと連携する関数 (ヒストリーやイベントなど)\n\n具体的に言うと、次のようなものを用意しました。\n\n| directoy name                        | package name                            |\n| ------------------------------------ | --------------------------------------- |\n| packages/common-module               | @type/common-module                     |\n| packages/common-variable             | @type/common-variable                   |\n| packages/fragment-auth-components    | @auth/fragment-auth-components          |\n| packages/fragment-product-item       | @product/fragment-product-item          |\n| packages/fragment-search-box         | @search/fragment-search-box             |\n| packages/function-event-hub          | @controller/function-event-hub          |\n| packages/function-history-navigation | @controller/function-history-navigation |\n| packages/function-renderer-proxy     | @controller/function-renderer-proxy     |\n| packages/function-search-api         | @search/function-search-api             |\n| packages/function-service-worker     | @type/function-service-worker           |\n\nどの名前も、その時の気分で雑に設定したので、気にしないでください。（笑）\n伝えたいのは、@XXX が 1 チームで管理する領域みたいなことをしたかっただけです。\n\npackage を使いたい場合は、次のような依存を設定します。\n\npackage.json\n\n```json\n{\n  \"dependencies\": {\n    \"@controller/function-event-hub\": \"^0.0.0\",\n    \"@type/common-variable\": \"^0.0.0\"\n  }\n}\n```\n\n## LitElement\n\n![LitElement](https://res.cloudinary.com/silverbirder/image/upload/v1614430086/silver-birder.github.io/blog/LitElement.jpg)\n\nhttps://lit-element.polymer-project.org/\n\n> LitElement\n> A simple base class for creating fast, lightweight web components\n\n純粋な WebComponents だけを使えばよかったのですが、次のような理由で LitElement を使いました。\n\n- Typescript が書ける\n- レンダリングパフォーマンスの良い lit-html が使える\n- プロパティ変化によるレンダリング更新ができる\n\nまあ、特にこだわりはないです。\n書き方は、次のとおりです。\n\n```typescript\nimport { LitElement, html, customElement, css, property } from \"lit-element\";\n\n@customElement(\"product-item\")\nexport class ProductItem extends LitElement {\n  static styles = css`\n    :host {\n      display: block;\n      border: solid 1px gray;\n      padding: 16px;\n      max-width: 800px;\n    }\n  `;\n  @property({ type: String })\n  name = ``;\n\n  render() {\n    return html`<div>${this.name}</div>`;\n  }\n}\n\ndeclare global {\n  interface HTMLElementTagNameMap {\n    \"product-item\": ProductItem;\n  }\n}\n```\n\nLitElement + Typescript では、open-testing を使ってテストすることができます。\nhttps://github.com/PolymerLabs/lit-element-starter-ts/blob/master/src/test/my-element_test.ts\n\nまた、jest でもテストができるようです。\n\nhttps://www.ninkovic.dev/blog/2020/testing-web-components-with-jest-and-lit-element\n\n## DynamicRendering\n\n![rendertron](https://res.cloudinary.com/silverbirder/image/upload/v1614430107/silver-birder.github.io/blog/rendertron.png)\n\nこのサンプルでは、カスタムエレメントを使って、ブラウザ側でレンダリングする 所謂 SPA の動きで構築しています。\n『SEO ガー！』と SSR しなきゃと思う訳ですが、正直 SSR を考えたくないです。(ハイドレーションなんて無駄なロードをブラウザにさせたくない）\n次の記事のように、ボットのアクセスのみに、ダイナミックレンダリングした結果（SPA のレンダリング結果 HTML）を返すようにしたいです。\n\nhttps://developers.google.com/search/docs/guides/dynamic-rendering?hl=ja\n\n技術的には、次のようなものを使えば良いです。\n\nhttps://github.com/GoogleChrome/rendertron\n\nfunction-renderer-proxy/src/renderer.ts\n\n```typescript\n...\nconst page = await this.browser.newPage(); // browser: Puppeteer.Browser\n...\nconst result = await page.content() as string;  // Puppeteerのレンダリング結果コンテンツ(HTML)\n```\n\n要は、Puppeteer で実際にレンダリングさせた結果を Bot に返却しているだけです。\n\n## EventHub\n\nフラグメント同士は、CustomEvent を通して連携します。\n\nhttps://developer.mozilla.org/ja/docs/Web/Guide/Events/Creating_and_triggering_events\n\n全て、この CustomEvent と AddEventListener を管理する EventHub(packages 名)を経由するようにします。(理想)\n\n## History\n\nページ全体のヒストリーは、HistoryNavigation(packages 名)で管理したいと考えています。(理想)\n\nhttps://developer.mozilla.org/en-US/docs/Web/API/History_API\n\nまた、ルーティングを制御する Web Components 向けライブラリ vaadin/router も便利そうだったので導入してみました。\n\nhttps://vaadin.com/router\n\n## ShareModule\n\nLitElement のようなどこでも使っているライブラリは、共通化してバンドルサイズを縮めたいです。\nWebpack のようなバンドルツールには、External や DLLPlugin、ModuleFederation などの共通化機能があります。\n\nhttps://webpack.js.org/concepts/module-federation/\n\n今回は、external を使っています。\n\ncommon-module/common.js\n\n```javascript\nexports[\"rxjs\"] = require(\"rxjs\");\nexports[\"lit-element\"] = require(\"lit-element\");\nexports[\"graphql-tag\"] = require(\"graphql-tag\");\nexports[\"graphql\"] = require(\"graphql\");\nexports[\"apollo-client\"] = require(\"apollo-client\");\nexports[\"apollo-cache-inmemory\"] = require(\"apollo-cache-inmemory\");\nexports[\"apollo-link-http\"] = require(\"apollo-link-http\");\n```\n\ncommon-module/webpack.config.js\n\n```javascript\nmodule.exports = {\n  entry: \"./common.js\",\n  output: {\n    path: __dirname + \"/public\",\n    publicPath: \"http://localhost:6006/public/\",\n    filename: \"bundle.js\",\n    libraryTarget: \"amd\",\n  },\n};\n```\n\n共通化したライブラリは、次の Tailor の index.html で読み込みます。\n\ntemplates/index.html\n\n```html\n<script>\n  (function (d) {\n    require(d);\n    var arr = [\n      \"lit-element\",\n      \"rxjs\",\n      \"graphql-tag\",\n      \"apollo-client\",\n      \"apollo-cache-inmemory\",\n      \"apollo-link-http\",\n      \"graphql\",\n    ];\n    while ((i = arr.pop()))\n      (function (dep) {\n        define(dep, d, function (b) {\n          return b[dep];\n        });\n      })(i);\n  })([\"http://localhost:6006/public/bundle.js\"]);\n</script>\n```\n\nそうすると、例えば searchBox の webpack では、次のようなことが使えます。\n\nfragment-search-box/webpack.config.js\n\n```javascript\nexternals: {\n    'lit-element': 'lit-element',\n    'graphql-tag': 'graphql-tag',\n    'apollo-client': 'apollo-client',\n    'apollo-cache-inmemory': 'apollo-cache-inmemory',\n    'apollo-link-http': 'apollo-link-http',\n    'graphql': 'graphql'\n}\n```\n\n## その他\n\nその時の気分で導入したものを紹介します。(or 導入しようと考えたもの)\n\n## GraphQL\n\nAPI は、雑に GraphQL を採用しました。特に理由はありません。\n\n## SkeltonUI\n\nSkelton UI も使ってみたいなと思っていました。\n\nhttps://material-ui.com/components/skeleton/\n\nReact を使わなくても、CSS の@keyframes を使えば良いでしょう。が、まあ使っていません。(笑)\n\nhttps://developer.mozilla.org/ja/docs/Web/CSS/@keyframes\n\n## Rxjs\n\ntypescript の処理をリアクティブな雰囲気でコーディングしたかったので導入してみました。\n\n(リアクティブに詳しい人には、怒られそうな理由ですね...笑)\n\nhttps://rxjs.dev/\n\n## 所感\n\nこれまで、Podium、Ara-Framework, そして Tailor といった Micro Frontends に関わるサーバーサイド統合ライブラリを使ってみました。\n\nhttps://silverbirder.github.io/blog/contents/microfrontends\n\nhttps://silverbirder.github.io/blog/contents/ara-framework\n\nこれらは、どれも考え方が良いなと思っています。\nPodium のフラグメントのインターフェース設計、Ara-Framework の Render とデータ取得の明確な分離、そして Tailor のストリーム統合です。\nしかし、これらは良いライブラリではありますが、プロダクションとしてはあんまり採用したくない(依存したくない)と思っています。\n\nむしろ、もっと昔から使われていた Edge Side Include や Server Side Include などを使ったサーバーサイド統合の方が魅力的です。\n例えば、Edge Worker とか良さそうです。(HTTP2 や HTTP3 も気になります)\n\nまあ、まだ納得いく Micro Frontends の設計が発見できていないので、これからも検証し続けようと思います。","publishedAt":"2020-10-04","slug":"tailor","title":"Zalando tailor で Micro Frontends with ( LitElement  & etcetera)"},{"body":"みなさん、こんにちは。silverbirder です。\n私の最近の興味として、Micro Frontends があります。\n\nhttps://silverbirder.github.io/blog/contents/microfrontends\n\n今、Ara-Framework というフレームワークを使った Micro Frontends のアプローチ方法を学んでいます。\n\n## Ara-Framework とは\n\n> Build Micro-frontends easily using Airbnb Hypernova\n\n※ [https://ara-framework.github.io/website/](https://ara-framework.github.io/website/)\n\nAra-Framework は、Airbnb が開発した Hypernova というフレームワークを使って、Micro Frontends を構築します。\n\n## Airbnb Hypernova とは\n\n> A service for server-side rendering your JavaScript views\n\n※ [https://github.com/airbnb/hypernova](https://github.com/airbnb/hypernova)\n\n簡単に説明すると、Hypernova はデータを渡せばレンダリング結果(HTML)を返却してくれるライブラリです。\nこれにより、データ構築とレンダリングを明確に分離することができるメリットがあります。\n\n## Ara-Framework アーキテクチャ\n\nAra-Framework のアーキテクチャ図は、次のようなものです。\n\n![ara framework overview](https://res.cloudinary.com/silverbirder/image/upload/v1693362600/silver-birder.github.io/blog/1%2A43CBDwIZ8P2q_ZfGg_ktUQ.png)\n\n※ [https://ara-framework.github.io/website/docs/nova-architecture](https://ara-framework.github.io/website/docs/nova-architecture)\n\n構成要素は、次のとおりです。(↑ の公式ページにも説明があります)\n\n- Nova Proxy\n  - ブラウザのアクセスを Layout へプロキシします。\n  - Layout から返却された HTML をパースし、Hypernova のプレースホルダーがあれば、Nova Cluster へ問い合わせします。\n  - Nova Cluster から返却された HTML を、Hypernova のプレースホルダーに埋め込み、ブラウザへ HTML を返却します。\n- Nova Directive (Layout)\n  - 全体の HTML を構築します。Hypernova のプレースホルダーを埋め込みます。\n  - Node.js, Laravel, Jinja2 が対応しています。\n- Nova Cluster\n  - Nova Binding を管理するクラスタです。\n  - Nova Proxy と Nova Bindings の間に位置します。\n- Nova Bindings (Hypernova)\n  - データを渡されて、HTML をレンダリングした結果を返します。 (Hypernova をここで使います)\n  - React, Vue.js, Angular, Svelte, Preact が対応しています。\n\nこのように、Layout と Rendering (Nova Bindings) を明確に分けることで、独立性、スケーラビリティ性が良いのかなと感じます。\n各レイアの間にキャッシュレイヤを設けることでパフォーマンス向上も期待できます。\n\n詳しくは、公式ページをご確認下さい。\n\n## Ara-Framework サンプルコード\n\nAra-Framework を実際に使ってみました。サンプルコードは下記にあげています。\nhttps://github.com/silverbirder/micro-frontends-sample-code-2\n\npackage.json はこんな感じです。\n\npackage.json\n\n```json\n  \"scripts\": {\n    \"cluster\": \"cd cluster && PORT=5000 ara run:cluster --config ./views.json\",\n    \"layout\": \"cd layout && PORT=8080 node ./bin/www\",\n    \"proxy\": \"cd proxy && HYPERNOVA_BATCH=http://localhost:5000/batch PORT=8000 ara run:proxy --config ./nova-proxy.json\",\n    \"search:dev\": \"cd search && PORT=3000 ./node_modules/webpack/bin/webpack.js --watch --mode development\",\n    \"product:dev\": \"cd product && PORT=3001 ./node_modules/webpack/bin/webpack.js --watch --mode development\",\n    \"dev\": \"concurrently -n cluster,layout,proxy,search,product \\\"npm run cluster\\\" \\\"npm run layout\\\" \\\"npm run proxy\\\" \\\"npm run search:dev\\\" \\\"npm run product:dev\\\"\",\n  }\n```\n\n作っていく手順は、次の流れです。\n\n1. Nova Proxy を作成\n1. Nova Directive (Layout) を作成\n1. Nova Cluster を作成\n1. Nova Bindings (Hypernova) を作成\n\nAra-Framework を使うためには、次の準備をしておく必要があります。\n\n```text\nnpm i -g ara-cli\n```\n\n## Nova Proxy\n\nNova Proxy は、Nova Directive へ Proxy しますので、その host を書きます。\n\nnova-proxy.json\n\n```json\n{\n  \"locations\": [\n    {\n      \"path\": \"/\",\n      \"host\": \"http://localhost:8080\",\n      \"modifyResponse\": true\n    }\n  ]\n}\n```\n\nまた、Nova Proxy は、Nova Cluster へ問い合わせするため、`HYPERNOVA_BATCH` という変数に URL を指定する必要があります。\nNova Proxy を動かすときは、次のコマンドを実行します。\n\n```text\nHYPERNOVA_BATCH=http://localhost:5000/batch PORT=8000 ara run:proxy --config ./nova-proxy.json\n```\n\n## Nova Directive (Layout)\n\nNova Directvie は、`hypernova-handlebars-directive` を使います。\nこれは、Node.js の handlebars テンプレートエンジン(hbs)で使えます。\n\nExpress の雛形を生成します。\n\n```text\nnpx express-generator -v hbs layout\n```\n\n詳細は割愛しますが、次の HTML ファイル(hbs)を作成します。\n\n※ 詳しくはこちら [https://ara-framework.github.io/website/docs/render-on-page](https://ara-framework.github.io/website/docs/render-on-page)\n\nlayout/index.hbs\n\n```text\n<h1>{{title}}</h1>\n<p>Welcome to {{title}}</p>\n\n{{>nova name=\"Search\" data-title=title }}\n\n<script src=\"http://localhost:3000/public/client.js\"></script>\n<script src=\"http://localhost:3001/public/client.js\"></script>\n```\n\n`{{>nova}}` が Hypernova のプレースホルダーである `hypernova-handlebars-directive` です。\nname は、Nova Bindings の名前 (後ほど説明します)、data-\\*は、Nova Bindings に渡すデータです。\nまた、script で client.js を load しているのは、CSR を実現するためです。\n\n動かすのは、Express を動かすときと同じで、次になります。\n\n```text\nPORT=8080 node ./bin/www\n```\n\n## Nova Cluster\n\nNova Cluster は、Nova Bindings を管理します。\n\nviews.json\n\n```json\n{\n  \"Search\": {\n    \"server\": \"http://localhost:3000/batch\"\n  },\n  \"Product\": {\n    \"server\": \"http://localhost:3001/batch\"\n  }\n}\n```\n\nSearch や Product は、後ほど作成する Nova Bindings の名前です。server は、Nova Bindings が動いている URL です。\n\nNova Cluster を動かすときは、次のコマンドを実行します。\n\n```text\nPORT=5000 ara run:cluster --config ./views.json\n```\n\n## Nova Bindings\n\nNova Bindings を作るために、次のコマンドを実行します。\n\n```text\nara new:nova search -t react\nara new:nova product -t vue\n```\n\nそこから、自動生成されたディレクトリから、少し修正したものが次のとおりです。\n\nsearch/Search.jsx\n\n```text\nimport React, { Component } from 'react'\nimport { Nova } from 'nova-react-bridge'\n\nclass Search extends Component {\n  render() {\n      <div>\n        <div>Search Components!</div>\n        <table>\n          <tr>\n            {['🐙', '🐳', '🐊', '🐍', '🐷', '🐶', '🐯'].map((emoji, key) => {\n              return <td key={key}>\n                <Nova\n                  name=\"Product\"\n                  data={{title: emoji}}/>\n              </td>\n            })}\n          </tr>\n        </table>\n      </div>\n  }\n}\n```\n\n今までの説明ではなかったですが、Nova Bridge である `nova-react-bridge` を使っています。\nこれは、Nova Directive に似ているのですが、使えるファイルが React や Vue.js などの JS フレームワークに対応しています。\nそのため、Nuxt.js や Next.js,Gatsby.js にも使えるようになります。\n\n※ わかりにくいですが、このサンプルの Nova Bridge は、CSR で動作します。SSR で動作させるためには、Nova Proxy を挟む必要が (たぶん) あります。\n\nproduct/Product.vue\n\n```text\n<template>\n  <div>{{title}}</div>\n</template>\n\n<script>\nexport default {\n  props: ['title']\n}\n</script>\n```\n\nNova Bindings のこれらを動作させるためには、次のコマンドを実行します。\n\n```text\n## search\nPORT=3000 ./node_modules/webpack/bin/webpack.js --watch --mode development\n## product\nPORT=3001 ./node_modules/webpack/bin/webpack.js --watch --mode development\n```\n\n## 動作確認\n\n今まで紹介したものを同時に実行する必要があります。\nそこで、`concurrently` を使います。\n\n```text\nconcurrently -n cluster,layout,proxy,search,product \"npm run cluster\" \"npm run layout\" \"npm run proxy\" \"npm run search:dev\" \"npm run product:dev\"\n```\n\n動作として、次のような画像になります。\n\n![nova results](https://res.cloudinary.com/silverbirder/image/upload/v1614430832/silver-birder.github.io/blog/nova_results.png)\n\n## 最後に\n\n繰り返しますが、Ara-Framework を使うとデータ構築(Nova Directive)とレンダリング(Nova Bindings)を明確に分離できます。\nまた、レンダリング部分は、それぞれ独立できます。今回紹介していない API 部分は、誰がどのように管理するのか考える必要があります。\n\nただ、Nova Bindings で使用する CSR 用 javascript は、重複するコードが含まれてしまい、ブラウザロード時間が長くなってしまいます。\nそこで、webpack 5 から使えるようになった Federation 機能を使って解決するとった手段があります。\n\nAra-Framework の紹介でした！","publishedAt":"2020-08-23","slug":"ara-framework","title":"Ara-Framework で Micro Frontends with SSR"},{"body":"どうも、こんにちは。Re:ゼロ 2 期 始まりましたね 👏、 [@silverbirder](https://twitter.com/silverbirder) です。\n最近、仕事の関係上、Apache Beam + Kotlin を使うことになりました。それらの技術が一切知らなかったので、この記事に学んだことを書いていきます ✍️。\n\nサンプルリポジトリは、下記に載せています。\n\nhttps://github.com/silverbirder/apache-beam-kotlin-example/tree/master/src/main/kotlin\n\n## Apache Beam とは\n\nhttps://www.st-hakky-blog.com/entry/2020/04/29/172220\n\n**Batch や Streaming を 1 つのパイプライン処理** として実現できるデータパイプライン、それが Apache Beam です。(Batch + Stream → Beam)\n\n言語は、Java, Python, Go(experimental)が選べます。 また、パイプライン上で実行する環境のことをランナーと呼び、Cloud Dataflow や Apache Flink、Apache Spark などがあります。\n\n※ Streaming 処理は、サーバーの能力がボトルネックになりがちです。そこで、Cloud Dataflow という GCP のマネージドサービスを使用すると、その問題が解消されます。\n\n機械学習など豊富な **分析ライブラリ** を使いたい場合は、Python、 **型安全な** 開発をしたい場合は、Java を選べば良いかなと思います。\n\n今回は、Java を選びました。モダンな書き方ができる Kotlin でコーディングします。\n\n## セットアップ\n\nソフトウェアバージョンは、次のとおりです。\n\n```shell\njava -version\nopenjdk version \"1.8.0_252\"\nOpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_252-b09)\nOpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.252-b09, mixed mode)\n```\n\nIDE として intelliJ を使用しており、Kotlin SDK(1.3.72)が内蔵しています。\n\n```shell\ngit clone https://github.com/silverbirder/apache-beam-kotlin-example.git && cd apache-beam-kotlin-example\n./gradlew build\n```\n\n## パイプライン処理の概要\n\n```shell\n1. データの入力する(input → PCollection)\n2. 入力されたデータを変形させる (PCollection → PTransform → PCollection)\n3. 加工したデータを出力する (PCollection → output)\n```\n\nPCollection は、ひとかたまりのデータセットだと思って下さい。\n\nよくあるサンプルコード [WordCount](https://github.com/silverbirder/apache-beam-kotlin-example/blob/master/src/main/kotlin/WordCount.kt) を例に進めます。\n\n※ 元々は、[ApacheBeam 公式の WordCount](https://github.com/apache/beam/blob/master/examples/kotlin/src/main/java/org/apache/beam/examples/kotlin/WordCount.kt)があったのですが、ローカルマシン単体で動かせないため、多少アレンジしました。WordCount は、ある文章から単語を抽出しカウントを取るだけです。\n\nメインのコードは、こちらです。動かすときは、IDE からデバッグ実行します。（この辺りは省略します。詳しくは Makefile を見て下さい 🙇‍♂️）\n\n```kotlin\n@JvmStatic\nfun main(args: Array<String>) {\n    val options = (PipelineOptionsFactory.fromArgs(*args).withValidation().`as`(WordCountOptions::class.java))\n    runWordCount(options)\n}\n\n@JvmStatic\nfun runWordCount(options: WordCountOptions) {\n    // パイプラインを作る（空っぽ）\n    val p = Pipeline.create(options)\n\n         // Textファイルからデータを入力する → PCollection\n        p.apply(\"ReadLines\", TextIO.read().from(options.inputFile))\n\n        // PCollectionをPTransformで変形させる\n        .apply(CountWords())\n        .apply(MapElements.via(FormatAsTextFn()))\n\n        // Textファイルにデータ(PCollection)を出力する\n        .apply<PDone>(\"WriteCounts\", TextIO.write().to(options.output))\n\n    // パイプラインを実行する\n    p.run().waitUntilFinish()\n}\n```\n\n## PTransform\n\nApache Beam のコアとなる PTransform についてサンプルコードを載せます。\n\n## ParDo\n\nParDo は、PCollection を好きなように加工することができます。\n最も、柔軟に処理を書くことができます。\n\n```kotlin\n    // PTransformによる変形処理\n    public class CountWords : PTransform<PCollection<String>, PCollection<KV<String, Long>>>() {\n        override fun expand(lines: PCollection<String>): PCollection<KV<String, Long>> {\n\n            // 文章を単語に分割する\n            val words = lines.apply(ParDo.of(ExtractWordsFn()))\n\n            // 分割された単語をカウントする\n            val wordCounts = words.apply(Count.perElement())\n            return wordCounts\n        }\n    }\n\n    public class ExtractWordsFn : DoFn<String, String>() {\n        @ProcessElement\n        fun processElement(@Element element: String, receiver: DoFn.OutputReceiver<String>) {\n        ...\n    }\n```\n\n## GroupByKey\n\nKey-Value(KV)の PCollection を Key でグルーピングします。\n\n```kotlin\nimport java.lang.Iterable as JavaIterable\n\n// PCollection<KV<String, Long>>\nval wordCounts = words.apply(Count.perElement())\n\n// PCollection<KV<String, JavaIterable<Long>>>\nval groupByWord = wordCounts.apply(GroupByKey.create<String, Long>()) as PCollection<KV<String, JavaIterable<Long>>>\n```\n\nKotlin では、Iterable が動作できないため、Java の Iterable を使う必要があります。\n\n## Flatten\n\n複数の PCollection を 1 つの PCollection に結合します。\n\n```kotlin\n// PCollection<KV<String, Long>>\nval wordCounts = words.apply(Count.perElement())\n\n// PCollectionList<KV<String, Long>>\nval wordCountsDouble = PCollectionList.of(wordCounts).and(wordCounts)\n\n// PCollection<KV<String, Long>>\nval flattenWordCount = wordCountsDouble.apply(Flatten.pCollections())\n```\n\n## Combine\n\nPCollection の要素を結合します。\nGroupByKey の Key 毎に要素を結合する方法と、PCollection 毎に要素を結合する方法があります。\n今回は、GroupByKey のサンプルコードです。\n\n```kotlin\n// PCollection<KV<String, Long>>\nval wordCounts = words.apply(Count.perElement())\n\n// PCollection<KV<String, Long>>\nval sumWordsByKey = wordCounts.apply(Sum.longsPerKey())\n```\n\n## Partition\n\nPCollection を任意の数でパーティション分割します。\n\n```kotlin\n// PCollection<KV<String, Long>>\nval wordCounts = words.apply(Count.perElement())\n\n// PCollection<KV<String, Long>>\nvar 10wordCounts = wordCounts.apply(Partition.of(10, PartitionFunc()))\n```\n\n## Streaming と Windowing\n\nパイプラインを、そのまま使えば Batch 実行となります。\nBatch は、有限のデータに対し、Streaming は無限のデータに対して使います。\n無限のデータを処理するのは、Windowing というものを使い、無限を有限のデータにカットして、処理します。\n\nStreaming 処理するためには、下記のようにコードにします。\n\n```kotlin\n    @JvmStatic\n    fun main(args: Array<String>) {\n        val options = (PipelineOptionsFactory.fromArgs(*args).withValidation().`as`(WordCountOptions::class.java))\n        runWordCount(options)\n    }\n\n    @JvmStatic\n    fun runWordCount(options: WordCountOptions) {\n        val p = Pipeline.create(options)\n        p.apply(\"ReadLines\",\n                        TextIO\n                        .read()\n                        .from(\"./src/main/kotlin/*.json\")\n                        // fromで指定したファイルがないか監視する。(入力値は無限)\n                        //  10秒ごとに監視、5分間変更がなければ終了。\n                        .watchForNewFiles(standardSeconds(10), afterTimeSinceNewOutput(standardMinutes(5)))\n             )\n\n            // 30秒間毎にWindowingする。（無限のデータを、有限のデータにカットする）\n            .apply(Window.into<String>(FixedWindows.of(standardSeconds(30))))\n            .apply(CountWords())\n            .apply(MapElements.via(FormatAsTextFn()))\n            .apply<PDone>(\"WriteCounts\", TextIO.write().to(options.output).withWindowedWrites().withNumShards(1))\n        p.run().waitUntilFinish()\n    }\n```\n\n## テストコード\n\nApache Beam もテストコードが書けます。\nサンプルコードは、[こちら](https://github.com/silverbirder/apache-beam-kotlin-example/blob/master/src/test/kotlin/WordCountTest.kt)です。\n\n実行するパイプラインを TestPipeline にすることで、テストができます。\n\n```kotlin\nimport org.apache.beam.sdk.testing.TestPipeline\n\nfun countWordsTest() {\n        // Arrange\n        val p: Pipeline = TestPipeline.create().enableAbandonedNodeEnforcement(false)\n        val input: PCollection<String> = p.apply(Create.of(WORDS)).setCoder(StringUtf8Coder.of())\n        val output: PCollection<KV<String, Long>>? = input.apply(CountWords())\n\n        // Act\n        p.run()\n\n        // Assert\n        PAssert.that<KV<String, Long>>(output).containsInAnyOrder(COUNTS_ARRAY)\n    }\n\n    companion object {\n        val WORDS: List<String> = listOf(\n            \"hi there\", \"hi\", \"hi sue bob\",\n            \"hi sue\", \"\", \"bob hi\"\n        )\n        val COUNTS_ARRAY = listOf(\n            KV.of(\"hi\", 5L),\n            KV.of(\"there\", 2L),\n            KV.of(\"sue\", 2L),\n            KV.of(\"bob\", 2L)\n        )\n    }\n```\n\n## 終わりに\n\nApache Beam は、他にも Side input や Additional outputs などがあります。\n使いこなせるためにも、これからも頑張っていきます！\n\nさて、Re:ゼロ 2 期を見ましょう 👍","publishedAt":"2020-07-10","slug":"apache-beam-kotlin","title":"Apache Beam + Kotlin 開発 実践入門"},{"body":"最近、Property Based Test という言葉を知りました。\n他にどういうテストの種類があるのか気になったので、調べてみました。\n本記事は、テストの種類を列挙します。\n※ 使用する技術は、私の都合上、node.js で選んでいます。\n\n## テスト観点一覧\n\n## Cache Test\n\nWeb アプリでは、様々な Cache が使われます。\n例えば、ブラウザ Cache、CDN Cache、プロキシ Cache、バックエンド Cache などなどです。\nCache は、便利な反面、使いすぎると、どこがどう Cache しているのか迷子になってしまいます。\nWeb アプリでも、Cache をテストする必要がありそうです。\n\nhttps://github.com/http-tests/cache-tests\n\n## Code Size Test\n\n大きなサイズの JS ライブラリを読み込むと、レスポンスタイムが悪化してしまいます。そこで、常にコードサイズを計測する必要があります。\n\nhttps://github.com/ai/size-limit\n\n[![https://github.com/ai/size-limit](https://res.cloudinary.com/silverbirder/image/upload/v1614429908/silver-birder.github.io/blog/size-limit.png)](https://github.com/ai/size-limit)\n\n## Complexity Test\n\n循環的複雑度(Cyclomatic complexity)は、制御文(if や for)の複雑さを計測します。\n複雑なコードは、バグの温床になりがちなので、極力シンプルなコードを心がけたいところです。\n\nhttps://eslint.org/docs/rules/complexity\n\n## Copy&Paste Test\n\nCopy&Paste は、DRY の原則に反するため、特別な理由がない限りは、してはいけません。Copy&Paste を検出するツールがあるみたいです。\n\nhttps://github.com/kucherenko/jscpd\n\n[![jscpd](https://res.cloudinary.com/silverbirder/image/upload/v1614429933/silver-birder.github.io/blog/jscpd.png)](https://github.com/kucherenko/jscpd)\n\n## Cross Browser/Platform Test\n\nサポートするブラウザや、プラットフォーム(iOS,Android,Desktop など)の動作検証が必要です。\nそのため、サポートするブラウザやプラットフォームの環境を準備しなければなりません。\nそういう環境を手軽に使えるサービスがあったりします。\n\nhttps://github.com/browserstack\n\n## E2E Test\n\nWeb アプリを、端から端まで (End To End: E2E)を検証します。\n例えば、ユーザーが Web アプリを訪れて、クリックや入力するなど、使ってみることです。\nこのテストは、不安定なテスト(よく失敗する)になりがちなので、安定稼働できるような取り組みが必要です。\n例えば、操作する処理の抽象化や、データ固定などです。\n\nhttps://github.com/cypress-io/cypress\n\n## Exception Test\n\n正常系、準正常系、異常系などのテストが必要です。\n準正常系は、システムが意図的にエラーとしているものです。例えば、フォーム入力値エラーとかです。\n異常系は、システムが意図せずエラーとなるものです。例えば、Timeout エラーとかです。\n\nまた、Java が得意な人なら知っているであろう、検査例外や非検査例外という例外の扱い方があります。\n基本的には検査例外はエラーハンドリングし、非検査例外はエラーハンドリングしない方針が良いです。\n\n## Flaky Test\n\n不安定なテストのことを指します。これに対するアプローチ方法の１つに、Google 社の資料があります。\n\n[https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45880.pdf](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45880.pdf)\n\n日本人がまとめて頂いたものが、次の資料です。\nhttps://speakerdeck.com/nihonbuson/flakytests\n\n## Integration Test\n\nIntegration Test は、Unit Test のような単一機能を統合した検証になります。\n定義によりますが、私は『Unit Test では発見できないようなもの』かなと思います。\nUnit Test でカバーできていなくても、他のテストで検証できていれば、Integration Test は不要になります。\n\n## Logging Test\n\nログ出力が適切なレベルで出力されているか検証する必要があります。\nINFO, WARN, ERROR などがルールに基づいて使い分けされているか気になります。\nログを出すことができるかどうかは、ログライブラリの検証になりますので、必要ないかもしれませんが、\n意図したタイミングで、意図したログレベルで、意図したメッセージが出力されるかは、テストしても良いと思います。\n\n## Monkey Test\n\nお猿さんがランダムにテストするような、モンキーテストです。\nテストのパターン網羅が難しい場合や、パターン網羅できているけどダメ押しで、このテストをします。\n\nhttps://github.com/marmelab/gremlins.js/\n\n[![gremlins.js](https://res.cloudinary.com/silverbirder/image/upload/v1614429752/silver-birder.github.io/blog/gremlins.gif)](https://github.com/marmelab/gremlins.js)\n\n## Multi Tenanct Test\n\nマルチテナントは、企業者（利用者）毎に区別した、同一のシステムを提供する方式です。\nこれは、企業毎にサブドメインを分けたりするため、その環境毎のテストが必要になります。\n\n## Mutation Test\n\nテストを検証するため、突然変異テストというものがあります。\nプロダクトコードを破壊することで、テストも壊れるかどうかを検証します。\nもし、プロダクトコードを壊しても、テストが成功してしまうと、それは正しくテストできていません。\n\nhttps://github.com/stryker-mutator/stryker\n\n[![https://stryker-mutator.io/stryker/quickstart](https://res.cloudinary.com/silverbirder/image/upload/v1614429792/silver-birder.github.io/blog/stryker-mutator.gif)](https://stryker-mutator.io/stryker/quickstart)\n\n## Chaos Test\n\n障害を注入した際に、どういった動きになるのかを検証するテストです。\n\nhttps://github.com/goldbergyoni/node-chaos-monkey\n\n## Performance Test\n\nパフォーマンスと言っても、\nCPU 使用率、メモリ使用率、レスポンスタイム、RPS など様々な指標があります。\nこれらを計測し、SLO などの基準値を満たせているかを検証しておく必要があります。\n\nhttps://github.com/bestiejs/benchmark.js/\n\n## Property Based Test\n\nデータを半自動生成し、テストをする手法です。\n\nhttps://github.com/dubzzz/fast-check\n\n## Regression Test\n\nRegression Test は、修正した内容が意図せず他の箇所に影響を及ぼしていないか(デグレーション)を確認するテストです。\nこのテストは幅広い意味を持つので、ここに内容されるテスト種類は多いと思います。\n\n## Robustness Test\n\nWeb アプリは、ロバストであるべきです。\n何かしら Web アプリ内で障害が発生したとしても、最低限のサービスだけでも提供するのが好まれます。\nもちろん、その際の HTTP ステータスを 200 にせず、障害にあったステータスを返しましょう。\n\n## Security Test\n\nセキュリティのテストは、どんな Web アプリでも必須になります。\nセキュリティの専門家ではないので、どういうテストが必要なのかは、ここでは割愛します。\n\n依存するパッケージ脆弱性検査には、下記のコマンドが有効です。\n\n```text\nnpm audit fix\n```\n\n## SEO Test\n\nWeb アプリへ流入数を改善するためには、SEO は不可欠です。\nlighthouse というツールで SEO スコアを見ることができるみたいです。\n\nhttps://github.com/GoogleChrome/lighthouse-ci\n\n[![https://github.com/GoogleChrome/lighthouse-ci](https://res.cloudinary.com/silverbirder/image/upload/v1614429818/silver-birder.github.io/blog/lighthouse-ci.png)](https://github.com/GoogleChrome/lighthouse-ci)\n\n## Smoke Test\n\nSmoke Test は、Web アプリが最低限動作するために必要なケースを確保する検証です。\n例えば、トップページへリクエストしたら、レスポンスが HTTP 200 で返却されるとかです。\n\nこの最低限の動作保証がなければ、これ以上の詳細なテストができません。\n個人的には、Smoke Test → E2E Test の順で進むのかなと思っています。\n\n## Snapshot Test\n\nWeb アプリへリクエストし、そのレスポンスである HTML(スナップショット)を保存します。\nこの HTML が、変更前と比較して変化がないかの検証をするのが、Snapshot test です。\nリファクタリングなど、変化がない修正に対して有効です。\n\nhttps://jestjs.io/docs/ja/snapshot-testing\n\n## Static Test\n\nStatic Test は、Web アプリを動かさなくても検証できるテストです。\nよくあるのが、Linter です。\n\n- HTML\n  https://github.com/htmlhint/HTMLHint\n\n- CSS\n\nhttps://github.com/CSSLint/csslint\n\n- JS\n\nhttps://github.com/eslint/eslint\n\n- SVG\n\nhttps://github.com/birjolaxew/svglint\n\n- Commit\n\nhttps://github.com/conventional-changelog/commitlint\n\n- Docker\n\nhttps://github.com/RedCoolBeans/dockerlint/\n\nこれらは、プルリクエストで機械的に指摘する Danger との相性が良いです。\n\nhttps://github.com/danger/danger\n\n## Unit Test\n\n単一機能をテストする Unit Test があります。この Unit Test が全て PASS したら、\n他のテストを進めるのが一般的かなと思います。\n\nhttps://github.com/facebook/jest\n\n### Code Coverage\n\nUnit テストで、どこをテストできたかのカバレッジを見ることができます。\n感覚としては、全体の 8 割を満たしていれば良いかなと思います。\n\n[https://jestjs.io/docs/en/cli.html#--coverageboolean](https://jestjs.io/docs/en/cli.html#--coverageboolean)\n\n実際に動作している JS や CSS のカバレッジを収集することもできます。\n\nhttps://speakerdeck.com/pirosikick/puppeteerdeiranaicsswoxiao-su\n\nhttps://gist.github.com/silverbirder/71135913192fbca51a7e26924bd36b8b\n\n## Visual Regression Test\n\n見た目の変化を監視する必要があります。例えば、リンク切れとかがあれば、検出するべきです。\n\nhttps://github.com/garris/BackstopJS\n\n[![https://github.com/garris/BackstopJS](https://res.cloudinary.com/silverbirder/image/upload/v1614429842/silver-birder.github.io/blog/BackstopJS.png)](https://github.com/garris/BackstopJS)\n\n## 最後に\n\nどういうテストの観点があるのか、調べたり、経験則よりざっと書いてみました。\n全てをテストする必要はなく、『どういう動作の品質を担保したいか』を意識して、\n取捨選択するのが良いと思います。\n最後まで読んでいただき、ありがとございます。","publishedAt":"2020-06-18","slug":"testing_pattern","title":"Webアプリのテスト観点を調べてまとめてみた (25選)"},{"body":"みなさん、Zoom 使っていますか？\nZoom の Meeting を自動生成する GAS ライブラリを公開しましたので、\nそのきっかけと使い方について紹介しようと思います。\n\n## きっかけ\n\n社の Slack で次の qiita の記事を知りました。\n\nhttps://qiita.com/kudota/items/b480610cc3f575a8ec6f\n\nGAS から Zoom の Meeting を作れるのって、簡単なんだな〜と思いつつ、\n\"cron のように使いたい\"という Slack のコメントがあったので、サクッと一日で作ってみました。\n\n定期的に Zoom の Meeting(ID やパスワード)を更新する会社はあるはずです。\nそういう会社にとっては、このツールは、便利かもしれません。\n\n## 作ったもの\n\nhttps://github.com/silverbirder/zoom-meeting-creator\n\nこれを GAS 側でライブラリ追加すると使えます。\nこの GAS では、\n\n- Zoom の Meeting を作成\n- Slack との連携\n\nができます。この機能を、GAS の定期実行を組み合わせれば、\"Zoom の Meeting 作成を cron のように\"使えるようになります。","publishedAt":"2020-06-06","slug":"zoom-meeting-creator","title":"ZoomのMeetingを自動生成するGASライブラリ zoom-meeting-creator を作った"},{"body":"Google や Github など、様々なサービスのプロフィール情報(画像, etc)を一括更新するツール、puppeteer-account-manager を開発しました。\n開発の目的や、開発から得た知見を紹介します。\n\nリポジトリは、こちらです。\n\nhttps://github.com/silverbirder/puppeteer-account-manager\n\n## なんで作ったの\n\nGithub や Twitter、Facebook など、Web サービスにはプロフィール画像を登録することができます。\n私の性格上、どのサービスでも、同じ画像で登録したいと考えています。\n\nそのため、いい感じのプロフィール写真を手に入れたら、全サービスのプロフィール画像を再登録しないと気がすまなくなり、とても面倒です。\nそこで、今回、その面倒さを解決したく、このツールを作りました。\n\n## それ、Gravatar で良くない\n\n今回の面倒さは、Gravatar という Web サービスで解決できるかもしれません。\n\nhttp://gravatar.com/\n\nこのサービスは、グローバルなプロフィール画像を提供するサービスです。\nAPI 経由で、プロフィール画像を取得できます。\n\nしかし、次の問題があったので、却下となりました。\n\n- gravatar が提供するプロフィール画像サイズは 80px × 80px\n  - サービスによっては、小さすぎる\n    - 画像サイズを拡大することができるが、画質がよくない\n- gravatar が提供するプロフィール項目が固定\n  - 画像だけではなく、プロフィール項目も一括登録したかった\n    - サービスによっては、プロフィール項目がマッチしない\n\nそこで、Contentful という API ベースの CMS を使うことにしました。\n\nhttps://www.contentful.com/\n\nContentful では、自由に項目を決めることができます。\n独自に作った項目 (画像や紹介文)を、API 経由で取得できるため、とても便利です。\n\n## どうやって作ったの\n\n愚直なやり方です。\nPuppeteer と呼ばれる Chrome ブラウザを自動操作できるライブラリを使いました。\nChrome ブラウザから、\"各サービスへログインし、写真をアップロードする\"処理を自動化しただけです。\n\nhttps://github.com/puppeteer/puppeteer\n\n## プロフィール画像を更新する API は、なかったの\n\nサービスによってはあります。例えば、Twitter には、次のようなプロフィール画像を更新する API があります。\n\nhttps://developer.twitter.com/en/docs/accounts-and-users/manage-account-settings/api-reference/post-account-update_profile_image\n\nただ、全てのサービスには、そのような API はありません。\nAPI を使って更新するのが正しい姿ですが、全サービスの実装方法の足並みを揃えるために、\nPuppeteer で自動操作することにしました。\n\n## パスワードって大丈夫\n\nPuppeteer を動かす node アプリケーションと、Chrome ブラウザを同一マシン内で動作するようにしました。\nそのため、node アプリケーション実行中に、パスワードを傍受されることはありません。\nまた、パスワードの設定は環境変数から注入するようにしています。\nDocker コンテナで動作できるようにしているので、ローカルでも、コンテナサービスでも動かすことができます。\n\n今後、パスワードの管理は、Keepass や Lastpass のようなサービスと連携したいと思っています。\n\nhttps://github.com/keeweb/kdbxweb\n\n## どのサービスが対応している\n\nこれは、私が楽になりたいために作ったため、使い方が、限定的になっています。\n\n| サービス名 | 認証手段     |\n| ---------- | ------------ |\n| Hatena     | Google 認証  |\n| Qiita      | Google 認証  |\n| Medium     | Google 認証  |\n| Note       | Twitter 認証 |\n| devTo      | Github 認証  |\n| Twitter    | 通常認証     |\n| Github     | 通常認証     |\n| Google     | 通常認証     |\n| Facebook   | 通常認証     |\n| LinkedIn   | 通常認証     |\n\n詳しくは、\n\n[https://github.com/silverbirder/puppeteer-account-manager/blob/master/src/index.ts](https://github.com/silverbirder/puppeteer-account-manager/blob/master/src/index.ts) をご確認下さい。\n\n## どんな学びがあった\n\n結構色々とハマりました。\n\n## 極力 セレクタ指定したコードを書かない\n\nWeb サービスが返す HTML は、いつもずっと変わらないことはありません。\nある id や class の html タグがずっと残り続けるとは限りません。\n\nそこで、できる限り、セレクタを指定せずにブラウザ操作をするようにしました。\n例えば、\n\n- ボタンやリンクをクリックしてページ遷移するのではなく、目的のページへ最短で直接遷移する\n  - [https://medium.com/me](https://medium.com/me) とか。\n- submit ボタンをクリックするのではなく、エンターキーを入力する\n\nです。こうすることで、安定した自動化ができました。\n\n## XPath が意外と使える\n\nGoogle や Medium では、id や class がランダム値になっています。\nそのため、単純な id や class を指定して進めることができません。\n\nそこで、『○○』のテキストが含まれているセレクタの指定することが、XPath でできます。\nこれは、助かりました。\n\n## ログインが難しいものは、無理せず諦める\n\nAmazon のログインは、2 段階認証が発生します。\nテキストメッセージや、音声電話によるログインが求められ、Puppeteer 単体ではどうしようもありません。\n\nこの 2 段階認証の機能を解除することもできますが、セキュリティ上よろしくないので、ここは無理せず諦めることにしました。\n\n## 並列処理をガンガン実行する\n\n処理速度向上のため、全サービスを Promise.all で並列処理しました。それぞれが、シークレットウィンドウで開くことで、独立して処理するようにもしました。\nしかし、たまに Puppeteer が落ちてしまうことがあります。原因は、実行しているマシンのスペック(Core 数)にも影響しますが、サービス側からの影響も受けたりします。\nそのため、落ちても大丈夫のようにエラーハンドリングし、リトライするようにしました。\n\nまた、失敗したらどういった画面なのか知りたいので、スクリーンショットを撮るようにもしました。\n\n## Docker で実行可能に\n\nPuppeteer に必要なモジュールを Docker に詰め込み、ログイン情報等を環境変数から外注することで、\n環境非依存の実行環境ができました。そのため、Pub/Sub と Container Engine 等を組み合わせれば、\nContentful の Webfook 経由で、アカウント情報を更新することができます。\n\n## 終わりに\n\n私の性格がもっと大雑把であれば、このツールを作らなかったのですが、どうしても気になって仕方がなく... (笑)\n最後まで読んでいただき、ありがとうございました。","publishedAt":"2020-06-04","slug":"puppeteer_account_manager","title":"アカウント画像一括更新ツールを作ったので、紹介と学びについて"},{"body":"Micro Frontends という Web フロントエンドアーキテクチャがあります。\nこのアーキテクチャを知るために、書籍を読み、簡単なサンプル Web アプリを開発しました。\nそこから学んだことをすべて議事録として残したいと思います。\n\n## モノリシックな Web アプリケーション\n\nマイクロサービスという考え方の多くは、バックエンドへ適用されることが一般的です。\n一方で、フロントエンドは依然モノリシックなままの状態です。\n\nEC サイトのような Web アプリケーションでは、様々な専門知識(商品、注文、検索など)を必要とし、フロントエンド開発者の守備範囲がとても広くなってしまいます。\n開発者には限界があり、いつしか**トラブルシューティングに追われる日々**になってしまいます。\n\nそこで、Micro Frontends というアーキテクチャの出番です。\n\n## Micro Frontends とは\n\n> それはマイクロサービスの考え方をフロントエンドに拡張したものです。\n\n![micro frontends monolith-frontback-microservices](https://res.cloudinary.com/silverbirder/image/upload/v1693364015/silver-birder.github.io/blog/monolith-frontback-microservices.png)\n\n![micro frontends verticals-headline](https://res.cloudinary.com/silverbirder/image/upload/v1693364017/silver-birder.github.io/blog/verticals-headline.png)\n\n※ [https://micro-frontends-japanese.org](https://micro-frontends-japanese.org)\n\n要は、バックエンドだけでなく、バックエンドからフロントエンドまでをマイクロサービス化することです。\n\nさらに詳しく知りたい方は、次のページをご参考下さい。とてもわかりやすいです。\n\nhttps://micro-frontends-japanese.org/\n\nまた、次の書籍を読むと、\nhttps://www.manning.com/books/micro-frontends-in-action\n\n> Amazon does not talk a lot about its internal development structure. However, there are reports that **the teams who run its e-commerce site have been working like this**for a long time. ...\n> **Micro frontends are indeed quite popular in the e-commerce** sector. **\n> In 2012\n>** the Otto Group, a Germany based mail order company and one of the world’s\n> largest e-commerce players started to split up its monolith. ...\n> The Swedish furniture company **IKEA and Zalando**, one of Europes biggest fashion retailers, moved to this model. ...\n> But micro frontends are also used in other industries. **Spotify** organizes itself in autonomous end-to-end teams they call Squads. ...\n\nExcerpt From: Michael Geers. “Micro Frontends in Action MEAP V03.” iBooks.\n\nという内容があります。\n\nIKEA や Zalando といった**EC サイトが Micro Frontends を採用する**ケースが多く、公には言っていませんが、Amazon も Micro Frontends で取り組んでいるようです。\nEC サイトだけでなく、Spotify のようなサービスにも適用されるケースがあります。\n\n## Micro Frontends の良さ\n\n私が思う Micro Frontends から得られる最大の恩恵は、\"**局所化**\" だと思います。\n\nフロントエンドをサービス毎(商品、注文、検索など)に分割することで\n\n- サービスの**専門性**向上\n  - ex. 対象サービスのフロントエンドだけに集中できる\n- サービスの**開発速度**向上\n  - ex. 対象サービスのソースコードだけ読めば良い\n  - ex. 対象サービスだけにライブラリアップデートすれば良い\n  - ex. フレームワークの切り替えは対象サービスだけすれば良い\n\n少し薄っぺらいかも知れませんが、↑ のように実感しています。\n\n※ Micro Frontends は Web ベースのアーキテクチャになります。\n\n## Micro Frontends の難しさ\n\nここは、まだちゃんと掘り下げれていませんが、次のようなものがあります。\n\n- 特定チームが改善しても、チーム全体が改善しない\n  - ex. あるチームが webpack のビルド時間短縮に成功しても、他のチームは影響を受けない\n  - ex. 全てのチームが採用しているライブラリのセキュリティパッチは、それぞれのチームが更新しなければならない\n- チーム全体へ共有する仕組みを考える必要がある\n  - ex. デザインシステム、パフォーマンス、ナレッジ\n- エッジな技術スタック採用は、チームメンバー移動を困難にする\n  - ex. パラダイムシフトが発生してしまう 技術スタック\n\n## Micro Frontends の作る上で考えること\n\nフロントエンドをマイクロサービス化するということは、各サービスで HTML/CSS/JS を作ることになります。\nそれらの**サービスを統合するサービス**が重要になってきます。\n\n大きく分けて 2 つの統合パターンがあります。\n\n| 種類                   | 解決手段                            | メリット                                                                                                       | デメリット                                                                       |\n| ---------------------- | ----------------------------------- | -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n| サーバーサイド統合     | SSI, ESI, Tailor, Podium            | ・SEO 対策上良い / ・ユーザーのネットワークレイテンシーが少ない / ・初回ロードパフォーマンスが優れている | ・インタラクションアプローチが不得意                                             |\n| クライアントサイド統合 | ~~Ajax, Iframe,~~ Web Components | ・Web 標準 / ・シャドウ DOM による堅牢な作り                                                                | ・サポートブラウザに依存する / ・クライアント側の JavaScript が有効であること |\n\nまた、これら 2 つの選択基準は次のようになります。\n\n| 種類                   | 選択基準                                                                                                                    |\n| ---------------------- | --------------------------------------------------------------------------------------------------------------------------- |\n| サーバーサイド統合     | 良好な読み込みパフォーマンスと検索エンジンのランキングがプロジェクトの優先事項であること                                    |\n| クライアントサイド統合 | さまざまなチームのユーザーインターフェイスを 1 つの画面に統合する必要があるインタラクティブなアプリケーションを構築すること |\n\n今回、私はサーバーサイド統合(Podium)を選択しました。\nただ、インタラクティブなアプローチも必要だったため、**Hydration**を使いました。\n\n> Hydration refers to the client-side process during which Vue takes over the static HTML sent by the server and turns it into dynamic DOM that can react to client-side data changes.\n\n※ [https://ssr.vuejs.org/guide/hydration.html](https://ssr.vuejs.org/guide/hydration.html)\n\nHydration は、サーバーサイドでレンダリングした静的 HTML に、クライアントサイドの動的レンダリングができるようにするようなものです。\n\n※ クライアントサイド統合(Web Components)でも良かったのですが、私都合により却下となりました。\n\n## Micro Frontends サンプル Web アプリ\n\napple, banana, orange という商品を検索するだけのサンプル Web アプリを作りました。\n\n概要図はこちらです。\n\n![micro frontends sample overview](https://res.cloudinary.com/silverbirder/image/upload/v1588513402/micro-frontends-sample-code/micro_frontends_sample.jpg)\n\nサンプルコードは、ここに置いています。\nhttps://github.com/silverbirder/micro-frontends-sample-code\n\n## サービス\n\n| サービス     | 役割                       | JS フレームワーク              |\n| ------------ | -------------------------- | ------------------------------ |\n| team-search  | 商品を検索するサービス     | Vue.js                         |\n| team-product | 商品を表示するサービス     | React.js                       |\n| team-page    | サービスを統合するサービス | フレームワーク未使用 (Node.js) |\n\n## 仕組み\n\nPodium というライブラリを採用しました。\n\nhttps://github.com/podium-lib/\n\nこれは、フロントエンドのサービスを簡単に統合できるようなライブラリになっています。\nPodium には大きく分けて 3 つの機能があります。\n\n- [@podium/podlet](https://www.npmjs.com/package/@podium/podlet)\n  - ページフラグメントサーバーを構築する\n  - ex. team-search, team-product\n- [@podium/layout](https://www.npmjs.com/package/@podium/layout)\n  - Podlet を集めて、ページ全体のレイアウトを構築する\n  - ex. team-page\n- [@podium/browser](https://www.npmjs.com/package/@podium/browser)\n  - ブラウザベースの機能を提供する\n  - MessageBus による Podlet 同士のコミュニケーション\n  - ex. team-search, team-product で publish/subscribe\n\n### @podium/podlet\n\nPodlet には、manifest.json と呼ばれる値を返却することが必須になっています。\nmenifest.json には、サービスのエンドポイントや、Asset(JS や CSS)のパスが明記されています。\n\nteam-search では\n\n```shell\ncurl https://team-search.fly.dev/manifest.json | jq .\n  {\n    \"name\": \"search\",\n    \"version\": \"1.0.0\",\n    \"content\": \"/\",\n    \"fallback\": \"\",\n    \"assets\": {\n      \"js\": \"/search/static/fragment.js\",\n      \"css\": \"\"\n    },\n    \"css\": [],\n    \"js\": [\n      {\n        \"value\": \"/search/static/fragment.js\",\n        \"async\": true,\n        \"defer\": true,\n        \"type\": \"default\"\n      }\n    ],\n    \"proxy\": {}\n  }\n```\n\nというレスポンス結果になります。\n\n### @podium/layout\n\nLayout では、Podlet の manifest.json の定義に従って fetch することになります。\n\nteam-page では\n\n```javascript\n// server.js (express)\napp.get(`/`, async (req, res) => {\n  const incoming = res.locals.podium;\n\n  const [searchBox] = await Promise.all([\n    podletSearch.fetch(incoming, { pathname: \"/search/box\", query: req.query }),\n  ]);\n  const [items] = await Promise.all([\n    podletProduct.fetch(incoming, {\n      pathname: \"/product/items\",\n      query: { id: searchBox.headers[\"x-product-items\"] },\n    }),\n  ]);\n\n  res.podiumSend(`\n        <html>\n            <head>\n                <title>Shop</title>\n                ${searchBox.js.map((js) => js.toHTML())}\n                ${items.js.map((js) => js.toHTML())}\n            </head>\n            <body>\n                <div id=\"app-shell\">\n                    ${searchBox.content}\n                    ${items.content}\n                </div>\n            </body>\n        </html>\n    `);\n});\n```\n\nのように Podlet を使って、ページ全体を構築します。このようにサーバーサイドで統合しています(SSR)。\nしかし、インタラクティブなアクションも必要なため、Podlet から Hydrate するための js を読み込んでいます。\n\nまた、team-search の検索結果(x-product-items)を team-product へ渡しているため、商品の検索結果を含めて SSR が実現できます。\n\n### @podium/browser\n\nサーバーサイドは、podium/podlet, podium/layout で連携できます。\nクライアントサイドは、この @podium/browser の MessageBus で連携できます。\n\n今回のサンプル Web アプリでは、次のようなユースケースに使用しています。\n\n1. ユーザーが検索ボックスにキーワードを入力する\n1. team-search がキーワードから商品を検索する\n1. team-search が 2 の結果を publish する\n1. team-product が 3 を subscribe し、商品を更新する\n\n```javascript\n// team-search.js\nmessageBus.publish(\"search\", \"search.word\", { items: hitItems });\n```\n\n```javascript\n// team-product.js\nmessageBus.subscribe(\"search\", \"search.word\", (event) => {\n  hydrate(\n    <Items {...{ items: event.payload.items }} />,\n    document.querySelector(\"#team-product-items\")\n  );\n});\n```\n\nこのようにすることで、画面更新ではなく部分更新ができました。\nインタラクティブな操作も実現可能です。\n\n## 状態管理, ルーティング\n\nここは、まだきちんと作っていませんが、次のようなコンセプトで設計するのが良いと思います。\n\n- 状態管理\n  - 各サービスが状態管理する。状態は共有しない。\n  - 統合サービスが共通的な状態を管理する。\n- ルーティング\n  - 各サービスが query を設定する。\n  - 統合サービスが URL パスを管理する。\n\n## その他\n\n各サービスは、fly.io という PaaS へデプロイしています。\n\nhttps://fly.io/\n\nCDN で SSR が実行できる **Edge Worker**を使用しています。\nこれにより、SSR 結果をキャッシュし、高速にレスポンスを返却できます。\n\nただ、サンプル Web アプリでは、全くその力を引き出せていないです...\n\n※ 参考記事\nhttps://mizchi.hatenablog.com/entry/2019/02/21/235403\n\n## サンプル Web アプリで分かったこと\n\n## SSR + CSR (Hydration) が実現可能\n\n**サーバーサイド統合であっても、CSR は実現可能**です。 ただし、Hydration には\n**パフォーマンス面に難有り**なため、このあたりは課題として残ります。 また、CSR\nするための bundle した javascript の size には注意が必要です。\n\n例えば、次のリポジトリにある \"shared_vendor_webpack_dll\" のように、vendor ファイルを共有することで、\njavascript の size を減らすといった手段があります。\n\nhttps://github.com/naltatis/micro-frontends-in-action-code\n\nまた、次のリポジトリにある zalando tailor は、script load を streaming することで、\n全体の script load 完了時間を短縮するツールもあります。\n\nhttps://github.com/zalando/tailor\n\n## サービス内で技術スタックを選択できる\n\nマイクロサービスでは、よくあるメリットとして挙げられるものです。\nフロントエンドでも、同様に技術スタックを自由に選択できます。\n\n今回では、React.js と Vue.js を使用しています。\nこれを Riot.js や Svelte.js にも切り替えることも可能です。\n\n**フロントエンド界隈では、JS フレームワークの変化が激しい**ので、\nこのメリットは大切だと思います。\n\nただし、Podium の manifest.json を返却しなければなりません。\n今の所、Podium に対応しているのは Express のみなので、Express を使用する\nフレームワークのみとなります。\n\n## サービス毎のフロントエンドに集中できる\n\n検索サービスだと、検索に特化したフロントエンドのみに集中することができます。\n商品サービスだと、商品の表示内容のみに集中することができます。\n\nただ、どうしても他サービスと連携する要件が出てきます。\nこれは、マイクロサービスとしての難しさだと思います。\n例えば、各サービスがどのタイミングでイベント登録するのかを考える必要があります。\n\n## 最後に\n\nEC サイトのようなアプリケーションでは『商品を探しやすくする』『買いたくなるような商品を表示する』\n『商品を簡単に購入できる』などフロントエンドでやるべきことが多くあります。\n\nそういうサービスにおけるフロントエンドがモノリシックであれば、\n統一性が欠けてしまったり、知らぬ間にバグを埋め込んでしまうケースが発生してしまいます。\n\nMicro Frontends は、このような**複雑化するフロントエンドにメスを入れる良いアーキテクチャ**だと思います。\nただし、バックエンドにおけるマイクロサービス化による課題があるように、フロントエンドにおける\nマイクロサービス化にも課題はあるはずです。\n\n日本では、Micro Frontends の導入実績が少なく、まだまだ発展途上だと思います。\nこの記事が、どこかのサービスへの参考になればと思います。\n\n最後まで読んで頂き、ありがとうございました。\n\n## 参考リンク\n\nhttps://github.com/ChristianUlbrich/awesome-microfrontends","publishedAt":"2020-05-04","slug":"microfrontends","title":"Micro Frontends を学んだすべて"},{"body":"Twitter に投稿されている Link を収集するツール Cotlin を作りました。\n\n**\n  <span style={{color: \"#d32f2f\"}}>Co</span>\n**\nllec\n**\n  <span style={{color: \"#d32f2f\"}}>t lin</span>\n**\nks in tweet\n\nから、Cotlin という名前にしました。Android のアレに似ています。\n\nhttps://github.com/silverbirder/Cotlin\n\nhttps://www.npmjs.com/package/@silverbirder/cotlin\n\n## 動機\n\n私は、[connpass](https://connpass.com/)等を使って、技術系のカンファレンスに参加することがありました。\nカンファレンスで発表された資料は、Twitter で公開されることが多々あるので、それを自動収集できるようにしたいと考えたのが、Cotlin を作った動機です。\n\n## 技術スタック\n\nGoogle Apps Script ([Clasp](https://github.com/google/clasp/)) + Twitter API ([tweet search API](https://developer.twitter.com/en/docs/tweets/search/overview)) です。\n[ライブラリを公開](https://github.com/silverbirder/Cotlin#use-by-google-apps-script)していて、それを元に[API](https://github.com/silverbirder/Cotlin/blob/master/sample/api.js)と[Client](https://github.com/silverbirder/Cotlin/blob/master/sample/client.js)を簡単に作れるようにサンプルコードも用意しています。使い方は、全て[README.md](https://github.com/silverbirder/Cotlin/blob/master/README.md)にあります。\n\n## 困ったこと\n\nTweet に記述したリンクは、全て[t.co](https://help.twitter.com/ja/using-twitter/url-shortener)に短縮されてしまいます。\nこの短縮 URL からオリジナル URL を手に入れるために、リダイレクトする必要があります。\n実際に作ってみると、次のような記事に書いたとおり、GAS で書くと、少し困ったことがありました。\n\nhttps://silverbirder.github.io/blog/contents/gas_fetchall_redirect\n\nそこで、複数のリダイレクト URL へリクエストする処理を並列化するために、Golang で開発していました。\n\nしかし、そもそも Twitter API ([tweet search API](https://developer.twitter.com/en/docs/tweets/search/overview))のレスポンスには、オリジナル URL が含まれている([expanded_url](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets))ことに気づき、結局、Google Apps Script ([Clasp](https://github.com/google/clasp/))で開発することになりました。\n\n## 良かったこと\n\n毎日、プレゼンテーション資料を収集し、スプレットシートに記録するよう、自動化しました。  \n※ 都合により、URL のリンクと Tweet のリンクのみ記載しています。\n\nhttps://docs.google.com/spreadsheets/d/1IaJOw9-GdoHhz3D0CzvJfFitrmEN8KpgIleer9rmxiw/edit?usp=sharing\n\n次のような資料を発見できるようになりました。\n\n- **世界中**のプレゼンテーション資料\n- **知らない技術カンファレンス**の資料\n- **個人や学生**が公開した資料\n\nそこから、次のような良かったことがありました。\n\n- 『テストについて、同じように困っている人がいた。○○ という技術で解決してるんだ！知らなかった！』\n- 『最近気になっている ○○ のアーキテクチャの資料だ。メリット・デメリットがよくまとまってて良い！』\n- 『リモートワークを取り組んでいる企業の話だ。これから私もリモートワークになるから、先に知見を知っておこう！』\n\n毎日、資料を読んでいると、1 日 2,3 件ほど、自分の琴線に触れるものが現れます。とても刺激を受けて、作ってよかったなと思いました。\n\n## 最後に\n\n動機であった技術カンファレンスの参加は、実は最近減少しています。\n理由は色々ありますが、まあ伏せておきます。\n\nこういったツールによって、アンテナを広く張り巡らせておくことができます。\nこれのおかげで、様々な関心事をキャッチアップできるようになりました。\n\n上のスプレットシートは、ずっと更新し続ける予定ですので、活用下さい。","publishedAt":"2020-03-15","slug":"twitter_cotlin","title":"TwitterにあるLinkを収集するツール Cotlin で、世界中のプレゼンテーション資料を知ろう"},{"body":"## きっかけ\n\nみなさん、リモートワーク（テレワーク）してますか？\nHangouts Meet や Zoom といったビデオ会議ツールを使う機会が増えたと思います。\n\nそんな中、次の記事が流行りました。\n\nhttps://level69.net/archives/26902\n\n> バ美肉（バびにく）とは、バーチャル美少女受肉またはバーチャル美少女セルフ受肉の略語\n> https://ja.wikipedia.org/wiki/バ美肉\n\nこれにより、ビデオ会議(例は Zoom)で、次のようなバーチャル美少女 (になりきった私)が参加できるようになります。もちろん、声もボイスチェンジできます。\n\n![バーチャル美少女 (私)](https://res.cloudinary.com/silverbirder/image/upload/v1614428127/silver-birder.github.io/blog/virtual_beautiful_girl_me.png)\n\n![Whiteboard in Zoom](https://res.cloudinary.com/silverbirder/image/upload/v1614428171/silver-birder.github.io/blog/whiteboard_in_zoom.png)\n\nWindows では、[Facerig](https://store.steampowered.com/app/274920/FaceRig/?l=japanese)というアプリで簡単に構築できるみたいです。\n\nこれを Mac で構築する方法を紹介しようと思います。\nMac + Bootcamp → Windows10 + Facering でもできると思いますが、動作不安定になる可能性があったため、極力避けようと思い、却下しました。\n\n## 構成\n\n私は、次のような構成になりました。\n\n![バ美肉's structure](https://res.cloudinary.com/silverbirder/image/upload/v1614428221/silver-birder.github.io/blog/virtual_beautiful_girl_structure.png)\n\n音声と動画の 2 つに分かれます。\nまた、ビデオ会議ツールと連携するため、仮想デバイス(Soundflower, CamTwist)が必要になります。\n\n## 音声\n\n## Voice Changer: Gachikoe\n\n野太い声じゃなくて、かわいい声が聞きたいですよね。そうですよね。はい。\n\n[Gachikoe](https://booth.pm/ja/items/1236505)を使いました。\n\nGachikoe は、次のような設定にしました。\n\n![Gachikoe](https://res.cloudinary.com/silverbirder/image/upload/v1614428254/silver-birder.github.io/blog/gachikoe.png)\n\n![Gachikoe settings](https://res.cloudinary.com/silverbirder/image/upload/v1614428287/silver-birder.github.io/blog/gachikoe_settings.png)\n\nOutput を soundflower (2ch)にしています。\n\n## 仮想マイク\n\n仮想マイクは、Soundflower を使います。\nhttps://github.com/mattingalls/Soundflower/tags\n\n音声出力のルーティングを制御するために、LadioCast も使いました。\nhttps://apps.apple.com/jp/app/ladiocast/id411213048?mt=12\n\nLadioCast は、次のような設定にしました。\n\n![LadioCast](https://res.cloudinary.com/silverbirder/image/upload/v1614428329/silver-birder.github.io/blog/ladio_cast.png)\n\nInput を soundflower (2ch)とし、Output を soundflower (64ch)としています。\n\n## 動画\n\n## Application for VTuber\n\n### Desktop: 3tene\n\nデスクトップで動かす場合は、3tene(ミテネ)を使いました。\n\nhttps://3tene.com/\n\n3tene は、特に設定は必要ありません。\n撮影前には、Web カメラとリップシンク(口の動きの同期)を起動しておきましょう。\n\n![3tene](https://res.cloudinary.com/silverbirder/image/upload/v1614428380/silver-birder.github.io/blog/3tene.png)\n\n#### Asserts\n\n肝心のキャラクターですが、3tene は VRM 形式でなければならないそうです。(よくわかっていません)  \n私は、次のサイトでダウンロードしました。\n\nhttps://hub.vroid.com/\n\nhttps://3d.nicovideo.jp/\n\n### Mobile: Reality\n\nモバイルで動かす場合は、Reality を使いました。\n\nhttps://apps.apple.com/jp/app/reality-%E3%83%90%E3%83%BC%E3%83%81%E3%83%A3%E3%83%AB%E3%83%A9%E3%82%A4%E3%83%96%E9%85%8D%E4%BF%A1%E3%82%A2%E3%83%97%E3%83%AA/id1404176564\n\nReality は、特に設定は必要ありません。\n好みのキャラクターをカスタマイズして簡単に作れます。\n\n私は、これです。\n\n[![reality me](https://res.cloudinary.com/silverbirder/image/upload/v1614428417/silver-birder.github.io/blog/reality_me.jpg)](https://reality.wrightflyer.net/profile/443e9213)\n\niPhone で撮影している画面を Mac に反映する必要があります。\nMac と iPhone を接続し、QuickTime Player へ出力します。こんな感じです。\n\n![iPhone To QuickTime Player](https://res.cloudinary.com/silverbirder/image/upload/v1614428459/silver-birder.github.io/blog/iPhone_to_quick_time_player.png)\n\nnone は、私の iPhone デバイス名です。\n\n## 仮想カメラ\n\nCamTwist という仮想カメラを使いました。\nhttp://camtwiststudio.com/download/\n\nCamTwist は、次のような設定にしました。\n\n![CamTwist](https://res.cloudinary.com/silverbirder/image/upload/v1614428498/silver-birder.github.io/blog/cam_twist.png)\n\n例では、QuickTime Player のアプリケーションを選択しています。3tene の場合は、3tene の選択肢を選択すれば良いです。\n\n## 使い方 (Zoom)\n\n今まで説明したものを起動した状態で、Zoom を起動します。\nZoom は、次のような設定にしました。\n\n![Zoom > Settings > Video](https://res.cloudinary.com/silverbirder/image/upload/v1614428582/silver-birder.github.io/blog/zoom_settings_video.png)\n\n動画は、CamTwist から取得するようにします。\n\n![Zoom > Settings > Audio](https://res.cloudinary.com/silverbirder/image/upload/v1614428625/silver-birder.github.io/blog/zoom_settings_audio.png)\n\n音声は、Soundeflower (64ch)から取得するようにします。\n\nこれで、**Mac で バ美肉 することができました！**\n\n## 終わりに\n\nテレビ会議で、こういった \"リアルな姿を出さず、異なる人物を出す\" のは、実際役立つものなのでしょうか。\nテレビ会議ツール、例えば Zoom では、音声や動画を隠せる機能はあります。\n\"リアルな姿を隠したい\"要求は、すでに解決できています。\n\n今回のような\"バ美肉\"って、どういうメリットがあるのか、んーってなりました。\nネタ的には『可愛い女の子と会話すると、生産性があがる』なのですが...脳が震える。\n\n## 参考リンク\n\nhttps://kumak1.hatenablog.com/entry/2018/09/27/234203\n\nhttp://kuroyam.hatenablog.com/entry/2020/02/27/204246\n\nhttps://mzyy94.com/blog/2020/02/25/virtual-bishoujo-meeting/\n\nhttps://www.excite.co.jp/news/article/MoguraVR_voice-changer-pickup5/\n\nhttps://www.cg-method.com/entry/gachikoe/#Gachikoe\n\nhttps://vtuberkaibougaku.site/2019/01/31/post-3176/","publishedAt":"2020-03-08","slug":"mac_babiniku","title":"Mac で バ美肉 りたい！  (Zoom + Gachikoe + 3Tene or Reality)"},{"body":"Google Apps Script (以下、GAS)で、困ったことがあったので備忘録として残しておこうと思います。\n\n## やろうとしたこと\n\n特定ハッシュタグにおける、ツイートに書いてあるリンクを集めようとしていました。\nそのリンクは、特定のドメインのみでフィルタリングしたいとも思っていました。\nこれらを RESTful API として提供したかったので、手軽に作れる GAS で作ろうと考えていました。\n\n## 取り組んでみたこと\n\nTwitter に書くリンクは、全て短縮 URL になります。\nそのため、短縮 URL にアクセスし、リダイレクト先の URL を取りに行く必要がありました。\nGAS では、リクエストメソッドである fetch があります。その fetch の`followRedirects`というオプションを false にし、responseHeader の location を取ることで、解決(リダイレクト先の URL 取得が)できます。\n\nhttps://developers.google.com/apps-script/reference/url-fetch/url-fetch-app#advanced-parameters\n\nまた、1 リクエストだけをする fetch では、直列処理になってしまうため、大変遅いです。\n複数リクエストが同時にできる featchAll を使うことで、並列処理ができ、パフォーマンスが良いです。\n要するに次のようなコードで解決しようと考えていました。\n\n![FetchAllとRedirectURL](https://res.cloudinary.com/silverbirder/image/upload/v1614429255/silver-birder.github.io/blog/FetchAll_and_RedirectURL.png)\n\n```typescript\nlet urlList: Array<string> = [\"https://t.co/XXXX\", \"https://t.co/YYYY\"];\nconst locationList: Array<string> = [];\nwhile (true) {\n  const requestList: Array<URLFetchRequest> = urlList.map((url: string) => {\n    return {\n      url: url,\n      method: \"get\",\n      followRedirects: false,\n      muteHttpExceptions: true,\n    };\n  });\n  const responseList: Array<HTTPResponse> = UrlFetchApp.fetchAll(requestList);\n  urlList = [];\n  responseList.forEach((response: HTTPResponse) => {\n    const allHeaders: any = response.getAllHeaders();\n    const location: string = allHeaders[\"Location\"];\n    if (location) {\n      locationList.push(location);\n      urlList.push(location);\n    }\n  });\n  if (urlList.length === 0) {\n    break;\n  }\n}\nreturn locationList;\n```\n\n### 追記 (20200228)\n\nhttps://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n\nTwitter の API レスポンスに `urls` がありました。説明はありませんでしたが、Tweet に貼られたリンク(短縮 URL と、オリジナル URL)の情報が入るそうです。\n\n```text\n\"urls\": [\n          {\n            \"url\": \"https://t.co/Rbc9TF2s5X\",\n            \"expanded_url\": \"https://twitter.com/i/web/status/1125490788736032770\",\n            \"display_url\": \"twitter.com/i/web/status/1…\",\n            \"indices\": [\n              117,\n              140\n            ]\n          }\n ]\n```\n\n## 困ったこと\n\nこの手段だと、Location を 1 つ 1 つ辿っていくことになります。\nそのため、リダイレクトを自動的に追う( `followRedirects: true` )よりも、処理コストが大きいです。まあ、そこは目を瞑ります。\n\n次です。\n\nhttps://www.monotalk.xyz/blog/google-app-script-%E3%81%AE-urlfetchapp-%E3%81%AE-%E4%BE%8B%E5%A4%96%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/\n\nfetch や fetchAll は、`muteHttpExceptions: true` としたとしても、ExceptionError が発生してしまいます。\nそうすると、例えば 1000 件の URL を fetchAll した場合、**どれが成功で、どれが失敗で、どれが未実施か** がわからないというところです。\n\n![FetchAllとRedirectURL (Error)](https://res.cloudinary.com/silverbirder/image/upload/v1614429297/silver-birder.github.io/blog/FetchAll_and_RedirectURL_error.png)\n\nPromise.allSettled が使えれば、解決できるのかなと思いますが、現状 Promise は使えません。\n\n私が思う解決策としては、\n\n- fetchAll ではなく、fetch を使う\n- fetchAll でリクエストする件数をいくつかの塊に分ける。(一気にではなく、分ける）\n\n## 最後に\n\nそもそもなのですが、今回やろうとしたことって GAS の良さがないですよね。\nGAS は、GSuites 連携を簡単にできるという良さがあります。\n\nしかし、今回はちょっとしたクローラーを作りたいだけでした。もちろん、GAS でも作れると思いますが、いくつかを妥協しないといけなくなります。\n\nもし、そこが妥協できないのであれば、別の手段を検討する必要があります。\n\n## 教訓\n\n- 表面的\n  - fetchAll するときは、リダイレクト先 URL を取得しない\n- 根本的\n  - 目的に適したツールを選択する\n\nちなみに、このツールは、並列処理をシンプルにコーティングできる golang で書き直そうと考えています。","publishedAt":"2020-02-24","slug":"gas_fetchall_redirect","title":"Google Apps Script で FetchAllとRedirctURL の組み合わせは悪い"},{"body":"## ターゲットユーザー\n\n- GMail と GCalendar を使っている人\n\n## メールを開くって面倒じゃないですか\n\n例えば、次のようなメールを受信していたとします。\n\n- アマゾンで商品を購入した際、お届け予定日が記載されたメール\n- 映画館(TOHO シネマ)でネット予約した際、上映日が記載されたメール\n- ホテルをネット予約した際、宿泊日が記載されたメール\n\n『いつ商品が届くのかな？メールを確認しよう』が、**面倒と感じませんか**？私は面倒と思います。\nGoogle は気を利かせて、次のような予定を勝手に登録してくれることがあります。（良い悪いがありますが...）\n\n![unknownorganizer@calendar.google.com](https://res.cloudinary.com/silverbirder/image/upload/v1614431051/silver-birder.github.io/blog/unknownorganizer_google_calendar.png)\n\nこの気を利かせるかどうかは、Google の判断によるため未知数です。\n先程あげた例のメールも、同様のことが勝手にしてくれたら良いな〜と思っていました。\nそこで、rMinc というツールを作りました。\n\n※ 昔、[gas-for-amazon-calendar](https://github.com/silverbirder/gas-for-amazon-calendar)という、アマゾンからのお届け予定日が記載しているメールを GCalendar に登録するツールを作りましたが、\nアマゾンのメールに特化しすぎてしまい、汎用性がないものとなりました。\n\n## rMinc is 何\n\nhttps://www.npmjs.com/package/@silverbirder/rminc\n\n> rMinc is the Google Apps Script Library that register Mail in Calendar.\n\n以下サービスからの GMail が届いたときに、その内容を抽出して GCalendar に登録します。\n\n- [Amazon](https://www.amazon.co.jp/)\n  - 発送のお知らせ (お届け予定日)\n- [TOHO CINEMAS](https://www.tohotheater.jp/)\n  - チケット購入完了のお知らせ (上映日)\n- [食宅便](https://shokutakubin.com/)\n  - 配送手配のお知らせ (お届け予定日)\n\nまた、これ以外にも対応したいサービスがあると思うので、カスタマイズして使えるようにしました。\n詳しくは、[README.md](https://github.com/silverbirder/rMinc/blob/master/README.md)をご確認下さい。\n\n概要はこんな感じです。\n\n![overview](https://res.cloudinary.com/silverbirder/image/upload/v1581769421/rMinc/rMinc_overview.png)\n\n1. 特定キーワードでメールを抽出\n   1. アマゾンなら、[from:(shipment-tracking@amazon.co.jp) 発送](https://github.com/silverbirder/rMinc/blob/master/src/user/mailRule/amazonMailRule.ts#L61)\n1. メールの下記を抽出\n   1. タイトル\n   1. 本文\n      1. イベント開始日&終了日 (予定日とか）\n      1. 場所 (配達先とか)\n   1. メールのリンク\n1. 抽出した内容を GCalendar に登録\n\n実際に使ってみるとこんな感じになります。\n\n![example](https://res.cloudinary.com/silverbirder/image/upload/v1581760683/rMinc/rMinc_sample.png)\n\n小さくて見えないと思いますが、お届け予定日、タイトル、配達先、メールリンクが登録されています。\n\nこのツール([sample.js](https://github.com/silverbirder/rMinc/blob/master/sample/sample.js))を GAS 上で**<span style={{color: \"#d32f2f\"}}>定期的に動かしておくだけ</span>**で、自動的に GCalendar へ予定登録されます。当たり前ですが、無料です。\n\n※ RMinc は、[README.md](https://github.com/silverbirder/rMinc/blob/master/README.md)にある APP ID を登録する必要あり\n\n## 最後に\n\nGoogle Apps Script は、エンジニアにとって、とても強力な武器です。特に、G Suite を積極的に使っている人にとっては、欠かせないものです。\n\nこういった **<span style={{color: \"#d32f2f\"}}>かゆいところに手が届く</span>** ことができるのは、Google Apps Script の魅力的なところです。\nぜひぜひ、積極的に活用していきたいですね！","publishedAt":"2020-02-17","slug":"rminc","title":"GMailをGCalendarに登録するサービス rMinc を作ってみた"},{"body":"## 画像で会話って楽しい\n\n皆さん、チャットツールでコミュニケーションするとき、絵文字や画像って使ってますか？\n僕はよく使ってます。人とコミュニケーションするのに、文字だけだと**堅苦しい**イメージですよね。\n例えば、\n\n『OK です、それで先に進めて下さい。』\n\nというフレーズだけだと、相手がどのような感情なのか読み取りにくいです。\n\nそこで、次のような画像でコミュニケーションを取ると、柔らかい印象を与えることができます。\n\n![golia LGTM](https://res.cloudinary.com/silverbirder/image/upload/v1580997144/LGTM/golia.png)\n\n## Tiqav2\n\n## Tiqav とは\n\n画像を使って会話をするためのサービスとして、Tiqav があります。\n\n[http://dev.tiqav.com/](http://dev.tiqav.com/)\n\n現在は、サービス終了しています。\nTiqav2 は、その Tiqav を参考にして作りました。\n\n## Tiqav2 とは\n\nTiqav2 は、大きく分けて 2 つの機能があります。\n\n1. 画像とテキストを保存\n1. 画像を検索&表示\n\n## 2 つの機能\n\n### 画像とテキストを保存\n\n![Saving flow by Tiqav2](https://res.cloudinary.com/silverbirder/image/upload/v1614429484/silver-birder.github.io/blog/saving_flow_by_tiqav2.png)\n\n検索する為には、全文検索サービスの Algolia を使います。\n\nhttps://www.algolia.com/\n\nAlgolia に保存する情報は、主に 3 つです。画像 URL と拡張子、そしてテキストです。\n画像は画像変換&管理サービスの Cloudinary に保存します。保存後、Cloudinary より、画像 URL と拡張子が手に入ります。\n\nhttps://cloudinary.com/\n\nテキストは、Google Cloud Vision API へ画像を渡すことでテキストを抽出します。\nもちろん、手動でテキストを設定することもできます。\n\nhttps://cloud.google.com/vision/\n\n### 画像を検索&表示\n\n![Searching Flow  By Tiqav2](https://res.cloudinary.com/silverbirder/image/upload/v1614429523/silver-birder.github.io/blog/searching_flow_by_tiqav2.png)\n\nテキストで全文検索を行います。その結果の ID と Extension を組み合わせることで、\n画像を表示することができます。Extension の種類は、Cloudinary のサポートするもの全てになります。\n\n```text\n\"gif\", \"png\", \"jpg\", \"bmp\", \"ico\", \"pdf\", \"tiff\", \"eps\", \"jpc\", \"jp2\", \"psd\", \"webp\", \"zip\", \"svg\", \"mp4\", \"webm\", \"wdp\", \"hpx\", \"djvu\", \"ai\", \"flif\", \"bpg\", \"miff\", \"tga\", \"heic\"\n```\n\nhttps://cloudinary.com/documentation/image_transformations#supported_image_formats\n\nこの画像を表示する機能を使うと、次のように Slack 上で画像を送信することができます。\n\n![Send Tiqav2 URL on Slack](https://res.cloudinary.com/silverbirder/image/upload/v1614429563/silver-birder.github.io/blog/send_tiqav2_URL_on_slack.png)\n\n詳しい機能は、次のリポジトリをご確認下さい。\n\nhttps://github.com/silverbirder/tiqav2\n\n## SaaS は個人開発には最適\n\n今回、全文検索であったり画像管理は、SaaS に全て任せました。テキスト抽出はなくてもよかったのですが、Google Cloud Vision API が、そこそこ使えたため、そちらも使いました。\n\n個人で開発する際、リソース（時間、お金、人）は組織に比べて**とても小さい**です。\nSaaS は、１つのことを上手くやってくれるし、個人の利用範囲であれば無料なものが多いです。\nニッチなカスタマイズしたい要求がない限り、SaaS は大体の要望を叶えてくれます。\nどんな種類の SaaS があるか知りたい方は、↓ のサイトを見てみて下さい。参考になるはずです。\n\nhttps://saasblocks.io/\n\n**SaaS に面倒なことは任せて、プロダクトコードに集中する**ことは、私にとって、とても大切にしています。\nちなみに今回のプロダクトコードは、CleanArchitecture + InversifyJS で作りました。\n\n## 終わりに\n\nTiqav2 は、OSS として公開していますので、誰でも無料で構築できます。\nぜひ、使ってみて下さい。快適なコミュニケーションを目指しましょう！","publishedAt":"2020-02-08","slug":"tiqav2_release","title":"1コマ漫画検索サービスTiqav2 (Algolia + Cloudinary + Google Cloud Vision API) 作ってみた"},{"body":"Google Apps Script(以下,GAS)でライブラリを公開しました。ライブラリを開発する際、**テストのフィードバックサイクルを短くする**ため、`Clasp + Typescript + Jest` という技術スタックを選択しました。\nその開発体験について共有しようと思います。特段変わったことはしていません。\n\n## Google Apps Script のテストってどうしてますか\n\n[script.google.com](https://script.google.com/)にアクセスしてデバッグ実行って、しんどくないですか？\n\n![Google Apps Script Debugging ...](https://res.cloudinary.com/silverbirder/image/upload/v1614431285/silver-birder.github.io/blog/google_apps_script_debugging.png)\n\n- ネットワーク越しでステップ実行するため、**遅い**\n- G Suite 系のサービスと連携すると、サービス側の調整(データ準備とか)が**面倒**\n- デバッグ機能が**貧弱**\n\nとても**ストレスフル**です。単純な GAS なら別に良いんですが、少し複雑な GAS を作ろうと思うと、問題に感じます。\n\n## ローカルで動かそう\n\nGAS をローカル環境で動かすことができる Clasp というコマンドラインツールが Google より公開されています。\n\nhttps://github.com/google/clasp\n\nまた、Clasp は Typescript をサポートしているため、型を中心としたコーディングが可能となりました。\n\nhttps://www.npmjs.com/package/@types/google-apps-script\n\nTypescript を選択すると、Interface 設計が容易になります。もちろん、`.gs` ファイルでも同様の事は実現できると思います。\n\n次に、Jest と呼ばれるテストツールを組み合わせることで、ローカル環境でテストが可能になります。\n\nhttps://jestjs.io/docs/getting-started\n\nただ、単純にテストコードが書けません。\n例えば、カレンダーイベントを取得するテストをコーディングするとき、次のようなスクリプトを書いたとします。\n\n```typescript\nconst calendar: Calendar = CalendarApp.getCalendarById(\n  \"<your google calendar id>\"\n);\ncalendar\n  .getEvents(new Date(\"2020-01-01\"), new Date(\"2020-01-02\"))\n  .forEach((calendarEvent: CalendarEvent) => {\n    console.log(calendarEvent.getTitle());\n  });\n```\n\nこう書いてしまうと、本当のカレンダーイベントを取りに行ってしまいます。テストであれば、そういった処理は避けたいところです。\nそこで、`CalendarApp` を偽物のオブジェクト、つまり Mock オブジェクトに差し替えるため、依存性逆転の原則(dependency inversion principle)を適用します。\n\n```typescript\ninterface ICalendarApp {\n  calendars?: Array<ICalendar>;\n  getCalendarById(id: string): ICalendar;\n}\n\ninterface ICalendar {\n  calendarEvents?: Array<ICalendarEvent>;\n  getEvents(startTime: Date, endTime: Date): Array<ICalendarEvent>;\n}\n\ninterface ICalendarEvent {\n  title?: string;\n  getTitle(): string;\n}\n\nclass CalendarAppMock implements ICalendarApp {\n  calendars?: Array<ICalendar>;\n\n  getCalendarById(id: string): ICalendar {\n    return this.calendars![0].calendar;\n  }\n}\n\nclass CalendarAppImpl implements ICalendarApp {\n  getCalendarById(id: string): ICalendar {\n    const calendar: ICalendar = CalendarApp.getCalendarById(id);\n    return calendar;\n  }\n}\n```\n\nこのようなインターフェース・クラスを準備し、先程のコードを次のようにします。\n\n```typescript\nconst calendar: ICalendar = new CalendarAppMock().getCalendarById();\ncalendar\n  .getEvents(new Date(\"2020-01-01\"), new Date(\"2020-01-02\"))\n  .forEach((calendarEvent: ICalendarEvent) => {\n    console.log(calendarEvent.getTitle());\n  });\n```\n\n結果、`CalendarApp` の代わりに Mock オブジェクトを差し込めるようになりました。ローカルテストが可能となります。\n\nもちろん、プロダクトコードでは、`CalendarAppMock` ではなく、 `CalendarAppImpl` を使用すれば良いです。\nMock で差し替えるオブジェクトが増えると、InversifyJS のような DI コンテナを検討してみると良いかもしれません。\n\nhttps://github.com/inversify/InversifyJS\n\nこうすることで、Jest によるテストが動作するようになります。  \n実際に、開発・公開したライブラリでも十分にテストをすることができました。\n\nhttps://www.npmjs.com/package/@silverbirder/caat\n\n```shell\nCaAT $ npm run test -- --coverage\n\n> jest \"--coverage\"\n\n PASS  __tests__/utils/dateUtils.test.ts\n PASS  __tests__/group/groupImpl.test.ts\n PASS  __tests__/member/memberImpl.test.ts\n---------------------|---------|----------|---------|---------|-------------------\nFile                 | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s\n---------------------|---------|----------|---------|---------|-------------------\nAll files            |   98.43 |    97.62 |   96.67 |   98.37 |\n __tests__           |     100 |      100 |     100 |     100 |\n  generator.ts       |     100 |      100 |     100 |     100 |\n src/calendar        |    93.1 |      100 |   92.31 |   92.59 |\n  calendarAppImpl.ts |      60 |      100 |      50 |      60 | 6,7\n  calendarAppMock.ts |     100 |      100 |     100 |     100 |\n src/group           |     100 |      100 |     100 |     100 |\n  groupImpl.ts       |     100 |      100 |     100 |     100 |\n src/member          |     100 |    94.74 |     100 |     100 |\n  memberImpl.ts      |     100 |    94.74 |     100 |     100 | 38\n src/utils           |     100 |      100 |     100 |     100 |\n  dateUtils.ts       |     100 |      100 |     100 |     100 |\n---------------------|---------|----------|---------|---------|-------------------\n\nTest Suites: 3 passed, 3 total\nTests:       23 passed, 23 total\nSnapshots:   0 total\nTime:        2.826s, estimated 6s\nRan all test suites.\n```\n\nライブラリとして提供する機能のテストが、たったの**約 3 秒**で終わります。\n**ストレスフリー**にローカル開発が可能となりました。\n\n詳しくは、実際に作ったライブラリのソースコード([\\_\\_tests\\_\\_](https://github.com/silverbirder/CaAT/tree/master/__tests__))を御覧ください。\n\n## 終わりに\n\nGAS は、とても便利です。生産性が向上します。\nサクッと API を構築できますし、G Suite との連携も(当たり前ですが)簡単です。\n\nただ、メンテナンス性が低いコードになると、**陳腐化され誰も面倒が見れなくなります**。\n常にクリーンであり続けるためには、テストコードは**必須**です。\nGAS を運用する方々には、是非ともテストコードを検討下さい。\n\n## え、あ、ちょっとまって。ライブラリの紹介\n\nアジャイル開発で、かつ、Google Calendar で予定管理しているチームには是非とも使って頂きたいライブラリです。\n\nhttps://github.com/silverbirder/caat\n\n> CaAT is the Google Apps Script Library that Calculate the Assigned Time in Google Calendar.\n\nこのツールでできることは、次のとおりです。\n\n- 指定期間における特定ユーザーの Google Calendar で予定されている時間(分)を取得\n- 重複している予定は、連続した予定とみなす\n- 指定の時間・単語は、計算対象外とみなす (ランチなど）\n- 誰がいつ休みなのか、終日イベントから取得\n\n実際にサンプルコードがあるので、ご参考下さい。\n\nhttps://github.com/silverbirder/SampleCaat","publishedAt":"2020-02-01","slug":"thing_the_gas_testing_code","title":"Google Apps Script でも テスト がしたい！ (Clasp + Typescript + Jest)"},{"body":"## 背景\n\n普段、業務でユニットテストを書いたり、レビューをしたりしています。\nユニットテストがあることは良いことなのですが、困ったことがあります。\n\nそれは、ユニットテストのルールが明確じゃない点です。\nそのため、人によって、ユニットテストの書き方がマチマチで、なんとかしたいなと困っています。\n\n- １つのテストケースに、Assert が複数あり、散在している。\n- 似たようなテストデータの構築が、いろいろなテストケースにある。\n- テストする関数名が、パット見よくわからない。\n\n本記事では、ユニットテストを書く上で守ってほしいことをピックアップしました。\n\n## 守って欲しいこと\n\n## 1. 可読性のあるテストコード\n\n### 1.1. テストメソッド名の統一\n\nテストメソッドの命名規則は、あったほうがよいです。\nテストランナーツールの実行結果では、関数名を表示されることがあります。\nそこから『どういうテストをしていたのか』が読んで分かると、わざわざテストの中身を見る必要はありません。\n\n下記のような命名規則が良いそうです。\n\n- テスト対象のメソッドの名前。\n- それがテストされるシナリオ。\n- シナリオが呼び出されたときに想定される動作。\n\n```text\n// Bad\nTest_Single\n```\n\n```text\n// Good\nAdd_SingleNumber_ReturnsSameNumber\n```\n\n※[テストの名前付け](https://docs.microsoft.com/ja-jp/dotnet/core/testing/unit-testing-best-practices#naming-your-tests)より引用\n\n※『正しく表示されていること』という期待値は、極力避けましょう。具体的な値を期待値に設定しましょう。\n\n### 1.2. 論理制御を避ける\n\nif や for 等の制御は、テストコードの見通しが悪くなるため、極力避けましょう。\n共通化するよりも、愚直に書いたほうが読みやすいです。パフォーマンスは、そこまで気にしなくて良いですから。\n\n### 1.3. マジックナンバーを避ける\n\nプロダクトコードでは、ちゃんとマジックナンバーを避けていても、\nテストコードでは、マジックナンバーを使っていることがあります。\n横着せずに、ちゃんと適切な変数名で表現しましょう。\n\n### 1.4. テストデータを外部ファイルに切り出す\n\nテストコードを書いていると、テストに必要なテストデータの構築をする必要があります。\nテストケース毎に書いても良いですが、見通しを良くするためにテストデータを別ファイルに分けましょう。\nただ、２つ以上のテストケースで参照される場合のみにしておきましょう。\n\nテストデータは、プログラミング言語の相性に良い構造化ファイルを使うと良いです。\n\n- JSON\n- CSV\n- XML\n- YAML\n\n### 1.5. テストケースの構成を統一する\n\nテストケースは、3 つの構成で記述すると読みやすいです。\n\n- Arrange (準備)\n- Act (実行)\n- Assert (検証)\n\nこれらを上から順番に実行されるようにテストコードを書いていきましょう。\n\n```text\n// Bad\nArrange => Act => Arrange => Act => Assert\n```\n\nのように順番を Mix するよりも、\n\n```text\n// Good\nArrange => Arrange => Act => => Act => Assert\n```\n\nのように順番を揃えるほうが読みやすいです。\n\n### 1.6. １つのテストケースで複数の検証をしない\n\n１つのテストケースに、複数の検証を行ってしまうと、何のテストケースなのかわかりにくくなってしまいます。そのため、検証するのは 1 つに絞るようにしましょう。\n例外としては、コンストラクタの検証です。インスタンス化したオブジェクトの属性（プロパティ）値を検証することがあるので、その際は、複数の検証を許可します。\n\n### 1.7. テストコードは最小限に\n\nテスト対象のインスタンスに、**検証しない・不必要な**データの設定することは、余計な混乱を招くため、やめましょう。\nまた、設定するデータは、hoge などの意味のない値を設定するのではなく、本物に近いデータを設定しましょう。\n\n## 2. Matcher の活用\n\n### 2.1. 自然言語に近い形式で Assert する\n\n検証すべき変数を Boolean の形に変換し、AssertTrue することが多々あります。\nしかし、読みやすさの観点でいうと、Matcher に標準で備わっている関数を使う方が読みやすいです。\n\n```text\n// Bad\nassertTrue(actual.contains('hello'))\n```\n\n```text\n// Good\nassertThat(actual, hasItems('hello'))\n-> assert that actual has items \"hello\".\n```\n\n### 2.2. 変数名をわかりやすくする\n\nテストコードを書くときは、期待する値を Expect, 実際の値を Actual という\n変数名にしましょう。そうすると、何を検証しているのかわかりやすくなります。\n\nまた、モックやスタブ、スパイと言ったテストコードでよく出てくる用語を変数名で使用する際、きちんと使い分けをしましょう。モックという変数名なのに、実際はスタブのような使い方をしていると、誤解を招いて困ります。\n\n## 3. テストパターン\n\n### 3.1. ホワイトボックステストとブラックボックステスト\n\nテストコードを書いている人は、基本的には内部仕様を把握しているはずなので、ホワイトボックスでテストを書くことが多いと思います。\nまた、網羅性を高めるために、パラメータテスト（組み合わせテスト）や、同値、境界値のようなブラックボックステストも書くのも良いでしょう。\n\n### 3.2. 正常・準正常・異常系\n\n| 種類           | 内容                                         |\n| -------------- | -------------------------------------------- |\n| 正常系テスト   | 標準的な振る舞いをテスト                     |\n| 準正常系テスト | バリデーションエラー等のエラーに対するテスト |\n| 異常系テスト   | API 接続エラー等のエラーに対するテスト       |\n\n### 3.3. Fail のテスト\n\nテストコードに、予期しない処理が走った場合、強制的に Fail にさせることも大切です。\n例えば、『非推奨な機能が使用された場合、Fail にさせる』は便利です。\n\n### 3.4. private メソッドの検証\n\nprivate メソッドの検証は、public メソッド経由で検証しましょう。\n\n## 4. 大量にあるテストコード\n\n### 4.1. プロダクトコードと同じ階層構造\n\nプロダクトコードと同様に、テストコードもフォルダ毎にグループピングすると良いでしょう。\n横並びにテストコードがあると、読みにくくなるからです。\n\n例えば、プロダクトコードと全く同じ階層構造のフォルダ構成にすると良いかも知れません。\n\n### 4.2. 単位を分けたテストコード\n\n次のような単位でグルーピングすると良いです。\n\n- 初期化処理を含めた単位でグループ化\n  - ex. 在庫している商品が\"空\"の場合、 \"1 つ\"だけの場合、 \"複数\"の場合\n\nよくあるテストクラスを継承してテストクラスを作るケースがありますが、避けたほうがよいでしょう。いつの間にか、必要以上の巨大な機能が備わってしまっています。Setup や Teardown に、必要な処理をセットしましょう。\n\n### 4.3. テスト実行時間が長くなってしまったら\n\n下記のいずれかを試すと良いでしょう。\n\n- テストの実行環境を強化する（マシンスペック）\n- 並列にする\n- 実行するテストを絞り込む\n\nそもそものプロダクトコードのパフォーマンスが悪いのであれば、そちらを改善するのが一番良いでしょう。\n\n## 終わりに\n\n書いていて、感じたことは『テストコードは、読みやすさが大事』という点です。\nプロダクトコードの書き方と、テストコードの書き方は、似ているようで違います。\nプロダクトコードでは、保守性の高い洗練されたクラス設計や、ハイパフォーマンスが発揮される処理が求められることがあります。しかし、テストコードはそれらを求められていないと思います。\n\nテストコードには、プロダクトコードの仕様を**素直に表現されたドキュメント**として扱われるべきです。\n意図が伝わりづらいテストコードがあった場合、『このテストケースが落ちているけど、なんで？』と疑問を持ち、『落ちているのが正しいの？』と疑心暗鬼に陥ってしまいます。それはとても残念です。そんなことにならないためにも、テストコードは、『読みやすさ』を大切にして設計すべきと思います。\n\n## 参考文献\n\n- [JUnit 実践入門 ~体系的に学ぶユニットテストの技法 (WEB+DB PRESS plus)](https://www.amazon.co.jp/dp/477415377X)\n- [.NET Core と .NET Standard での単体テストのベスト プラクティス](https://docs.microsoft.com/ja-jp/dotnet/core/testing/unit-testing-best-practices)","publishedAt":"2020-01-12","slug":"things_to_keep_in_writing_unit_tests","title":"ユニットテストを書く上で守りたいこと"},{"body":"## TL;DR\n\n1. Docker コンテナ上で、 `ts-node-dev --inspect=0.0.0.0:9229 ./dist/index.js` を実行\n\n![ts-node-dev](https://res.cloudinary.com/silverbirder/image/upload/v1614345272/silver-birder.github.io/blog/ts-node-dev.png)\n\n1. IntelliJ 上で、`Attach to Node.js/Chrome` を実行\n\n`Run > Edit Configuration ... > +ボタン > Attach to Node.js/Chrome`\n\n![Attach to Node.js/Chrome](https://res.cloudinary.com/silverbirder/image/upload/v1614345318/silver-birder.github.io/blog/Attach_to_Node_js_Chrome.png)\n\n1. IntelliJ 上で BreakPoint を貼り、ブラウザにアクセス\n\n![IntelliJ Breakpoint](https://res.cloudinary.com/silverbirder/image/upload/v1614345359/silver-birder.github.io/blog/IntelliJ_Breakpoint.png)\n\n※ Docker コンテナでは、アプリ用ポート(8080)と、inspect 用ポート(9229)を開放する必要あり\n\n![8080と9229portの開放](https://res.cloudinary.com/silverbirder/image/upload/v1614345390/silver-birder.github.io/blog/8080%E3%81%A89229port%E3%81%AE%E9%96%8B%E6%94%BE.png)","publishedAt":"2019-12-28","slug":"intelliJ_typescript_docker_remote_debug","title":"IntelliJ + TypeScript + Docker で Remote Debug (Break Point)"},{"body":"## まえおき\n\nこれから iOS を前提として話を進めていきますが、話の主題としては iOS かどうかはあまり関係ありません。\n\n## NFC Automation Trigger\n\n[13.1 の iOS リリース](https://support.apple.com/ja-jp/HT210393#131)により NFC Automation Trigger が使えるようになりました。NFC とは、Wiki によると次のようなものです。\n\n> 狭義には Near field communication（NFC）の訳語。NFC は RFID（Radio Frequency IDentification）と呼ばれる無線通信による個体識別の技術の一種で、近距離の無線通信技術を統一化した世界共通の規格である。IC チップを内蔵した NFC タグを NFC のリーダ・ライタ機能を有する機器で読み取ったり書き込んだりする。\n\n※ https://ja.wikipedia.org/wiki/近距離無線通信\n\n有名なものとしては、[モバイル Suica](https://www.jreast.co.jp/mobilesuica/index.html/)でしょうか。AppleWatch がリーダ機として扱われます。\n\n![apple_watch_suica](https://res.cloudinary.com/silverbirder/image/upload/v1614345501/silver-birder.github.io/blog/apple_watch_suica.jpg)\n\n今回のリリースである NFC Automation Trigger は、この NFC を読み込むと自動的に特定のアクションを Trigger することができます。\n例えば、特定の NFC タグを iPhone が読み取ると、3 分のタイマーが起動する！とか。ま、表題の件を用意したんですけどね！（笑）\n\n## とりあえずこんなの作ったよ\n\n登録している NFC タグを iPhone が読み取ると、扉に設置しているスマートロックアイテム SESAME の[SESAME API](https://docs.candyhouse.co/#sesame-api)を Request して扉の鍵が解錠されます。\n\n![sesame_nfc_before](https://res.cloudinary.com/silverbirder/image/upload/v1614345607/silver-birder.github.io/blog/sesame_nfc_before.png)\n\n↓ 白色の NFC タグにスマホを近づけると...?\n\n![sesame_nfc_after](https://res.cloudinary.com/silverbirder/image/upload/v1614345642/silver-birder.github.io/blog/sesame_nfc_after.png)\n\nNFC Automation Trigger が作動！解錠！\n\nhttps://twitter.com/silverbirder/status/1187016726363299840\n\n作成方法は、とっても**かんたん**です。iPhone 標準アプリ shortcut と、[NFC タグ(１枚 94 円)](https://www.amazon.co.jp/gp/product/B00GXSGL5G/)があれば誰でも作れます。もちろん、**[SESAME](https://www.amazon.co.jp/dp/B0787N1L3M)**が必要ですけどね（笑)。\n\nshortcut で、次の準備をしました。\n\n1. [RESTfulAPI のショートカット](https://support.apple.com/ja-jp/guide/shortcuts/apd58d46713f/ios)を使って[SESAME API](https://docs.candyhouse.co/#sesame-api)を設定する。\n1. [個人用オートメーション](https://reliphone.jp/nfc-automation/)を作成し、用意した NFC タグをスキャンする。\n1. 2 のオートメーションを 1 のショートカットと紐付ける。\n\nこれの良いところは、次の２点でしょうか。\n\n- 標準アプリだけで完結\n- NFC タグ自体には何も加工しないため安全\n\n※ SESAME には、扉に近づいたら解錠する**[手ぶら解錠](https://jp.candyhouse.co/blogs/how-to/%E6%89%8B%E3%81%B6%E3%82%89%E8%A7%A3%E9%8C%A0%E6%A9%9F%E8%83%BD-%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B)**や、スマホをノックするだけで解錠する**[ノック解錠](https://jp.candyhouse.co/blogs/how-to/%E3%83%8E%E3%83%83%E3%82%AF%E6%A9%9F%E8%83%BD%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B)**というものがあります。本来は、これを使いたかったのですが精度が低いため実用性に欠けると思っています。\n\n## 考察\n\nこの NFC Automation Trigger は、アイデア次第でいくらでも、便利なことができます。\n今回の目的は 「**個人利用**で、**ライフハック**できるものを作りたい」というものです。\n\nただ正直、iPhone をわざわざ NFC に近づける動作は**面倒**だと思います。\n\n私の部屋には[VUI](https://en.wikipedia.org/wiki/Voice_user_interface)として[GoogleHome](https://store.google.com/jp/product/google_home_mini)があり、スマートリモコンの[NatureRemo](https://nature.global/)や、物理ボタン自動化の[SwitchBot](https://www.switchbot.jp/)、コンセントのスマート化[TP-Link](https://www.amazon.co.jp/dp/B078HSBNMT/)などが GoogleHome と連携しています。\n手で操作するよりも、声で操作する方が、数ステップですが**遥かに効率的**と感じます。\n\nつまり、VUI で管理できている空間に関しては、NFC の Trigger はあまり役立ちはしないのかなと思っています。逆に、**VUI の管理外の空間**、私の部屋でいうと、トイレとか洗面台、玄関には NFC が役立つかもしれません。また、**声を発するのが躊躇われる環境**においても、NFC の方が役立つと思っています。\n\n外の環境では、どうでしょうか。NFC を貼れる場所なので、限定はされます。\n自宅の郵便ポスト、自転車・車、衣類、カバン、傘、学校や職場のマイ机・椅子とかでしょうか。\n[NFC タグ(１枚 94 円)](https://www.amazon.co.jp/gp/product/B00GXSGL5G/)は、シールのように柔らかいので、コップやボールにも貼れると思います。[アマゾンダッシュボタン](https://ja.wikipedia.org/wiki/Amazon_Dash)が一時流行っていましたが、あれと似たようなこともできます。例えば、「トイレットペーパの入れ物に NFC タグを貼っておいて、なくなりそうになったら NFC タグを読み込んで注文する」みたいな。もちろん、注文する処理は、自前で組む必要がありますよ。アマゾン定期注文には向いていないものには、良いかもですね。\n\nさらに、shortcut では**変数を注入できる**ため、例えば、現在地を NFC トリガーに注入することで、\n「現在地から自宅までのタクシーを予約する」NFC トリガーもできちゃいます。\n\n個人利用という括りであっても、NFC Automation Trigger の使い道はとても多いと思います。\n商用利用と考えると、更にあると思いますが、省略します。\n\n## さいごに\n\nNFC Automation Trigger という機能は、珍しくありません。\nしかし、とても使いやすくカスタマイズ性が高いため、アイデア次第でいくらでも化けれます。\n一攫千金？を目指すのも良いですが、やっぱり**ライフハック**をつきつめたいなと思う私でした。","publishedAt":"2019-12-28","slug":"nfc_automation_trigger_sesame_api","title":"NFC Automation Trigger + SESAME API による自動解錠と考察"},{"body":"GDG DevFest Tokyo 2019 というイベントに参加してきました。\n最近はプライベートの都合上、中々時間が取れていませんでした。\nしかし今回、会社の都合上、良い感じに時間を確保できたため、こちらのイベントに参加してきました。\n`大阪→東京` でわざわざ新幹線を使ってまで参加しましたが、それに見合う発見が多くありました。\n今回、私が学んだ内容について、報告しようかなと思います。\n\n![GDG DevFest Tokyo 2019 スポンサー](https://res.cloudinary.com/silverbirder/image/upload/v1614429063/silver-birder.github.io/blog/GDG_DevFest_Tokyo_2019_Sponsor.jpg)\n\n![GDG DevFest Tokyo 2019 提灯](https://res.cloudinary.com/silverbirder/image/upload/v1614429118/silver-birder.github.io/blog/GDG_DevFest_Tokyo_2019_Lantern.jpg)\n\nhttps://gdg-tokyo.connpass.com/event/137666/\n\n## GDG DevFest Tokyo 2019\n\n> DevFest は、Google Developer Group (GDG) コミュニティによって世界各地で開かれるデベロッパー向けイベントです。東京では、Android、Google Cloud Platform（GCP）、Web、Firebase、Machine Learning （ML）、Assistant、Flutter、Go といった様々な技術の最新情報や現場でのノウハウを一日で学べるコミュニティイベントとして開催しています。去年に引き続き 4 回目の開催となります。\n\nhttps://tokyo.gdgjapan.org/devfest2019\n\n| 名称                                        | GDG DevFest Tokyo 2019                                                                                                                                                                                   |\n| ------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| DevFest Day1 / 2019 年 12 月 14 日（土） | Sessions、Codelab、After Party / 11:00 開始（開場 10:30 予定）18:00 終了 / ※終了後、懇親会パーティ開催します。 / 開催場所：国立大学法人電気通信大学 / 〒 182-8585 東京都調布市調布ヶ丘 1-5-1 |\n| DevFest Day1 / 2019 年 12 月 15 日（日） | Special Hands-on、Office Tour / 14:00 〜 17:00 予定 / ※14 日にご参加いただいた方の中から抽選で 100 名ご招待 / 開催場所：Google Japan / 〒 150-0002 東京都渋谷区渋谷 3 丁目 21−3              |\n\n私は、DevFest Day1 のみの参加でした。\n開催場所は、**電気通信大学**です。スタッフさんの多くは学生さんだったと思います。積極的にサポートされていた姿は、立派だなと勉強になりました。\n\n## DevFests\n\n> DevFests are community-led developer events hosted by Google Developer Groups around the globe. GDGs are focused on community building and learning about Google’s technologies.\n\nhttps://devfest.withgoogle.com/\n\nDevFests 自体は、グローバルで活動されている GDG がホストのイベントです。\n下の図は、**2019 年**の活動実績&予定です。全国各地で広く活発的に行われていることが分かると思います。\n\n![Find an upcoming community-led DevFest near yo](https://res.cloudinary.com/silverbirder/image/upload/v1614428965/silver-birder.github.io/blog/find_an_upcoming_community-led_dev_fest_near_yo.png)\n\nまた、コミュニティの Youtube のチャンネルもあります。\n\nhttps://www.youtube.com/channel/UCXDc-ckqru8BgppXbCt0APw\n\n動画には、文字起こしとして 英語(自動生成)だけでなく、 **英語(CC)** もあります。\n英語のリスニングが苦手な人でも、文字から理解できるようになっています。こういう配慮はさすがですね。\n\n## Google Developer Experts (GDE)\n\n今回登壇されている方の多くが、 **Google Developer Experts (GDE)** という言葉を仰っていました。\n最初は『Google 社内の何かしらのポジションか？』と思っていましたが、違っていました。\n\n> A global program to recognize individuals who are experts and thought leaders in one or more Google technologies. These professionals actively contribute and support the developer and startup ecosystems around the world, helping them build and launch highly innovative apps.\n\nhttps://developers.google.com/community/experts\n\nGDE の人は、端的に言うと『Google のテクノロジを開発者やスタートアップ企業らに対して支援・啓蒙活動をしている Google 外の人』です。\nGDE になるためには、Google、Google パートナーからの紹介から入る必要があるそうです。\n\n## Sessions\n\n今回のセッションでは、次のようなカテゴリでグループ分けされていました。\n\n- Android\n- Assistant\n- Cloud\n- Design\n- Firebase\n- Flutter\n- Go\n- ML\n- Web\n- misc (other かな)\n\n私は、Web が好きな人なので、そのカテゴリを積極的に選んでいきました。\n\n## Keynote2: 円周率世界記録への道\n\nSpeaker: 岩尾 エマ はるかさん\n\nこちらの記事が、今回の話のテーマとなります。\n\nhttps://it.srad.jp/story/19/03/17/043207/\n\n岩尾 エマ はるかさんのお話は、おおよそ[Wiki](https://en.wikipedia.org/wiki/Emma_Haruka_Iwao)に記載があるとおりです。\n\n今回の発表の話にあった、以下の話が印象的でした。\n\n- Linkedin 経由で Google からのオファーがあり、『５回面接をして、ようやく合格した』\n\n岩尾さんは、『面接するのは無料』という精神で、何度も Try し続けて合格を勝ち取った人です。同じ大阪出身だそうで、納得しました。（笑）\n\nまた、元々英語は得意な方ではなかったという話も紹介されていました。\n私も英語について悩んでおり、とても共感する部分が多かったです。\n`英語ができることによって、選択肢は広がる` という当たり前の話があったのですが、\n『語学が苦手だけど、Google(海外)で勤務できるようになった』という岩尾さんの経歴を知ると、頑張ってみようと思えました。\nとても感謝しています。\n\n## Chrome Dev Summit 2019: Recap\n\nSpeaker: 矢倉 眞隆さん\n\nChrome Dev Summit(CDS) は、今まで以下のようなテーマが中心でした。\n\n- 2013\n  - Web API, パフォーマンス\n- 2015\n  - PWA\n\nそして、今回の CDS では今までの **ゴリゴリの JS** 話から少し外れたものもいくつかあり、\nその紹介をされていました。\n\n### HTML と CSS\n\n#### HTML isn't done\n\nhttps://www.youtube.com/watch?v=ZFvPLrKZywA\n\nHTML は、まだ成熟されたものではなく、まだまだ改善の余地があるという考えから、\nいくつかの改善提案の話が紹介されていました。\n\n丸裸な純粋の HTML でも、わかりやすい UI を標準で表現できるのであれば、ユーザーにとっては\nありがたいことですよね。だって、いろんなサイトのいろんな UI を知らなくて済むのですから。\n個人的(開発者)には、Edge が Chromium ベースになることが、とても嬉しいです。\nリリースが 2020 年 1 月 15 日だそうなので、もう間もなくですね。\n\n#### Next-generation web styling\n\nhttps://www.youtube.com/watch?v=-oyeaIirVC0\n\nscroll-snap という機能は、スクロールの制御を CSS で実現しようとしています。\n従来は、Javascript でハックな技を駆使していましたが、不要となります。\nデザイナーだけでなく、JS を担当するエンジニアも必見です。\n\n### JS +SEO\n\nSEO の話がありました。\n\nhttps://www.suzukikenichi.com/blog/how-to-make-your-content-shine-on-google-search/\n\nGooglebot が最新の Chromium ベースになったことで、Chrome でブラウザを動かすのと同じような振る舞いになるそうです。\n今までは、Chrome 41 ベースで Googlebot が動いていたため、新しい JavaScript 構文やブラウザ API を使えなかったそうです。\nまた、ShadowDOM にも対応しているので、これは WebComponents を推進していることになるのでしょうか。\n\n### リアルワールド指向のパフォーマンス\n\n開発環境で Javascript を動かしたとしても、本番環境で動かすと実は遅かったりします。\nそれは、Javascript による処理が複雑化していることも要因となります。\nこの現象は、ネットワーク通信が悪い環境（海外）であれば、より明確に実感するはずです。\nこのようなケースを考慮したテスト環境が必要なのではないかと、私は思います。\n\n以下の記事にある通り、Google は「遅い」と感じるページに警告を出してくれます。\n\nhttps://jp.techcrunch.com/2019/11/12/2019-11-11-google-chrome-to-identify-and-label-slow-websites/\n\nパフォーマンス計測ツールを活用することで、事前に確認しておきましょう。\n\n- web.dev\n- PageSpeed Insights\n- Lighthouse\n\nまた、Javascript をシングルスレッドによる低パフォーマンスに対するアプローチ方法を紹介されていました。\n\nhttps://www.youtube.com/watch?v=7Rrv9qFMWNM\n\n詳しくは、下記をご参考下さい。\n\nhttps://medium.com/lazy-learning/my-summary-of-the-main-thread-is-overworked-underpaid-chrome-dev-summit-2019-cd65efdf1ce1\n\n## ネイティブアプリと Web アプリの差を埋めるには：Project Fugu とマルチスレッドプログラミング\n\nSpeaker: 清水 智公さん\n\n### ネイティブアプリと Web アプリの差\n\nWeb アプリは、ブラウザ上で動作するのものです。ブラウザから提供されている API を通して、Web アプリを構築します。\nしかし、ブラウザからマシンのネイティブな部分、例えばマシンにあるファイルにアクセスしたり、ファイルをマシンに\n保存したりする操作はできません。この制限は、ブラウザが安全性を担保するためのトレードオフであり、仕方がありません。\n\n### Project Fugu\n\n> Fugu’s mission is to close the capabilities gap with native to enable developers to build new experiences on the web while preserving everything that is great about the web.\n\nhttps://www.chromium.org/teams/web-capabilities-fugu\n\nProject Fugu とは、ネイティブとのギャップを縮めるために、(Chrome)ブラウザからネイティブな部分を操作する試みのプロジェクトのことです。\nネイティブ部分を操作するため、誤った使い方をするととても危険です。\nそのような危険性を、『毒』を持つふぐの名前を借りて Project Fugu というそうです。\n\n提案中の機能一覧は、下記のシートになります。\n\nhttp://goo.gle/fugu-api-tracker\n\nこの中には、例えば『Contact Picker API』というものがあります。\n名前の通り、ネイティブアプリに登録されている電話帳にアクセスできるようになります。\nこれにより、例えば『シェアしたいユーザーの情報を電話帳より取得する』ことが実現できます。\n\n### Worker\n\nブラウザは、Task(Event→Scripting→Rendering→Painting)という単位で動作します。\nこれは、1 つのメインスレッドのみで動作します。\n\nブラウザにおける fps の目標値は 60fps だそうです。\n\n> 60fps のフレームレートがなめらかなパフォーマンスの目標値であり、あるイベントに対して必要なすべての更新に与えられた時間は 16.7 ミリ秒です。\n\nhttps://developer.mozilla.org/ja/docs/Tools/Performance/Frame_rate\n\n1Task を実行するのに 16.7 ミリ秒を超えてしまうと、ガタガタした動作になってしまいます。\nそこで、Web Worker という技術で解決しようと考えました。\n\n> Web Worker は、ウェブコンテンツがスクリプトをバックグラウンドのスレッドで実行するためのシンプルな手段です。\n\nhttps://developer.mozilla.org/ja/docs/Web/API/Web_Workers_API/Using_web_workers\n\nしかし、スレッド間のメッセージパッシングが複雑化してしまう問題があるそうです。\nその問題を、さらに解決するため、GoogleChromeLabs は、comlink なるライブラリを開発しました。\n\n> Comlink makes WebWorkers enjoyable. Comlink is a tiny library (1.1kB), that removes the mental barrier of thinking about postMessage and hides the fact that you are working with workers.\n\nhttps://github.com/GoogleChromeLabs/comlink\n\nWeb Worker におけるメッセージパッシングの複雑さが comlink によって減少するそうです。\n\n※ atomics.wait() atomics.notify()の話もありました。\n\n## How to Distribute Your Web App? 「インストール」可能なウェブアプリ\n\nSpeaker: 宍戸 俊哉さん  \nタイトル通り、Web アプリをどのようにして配布するのかというテーマで、\n様々な手段の紹介をされていました。\n\n### PWA\n\nWeb 好きならご存知の Progressive Web App (PWA)のお話です。\nWeb アプリに対して、よくある PWA 機能は次のとおりです。\n\n- オフラインで閲覧\n- Push 通知\n- フルスクリーン\n\nPWA は、Web アプリでありながら、ネイティブアプリにとても近い存在に位置しています。\n\n例えば、サンタトラッカーという Web アプリがとても良い例です。\n\nhttps://santatracker.google.com/\n\nソースコードも公開されており、PWA として良い参考例になります。\n\nhttps://github.com/google/santa-tracker-web\n\nこの Web アプリを『ホーム画面に追加』し、その追加されたアプリを起動してみて下さい。\nネイティブアプリと似たユーザー体験ができるはずです。\n\n### ブラウザのブックマークで良いのでは\n\nわざわざ『ホーム画面に追加』しなくても、ブックマークを使えばよいのでは？\nという議論がありました。\n話の主となっていたのは、モバイルファーストというキーワードでした。\n現在、モバイルからのブックマーク利用率はとても小さいみたいですが、\n『え？普通に利用しているけど』と反感してしまいました。私が遅れているのでしょうか。\n今の時代、『ホーム画面に追加』が多いのでしょうか。少し疑問です。\n\n### インストールを促す手段\n\nPWA をインストールしてもらう場合、Mini-infobar というもので誘導します。\nただ、この Mini-infobar はヘルパーとして使われるため、別途 UI を用意する必要があるそうです。\n\n> The mini-infobar is only meant as a helper, and it will go away in the future.\n\nhttps://developers.google.com/web/fundamentals/app-install-banners/promoting-install-mobile\n\nただ、既にネイティブアプリがある場合、PWA のインストール要求したくありません。\nそんなときは、『既にネイティブアプリをインストールしているかどうか』判断する仕組みが既にあるそうです。(origin trials)\n\nhttps://web.dev/get-installed-related-apps/\n\n### Desktop PWA\n\nモバイルだけでなく、Desktop にも PWA を適用できます。\n\n先程紹介したサンタトラッカーは、Desktop PWA にも対応しています。\n\nhttps://santatracker.google.com/\n\nアドレスバーにある+ボタンよりインストールできます。\n\n### Trusted Web Activities (TWA)\n\n> Trusted Web Activity は、Android アプリ内で Chrome ブラウザを全画面で実行します。\n\nhttps://developers-jp.googleblog.com/2019/03/trusted-web-activity.html\n\nAndroid アプリでも、PWA が実現できるみたいです。\n\n> TWA は、Android アプリの全画面ウェブ コンテンツで WebView では利用できない Chrome 機能を使いたい場合や、Chrome ブラウザとオリジン ストレージを共有することでユーザーのナビゲーションが便利になる場合などに適しています。\n\n私は Android ユーザーはないので、GooglePlay からアプリをダウンロードできません。\n\n- Rakuten Pasha\n- OYO Rooms\n\nのようなものが TWA 対応しているそうです。\n会社内で使うアプリ(勤怠, 経費, etc)を、TWA として配信することも１つの使い道と紹介されていました。\n\nTWA の開発には、次のライブラリが便利だそうです。\n\nhttps://github.com/GoogleChromeLabs/llama-pack\n\n### Web Packaging\n\nPWA や Destop PWA, TWA といったもので、様々なところから Web アプリを\n配布する手段が増えました。では、オフラインの場合はどうでしょうか。\nその場合は、Web Packaging の Web Bundles が使えます。\n\nhttps://github.com/WICG/webpackage\n\nWeb Packaging には、大きく２つのものが含まれています。\n\n- Signed HTTP exchanges\n- Web Bundles\n\n前者は、AMP ページの URL を google ホストから元のホストへ戻す際に有効だそうです。\n\nhttps://amp.dev/documentation/guides-and-tutorials/optimize-and-measure/signed-exchange/\n\n後者は、Web のアプリケーションを人まとまりにし、オフライン上で提供することができるそうです。\n\nhttps://www.youtube.com/watch?v=xAujz66la3Y\n\n※ chrome canary フラグを有効化する必要あり\n\n## Yearly Web 2019\n\nSpeaker: Jxck さん  \n2019 に起きた Web に関する Topic をざっくりと紹介されていました。\n[ご本人のブログ](https://blog.jxck.io)に、詳細が載っていますので、こちらでは項目だけリストアップします。\n\n| Topics                          | 補足                                              |\n| ------------------------------- | ------------------------------------------------- |\n| Dark Mode, High Contrast Mode   |                                                   |\n| portal tag                      | 画面遷移を CSS でアレンジするアレ。まだバグが多い |\n| WebAssembly                     |                                                   |\n| WebAuthN                        | Authenticator を使った認証 API                    |\n| ES2019                          | nullish coalescing/ optional chaining             |\n| Intelligent Tracking Prevention | 合意のないトラッキングはダメ!ゼッタイ!            |\n| Project Fugu                    |                                                   |\n| DNS over HTTPS/TLS              | DNS クエリも暗号化                                |\n| Edge Chromium                   |                                                   |\n| WebPackaging                    |                                                   |\n| WebTransport WebCodecs          | ゲームで役立つ?                                   |\n| WebComponents v0 → v1           |                                                   |\n| Same Site Cookie Lax by default | Cookie を同じサイトでしか送られなくする           |\n| TLS 1.0/1.1 → 1.2               |                                                   |\n\n## Perspective of Angular in 2020\n\nSpeaker:稲富 駿さん\n\nセッション内容は、Angular における 2019 年のアップデート内容と、2020 年とその先の未来についてです。\n\n以下を要チェック！\n\n- [dev.to/angular-jp](https://dev.to/angular-jp)\n- [community.angular.jp](https://community.angular.jp/)\n\nちなみに、私は Augular の v2 で止まっています。（笑）\n\n### Updates in 2019\n\nAngular の価値(values)は、\n\n- Apps That users to use\n- Apps That developers to use\n- Community where everyone feels welcome\n\nという 3 点あるそうです。私にとっては、v2 へのアップデートで大変つらい記憶がありますが...。\n\n2019 年,2020 年における Angular のバージョンは、\n\n- 2019-05\n  - v7.x\n  - v8.x\n- 2020-Q1\n  - v9.x\n- 2020-Q3\n  - v10.x\n\nこうみると、メジャーアップデートの更新がとても早いですね。\n追いつくのが大変そうです。\n\n#### v7.x\n\n- Size Budgets by default\n  - バンドル時のサイズを制限する機能\n  - パフォーマンス向上を期待\n- CDK Drag&Drop\n  - 手軽に Drag&Drop を実行可能\n- Virtual Scroll\n  - 画面に見えているものだけ DOM 構築される\n  - パフォーマンス向上を期待\n- Bazel\n  - gulp のようなビルドシステム\n  - Opt-in support\n\n#### v8.x\n\n- Differential Loading by Default\n  - ブラウザによって、polyfill の量をコントロール\n  - レガシーの部分はそのまま。モダンブラウザの polyfill の量が削減\n  - パフォーマンス向上を期待\n- Dynamic Import for Lazy Loading\n- Support Module Web Worker\n- ng deploy\n  - production build していない deploy が多くなかった。\n  - かならず --prod となる。\n\n主にパフォーマンス向上に取り組んだ 1 年だったそうです。\nAngular は All-in-One なフレームワークなため、どうしてもアプリケーションのコード量が\n他フレームワークに比べると多いと思います。そうすると、アプリケーションを読み込む際に、\n必要以上にロードされ、パフォーマンスが問題視されていたのでしょうか。\n\n### Roadmap 2020\n\n2020 年の Angular はどんなものになるのか、紹介されていました。\n\n#### v9.x\n\n- Ivy by Default\n  - Ivy は、angular の次世代コンパイラだそうです\n- CDK Clipboard API\n- CDK Testing Harness\n  - コンポーネントのテストをより抽象化\n  - await 処理が簡単になった\n- @angular/components\n- Strict Type -checking in templates\n\n2019 年はパフォーマンスというユーザーのための取り組みで、\n2020 年は開発者向けの取り組みが多いという印象でした。\n\n### Imagine the Future\n\n今までの Angular は、エンタープライズ向けのアプリや、\n小規模のアプリに使われていました。\n\n次は、Billion のユーザ向けアプリをターゲットにするそうです。\nそのためには、そのアプリに寄り添った機能提供ができるようにと考えているみたいです。\n例えば、SEO やアクセシビリティ、国際化といった観点です。\n\n## 終わりに\n\nWeb の進化は早いなと実感した濃い一日でした。\n吸収しすぎて、消化が追いつかないですね、ワクワクが止まらないです。\n\nGDE の方々は、どの方も専門領域がとても詳しく、かつ、説明の仕方が上手という印象を持ちました。\n私も GDE になってみたいので、得意分野を見つけるところから始めようと思います。\n\nまた来年 GDG イベントありましたら、参加したいなと思います！","publishedAt":"2019-12-16","slug":"gdg_devfest_tokyo_2019_web","title":"GDG DevFest Tokyo 2019に参加したら、Webの未来にワクワクした"},{"body":"CircleCI と BackstopJS を組み合わせて、『継続的に Web ページの視覚的な変化を監視するツール』を作成しました。\n\nhttps://github.com/silverbirder/silver-enigma\n\n## Motivation\n\nWeb アプリを運用する上で、システム改善は継続的に行われます。\nそのシステム改善をリリースする前に、入念なテスト（ユニットテスト、インテグレーションテスト、E2E テスト）をパスする必要があります。しかし、Web アプリの規模が大きくなるにつれて、**意図せずデグレ**が発生してしまう可能性が大きくなります。\nそのデグレを気づくのが『社内部指摘』なのか『エンドユーザからのお問い合わせ』からなのか分かりません。\nそこで、**Web アプリを定期的に監視すること**で、予想外なデグレッションを早期に発見できる仕組みが欲しくなりました。\n\n必要とする要件は、次のとおりです。\n\n- スケジューリング実行可能\n  - 無料で使えること\n- わかりやすい視覚的変化のレポート\n- カスタマイズしやすい監視方法\n\nここから、CircleCI + BackstopJS(Puppeteer)という組み合わせが生まれました。\n\n## Usage\n\n次の手順で構築できます。\n\n```shell\n~ $ node -v\nv12.9.1\n```\n\n1. backstop.json に監視したい URL を設定\n1. CircleCI に必要な環境変数を設定([README.md](https://github.com/silverbirder/silver-enigma/blob/master/README.md)参照)\n1. CircleCI で Job を実行し、Artifacts にあるレポートを閲覧\n\nPuppeteer を使って Web アプリへリクエストしています。\nそのため、『Javascript を無効にする』や『Cookie を設定する』といったニーズに対応できます。\n\n## Conclusion\n\nこのツールにより、外部から Web アプリの変化を早期に発見できるようになりました。\nただし、リクエストするスケジューリング間隔には十分にお気をつけください。\nリクエストをしすぎると、対象 Web アプリの負荷が高まってしまいます。","publishedAt":"2019-11-15","slug":"circle_ci_backstop_visual_regression_testing","title":"CircleCI + BackstopJS (Puppeteer) でビジュアルリグレッションテストを継続的に監視する"},{"body":"2019 年 10 月 11 日~2019 年 10 月 15 日の 5 日間、フィリピンに行ってきました。日本人男性(前職の先輩:Kikuchi)とフィリピン人女性が結婚するため、その結婚式旅行に同伴させて頂きました。Kikuchi さんとは、私が新人の頃に大変お世話になった方なので、お祝いの気持ちが込み上げてきました。:)\n\n![schedule](https://res.cloudinary.com/silverbirder/image/upload/v1614410969/silver-birder.github.io/blog/philippines_schedule.png)\n\n**はじめての海外旅行**だったので、当日までわくわくな気持ちでいっぱいでした。ただ…あれ(↓)を知るまでは…\n\n## フィリピン式トイレ\n\nフィリピン式トイレ！ 😰 拭き終わったトイレットペーパーをゴミ箱に捨てるだと！？ 😠 💩 信じられない…😵\n\n![Philippine Toilet](https://res.cloudinary.com/silverbirder/image/upload/v1614411005/silver-birder.github.io/blog/philippines_toilet.png)\n\nPhilippine Toilet もう駄目です、先輩。僕は行けません。僕は潔癖症なんです。あと、お腹が弱いんです…。けど、いくしかない…。\n\n## いざ、フィリピンへ\n\n![Cebu](https://res.cloudinary.com/silverbirder/image/upload/v1614411074/silver-birder.github.io/blog/philippines_cebu.jpg)\n\n1 日目、セブに到着したときには、すっかり夜でした。\n\nここで**ヤバい**社会に遭遇しました。道路です。車やバイクがガンガンに走ってきます。信号はほぼありません。**譲り合いの精神は、ほぼない**と感じるほどでした。関西人の強引さを最大限まで高めた人たちって感じです。\n\n特にバイクが多く、二人乗りが多かったです。中には、4 人家族(父・母・子 2 人)で１つのバイクを運転していました。生活上仕方がないとは言え、日本に比べると、とても危険です。\n\n![Ayala Center, Cebu](https://res.cloudinary.com/silverbirder/image/upload/v1614411121/silver-birder.github.io/blog/philippines_ayala_center_cebu.jpg)\n\nショッピングセンターにきました。とてもおしゃれ（語彙力）なイルミネーションです。\n\n![Kare Kare, Ayala CenterKare](https://res.cloudinary.com/silverbirder/image/upload/v1614411188/silver-birder.github.io/blog/philippines_kare_kare_ayala_center.jpg)\n\nKare という料理がフィリピン料理で有名です。晩ごはんに注文してみました。\n衝撃的に口に合わなかったです…。\n一緒に来ていた人が Kare Kare を味見して「**土**食べてるの？」と言われました…。これが本来の味なのか、お店独自のアレンジなのか分かりません。\n\n1 日目のホテルは、トイレットペーパーを流しても良いトイレでした。 😍\n\n## 2 日目の朝、散歩しました\n\n![Glass on the wall, Cebu](https://res.cloudinary.com/silverbirder/image/upload/v1614411240/silver-birder.github.io/blog/philippines_glass_on_the_wall_cebu.jpg)\n\n夜には見えなかったのですが、壁にガラスが刺さっていました。登り防止のようです。なんというか斬新です。\n\n![Move from Cebu to Bohol by ferry](https://res.cloudinary.com/silverbirder/image/upload/v1614411308/silver-birder.github.io/blog/move_from_cebu_to_bohol_by_ferry.jpg)\n\nフィリピン人女性の実家であるボホール（タグビララン）へフェリーで移動。\n小型（中型？）のフェリーだったため、とっても揺れました。あと、外の潮風が気持ち良いです。こういうオープンなところで満喫できるのは、個人的に好きなポイントです。\n写真に写っている人は、私ではありません。前職の先輩(Nakamura)で、とても明るくコミュニケーション力が高い兄貴です 👍\n\n![Tagbilaran, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411369/silver-birder.github.io/blog/philippines_tagbilaran_bohol.jpg)\n\nセブからボホール移動すると、一気に田舎感が出てきました。\nこういう所を期待していました 👏👏\nバイクが沢山あって、屋台も多く、とても生活感あふれる世界です。\n\n![Bohol Quality Mall, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411424/silver-birder.github.io/blog/bohol_quality_mall_bohol.png)\n\nスーパーにきました。日本に比べて、半端なくレジの待ち時間が長いです。長いです。長いです！\n商品をスキャンする → 商品を紙袋につめる の 2 ステップが、とっても時間がかかります。いかに、**日本のレジ打ちが洗練**されているのか実感しました。\nあと、従業員が**よくサボっています**。従業員の数が多い印象があり、そのせいか仕事をせずに、従業員同士で喋っていたり、携帯を触っていたり、さらには、お店の商品で投げあいっこすらしていました 😧。そう思うと、日本人はみんな真面目に働いているんだな〜。\n\n![Buy items](https://res.cloudinary.com/silverbirder/image/upload/v1614411479/silver-birder.github.io/blog/philippines_buy_items.png)\n\n偽ブランドの靴とカバンを買いました。どちらも 500 ペソ(約 1000 円)で購入できました。\nフィリピンの物価はとても安いです。500ml の水が 20 ペソ、約 40 円です。そもそも、フィリピンの平均的な月給は、約 2 万ペソです。貧富の差が激しいため、裸でやせ細った人もたくさんいました。\n\n![snack](https://res.cloudinary.com/silverbirder/image/upload/v1614411513/silver-birder.github.io/blog/philippines_snack.jpg)\n\n安いので、体に悪そうな（こういうときぐらいいいじゃない！）お菓子をいっぱい買いました。うん、どれも普通！ 😄\n人気の商品は、英語や日本語で商品説明の記載がありました。それ以外は、現地語のタガログ語みたいです。\n2 日目(&3 日目,4 日目)のホテルは、トイレットペーパーをゴミ箱に捨てる方式のトイレでした。 😫\n\n💩 を出した後、ゴミ箱の臭いがとても気にしていました。絶対その空間臭くなってるだろ！ … そんなことはありませんでした 😲。気にしすぎていたようです。外のトイレは汚かったですが、ホテル内のトイレは、十分に清潔にされていました。**基本的にホテルでトイレを済ませる**ことで、トイレ問題を乗り越えました！ 👍\n\n![Tasha, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411557/silver-birder.github.io/blog/philippines_tasha_bohol.jpg)\n\n3 日目の朝、ターシャを見に来ました。ターシャはとても小さく寂しがり屋のお猿さんです。聞くところによると、ターシャを驚かせてしまうと、死んでしまうそうです…。 Quiet !!!\n\n![Loboc river, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411614/silver-birder.github.io/blog/philippines_loboc_river_bohol.jpg)\n\nロボック川を下るツアーに参加しました。この川周辺に暮らしている人たちが、手を降ってくれました。あの人達は、どこで暮らしているのでしょう。 🤔\n\n![Music & Dance , Loboc riverBuggy, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411675/silver-birder.github.io/blog/music_and_dance_loboc_river_buggy_bohol.jpg)\n\n赤色の服を着た少年少女が音楽とダンスを披露してくれました。とっても可愛らしかったです。言葉が分からなくても、楽しめました！\n\n![Buggy, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411722/silver-birder.github.io/blog/philippines_buggy_bohol.jpg)\n\n次に、バギーという乗り物を体験しました。\n国際免許が不要で、敷地内を爆走します。フィリピンの天候は変わりやすいのですが、奇跡的にも、全イベント中は雨に合いませんでした。移動中に毎回雨が降っていました。 **天気の子は、我か！？**\n\n![Buggy 2, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411769/silver-birder.github.io/blog/philippines_buggy_2_bohol.jpg)\n\nまだ序盤の時の写真なので、服が汚れていません。しかし、ガソリンの臭い、バギーの音、晴れ晴れとした天候、これらの要素が僕の気分をハイにさせます。 🚗⚡️️\n水溜りが多く、基本的には避けて移動するのが安全です。しかし、安全などつまらない。\nあえて **水溜りに全力で突っ込む！** これがバギーの嗜みというものです。\n\n全身、ドロドロ（言葉通り）になりました（都合上、写真はありません）。終盤に水落場があるので、そこで綺麗にします。\n着替えは必須です！！！\n\n![Alona beach, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411816/silver-birder.github.io/blog/philippines_alona_beach_bohol.jpg)\n\nアロナビーチというところきました。もう夕方になっており、一日遊び疲れたせいか、ぐったりです。\n水切りして遊んで終わりました…。パラグライダー?をしている人たちをみかけました。楽しそうだな〜したいな〜と思いつつ、疲れていたので、ぼーっと眺めていました。（笑）\n\n![tricycle, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411857/silver-birder.github.io/blog/philippines_tricycle_bohol.jpg)\n\n夜ご飯の移動に、はじめてトライシクル（通称: トゥクトゥク)に乗りました。\n乗り物の作りはかんたんで、バイクとサイドカー、その上に屋根があるだけです。\n\nボホールでは、この乗り物で移動する人が多く、町中にたくさんいます。\n運転は、想像通りの粗目で、ちょっと危険です。\n帰りにチップをたくさん渡しました。とてもにこやかに返っていきました。\n\n![Halo Halo, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411902/silver-birder.github.io/blog/philippines_halo_halo_bohol.jpg)\n\n有名なデザート、Halo Halo を頂きました。上に乗っているのは、紫芋？で、パイナップル、ヨーグルト、シャーベット、スイカが入っていました。これは、当たり 😍 絶品でした！\n\n![Wedding, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411945/silver-birder.github.io/blog/philippines_wedding_bohol.jpg)\n\n4 日目の朝、メインイベントである結婚式です。結婚式は、基本的に英語を使っています。現地語であるタガログ語も使われていたのかもしれませんが、日本語しか分からない僕には、どちらにしろ分かりませんでした。（笑）\n海外にはじめてきたのですが、人と話したいのに**言葉が通じないというのは、とても残念で、もどかしかった**です。Google 翻訳を通して会話をしていたときもありましたが、あれは一時的なときな会話にしか向いていません。\n実際に生活してみると、少し英語が聞き取れた気がしました。\n\n![Wedding Road, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614411986/silver-birder.github.io/blog/philippines_wedding_road_bohol.jpg)\n\n結婚式に参加するのもはじめてでした。これがウィンディングロードというやつか！！\nいつか通ってみたいな〜。\n※ 新郎新婦の写真を載せたかったのですが、やめときました。\n結婚式が 2 時間ほど続いていました。何も言葉がわからないので、「神父の言葉 → 国歌 → 写真撮影」ぐらいのイメージしか伝わらなかったです。（笑）\n\n![Wedding Reception, Bohol](https://res.cloudinary.com/silverbirder/image/upload/v1614412033/silver-birder.github.io/blog/philippines_wedding_reception_bohol.jpg)\n\nフィリピンの披露宴では、「新郎新婦がダンスを踊っている際に、彼らの服に**お金を安全ピンで付ける**」という伝統的文化がありました。お金を付けるときは、こちらもダンスをする必要があります。僕はダンスなんて人生一度もなかったので、**謎ダンス**を踊りつつ、お金を付けて、すぐさま自席に戻りました。\nまた、独身の方向けのイベントがありました。これもフィリピン独自の文化？なのでしょうか。全て言語が通じないので、なんだかよくわからず、流れに身を任せて事なきを得ました。\n\n## 終わりに\n\n結婚式旅行というより、フィリピン旅行という印象が強い旅でした。僕は、初結婚式の参加、初海外旅行という状態だったので、とても心配していましたが、結果としてはとても楽しい時間を過ごせました。当初懸念していたトイレ問題は、気にしすぎていただけでした。\n\n外を世界を知ることで、自身の世界を評価できるという当たり前のことを再認識できました。他社を知ることで自社を評価できるように、海外を知ることで自国を評価できるようになりました。\n\nいまから、とても個人的な意見を話します。日本人は、時間をきっちり守るし、仕事も真面目に働くし、譲り合って生活する文化があると思っています。あと、日本では、小中学校のような一般教養が平等に与えられているのは、良いことだなって思います。誰でも等しく何にでもなれるチャンスがあります。\n\nフィリピンで驚いたことは、母国語（タガログ語）だけでなく、英語も普通に話せる人が多かったです。聞くところによると、複数言語を話せるのは当たり前だそうです。香港でも複数言語を扱える人が多いと聞きました。日本も母国語以外（英語）を学校で習いますが、獲得した能力的には低い印象があります。\n\n貧富の差が激しいフィリピンですが、どんなに貧しそうな人でもスマートフォンは必ず持っていました。とても不思議に感じます。おそらく古い型のスマートフォンを使っていると思うのですが、電気だったり WiFi はどうしてるのかなと謎でした。\n\n色々な発見が多かったフィリピン旅行ですが、また海外旅行を行ってみたくなりました。ただ、ツアーのような現地に詳しい人と一緒に行かないと、ちょっと不安だなと思います。ですので、次海外旅行するなら、ツアーから選んで見てみようと思います。とても楽しい旅行でした！","publishedAt":"2019-10-27","slug":"Philippines_Travel_Notes","title":"フィリピンに行ってきたら、日本は良いなって思うようになった"},{"body":"技術書典 7 で初執筆しました。\n\n## 記事の目的\n\n- 執筆でどういったことをしたのかの備忘録\n- **執筆を考えている人**の助けになりたい\n\n実際に販売する本は ↓ のものです。\n\nhttps://techbookfest.org/event/tbf07/circle/5117648689954816\n\n## きっかけ\n\n大学時代の友人である castaneai くんが技術書典 6 で初執筆しました。\n\nhttps://castaneai.hatenablog.com/entry/2019/04/24/093514\n\ncastaneai くんの話を聞いていると、得られるメリット(実績、交流)が大きいことと、\n製本までのフローがそこまで難しくないことを知りました。\nそこから、私も参加しようと思えるようになりました。\ncastaneai くんは、今回の技術書典 7 も参加するみたいです。興味がある方は是非お立ち寄りください。\n\nhttps://techbookfest.org/event/tbf07/circle/5182251830607872\n\n## 何をするのか\n\n大きく分けて３つのステップになります。\n\n1. 文章作成\n1. 製本\n1. 販売準備\n\nそれぞれ説明していきます。\n\n## 1. 文章作成\n\n本は何よりも文章が必要です。\nただ文章を書くだけでは、本になりません。\n書籍化するためのツールを使うと効率よく進みます。\n\n## 1.1. 書籍化ツール\n\n文章を書き、本っぽい見た目にする必要があります。\nRe:VIEW Starter というツールを使うと、学習コストゼロで、良い感じの本が出来上がります。\n\nhttps://kauplan.org/reviewstarter/\n\n次のコマンド１つで本の PDF が作られます。\n\n```shell\ndocker run --rm -v $PWD:/work kauplan/review2.5 /bin/bash -c \"cd /work; rake pdf\"\n```\n\n![ReViewStarter sample page](https://res.cloudinary.com/silverbirder/image/upload/v1614430347/silver-birder.github.io/blog/ReViewStarter_sample_page.png)\n\n**良い感じの本**の PDF が作成されました、最高です。\n\n## 1.2. 他ツール\n\n他にも次のようなツールがあります。\n\n- [textlint](https://github.com/textlint/textlint)\n  - テキストの表記ゆれを防止\n- [CircleCI](https://circleci.com)\n  - GitOps 的な執筆が可能\n- [Review Live Reload](https://github.com/yoshiko-pg/review-live-reload)\n  - テキスト更新後の自動 Preview\n\n執筆当初は、これらのツールを調査していました。\nしかし、一人で 100 ページ未満の規模の本を書くなら、特に必要ないかなと思ったので導入しませんでした。\n実際、なくても困りませんでした。\n\n## 1.3. レビュー\n\n文章を書いて終わる訳ではないです。\n文章の構成や表現が適切に伝わっているか確認する必要があります。\n読んでもらいたい対象読書に近い人を探して、レビューしてもらいます。\n\n### 1.3.1. 1st レビュー\n\n文章をざっくりと作り終えた時点でレビューしてもらいます。\nイメージとしては、各章とそれぞれの第一節ぐらいが書き終えている感じです。\n\n各章の構成がおかしくないかをレビューしてもらいます。構成がおかしいと、読者は困惑してしまいます。\n後々になって構成を変更すると、**後戻りコスト**が高く付きます。\n\n※ 実際は時間の都合上していません。\n\n### 1.3.2. 2nd レビュー\n\n各章の文章を**とりあえず**書き終えた段階でレビューしてもらいます。\nこれも、1st レビューと同様の目的です。\n2st レビューでは、もう少し細かいレベルで章(節)構成をレビューしてもらいます。\n\n### 1.3.3. 3rd レビュー\n\nコンテンツの構成に問題なければ、ようやく文章の中身をレビューしてもらいます。\n例えば、次のようなものを見てくれました。\n\n- 口調の統一 (です、ます）\n- 言葉の統一 (本、書籍）\n- 主語の明確化\n- 文章を短くする\n- 内容の誤り修正\n- 誤字脱字\n- 図や表の挿入\n\nまた、**GoogleDrive 上で PDF をレビュー**するのが便利です。\n直接文章にコメントできるので、オススメです。\n\nhttps://twitter.com/silverbirder/status/1167314554205786112\n\n## 1.5. 本のタイトル\n\n本を買ってもらうためには、本のタイトルは重要です。\n本の内容を推測しやすく、かつ、注目してもらえるタイトルにしようと考えました。\n私は、特定の技術の入門書を書いたので、「特定の技術 + 入門」という組み合わせにしようと思いました。\n結果、「はじめての WebComponents 入門」というタイトルにしました。\n\n## 1.6. イラストの作成\n\n本には、文章だけでなくイラストが必要になります。\n例えば、次のようなイラストが必要になります。\n\n- 表表紙\n- 裏表紙\n- 背表紙\n- 文章中に挿入するイラスト\n\nまた、少し内容が異なりますが、次のようなイラストも必要です。\n\n- サークル配置図 案内\n- サークルカット\n- サークルカット（グレートーン）\n\n表紙用のテンプレートがありますので、それを使います。\n\nhttp://www.nikko-pc.com/offset/template/tonbo.html\n\n**背表紙の幅はページ数によって変化します**。\n私は、70 ページほど予定していたので 4mm 幅で背表紙を描きました。\n幅計算は、テンプレート内に詳細が記載されていますので、ご参考下さい。\n（日光企画のお姉さんに指摘頂きました）\n\n### 1.6.1. 初イラスト\n\n私は Photoshop や Illustrator を使ったことがありません。\nまずは、環境準備からです。\n\n- iPad\n- Magic Pencil\n\nこれらを購入しました。\niPad と Magic Pencil を使うと、紙に書いている感覚で、イラストを書けるようになります。\n特に良かったのは「手の小指側の面が iPad に接しても無視される」ので、\n手の小指側の面を iPad にひっつけながらイラストがかけます。\niPad, Magic Pencil は買って正解でした。\nソフトウェアは、次のとおりです。\n\n- [Clip Studio](https://apps.apple.com/jp/app/clip-studio-paint-%E6%BC%AB%E7%94%BB-%E3%82%A4%E3%83%A9%E3%82%B9%E3%83%88%E5%88%B6%E4%BD%9C/id1262985592)\n  - メインのイラストツール\n  - iPad\n- [Good Notes](https://apps.apple.com/jp/app/goodnotes-5/id1444383602)\n  - 説明用のイラストツール\n  - iPad\n- [AnyFont](https://apps.apple.com/jp/app/anyfont/id821560738)\n  - 日本語用の Font\n  - iPad\n- [Fire Alpaca](https://firealpaca.com/ja/)\n  - イラストの調整\n  - iMac\n\nお絵かきが苦手だったので、知人に助けてもらい、なんとか作れました。\n\n![表表紙](https://res.cloudinary.com/silverbirder/image/upload/v1614430433/silver-birder.github.io/blog/front_cover_of_web_component_for_the_first_time.png)\n\n## 2. 製本\n\n製本には、技術書典オススメの日光企画さんにお願いしました。\n製本する際には、用紙の種類であったり綴じ方であったりと決める必要があります。\n\n私は、あまりこだわりがないので一般的なものを選択しました。\nそれは、次のようになります。\n\n| 種類                         | 選択                                   |\n| ---------------------------- | -------------------------------------- |\n| ご予約のセットまたは仕様は？ | 早割りセット                           |\n| 用紙サイズ                   | A5                                     |\n| 表紙込みページ数             | 72 ページ (表表紙+裏表紙+本文(70page)) |\n| 冊数                         | 300 冊                                 |\n| 本の閉じ方向                 | 左                                     |\n| 本の閉じ種類                 | 平綴じ                                 |\n| 表紙用紙                     | NP ホワイト 200kg                      |\n| 表紙の印刷種類               | 通常 4 色クリア PP                     |\n| 本文用紙                     | 上質 90kg                              |\n| 本文の印刷種類               | データ 150 線印刷                      |\n| 本文はじまりのページ         | 1 ページ目                             |\n| 遊び紙                       | 有り, 上質 90kg/イエロー/前            |\n\nhttps://jumpei-ikegami.hatenablog.com/entry/2018/10/21/084634\n\nを参考にしました。\n\n本文はじまりのページは、nombre をというものを設定する必要があります。\nRe:VIEW Starter は nombre 対応していて、次のコマンドを叩くだけです。\n\n```shell\ndocker run --rm -v $PWD:/work kauplan/review2.5 /bin/bash -c \"cd /work; rake pdf:nombre\"\n```\n\n用紙についてこだわりたい方は、次のリンクにあるようにサンプルを手に入れると良いでしょう。\n\nhttps://natuna.jp/marcket/10282/\n\n## 3. 販売準備\n\n## 3.1. 物品購入\n\n技術書典では、会場で本を販売することになります。\n販売するサークルブースを目立たせるために、いくつか物品を準備しました。\n\n| 名前                                                                                                                                     | 店舗       | 用途                 | サイズ       | イラスト |\n| ---------------------------------------------------------------------------------------------------------------------------------------- | ---------- | -------------------- | ------------ | -------- |\n| [折りたたみカードスタンド](https://iemonocatalog.com/wp-content/uploads/2019/05/daiso-100yen-card-stand01b.jpg)                          | ダイソー   | 値札                 | 110mm×60mm   | 必       |\n| [軟質クリアブックカバー](https://stripehome.net/wp-content/uploads/2018/05/daisobookcover11.jpg)                                         | ダイソー   | 見本誌カバー         | A5           | 不       |\n| [T 型カードスタンド](http://livedoor.blogimg.jp/n_lattice/imgs/0/7/07a9de37.jpg)                                                         | ダイソー   | 公式後払い QR コード | 90mm×128mm   | 必       |\n| [T 型カードスタンド](http://livedoor.blogimg.jp/n_lattice/imgs/0/7/07a9de37.jpg)                                                         | ダイソー   | PixivPayQR コード    | 90mm×128mm   | 必       |\n| [T 型カードスタンド](http://livedoor.blogimg.jp/n_lattice/imgs/0/7/07a9de37.jpg)                                                         | ダイソー   | 商品紹介             | 90mm×128mm   | 必       |\n| [T 型カードスタンド](http://livedoor.blogimg.jp/n_lattice/imgs/0/7/07a9de37.jpg)                                                         | ダイソー   | TwitterQR コード     | 90mm×128mm   | 必       |\n| [あの布](http://anonuno.shop-pro.jp/)                                                                                                    | 公式サイト | テーブル作業         | -            | 不       |\n| テーブルクロス前用紙                                                                                                                     | 印刷業社   | 宣伝                 | 900mm×600mm  | 必       |\n| [テーブルクロス](https://iemonocatalog.com/wp-content/uploads/2019/01/table-cloth-100yen-main03.jpg)                                     | ダイソー   | あの布を隠す         | 900mm×1200mm | 不       |\n| [テーブルクロス滑り止めシート](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR7H8zYedCGI_RtVMpgjakWWv5Gt6PT76gu93WcAUqx5e5XOxtH) | ダイソー   | あの布               | -            | 不       |\n| [本スタンド](https://www.instagram.com/p/BibVAdbFcAN/media/?size=l)                                                                      | ダイソー   | 見本誌               | -            | 不       |\n| タペストリー用紙                                                                                                                         | 印刷業社   | 宣伝                 | 728mm×1030mm | 必       |\n| [タペストリースタンド](https://www.amazon.co.jp/gp/product/B0052QLJEI/)                                                                  | ダイソー   | 宣伝                 | -            | 不       |\n| [名札](https://iemonocatalog.com/wp-content/uploads/2018/12/namecard-cliptyle-100yen-main.jpg)                                           | ダイソー   | 著者、売り子         | 50mm×25mm    | 必       |\n| [硬質カードケース](https://i2.wp.com/zatsuknowledge.com/wp-content/uploads/2019/04/IMG_4649.jpg)                                         | ダイソー   | お品書き             | A5           | 不       |\n| 複写式 領収書                                                                                                                            | ダイソー   | お客さん             | -            | 不       |\n| メモ、ふせん                                                                                                                             | ダイソー   | 作業                 | -            | 不       |\n| 養生テープ                                                                                                                               | ダイソー   | 作業                 | -            | 不       |\n| スケッチブック                                                                                                                           | ダイソー   | 作業                 | -            | 不       |\n| ダンボールカッター                                                                                                                       | ダイソー   | 作業                 | -            | 不       |\n\nhttps://note.mu/mochikoastech/n/nf484f114855c\n\nhttps://blog.vtryo.me/entry/techbookfest5-preparation-of-journey#登壇ブログなどによる宣伝活動\n\nhttps://note.mu/yagitch/n/nc796a0c2c796\n\n印刷する手段は 3 つあります。\n\n- 細かいもの\n  - 1 つのファイルにして[セブンイレブン印刷](https://blog.vtryo.me/entry/techbookfest5-preparation-of-journey#登壇ブログなどによる宣伝活動)\n- 大きなもの\n  - [ソクプリ](https://www.ooban-senmon.com)で印刷\n- 大量印刷\n  - [プリントパック](https://www.printpac.co.jp/)で印刷\n\n## 3.2. 電子書籍の準備\n\nピクシブ社のサービスである Booth を利用しました。\n\nhttps://booth.pm/ja\n\n特に専門的な知識が必要なことがなく、本の PDF を登録するだけです。\nせっかく足を運んで会場に来て頂いた方のために、電子書籍と物理本の違いを出そうと考えました。\n（中身のデータは同じです）\nそこで、物理本を購入して頂いた方には、**無料で電子書籍をプレゼント**することにしました。\n技術書典ではよくある方法だそうです。\n\nまた、サンプルの本をアップロードし、無料でダウンロードできるようにすることで、\n事前に本の中身を確認できるようにしました。\n\n[[見本誌] はじめての Web Components 入門 -4 つの基本機能から関連ライブラリまで-](https://silverbirder.booth.pm/items/1536228)\n\nただ、ダウンロード数を見る限り、あまり数は多くありませんでした。\nGoogle Analytics (**初登録**)と Booth が連携できるので、流入数を見れるのですが、\n離脱率が 86%という悲しい結果を知りました。ここは改善の余地がありそうです。\n\n![Booth on Google Analytics](https://res.cloudinary.com/silverbirder/image/upload/v1614430470/silver-birder.github.io/blog/booth_on_google_analytics.png)\n\npixiv ID 登録しないとダウンロードできないので、ここが駄目ならサービスを使わない方が良いかもしれません。\n見本誌に限っては、GoogleDrive で渡すようにするとかですかね。\n\n## 3.3. 支払い手段の準備\n\n技術書典では、次のような支払手段を用意しました。\n\n- 公式かんたん後払い\n- pixiv pay\n\n前者は、技術書典で口座情報を登録すると利用できます。\n後者は、アプリをダウンロードして商品を登録するだけです。無料です。\n\n他にも PayPay や Kyash といった手段も用意しようか迷ったのですが、やめました。\n理由は、支払い方法が若干複雑そうでしたからです。\n\n## 4. その他\n\n## 宣伝\n\nこの本のことを広く知ってもらうためには、宣伝が必要です。\n私が取った宣伝手段は次の通りです。\n\n1. Twitter で \"#技術書典 7\" タグ\n1. LINE の OpenChat や TL\n1. FaceBook\n1. 本の内容と関係する勉強会ハッシュタグ\n1. 会社\n1. 友人\n\nあとは、勉強会に参加して宣伝する手段もあります。\n\n**「興味を持ってくれそうな人」が「多い」場**を探す必要があります。\n例えば、4 番は事前に [connpass](https://connpass.com)で関係がありそうな勉強会を調べて、\n該当ハッシュタグで宣伝したりしました。\nまた、積極的に 1 番を実施していると、他のサークル参加さんがリツイートしてくれるため、とても助かりました。\n\nTwitter で宣伝するために、16:9 の画像を用意したりもしました。\n\nhttps://twitter.com/silverbirder/status/1172097536510676994\n\n## 被チェック数と販売冊数\n\n被チェック数は、お客さんが気になる本をチェックした数になります。\nこの数字から、印刷する冊数を決める大きな要因になります。\n\nhttps://note.mu/yagitch/n/n2b5576363f4e\n\n恥ずかしい話になりますが、私は毎朝この数字を見ていました。（笑）\n\nhttps://github.com/silverbirder/get-checked-number-for-techbook\n\n被チェック数を定期的に取得する API をサクッと作って、CloudFunction で稼働させています。\n\nhttps://twitter.com/silverbirder/status/1171178281380405248\n\nこのようにどの時間やどの曜日にチェックされるのかがわかるようになります。\n\n今回、300 冊を印刷することにしました。間違いなく残ってしまうと思うので、\nとらのあなさんへ委託しようと考えています。\n\nhttps://news.toranoana.jp/107460\n\n残ってしまったいくつかの本は、お家に保存用として持ち帰ろうと考えています。（笑）\n\n## 公式ツイッター\n\n公式ツイッターアカウントをフォローしておくと、なにかと便利です。\n\nhttps://twitter.com/techbookfest\n\n## Google カレンダー 登録\n\n技術書典のスケジュールが登録されている Google カレンダーを、ご自身のカレンダーにも登録することをオススメします。\n\nhttps://twitter.com/techbookfest/status/1083948257095503872\n\nいつまでに何をしないといけないのか逆算できるので、知っておいたほうが良いです。\n\n## スケジュールと実績\n\n公式予定と私の実績は次のとおりです。\n\n| 日付  | 公式予定                         | 筆者実績                                                                                                                                                         |\n| ----- | -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 07/10 | 当落通知日                       | 当選                                                                                                                                                             |\n| 07/12 | -                                | [入金済](https://twitter.com/silverbirder/status/1149650432039387137)                                                                                            |\n| 07/17 | 入金締切日                       | 入金済                                                                                                                                                           |\n| 07/20 | -                                | 計画立てる＆テーマ確定                                                                                                                                           |\n| 07/23 | -                                | castaneai くんに / 印刷用サークルカット書いてもらう                                                                                                           |\n| 07/27 | -                                | [サンプルコード作成完了](https://twitter.com/silverbirder/status/1155089319410843648)                                                                            |\n| 07/31 | 印刷用サークルカット締切日       | 登録済                                                                                                                                                           |\n| 08/02 | -                                | 原稿作成開始                                                                                                                                                     |\n| 08/15 | -                                | レビュー対応中(2st)                                                                                                                                              |\n| 08/21 | サークル配置発表日               | [宣伝済](https://twitter.com/silverbirder/status/1164294933752119296)                                                                                            |\n| 08/26 | 一般参加者向け正式サイトオープン | [宣伝済](https://twitter.com/silverbirder/status/1166171153875886080)                                                                                            |\n| 08/29 | -                                | [レビュー対応中(3st)](https://twitter.com/silverbirder/status/1167051004308684800)                                                                               |\n| 08/30 | -                                | 原稿作成完了, [Booth 登録](https://twitter.com/silverbirder/status/1167265421373788161), [製本依頼](https://twitter.com/silverbirder/status/1167379639724994560) |\n| 08/31 | -                                | [物品購入](https://twitter.com/silverbirder/status/1167775260139114496)(あの布は事前購入)                                                                        |\n| 09/06 | -                                | 現在                                                                                                                                                             |\n| 09/07 | サークル通行証の割当日           | -                                                                                                                                                                |\n| 09/19 | 見本誌の提出締切                 | -                                                                                                                                                                |\n| 09/22 | イベント当日                     | -                                                                                                                                                                |\n\n※ レビュー依頼中に、表紙等のイラスト作成を並行して進めていました。\n\nサンプルコードを書いている時は、「こんな話も増やそうかな？」と楽しい気分になれました。\n原稿を書いている時は、「予定日の ◯◯ 日には終わらせないと…」という苦しい時期がありました。\nなんだかんだで、日光企画さんの早割チケットを手に入れれたので満足です。\n\n## 終わりに\n\n私が今回、初執筆した経験を包み隠さずすべて公開しました。\n執筆をやってみてよかったことは次のとおりです。\n\n- 本を作るのは、意外と簡単\n  - ツールやサービスが十分整っている\n- 書いた本が好きになる\n  - いろんな人にみてほしい\n  - 書いた知識は、とても定着する\n- コミュニティが楽しい\n  - \"#技術書典\"のハッシュタグはオススメ\n  - フォロワーが増えた\n\n逆につらかったことは次のとおりです。\n\n- ずーっと本のことを考える\n- 締め切りに追われる\n- 文章力のなさを痛感する\n\n初執筆しようと考えている人にとって、何かの助けになれば幸いです。\n\nあとは、技術書典 7 当日を楽しむだけ！！","publishedAt":"2019-09-06","slug":"open_the_techbook7_first_experience","title":"技術書典7で初執筆した経験をすべて公開"},{"body":"エンジニアの皆さん、IoT 使っていますか？\nスマートホームに欠かせない IoT 商品を使うことで、生活体験はより良くなります。\n\nこの記事では、ご自宅をスマートホーム化するための IoT 商品をリストアップします。\n『そんなのあるの？』という気づきがあれば、幸いです。\n\n## スマートプロダクト リスト\n\n## スマートリモコン\n\n### Nature Remo\n\nhttps://nature.global/jp/nature-remo\n\n## スマートスピーカー\n\n### Google Home\n\nhttps://store.google.com/product/google_home\n\n## スマートロック\n\n### SESAME\n\nhttps://jp.candyhouse.co/\n\n## スマートトラッカー\n\n### Tile\n\nhttps://thetileapp.jp/\n\n## スマートタグ\n\n### Qrio Smart Tag\n\nhttps://qrio.me/smarttag/\n\n## スマートスイッチ\n\n### Switch Bot\n\nhttps://www.switchbot.jp/\n\n## スマートトースター\n\n### Toasteroid\n\nhttps://www.kickstarter.com/projects/258723592/toasteroid-first-app-controlled-smart-image-toaste\n\n## スマートボタン\n\n### Qmote S\n\n[http://qblinks.com/ja](http://qblinks.com/ja)\n\n## スマート加湿器\n\n### SwitchBot 加湿器\n\n[https://www.switchbot.jp/copy-of-switchbot](https://www.switchbot.jp/copy-of-switchbot)\n\n## スマートプラグ\n\n### TP‐Link HS105\n\nhttps://www.tp-link.com/jp/home-networking/smart-plug/hs105/\n\n## スマートスケール\n\n### Withings Body +\n\nhttps://www.withings.com/jp/ja/body\n\n## スマートスリープ\n\n### Withings Sleep\n\nhttps://www.withings.com/jp/ja/sleep\n\n## スマートライト\n\n### Light Strip Plus\n\n[https://www2.meethue.com/ja-jp/p/hue-white-and-color-ambiance-lightstrip-plus-jp-base/7190155J8](https://www2.meethue.com/ja-jp/p/hue-white-and-color-ambiance-lightstrip-plus-jp-base/7190155J8)\n\n## スマートカメラ\n\n### Arlo Ultra\n\nhttps://www.arlo.com/jp/products/arlo-ultra/default.aspx\n\n## スマート歯ブラシ\n\n### Philips Sonicare\n\nhttps://www.philips.co.jp/c-m-pe/electric-toothbrushes\n\n## スマートカーテン\n\n### Mornin' Plus\n\nhttps://mornin.jp/\n\n### SwitchBot Curtain\n\nhttps://www.rakunew.com/items/82929\n\n## スマートエアモニター\n\n### Awair\n\nhttps://jp.getawair.com/\n\n## スマートクリーナー\n\n### iRobot\n\nhttps://www.irobot-jp.com\n\n## スマートテレビ\n\n### Chromecast\n\nhttps://store.google.com/jp/product/chromecast\n\n## スマートウォッチ\n\n### Apple Watch\n\nhttps://www.apple.com/jp/watch/\n\n## スマートケトル\n\n### iKettle\n\nhttps://www.smarter.am/ikettle\n\n## スマートグラス\n\n### Focals\n\n[https://www.bynorth.com/focals](https://www.bynorth.com/focals)\n\n## スマートエナジーハブ\n\n### Nature Remo E\n\nhttps://nature.global/jp/nature-remo-e\n\n## Other\n\n### 食宅便\n\nhttps://shokutakubin.com/shop/default.aspx","publishedAt":"2019-09-06","slug":"smart_home_for_enginner","title":"エンジニアのためのスマートホーム化"},{"body":"この度、初めて書籍を出版することになりました！\n「はじめての Web Components 入門」本を技術書典 7 で販売します。\n\n## 技術書典 7 って\n\nコミックマーケットのエンジニア向けみたいなものです。\n詳しくは、下記のリンクを参照下さい。\n\nhttps://techbookfest.org/event/tbf07\n\n## あなたは誰\n\n詳しくは、私のポートフォリオを参照下さい。\n\nhttps://silverbirder.github.io/\n\nWeb アプリケーションが大好きなエンジニアです。\n今は、EC サイトのフロントエンドエンジニアをしています。\n\n## どんな本\n\nWeb Components について\n何も知らない方向けの書籍になります。\n書籍の内容の大きな流れは、下記のとおりです。どれもサンプルコードを用意しています。\n\n1. Web Components の基礎\n1. ★ 実際に Web Components を作成\n1. 関連ライブラリの紹介\n\n## 「実際に Web Components を作成 」について紹介\n\nお題として Todo Components を作ることになります。作る流れは順序立てて紹介しています。\n\n1. 最小限のコンポーネントを作成\n1. レンダリングの工夫\n1. コンポーネント間のデータ連携\n\n上記のステップを踏むことで Todo Components が完成します。もちろん、サンプルコードがあるので動作確認できます。\n\nまた、カバレッジ 100%テストコードの実装も紹介していますので、TDD も実現できます。Web Components のテストコードは、あまりネット上に紹介されていない印象があったので、折角なので混ぜてみました。\n\n最後に、（実際はしていませんが）Web Components を公開する手順も紹介しています。\n\n## コラムネタ\n\nコラムネタとして下記のようなもの（全てではない）を書いています。\n\n- cloneNode vs innerHTML\n- html-imports\n- WAI-ARIA\n- slot\n- :host\n\n## 目次\n\n- 第一章 フロントエンド開発\n  - フロントエンド開発の苦労\n  - コンポーネントベースの JS フレームワーク\n  - JS フレームワーク非依存\n  - まとめ\n- 第二章 Web Components\n  - 概要\n  - Web Components 4 つの基本機能\n  - ライフサイクルメソッド\n  - まとめ\n- 第三章 Web Components を作ってみよう\n\n  - 作って学ぶ\n  - TodoComponents を作ってみる\n  - [実践] TodoItem と TodoInput を作る\n  - [実践] render を工夫してみよう\n  - [実践] MyTodo を作る\n  - [実践] 各コンポーネントを連携する その 1\n  - [実践] 各コンポーネントを連携する その 2\n  - [実践] 各コンポーネントを連携する その 3\n  - [実践] テストコードを書く\n  - [補足] slot\n  - Web Components の公開\n  - まとめ\n\n- 第四章 Web Components の関連ライブラリ\n  - Polymer\n  - LitElement\n  - Material Web Components\n  - その他の周辺ライブラリ\n  - まとめ\n\n## なぜ書いたの\n\n主に下記のとおりです。\n\n1. Web Components を学習したかったから\n1. ポートフォリオとして残したいから\n1. エンジニアと交流したいから\n\n特に、1 番が大きかったです。\nWeb が大好きな私にとっては、Web Components という技術に興味がありました。\nけれど、実際に試したことがなかったので、これをきっかけにして使ってみたい！という欲求が大きくありました。\n\n## いつ、どこで販売されるの\n\n2019 年 09 月 22 日で、「池袋サンシャインシティ 展示ホール C/D」で販売します。\n弊サークル「silverbirder」の配置は「う 03C」です。\n\n![貴サークル「silverbirder」う03C](https://res.cloudinary.com/silverbirder/image/upload/v1614430611/silver-birder.github.io/blog/your_circle_silverbirder_03C.png)\n\n## 販売形態は\n\n本と電子本の 2 つにするつもりです。\n本は日光企画様より製本して頂いたもののみの販売となります。\n電子本は BOOTH で販売する予定です。\n\n本を購入された方は、電子本を**無料**で差し上げます。\n\n## 終わりに\n\n今回、初物が多すぎました（笑）。  \nそのせいで、プライベートの時間がほぼなくなりました（笑）。\n\n- 初技術書典参加\n- 初製本\n- 初 Web Components 勉強\n- 初クリスタ（イラスト用)\n\n技術書典では、エンジニアそれぞれの**今**書きたいものをアウトプットしています。\nそうすると、新鮮な情報をキャッチアップしやすくなるため、非常に情報収集するのが効率的だと思います。\n技術書典を参加したことがありませんが、執筆してみて思います。\n\n「**どの本も絶対面白い！**」はずです。\n\nだって、好きなこと書けるんですから（笑）。私も含まれます。\n\n技術書典 7 当日は、是非とも「う 03C」にお越し下さい〜〜！  \n（他のサークルさんの本買いに行きたい...!!!）\n\n## 関連リンク\n\n## 見本誌\n\n- [[見本誌] はじめての Web Components 入門 -4 つの基本機能から関連ライブラリまで-](https://silverbirder.booth.pm/items/1536228)\n\n## 技術書典 7\n\nhttps://techbookfest.org/event/tbf07/circle/5117648689954816\n\n## Twitter 宣伝\n\nhttps://twitter.com/silverbirder/status/1166171153875886080","publishedAt":"2019-08-30","slug":"first_release_techbook7","title":"技術書典7 で「はじめてのWeb Components入門」を初出版します！"},{"body":"今回、東京で開催されました Cloud Native Days Tokyo 2019 に 2 日間とも参加してきましたので、報告しようと思います。\nセッション毎の報告というより、全体を通した感想を話そうかなと思います。\n\nhttps://cloudnativedays.jp/cndt2019/\n\nリンクをまとめています。\n\nhttps://qiita.com/zaki-lknr/items/1c26bb713aef9645f5e6\n\n## CNCF の利用率\n\n一日目の Keynote で印象的だった内容です。\n発表者は、OSDT 実行委員長である長谷川さんです。\n\n来場者アンケート 1354 人から聞いた「クラウドネイティブ技術を活用フェーズについて」の紹介がありました。\n既に本番環境に適用している人は、なんと**46%**という驚きの結果でした。また、開発環境に至っては、**63%**ということでした。  \nこのイベントに参加している時点である程度フィルターはかかっていると思いますが、それでも大きな割合だと感じました。\n\n次の図では、CNCF プロジェクトの 180 日間における Commit 数をグラフ化したものです。\n生みの親である Google が 1 位で independent(個人)が 2 番目、日本企業 Fujitsu が 6 位です。熱意が伝わってきますね。\n\n[![https://www.stackalytics.com/cncf?date=180](https://res.cloudinary.com/silverbirder/image/upload/v1614429648/silver-birder.github.io/blog/stackalytics_cncf.png)](https://www.stackalytics.com/cncf?date=180)\n※ 2019/07/24 時点\n\nただ、CNCF のメンバーとして日本企業は**17 社**しかないそうで、まだまだこれからといったところでしょうか。\n\nhttps://landscape.cncf.io/members\n\nさらには、Kubernetes から認定された日本企業ではまだないみたいです。残念です。\n\nhttps://kubernetes.io/partners/#kcsp\n\n今後は、次のようなカンファレンスが海外でもあるみたいです。ぜひ参加してみたいと思います。\n\nhttps://events.linuxfoundation.org/events/kubecon-cloudnativecon-europe-2019/\n\nhttps://events.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2019/\n\n## CloudNative とは\n\n> クラウドネイティブ技術は、パブリッククラウド、プライベートクラウド、ハイブリッドクラウドなどの近代的でダイナミックな環境において、スケーラブルなアプリケーションを構築および実行するための能力を組織にもたらします。 このアプローチの代表例に、コンテナ、サービスメッシュ、マイクロサービス、イミューダブルインフラストラクチャ、および宣言型 API があります。\n\n※ [https://github.com/cncf/toc/blob/master/DEFINITION.md#日本語版](https://github.com/cncf/toc/blob/master/DEFINITION.md#日本語版)\n\n「スケーラブルなアプリケーションを構築および実行」が重要です。これを実現する手段の１つに Kubernetes があります。\n「CloudNative = Kubernetes」ではなく、「CloudNative ∋ Kubernetes」という感じです。\n\nただ、最近では Kubernetes を違う観点で考える人が増えてきたそうです。\nそれが、二日目の Keynote で発表された北山さんのスライドにあります。\n\nhttps://speakerdeck.com/shkitayama/change-the-game-change-the-world\n\nKubernetes は「platform のための platform」と言われるようになりました。\nこれは、slide.No.9(Kubernetes is a platform)で見て分かる通りで、次のようなことがわかります。\n\n- 運用管理者\n  - Self-Healing によってスケールが簡単になる\n- アプリケーション開発者\n  - 簡単にデプロイすることができる\n\nこれらは、たしかに「プラットフォームから得られる価値」になりますが、\n逆に次のような考慮が必要なってきます。\n\n- 運用管理者\n  - Self-Healing はどこまで信頼性を担保できるか\n- アプリケーション開発者\n  - ユーザー影響を最小限にするためには、どうればよいか\n\nこれらのような「プラットフォームを利用するコスト」が「プラットフォームから得られる価値」よりも大きくなってしまいがちになります。\nそこで、Operator (CRD)という概念が最近ホットになっています。\n\n## なぜ CRD がホットなのか\n\nCRD という言葉は様々なセッションで取り上げらていました。\nCRD と Operator については、下記をご参考下さい。\n\nhttps://silverbirder.github.io/blog/contents/kubernetes_meetup_tokyo_19_osaka_satellite\n\nKubernetes を運用すると、既存のリソースだけでは物足りない所がでてくるそうです。\nそういう部分が「プラットフォームを利用するコスト」を大きくしてしまいます。\nそこで、オリジナルのカスタマイズしたリソースを独自に開発し、運用を自動化することを目的とした\nCRD、Operator が生まれました。\nただ、独自に 1 から作るよりも、下記のサイトから使った方が効率的なときもあります。\n\nhttps://operatorhub.io/\n\nけど、結局は困ったとき、ソースコードを読むことになるので、それぐらいの能力がないと、\n運用を回せない気がします。\n\nzlab の ladicle さんの次のスライドがとてもわかりやすく、まとまっていました。\nこれは貴重な資料ですね。\n\nhttps://speakerdeck.com/ladicle/kuberneteswokuo-zhang-siteri-falseoperesiyonwozi-dong-hua-suru\n\nちなみに、独自に 1 から作ったケースがサイバーエージェントの山本さんの発表で、次のスライドです。\n\nhttps://speakerdeck.com/mayuyamamoto/kuberneteskuo-zhang-woli-yong-sitazi-zuo-autoscalerdeshi-xian-surusutoresuhurinayun-yong-falseshi-jie\n\n同じくサイバーエージェントの青山さんがライブコーディングされていたリポジトリが次のものになります。\n\nhttps://github.com/cloudnativejp/webserver-operator\n\n## Kubernetes は必要ですか\n\nKubernetes を使うべきかの話が 2 日間でちらほらありました。\n次のような議論もあります。\n\nhttps://www.atmarkit.co.jp/ait/articles/1907/23/news120.html\n\nCloudNative なアプリケーション構築を目指す場合、どうしても Kubernetes を使う方向になりがちですよね。  \n今回参加したセッションの多くの企業では、Kubernetes を採用するための検討が下記のような感じでした。\n\n- プレインな Kubernetes か、マネージドな Kubernetes か\n  - 大体はマネージドな Kubernetes を使う。\n  - かゆい所に手を伸ばすときになって、プレインな Kubernetes を使う。\n- Kubernetes のエンジニアは何人か。それは専属か\n  - どこも Kubernetes の知識を保有するエンジニアは少ない。\n  - 数人程度で専任で進めることが多い。\n- ノウハウを蓄積するために、スモールスタート\n\n様々なセッションがあった中で、とても王道なステップを踏まれている企業がありました。それは、SoftbankPaymentService の鈴木さんの次のスライドです。\n\nhttps://www.slideshare.net/JunyaSuzuki1/springpcf-cndt2019-osdt2019-keynote\n\n企業に適した CloudNative 化だなと勉強になりました。  \n特に「運用を回すコストを考慮すると、Kubernetes ではなく PaaS を使う」 というポイントが好きです。\n\n## Circuit Breaker\n\n耳にタコができるぐらい、この単語を聞きました。\n下記のサイトが参考になります。\n\nhttps://qiita.com/yasuabe2613/items/3bff44e662c922083264#circuit-breaker\n\n> 同期リクエストの先で一部のマイクロサービスに障害があると、クライアントやその先の「クライアントのクライアント」までブロッキングが波及することになりかねない。\n> この問題を、クライアントと実サービスの間に Circuit Breaker と呼ばれるプロキシを介在させて、実サービスの呼び出し失敗が一定基準を超えると、クライアントからのリクエストを即座にリジェクトさせて、ブロッキング連鎖を解消するパターン。\n\nKubernetes でアプリケーションを構築すると、分散システムの恩恵を受けるために、\nアプリケーションをマイクロサービス化する流れになります。そのマイクロサービス化でよく踏む地雷が、\n「後ろの API が死んだら、連鎖的に他サーバも死ぬ」という現象です。  \nこれを回避するために、上記の Circuit Breaker パターンを使う企業が多数いらっしゃいました。\n本当にいろんなセッションで聞きました...。\n\n## twelve factor app\n\n次の Wantedly さんのスライドが、私の中では話題になりました。\n\nhttps://speakerdeck.com/potsbo/k8s-kubernetes-8-factors\n\n要は、「アプリケーションとしての設計の考え方(twelve factor app)を、インフラ部分でも適用してみた」という感じです。\nどれも具体的なところまで説明されており、実際に Kubernetes を構築する際に役に立つものだと思います。\n\n## 技術にフォーカスした発表\n\n今回のイベントでは、何か 1 つの技術にフォーカスした発表が多くありました。\nそれぞれ私なりにまとめてみました。ご参考下さい。\n\n## Chaos Engineering\n\nhttps://speakerdeck.com/mahito/cndt-osdt-2019-2g1\n\n## Docker\n\nhttps://www.slideshare.net/AkihiroSuda/cndt-docker\n\n## Envoy\n\nhttps://speakerdeck.com/taiki45/cloudnative-days-tokyo-2019-understanding-envoy\n\n## Logging\n\nhttps://speakerdeck.com/yosshi_/kubernetes-loggingru-men\n\n## LinuxKernel\n\nhttps://speakerdeck.com/tenforward/cndt2019\n\n## Prometheus\n\nhttps://speakerdeck.com/tokibi/prometheus-setup-with-long-term-storage\n\n## Sandbox\n\nhttps://docs.google.com/presentation/d/1O9Q9E1hH6mBA5w8oDENnCYObZvij1-Dr_obvsY3X29k/edit\n\n## Scheduler\n\nhttps://speakerdeck.com/ytaka23/cloudnative-days-tokyo-2019\n\n## Spinnaker\n\nhttps://speakerdeck.com/sansanbuildersbox/introduction-to-deployment-patterns-with-spinnaker\n\n## Istio\n\nhttps://speakerdeck.com/dangossk/a-deep-dive-into-service-mesh-and-istio-cndt-2019\n\n## その他\n\nサイバーエージェントさんより、エンジニアにとってとても嬉しいアイテムを頂きました。\n\nhttps://twitter.com/ca_adtechstudio/status/1152080444445167616\n\nさっそく、キーボードにとりつけてみました。最高です！\n\n![ergodox with k8s keycap (cyberAgent)](https://res.cloudinary.com/silverbirder/image/upload/v1614429692/silver-birder.github.io/blog/ergodox_with_k8s_keycap.jpg)\n\nこちらのサービスから作られたそうで、私も自前で何か作ってみようかなと思いました。\n\n[https://www.wasdkeyboards.com/](https://www.wasdkeyboards.com/)\n\n## 最後に\n\nCloudNative にどっぷり浸かった 2 日間でした。  \nどの企業でも CloudNative を導入したことによる「つらみ」や「価値」を共有して頂いたおかげで、これから導入する人たち（私を含む）にとっては、有意義な時間でした。  \n全てのセッションを吸収できたわけではないですが、ここで記載したスライドだけでも理解を深めたいなと思います。\n\nhttps://cloudnativedays.jp/cndk2019/\n\n今度は大阪で開催されるそうです。これも絶対参加したいなと思います！\n\n## 蛇足（参加するまでの経緯）\n\n筆者は Web が大好きなエンジニアで、Kubernetes については理解が浅い人間です。主にフロントエンドに注力しています。  \nただ、昨年の DeveloperBoost2018 で、サイバーエージェントの青山さんのセッションをうけて Kubernetes に興味を持ち始めました。\n\nhttps://codezine.jp/article/detail/11291\n\n青山さんは Kubernetes にとても詳しい方で、世代が近いせいか、私もこれぐらい夢中になれるものを見つけたいと感じるようになりました。  \n私は Web に関わるものなら何でも好きで、Kubernetes も含まれます。そこで、青山さん著作の[Kubernetes 完全ガイド](http://www.wasdkeyboards.com/index.php/products/printed-keycap-singles/custom-art-cherry-mx-keycaps.html)を全て実践することにしてみました。もちろん**お家 Kubernetes**でです。\n実際に触ってみると、スケールする簡単さに驚きました。ほぼコマンド一発で Pod が複製されて、「え！？」とびっくりです。  \nそこから、段々とハマっていき今回のイベントに参加することになりました。","publishedAt":"2019-07-27","slug":"cloud_native_days_tokyo_2019","title":"Cloud Native Days Tokyo 2019 -2019年7月22-23日参加レポート"},{"body":"今回は DeNA さん主催の Frontend のイベントに参加してきましたので、\n報告しようと思います。hashtag はこちら [#frokan](https://twitter.com/hashtag/frokan)\n\n![frontend de kanpai tech board](https://res.cloudinary.com/silverbirder/image/upload/v1614429379/silver-birder.github.io/blog/frontend_de_kanpai_tech_board.jpg)\n\nfirebase の勢いがすごい。あと now も多少人気で、now 信者の私とっては嬉しい 。\n\n![frontend de kanpai novelty](https://res.cloudinary.com/silverbirder/image/upload/v1614429431/silver-birder.github.io/blog/frontend_de_kanpai_novelty.jpg)\n\n※ [https://twitter.com/DeNACreators/status/1152199891860389888](https://twitter.com/DeNACreators/status/1152199891860389888)  \n※ [https://twitter.com/antidotech/status/1152154690617872384](https://twitter.com/antidotech/status/1152154690617872384)  \n※ [https://twitter.com/wanami3103/status/1152202843618603008](https://twitter.com/wanami3103/status/1152202843618603008)\n\nhttps://frokan.connpass.com/event/135584/\n\n## イベント概要\n\n> 「Frontend de KANPAI!」（以下、FROKAN）は、フロントエンドエンジニアやフロントエンドに興味がある人が集い、ドリンク片手にゆるく交流・技術交換ができるコミュニティを目指しています。\n\n※ [https://frokan.connpass.com/event/135584/](https://frokan.connpass.com/event/135584/)\n\n特徴的だったのが立食形式という点です。\n会場には多少の椅子が用意されているものの、ほとんどの人が立ってドリンクを持ちながら、登壇者のお話を聞いていました。\n\n座っていると私はあんまり他の参加者とコミュニケーションしない人です。\n椅子があると、その椅子が自身のテリトリーになってしまって閉じこもってしまう気持ちがあります。\nしかし、立っているとその縛りがないので、楽にコミュニケーションを取れた感じがありました。\n照明が暗かったというところもあると思います。ちなみに、お酒は一切飲んでないです。（笑）\n\nただ、翌日は少しつらかったです...。\n\nhttps://twitter.com/silverbirder/status/1152348180643627008\n\n普段は、メモをがっつり書いて twitter に投稿している私ですが、\n今回は一切そのようなことをしていません。したがって、ほぼ記憶ベースでイベント内容を報告します。ご了承ください。\n誤りありましたら、ご指摘下さい。\n\n## 印象に残ったお話\n\n## React と WebComponents で Vanilla な開発\n\n### 日本経済新聞社 宮本 将 さん\n\nWebComponents に興味がある私は、この発表は気になっていました。\n\nhttps://twitter.com/silverbirder/status/1149648900627693572\n\n内容をざっくり説明すると「CustomElements をプロダクトとして使っていたけど、つらみがあったので typescript で縛るようにしたよ」\nというものでした。CustomElements は Web 標準の技術ですが、react や vue のような prop による型縛りがありません。\nすべて文字列として表現するため、バリデーションチェックがつらいというお話が印象的でした。\nそこで、react(JSX) + typescript を駆使して CustomElements を Wrap することで上記問題を解決されたそうです。\n\n実際に導入したことによる「つらみ」というものは、プロダクト導入検討している私にとってはありがたいお話でした。\n\nそもそも、なぜ CustomElements を導入したのかというお話もありました。\n日経さんでは WebApplication というより Static な WebSite に近いプロダクトだそうです。\nそのため、react や vue といったフレームワークは必要以上な機能が多いため却下し、\nVanilla な JS で CustomElements を進めて行こうという経緯があるそうです。\nプロダクトの特徴に応じてコンポーネント選択すべきね。\n\n※ CustomElements っていろんなフレームワークで対応しているんですね。\n\nhttps://custom-elements-everywhere.com/\n\n## 実録フグ料理\n\n### 株式会社ディー・エヌ・エー Takepepe さん\n\n当初、「お、ネタ枠か？」と思っていたのですが、\n予想以上に面白いお話でした。\n\nProject Fugu というものがあります。\n\nhttps://www.heise.de/blog/Fugu-Die-Macht-des-Kugelfisches-4255636.html\n\n> Unter dem Codenamen Fugu plant Google die Einführung zahlreicher Webschnittstellen in seinem Webbrowser Chrome, welche die Lücke zwischen Progressive Web Apps und ihren nativen Gegenstücken schließen wollen.\n\nGoogle 翻訳を通すと\n\n> コードネーム Fugu の下、Google は Chrome ウェブブラウザで数多くのウェブインターフェースを立ち上げることを計画している。これは Progressive ウェブアプリと彼らのネイティブの対応物との間のギャップを埋めるであろう。\n\nつまり Chrome ウェブブラウザからネイティブな部分を操作できることを目的としています。\n今回 Takepepe さんが紹介していたのは Shape Detection API です。\nバーコードやテキスト、そして顔を形状検出するデモの発表がありました。\nどれもサクッと簡単に動作していましたが、まだ実験的な機能なため安定しない部分もあるそうです。\n\n次の画像は顔検出した箇所にモザイクを入れるデモです。これは笑いました。\n\n![Shape Detection API Demo](https://res.cloudinary.com/silverbirder/image/upload/v1614429340/silver-birder.github.io/blog/Shape_Detection_API_Demo.jpg)\n\n※ [https://twitter.com/antidotech/status/1152180161413931008](https://twitter.com/antidotech/status/1152180161413931008)\n\nちなみに、Fugu という名前の由来は、\n「ネイティブな部分を操作することは色々な事ができるようになり夢が広がるが、使い所を誤ると危険なもの」という話から\nフグの「調理の仕方によって美味しい料理になるが、毒があるので調理の仕方を誤ると危険なもの」という自戒の念を込めて Fugu になりました。\nネイティブな部分を操作できるということは、センシティブな情報を取得できてしまうという面があります。\nそこが使い方によっては「毒」になるものですね。\n\n## 新しい API\n\n### 株式会社ディー・エヌ・エー feb19 さん\n\nhttps://speakerdeck.com/feb19/xin-sii-api\n\nいきなりポエムを語り始めた feb19 さん。\n「DeNA の人たちは、みんなこうなのか？」と面白く見ていました。\nこの発表では、HTML,CSS,JS の API が紹介されていました。\nLazyLoad という有名なものから、少しマニアックな inverted-color まで幅広く、よくこんなもの知ってるんだなと驚きました。\n\n## 最後に\n\nフロントエンドのイベントは、今回初めてかもしれません。 参加者の多くは、どちらかというと「陽の者」が多く、ノリが楽しい人たちばかりでした。 参加者の方と技術的な話をしたのですが、やはり react, vue, augular のワードが多かった印象です。なんだか聞き飽きた印象もありますが、それだけ需要があるのだなと改めて思いました。","publishedAt":"2019-07-20","slug":"frontend_de_kanpai_7","title":"【増枠】Frontend de KANPAI! 7 - Going on 令和 - 2019年7月19日参加レポート"},{"body":"## 背景\n\n今年の 9 月に PyConJP 2019 が開催されます。\n\nhttps://pycon.jp/2019/\n\nLT の募集があったので、LT 応募するためのネタ探しをはじめました 😄\n\n## IT Antenna Sites\n\n私が普段見ている IT 系のサイトから調べました。\nその時に使ったサイトを紹介します。\n※ 色々な人から参考にさせて貰ってます。 :)\n\n## Github\n\nhttps://github.com/trending/python\n\n## PublicKey\n\nhttps://www.publickey1.jp/mt6/mt-search.cgi?IncludeBlogs=2&tag=Python\n\n## Dev.to\n\nhttps://dev.to/t/python\n\n## Reddit\n\nhttps://www.reddit.com/r/Python\n\n## Hacker News\n\nhttps://hn.algolia.com/?query=python\n\n## Qiita\n\nhttps://qiita.com/tags/python\n\n## Hatena\n\nhttps://b.hatena.ne.jp/search/tag?q=Python\n\n## Medium\n\nhttps://medium.com/tag/python\n\n## Ubersuggest\n\nhttps://app.neilpatel.com/jp/ubersuggest/overview?keyword=python\n\n## GoogleTrend\n\n[https://trends.google.co.jp/trends/explore?q=python](https://trends.google.co.jp/trends/explore?q=python)\n\n他にオススメありましたら教えて下さい。 😆\n\n## Python ネタ\n\n次のような技術について知ることができました。\n\n## Deepfacelab\n\nhttps://github.com/iperov/DeepFaceLab\n\n> DeepFaceLab is a tool that utilizes machine learning to replace faces in videos. Includes prebuilt ready to work standalone Windows 7,8,10 binary (look readme.md).\n\n## Grumpy\n\nhttps://github.com/google/grumpy\n\n> Grumpy is a Python to Go source code transcompiler and runtime.\n\n## Pyodide\n\nhttps://github.com/iodide-project/pyodide\n\n> The Python scientific stack, compiled to WebAssembly\n\n## PyOxidizer\n\nhttps://github.com/indygreg/PyOxidizer\n\n> A modern Python application packaging and distribution tool\n\n## Pyre\n\nhttps://github.com/facebook/pyre-check\n\n> Performant type-checking for python.\n\n## Pyxel\n\nhttps://github.com/kitao/pyxel\n\n> A retro game engine for Python\n\n## ScrapydWeb\n\nhttps://github.com/my8100/scrapydweb\n\n> Web app for Scrapyd cluster management, Scrapy log analysis & visualization, Auto packaging, Timer tasks, Email notice, and Mobile UI\n\n## さいごに\n\nLT のネタとなるような Python に関する経験が乏しい私は、こういうアプローチでネタを探しました。まだどれを選択するかは決めていませんが、とりあえず応募はしようと思います！ 💪","publishedAt":"2019-07-03","slug":"Roundup_IT_Antenna_Sites","title":"Roundup IT Antenna Sites"},{"body":"大阪のグランフロント大阪で開かれました「AWS Summit Osaka 2019」に参加してきましたので、\n私の中で良かった３つのセッションを紹介したいなと思います。\n\nhttps://aws.amazon.com/jp/summits/osaka-2019/\n\n![もらったもの](https://res.cloudinary.com/silverbirder/image/upload/v1614430752/silver-birder.github.io/blog/AWS_Summit_Osaka_2019_Novelty.png)\n\nhastag はこちら [#AWSSummit](https://twitter.com/hashtag/AWSSummit)\n\n私のメモはこちら\n\nhttps://scrapbox.io/silverbirder-memo/AWS_Summit_Osaka_2019\n\n## Amazon Sumerian による VR/AR/MR アプリケーションの開発\n\n## Amazon Sumerian の位置づけ\n\nxR と呼ばれる３つの R について説明がありました。\n\n- xR\n  - VR (virtual reality)\n    - 仮想の世界に没入\n  - AR (augmented reality)\n    - 物理に仮想をオーバレイ\n  - MR(mixed reality)\n    - 物理と仮想が相互作用\n\nVR や AR については、広く知れ渡っていると思いますが、MR ははじめて聞きました。\n\nVR は、Oculus Quest のようなヘッドセットで仮想世界に没入できます。\n\nhttps://www.youtube.com/watch?v=BqM27iLnDJs\n\nAR は、ポケモン Go のようなアプリで現実世界に仮想のキャラクタを投影できます。\n\nMR は、VR と AR の Mix みたいな感じですね。ヘッドセットをかぶりながら、現実世界に仮想世界が mix された景色が見えます。  \n代表的なものとして、Microsoft HoloLens があります。\n\nAmazon Sumerian は、この VR/AR にフォーカスしたサービスになります。\n\n## xR アプリの課題\n\n課題は下記の感じです。\n\n- ハードウェアが浸透していない\n- 何が必要？\n- どうやって作る？\n- 使ってもらえるかわからない\n\n私自身、xR のアプリを作ったことが１回だけありますが、同じような課題に悩んだことがあります。どうしても専用ハードウェアが必要になり、使ってもらうハードルが高くなってしまいます。\n\n## Sumerian の特徴\n\n特徴は 4 つあります。\n\n- Web ブラウザベースの開発環境\n  - 開発する環境は Web ブラウザベースになるので、特別なものを用意する必要がないです。良いですね。\n- マルチプラットフォーム\n  - モバイル、デスクトップ、VR ヘッドセット、AR プラットフォームに対応しています。これが**一番魅力的**なんじゃないかなと思います。開発者にとってもユーザーにとってもありがたいですよね。\n- Sumerian Host\n  - セリフにあわせて口を動かしたりジェスチャーを行うキャラクターが 8 人いるそうです。こちらのキャラで開発する感じでしょうか？\n- AWS のサービスとの連携\n  - AWS SDK を使って各種サービスを使えます。そのため、より柔軟なアプリケーションを開発することができます。\n\n## 感想\n\nxR は Web 好きな私でも興味がある技術です。Sumerian をつかうことで、xR の開発をよりスピーディに進めれるようなサービスと感じました。\n実際触るかどうかは分かりませんが（無料枠使い切ってしまったので...)、こういった xR を開発するための手段を１つ知れたことは良かったと思います。  \n（他のクラウドサービスには xR 向けサービスないのですかね...?）\n\nhttps://aws.amazon.com/jp/sumerian/pricing/\n\nhttps://aws.amazon.com/jp/sumerian/\n\n※ 下記のレポートもご参考下さい\nhttps://dev.classmethod.jp/cloud/aws/awssummit-2019-tokyo-h2-01/\n\n## クラウドネイティブなモダンアプリケーション開発入門\n\n## モダンアプリケーションのデザインパターン\n\n今回紹介されたパターンは、マイクロサービスのデザインパターンのことを指しているのでしょうか。\nhttps://microservices.io/patterns/microservices.html\n\nデザインパターンといえば、GoF のデザインパターンが有名ですね。\nhttps://en.wikipedia.org/wiki/Software_design_pattern\n最近では、分散システムにフォーカスした[分散システムデザインパターン](https://www.oreilly.co.jp/books/9784873118758/)があります。\n\n今回登壇で話されいた内容を私が説明するより、下記のほうが十分に説明がありますので、そちらをご参考下さい。\nhttps://qiita.com/yasuabe2613/items/3bff44e662c922083264\n\n## 感想 (2)\n\n今回のセッションでは、少し駆け足になっていたせいか全て聞き取れなかった印象でした。\nただ、マイクロサービスデザインパターンの存在を知れてよかったです。\nCQRS というパターンを業務上調査した覚えがあるのですが、マイクロサービスデザインパターンの\n１種だったんですね。知りませんでした。\nデザインパターンというのは、先人の知恵が蓄積された素晴らしいカタログなので、\n１度目を通しておこうと思いました。\n\n※ 下記のレポートもご参考下さい\nhttps://dev.classmethod.jp/cloud/aws-summit-2019-day3-a03-06/\n\n## クラウドネイティブがもたらすスケーラブルな開発、インフラストラクチャー、そして組織\n\n## Nulab の現状\n\n### Nulab のサービス\n\nNulab では[backlog](https://backlog.com/ja/),[cacoo](https://cacoo.com/ja/),[typetalk](https://www.typetalk.com/ja/)の３つプロダクトをもっています。\nbacklog では、ユーザー数が順調に伸びてきており、今年で 100 万人を突破したそうです。\n\n### backlog について\n\nbacklog には、4 つのサービスに分かれており、それぞれ Issues, Wiki, Gantt, Git があります。\n前 3 つのサービスが Monolith で作られており、後 1 つのサービスが 3 つの言語(Perl, Python, Java)で作らていたそうです(Go で再実装されました)。\n\nインフラ部分については(backlog の話に限らない...?)、クラスタが日本に 6 個、海外に 2 個存在し、インスタンスが 200 個もあるそうです。\nそれらは、Terraform+Ansible で管理するようにしていたそうですが、**物理ホストのメンテナンスに大きくコストがかかる**という問題がありました。\nまた、コードベースが巨大化になると開発者、特に新規の人は理解するのに時間がかかってしまう問題もありました。\n\n## Kubernetes・EKS の導入\n\nBacklog の問題点から、開発やインフラをスケールするため Kubernetes を検討するようになりました。\nそこで(比較的規模が小さい?)Cacco に Kubernetes で動くように運用してみたそうです。Nulab ではコンテナのノウハウが蓄積されているので、効率よく進めれたそうですね。\nしかし、kubernetes で運用していくと、ControlPlane の面倒を見るのが手間になってきます。そこで、マネージドサービスである EKS を使いはじめたそうです。\n\nどういった点にメリット/デメリットがあるのか知るために、既存と新規を Nginx を通して平行提供したそうです。\n運用を進めることで kubernetes や EKS のノウハウが蓄積され、Backlog に EKS を検討する材料を手に入れることができます。\n\n## 感想 (3)\n\nNulab さんの取り組みで勉強になったのは「小さなところから検討したい技術を導入し、ノウハウを蓄積する」ところです。\n社内で実績がない技術をプロダクトとして導入するには、それなりに調査する必要があります。  \nまた、その技術に明るい人がいれば導入までの工数は短くなると思いますが、大抵の場合、そういった人は少ないはずです。\nそこで、Nulab さんのような取り組みをすると、低いリスクで大きなリターンが得られます。  \n小さいところからスタートするので、失敗してもリスクは少なくて済みますし、  \n運用ノウハウが蓄積できれば、拡大できます。  \n私も、プロダクトへ何度か提案したことがありますが、今回のポイントも検討してみたいなと思います。\n\n※ 下記のレポートもご参考下さい\nhttps://aws.amazon.com/jp/blogs/startup/summit-osaka-2019-racap/\n\n## 全体感想\n\nAWS Summit Osaka は今回が初めてだそうです。前回は震災の影響で中止になったみたいです。  \nAWS は、私がはじめて触ったクラウドサービスなので、今回参加してみました。  \nSumerian ってものを知りませんでしたし、マイクロサービスデザインパターンも知りませんでした。  \nこういう大規模なセミナーでは、様々なジャンルのセッションが集まっているので、全く知らない領域のセッションを受けてみたり、より Deep なセッションを受けたりと面白いです。  \n関西に住んでいる私にとっては、こういった大規模セミナーは中々珍しいので、とてもありがたかったです。","publishedAt":"2019-06-29","slug":"aws_summit_osaka_2019","title":"AWS Summit Osaka 2019 2019年6月27日参加レポート"},{"body":"今回は、ヤフー株式会社主催の下記セミナーに参加してきました。\nGoogle/Apple どちらも大好きで、けど海外カンファレンスにいけなかった私にとって、今回の報告会は**新鮮な内容**ばかりでした。\nその内容を記事に書こうと思います。\n\nhttps://yahoo-osaka.connpass.com/event/132601/\n\n![Google I/O WWDC まとめて報告会 看板](https://res.cloudinary.com/silverbirder/image/upload/v1614430881/silver-birder.github.io/blog/Google_I_O_WWDC_1.png)\n\n![YAHOO!Japan](https://res.cloudinary.com/silverbirder/image/upload/v1614430948/silver-birder.github.io/blog/Yahoo_japan.png)\n\n![けんさくとえんじん](https://res.cloudinary.com/silverbirder/image/upload/v1614430980/silver-birder.github.io/blog/kensaku_to_enjin.png)\n\nhashtag はこちら [#mixleap](https://twitter.com/hashtag/mixleap)\n\n## Google I/O とは\n\nGoogle が主催する、開発者向けイベントです。\nGoogle I/O では、WEB や Google が出しているガジェットなど様々な技術情報についてセッションが行われています。\n\nhttps://events.google.com/io/\n\n※ [https://yahoo-osaka.connpass.com/event/132601/](https://yahoo-osaka.connpass.com/event/132601/)\n\n## WWDC（Worldwide Developers Conference）とは\n\nApple が毎年開発している、開発者向けイベントです。\nWWDC では、apple の新製品の紹介や新しい技術についての発表が行われています。\n\n[https://developer.apple.com/wwdc19/](https://developer.apple.com/wwdc19/)\n\n※ [https://yahoo-osaka.connpass.com/event/132601/](https://yahoo-osaka.connpass.com/event/132601/)\n\nヤフーでは、google I/O と WWDC の両方に約 30 名の社員が参加したそうです。\nすごい数ですね。\n\n## Google I/O の概要と MLKit のアップデート 加藤 貴晴さん\n\n## Google I/O の概要\n\nGoogle I/O が始まったのは 2008 年からで、毎年開催しているそうです。\n今年は 2019 年なので、11 回目になります。\n\n今回は全部で 164 セッションありました。\nその内の TOP3 が下記のとおりでした。\n\n- Android 64\n- Web 39\n- ML/AI 32\n\nWeb 好きの私としては TOP2 というのが悔しいですね。(笑)\nML/AL が 3 番目とは驚きです。\n\n### Deplex on the web\n\nhttps://www.gizmodo.jp/2019/05/190305.html\n\nウェブベースでも使える GoogleAssistant のことで、レンタカーや映画の予約ができるみたいです。\nこれのすごいところは、レンタカーを予約するまでのステップを**全て自動入力**してくれるみたいです。\nそこまで便利になったのかと驚きました。\nちなみに、日本にはまだ対応していません。\n\n### WebAuthn\n\nパスワードレスな生体認証のことを指すそうです。\nこちらについてのセッションが下記のようです。\nhttps://developers.google.com/web/updates/2018/05/webauthn\n\nひとまず知ることができてよかったです。\n\n## ML\n\nML Kit の発表があったそうです。\nhttps://developers.google.com/ml-kit/\n\nその中でも、翻訳 API について報告会では熱く話されていました。\n\n### ML On-Device Translate API\n\nデバイス上で翻訳することができるようになります。\nそのため、外部とのやり取りができない環境でも翻訳できます。  \nつまり、オフラインでも動作します。\n\nまた、59 言語に対応しているというすごい数です。\n\n[https://firebase.google.com/docs/ml-kit/translation-language-support](https://firebase.google.com/docs/ml-kit/translation-language-support)\n\n一部無料で使えるとのことで、こういうスタンスは本当に大好きです。\nhttps://firebase.google.com/docs/ml-kit/android/translate-text\n\n※ 翻訳する際は中間に英語を挟むような作りになっているみたいです。\n\n### AutoML Vision Edge\n\nこちらも Edge というデバイス、つまりは Android 端末上で動作するカスタム機械学習モデルを作成できるサービスです。  \nここで注目したいのは、またしてもデバイス上(On-Device)で動作する点です。  \nGoogle ではこのデバイス上で完結する方針を、これからも進めていくのでしょうか。\n\nOn-Device だと、どうしてもデータをデバイス上に保存する必要があります。\nそのため、保存すべきデータをいかに軽量にするかという問題があります。\nオフライン環境でも動作できるようになれば、災害時や緊急事態には役立ちますよね。\nWeb 好きなら知っていると思いますが、PWA という技術があります。\nこちらにも OfflineMode という機能があり、こういった On-Device の先駆けとなっていたのでしょうか。\n\n## Google アシスタントの他プラットフォームへの拡張方法の紹介 一円 真治さん\n\nいろいろとお話されていたのですが、下記の内容が一番衝撃でした。\nhttps://japanese.engadget.com/2019/05/08/google-web-duplex/\n\n> Google はまったくあたらしい音声認識と言語理解モデルを開発し、100GB 必要だった学習モデルを 0.5GB 以下まで削減したとしています。これにより、学習モデルをスマートフォン内部に格納できるようになり、AI 機能の動作にネットワーク接続不要に。この結果、ほぼ遅延なくデバイス上で音声認識が行えるようになるとのことです。\n\nまたしてもデバイス上ですが、GoogleAssistant を動かすのにモデル作成が必要みたいです。\nそれにかかる容量が 100GB も必要だったものを 0.5GB まで削減したという衝撃的な発表があります。\nまた、AI 機能の動作にネットワーク接続が不要とのことなので、必要なデータをダウンロードできていれば、オフライン環境でも動作できます。\n\n## What’s WWDC? / Swift UI ’n Siri Recap 田中 達也さん\n\n## SwiftUI について\n\nWWDC で発表された SwiftUI は、WWDC を参加していた人みんながめちゃくちゃ盛り上がったそうです。\nSwift であんまり開発したことがないので、ほぼ想像で話しますが、\n従来の Swift による開発は、ソースコードをビルドして、端末にビルド後のデータを移動させて動作確認する必要がありました。\nそこを、SwiftUI はわざわざ端末にデータ移動せず、xcode 上で preview できるという開発者にとって、とてもハッピーな機能がついたようです。\n\n## SwiftUI ってどうやって使うの\n\nhttps://twitter.com/silverbirder/status/1143475061673717760?s=20\n\nこの件について登壇者さんに質問してみました。そのとおりとのことです。\nswiftUI を手軽に動かしたい場合は、playground でも試せるそうなので、近い内にやってみようかなと思います。\n\nhttps://qiita.com/shtnkgm/items/387132cd9633a59e7390\n\n## ショートカットアプリ\n\n標準で iphone にインストールされるようになったアプリで、正直あんまり使った覚えはありません。\n他アプリとの連携が用意になったらしいので、アプリ開発の幅が広がりますね。\n（すみません、SwiftUI のことばかり考えていました（笑））\n\n## AR・ML・その他 Apple プラットフォームのアップデート 林 和弘さん\n\n内容的には動画があったほうがわかりやすいのですが、\n都合上見せれないものばかりだったため、なんだかモヤっとした内容でした。（笑）\n\n## AR について\n\nARKit→ARKit2→ARKit3 の順で進化してきたのですが、動画がなく、ふ〜んってなってしまいました...。\n\n## Authentication\n\n「sign in with apple」という内容に私は惹かれました。\nApple の ID で認証ができるようになります。\n特に、JS ライブラリや、REST API の提供もあるそうです。\n\nJS ライブラリ\nhttps://developer.apple.com/documentation/signinwithapplejs\n\nREST API\nhttps://developer.apple.com/documentation/signinwithapplerestapi\n\n良いっすね〜！これで認証の種類が増えました！\n\n## 最後に\n\nGoogle I/O や WWDC には参加したいという気持ちがあるのですが、\nやはり英語のちからがまだまだ自信がありません。\n徐々に聞き取れるように勉強していきます。\nhttps://note.mu/silverbirder/m/mcad08e0f384b\n\n今回の報告会で何度も耳にした「デバイス上で動作、オフライン環境」は、\n今後、Google では力を入れていきたいのかなと思いました。\nいま私ができることは、無料で使える ML On-Device Translate API を試すぐらいかなと思います。\nあとは、今と同じで継続して技術情報に対して、アンテナを貼り続けるぐらいでしょうか。\n\nヤフーの社員さんたちは、こういった新技術に対してキャッチアップする姿勢が積極的で良いなと思います。\n私も負けないように頑張りたいと思います。","publishedAt":"2019-06-27","slug":"mix_leap_study_45","title":"【増枠】Mix Leap Study 45 - Google I/O、WWDCまとめて報告会！ 2019年6月15日参加レポート"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)では、RBAC による権限について学習しました。今回は最後に Kubernetes のコンポーネントについて学習します。\n\n## コンポーネント\n\nKubernetes では、下記のような構成になっています。\n\n![kubernetes_master.png](https://res.cloudinary.com/silverbirder/image/upload/v1639816831/silver-birder.github.io/blog/kubernetes_master.png)\n\n※ [https://kubernetes.io/docs/concepts/architecture/cloud-controller/](https://kubernetes.io/docs/concepts/architecture/cloud-controller/)\n\nそれぞれのコンポーネントについて学習します。\n\n## 現状確認\n\n```shell\npi@raspi001:~/tmp $ k get nodes\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   42d   v1.14.1\nraspi002   Ready    worker   42d   v1.14.1\nraspi003   Ready    worker   42d   v1.14.1\npi@raspi001:~/tmp $ k get pods -n kube-system -o=wide\nNAME                               READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\ncoredns-fb8b8dccf-mtzvd            1/1     Running   34         37d   10.244.0.26    raspi001   <none>           <none>\ncoredns-fb8b8dccf-nv6dj            1/1     Running   81         37d   10.244.2.151   raspi003   <none>           <none>\netcd-raspi001                      1/1     Running   31         42d   192.168.3.32   raspi001   <none>           <none>\nkube-apiserver-raspi001            1/1     Running   95         42d   192.168.3.32   raspi001   <none>           <none>\nkube-controller-manager-raspi001   1/1     Running   89         42d   192.168.3.32   raspi001   <none>           <none>\nkube-flannel-ds-arm-4s22p          1/1     Running   73         38d   192.168.3.34   raspi003   <none>           <none>\nkube-flannel-ds-arm-7nnbj          1/1     Running   88         38d   192.168.3.33   raspi002   <none>           <none>\nkube-flannel-ds-arm-ckwq5          1/1     Running   86         38d   192.168.3.32   raspi001   <none>           <none>\nkube-proxy-6fwl5                   1/1     Running   31         42d   192.168.3.32   raspi001   <none>           <none>\nkube-proxy-wgjdq                   1/1     Running   28         42d   192.168.3.33   raspi002   <none>           <none>\nkube-proxy-zvmqf                   1/1     Running   28         42d   192.168.3.34   raspi003   <none>           <none>\nkube-scheduler-raspi001            1/1     Running   87         42d   192.168.3.32   raspi001   <none>           <none>\n```\n\n下記は、MasterNode で動いています。\n\n- etcd-raspi001\n- kube-apiserver-raspi001\n- kube-controller-manager-raspi001\n- kube-scheduler-raspi001\n\n下記は、全 Node で動いています。\n\n- kube-flannel-ds\n- kube-proxy\n\ncoredns は、Master1 台と Worker1 台で動いています。\n\n※ [このとき](./start_the_learning_kubernetes_03)に設定しました。\n\n## etcd\n\nMasterNode に存在するコンポーネントです。\n分散 Key-ValueStore である etcd は、Kubernetes のクラスタにある全情報が保存されています。そのため、単一障害にならないようクラスタを組むことが推奨されているみたいです。ここのデータにアクセスするのは kube-apiserver から経由しなければなりません。\n直接確認したい場合は、etcdctl を使ってみると良いです。\n\n## kube-apiserver\n\nMasterNode に存在するコンポーネントです。\nKubernetesAPI を提供するコンポーネントです。kube-scheduler や kube-controller-manager,kubelet から呼ばれます。\netcd に対してリソースを管理するだけで、Pod の起動はしません。\n\n## kube-scheduler\n\nMasterNode に存在するコンポーネントです。\nNode 情報が未割り当ての Pod を検知して、その Pod に Node を割り当てるリクエストを kube-apiserver に送ります。\n割り当てるだけであって、Pod を起動させません。Node を割り当てる際、NodeAffinity や Taints などを考慮に入れます。\n\n## kubelet\n\n各 Node 上で動作するコンポーネントです。未割り当てだった Node が割り当てられたことを検知し、\n実際に Pod を起動します。\n\n## kube-controller-manager\n\nMasterNode に存在するコンポーネントです。\n様々なコントローラを実行するコンポーネントです。Deployment や ControllerReplicaSetController では、\n状態を監視し、期待する Pod 数と現在の Pod 数を見ます。kube-apiserver に対して、過不足分の Pod を調整するよう要求します。\nその後は、さきほどの kube-scheduler,kubelet の一連の流れになります。\n\n## kube-proxy\n\n各 Node 上で動作するコンポーネントです。NodePort や ClusterIP 宛のトラフィックを転送します。\n\n## kube-dns\n\nkubernetes クラスタ内の名前解決やサービスディスカバリに利用される DNS サーバです。\n私の環境では、CoreDNS を使っていました。\n\n## そのほか\n\n## CustomResourceDefinition(CRD)と Operator\n\nCRD は独自のリソースを定義できるリソースです。このような拡張性をもたせることで、様々な開発が進められます。\nCRD は、単なる Kubernetes オブジェクトなだけなので、Operator というカスタムコントローラをセットで作る必要があります。\nOperator Framework と呼ばれるもので簡単に作成できるそうです。\n\n## 最後に\n\nようやく Kubernetes 完全ガイドの内容を読み切ることができました。\n当初は、ここまで記事にアウトプットし続けるつもりはなかったです。\n実際に kubernetes を raspberryPi 上で動かしてみると、\nいろいろな発見があってのめり込んでしまいました。\n\nただ、[一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)ぐらいから、いろいろとあって、\n書籍の内容を、ほぼそのまま使わさせてもらいました。（笑)\n\nこれからは、実際に GKE を使ってアプリケーション開発をしてみようと思います。","publishedAt":"2019-06-10","slug":"start_the_learning_kubernetes_16","title":"一足遅れて Kubernetes を学び始める - 16. コンポーネント -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)では、Affinity などで Pod のスケジューリングについて学習しました。今回は、セキュリティについて学習します。\n\n## サービスアカウント\n\nPod で実行するためのプロセスを制御するために割り振られるアカウントのことをサービスアカウントというそうです。\n\n```yaml\n## sample-serviceaccount.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: sample-serviceaccount\n  namespace: default\nimagePullSecrets:\n  - name: hogehoge\n```\n\nこれを apply してみます。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-serviceaccount.yaml\npi@raspi001:~/tmp $ k get serviceaccounts sample-serviceaccount -o yaml\n...\nsecrets:\n- name: sample-serviceaccount-token-4xhgm\n```\n\nサービスアカウントが作成されました。また、imagePullSecrets の内容が secrets に登録されました。(sample-serviceaccount-token-4xhgm)\nimagePullSecrets は private な docker レジストリに使います。\n\n```shell\npi@raspi001:~/tmp $ k get secrets sample-serviceaccount-token-4xhgm -o yaml\napiVersion: v1\ndata:\n  ca.crt: ...\n  namespace: ZGVmYXVsdA==\n  token: ...\nkind: Secret\nmetadata:\n  annotations:\n    kubernetes.io/service-account.name: sample-serviceaccount\n    kubernetes.io/service-account.uid: 4bd076da-8854-11e9-af26-b827eb8ccd80\n  creationTimestamp: \"2019-06-06T12:12:04Z\"\n  name: sample-serviceaccount-token-4xhgm\n  namespace: default\n  resourceVersion: \"584634\"\n  selfLink: /api/v1/namespaces/default/secrets/sample-serviceaccount-token-4xhgm\n  uid: 4bfbe8bb-8854-11e9-af26-b827eb8ccd80\ntype: kubernetes.io/service-account-token\n```\n\n認証に必要な token が登録されていますね。\n\n## RBAC (Role Based Access Control)\n\nRBAC は、さきほど作成したサービスアカウントと、どういった操作を許可するのかを定めた Role を紐付け(RoleBinding)して、権限管理をします。1 つの Role に対して複数のサービスアカウントを RoleBinding できます。\n\nRBAC は、２つのレベルがあり、１つは Namespace レベルで、もう一つはクラスタレベルがあります。\n設定範囲がクラスタの方が大きい感じです。(namespace 横断して設定する場合はクラスタレベルにする)\n\n- Role と ClusterRole\n- RoleBinding と ClusterRoleBinding\n\n操作の種類ですが、どの Deployment や DaemonSet のようなリソースに対して下記のものがあります。\n\n| \\*     | 全ての処理 |\n| :----- | :--------- |\n| create | 作成       |\n| delete | 削除       |\n| get    | 取得       |\n| list   | 一覧取得   |\n| update | 更新       |\n| patch  | 一部変更   |\n| watch  | 変更の追従 |\n\n※ [Kubernetes の RBAC について](https://qiita.com/sheepland/items/67a5bb9b19d8686f389d)\n\n今回は[Kubernetes 道場 20 日目 - Role / RoleBinding / ClusterRole / ClusterRoleBinding について](https://cstoku.dev/posts/2018/k8sdojo-20/)を参考に進めます。\n\n新しく作ったサービスアカウントでコンテキストを作成し、そのアカウントから Pod 情報を取得できるか試してみます。\nそのためには、サービスアカウントの認証情報を通しておく必要があります。\n\n※ Role と ClusterRole に大きな違いはないため、Role を試します。\n\n```shell\npi@raspi001:~/tmp $ TOKEN=$(k get secret/sample-serviceaccount-token-jd279 -o json | jq -r .data.token)\npi@raspi001:~/tmp $ DECODE_TOKEN=$(echo -n $TOKEN | base64 -d)\npi@raspi001:~/tmp $ k config set-credentials sample-serviceaccount --token $DECODE_TOKEN\n```\n\nでは、コンテキスト(sample-sa-context)を作成して、それを使用します。\n\n```shell\npi@raspi001:~/tmp $ k config set-context sample-sa-context --user sample-serviceaccount --cluster kubernetes\npi@raspi001:~/tmp $ k config use-context sample-sa-context\npi@raspi001:~/tmp $ k config get-contexts\nCURRENT   NAME                          CLUSTER      AUTHINFO                NAMESPACE\n          kubernetes-admin@kubernetes   kubernetes   kubernetes-admin\n* sample-sa-context             kubernetes   sample-serviceaccount\n```\n\n新たに作成したサービスアカウントで Pod の情報が取得できるか試してみます。\n\n```shell\npi@raspi001:~/tmp $ k get po\nError from server (Forbidden): pods is forbidden: User \"system:serviceaccount:default:sample-serviceaccount\" cannot list resource \"pods\" in API group \"\" in the namespace \"default\"\n```\n\nError になりました。sample-serviceaccount は何も Role をバインドしていないからですね。\nでは、RoleBinding していきます。\n\n元に戻ります。\n\n```shell\npi@raspi001:~/tmp $ k config use-context kubernetes-admin@kubernetes\n```\n\n```yaml\n## sample-role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: sample-role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"watch\", \"list\"]\n```\n\n```yaml\n## sample-rolebinding.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: sample-rolebinding\n  namespace: default\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: sample-role\nsubjects:\n  - kind: ServiceAccount\n    name: sample-serviceaccount\n    namespace: default\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-role.yaml\npi@raspi001:~/tmp $ k apply -f sample-rolebinding.yaml\n```\n\nでは、もう一度試してみます。\n\n```shell\npi@raspi001:~/tmp $ k config use-context sample-sa-context\npi@raspi001:~/tmp $ k get po\nNAME                                      READY   STATUS    RESTARTS   AGE\n...\n```\n\nおお、取得できました！\nもとに戻しておきます。\n\n```shell\npi@raspi001:~/tmp $ k config use-context kubernetes-admin@kubernetes\n```\n\n## SecurityContext\n\nコンテナに対してセキュリティ設定をすることができます。\n例えば、Capabilities の追加・削除、実行するユーザ、グループの変更、ファイルの ReadOnly 化などができるそうです。\n\n```yaml\n## sample-capabilities.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-capabilities\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      securityContext:\n        capabilities:\n          add: [\"SYS_ADMIN\"]\n          drop: [\"AUDIT_WRITE\"]\n```\n\napply し、中身を確認してみます。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-capabilities.yaml\npi@raspi001:~/tmp $ k exec -it sample-capabilities /bin/bash\nroot@sample-capabilities:/# apt update && apt install libcap2-bin\nroot@sample-capabilities:/# capsh --print | grep Current\nCurrent: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_sys_admin,cap_mknod,cap_setfcap+eip\nroot@sample-capabilities:/# exit\n```\n\ncap_sys_admin が増えてますね。audit_write は見つかりません。\nそもそも、どんな種類があるのか分からなかったので、[こちら](https://qiita.com/muddydixon/items/d2982ab0846002bf3ea8)を参考にしました。\n\n## PodSecurityContext\n\nPod(全てのコンテナ)に対してセキュリティ設定をすることができます。\n例えば、実行するユーザやグループの制御、root 実行を拒否したり、カーネルパラメータを上書きすることもできます。\n\n```yaml\n## sample-runuser.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-runuser\nspec:\n  securityContext:\n    runAsUser: 99\n    # runAsGroup: 99\n    supplementalGroups:\n      - 1001\n      - 1002\n  containers:\n    - name: centos-container\n      image: centos:7\n      command: [\"/bin/sleep\", \"3600\"]\n```\n\nでは、apply しています。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-runuser.yaml\npi@raspi001:~/tmp $ k exec -it sample-runuser -- id\nuid=99(nobody) gid=99(nobody) groups=99(nobody),1001,1002\npi@raspi001:~/tmp $ k exec -it sample-runuser -- ps aux | grep sleep\nnobody       1  0.0  0.0   2032   372 ?        Ss   14:02   0:00 /bin/sleep 3600\n```\n\n実行したユーザが nobody(99)に変更されていますね。また、supplementalGroups で、プライマリ GID に指定の GID を追加することができます。\n\n## そのほか\n\nPodSecurityPolicy や、NetworkPolicy、そして認証、認可の AdmissionControl というものもあるそうです。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-serviceaccount.yaml -f sample-role.yaml -f sample-rolebinding.yaml -f sample-capabilities.yaml -f sample-runuser.yaml\npi@raspi001:~/tmp $ k config delete-context sample-sa-context\n```\n\n## 最後に\n\n主に RBAC について学習しました。\n複数人で開発する際は、コンテキストを分けて開発を進めるのが良いみたいですね。\n今回で取り組んだように、誰がどの権限を持っているかを RBAC で管理できるので、\n必要以上の権限を与えられて事故るようなことは少なくなりますね。\n（といっても、まだ個人でしか使ってないので分かりませんが...）\n次回は、最後で[こちら](./start_the_learning_kubernetes_16)です。","publishedAt":"2019-06-07","slug":"start_the_learning_kubernetes_15","title":"一足遅れて Kubernetes を学び始める - 15. セキュリティ -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)では、requests や limit といったヘルスチェックの仕方を学びました。今回は、Affinity などによるスケジューリングについて学習します。\n\n## スケジューリング\n\nこれから学ぶスケジューリングでは、大きく分けて２つに分類します。\n\n- Pod のスケジューリング時に特定の Node を選択する方法\n  - Affinity\n  - Anti-Affinity\n- Node に対して汚れをつけて、それを許容できる Pod のみスケジューリングを許可する方法\n  - 汚れ = Taints\n  - 許容 = Tolerations\n\n## Node のラベル確認\n\nデフォルトで設定されている Node のラベルを見てみます。\n\n```shell\npi@raspi001:~/tmp $ k get nodes -o json | jq \".items[] | .metadata.labels\"\n{\n  \"beta.kubernetes.io/arch\": \"arm\",\n  \"beta.kubernetes.io/os\": \"linux\",\n  \"kubernetes.io/arch\": \"arm\",\n  \"kubernetes.io/hostname\": \"raspi001\",\n  \"kubernetes.io/os\": \"linux\",\n  \"node-role.kubernetes.io/master\": \"\"\n}\n{\n  \"beta.kubernetes.io/arch\": \"arm\",\n  \"beta.kubernetes.io/os\": \"linux\",\n  \"kubernetes.io/arch\": \"arm\",\n  \"kubernetes.io/hostname\": \"raspi002\",\n  \"kubernetes.io/os\": \"linux\",\n  \"node-role.kubernetes.io/worker\": \"worker\"\n}\n{\n  \"beta.kubernetes.io/arch\": \"arm\",\n  \"beta.kubernetes.io/os\": \"linux\",\n  \"kubernetes.io/arch\": \"arm\",\n  \"kubernetes.io/hostname\": \"raspi003\",\n  \"kubernetes.io/os\": \"linux\",\n  \"node-role.kubernetes.io/worker\": \"worker\"\n}\n```\n\narch や os はデフォルトで設定されているみたいです。\n次以降の学習のため、ラベルをはります。\n\n```shell\npi@raspi001:~/tmp $ k label node raspi002 cputype=low disksize=200\npi@raspi001:~/tmp $ k label node raspi003 cputype=low disksize=300\n```\n\n## NodeSelector\n\n最も簡単な NodeAffinity の設定です。\n指定するラベルに属する Node に Pod を割り当てるようスケジューリングします。簡易なので、equality-base のみしか指定できません。\n\nでは、disksize が 300 の Node(raspi003)に Pod を配置しましょう。\n\n```yaml\n## sample-nodeselector.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-nodeselector\n  labels:\n    app: sample-app\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n  nodeSelector:\n    disksize: \"300\"\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-nodeselector.yaml\npi@raspi001:~/tmp $ k get pods sample-nodeselector -o wide\nNAME                  READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\nsample-nodeselector   1/1     Running   0          21s   10.244.2.130   raspi003   <none>           <none>\n```\n\n期待通りですね。OK です。\nnodeSelector はイコールでしか表現できないので、柔軟性に欠けます。\n\n## Affinity\n\nAffinity は、NodeSelector よりも柔軟に設定できます。つまり、set-based の指定方法です。\n詳しくは[こちら](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#set-based-requirement)を参照下さい。今回は In オペレータを使います。\n\n```yaml\n## sample-node-affinity.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-node-affinity\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n          - matchExpressions:\n              - key: disktype\n                operator: In\n                values:\n                  - hdd\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 1\n          preference:\n            matchExpressions:\n              - key: kubernetes.io/hostname\n                operator: In\n                values:\n                  - raspi002\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n```\n\nNodeAffinity では、required と preferred の 2 つ設定できます。\n\n- required\n  - 必須スケジューリングポリシー\n- preferred\n  - 優先的に考慮されるスケジューリングポリシー\n\n必須条件が「cputype=low である Node(raspi002,raspi003)」で、優先条件が「hostname=raspi002 である Node」です。\n適用してみましょう。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-node-affinity.yaml\npi@raspi001:~/tmp $ k get pods sample-node-affinity -o wide\nNAME                   READY   STATUS              RESTARTS   AGE   IP       NODE       NOMINATED NODE   READINESS GATES\nsample-node-affinity   0/1     ContainerCreating   0          5s    <none>   raspi002   <none>           <none>\n```\n\n確かに raspi002 に配置されました。では、raspi002 をスケジューリングできなくするとどうなるのでしょうか。\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-node-affinity.yaml\npi@raspi001:~/tmp $ k cordon raspi002\npi@raspi001:~/tmp $ k apply -f sample-node-affinity.yaml\npi@raspi001:~/tmp $ k get pods sample-node-affinity -o wide\nNAME                   READY   STATUS              RESTARTS   AGE   IP       NODE       NOMINATED NODE   READINESS GATES\nsample-node-affinity   0/1     ContainerCreating   0          11s   <none>   raspi003   <none>           <none>\n```\n\n今度は、raspi002 を cordon したので、raspi003 に移りました。優先なので、満たされなくても良いのですね。必須条件が満たされなかったら、Pending になります。\n\n元に戻します。\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-node-affinity.yaml\npi@raspi001:~/tmp $ k uncordon raspi002\n```\n\n## AND と OR\n\nnodeSelectorTerms や matchExpressions は配列なので複数指定できます。\n\n```yaml\n## sample.yaml\nnodeSelectorTerms:\n  - matchExpressions:\n      - A\n      - B\n  - matchExpressions:\n      - C\n      - D\n```\n\n上記の場合は、 (A and B) OR (C and D)という条件になります。\n\n## Anti-Affinity\n\nAnti-Affinity は、Affinity の逆です。つまり、特定 Node 以外の Node に割り当てるよう\nスケジューリングします。特別な指定はなく、単に Affinity の否定形式にするだけです。言葉だけですね。\n\n## Inter-Pod Affinity\n\n特定の Pod が実行されているドメイン上へ Pod をスケジューリングするポリシーです。\nPod 間を近づけることができるので、レイテンシを下げることができます。\n\nまず、特定の Pod は、先程の NodeSelector で使ったものとします。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-node-affinity.yaml\npi@raspi001:~/tmp $ k get pods sample-nodeselector -o wide\nNAME                  READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\nsample-nodeselector   1/1     Running   0          36m   10.244.2.130   raspi003   <none>           <none>\n```\n\n```yaml\n## sample-pod-affinity-host.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-pod-affinity-host\nspec:\n  affinity:\n    podAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchExpressions:\n              - key: app\n                operator: In\n                values:\n                  - sample-app\n          topologyKey: kubernetes.io/hostname\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n```\n\nこれだと、sample-app がある Node で kubernetes.io/hostname(=raspi003)と同じ Node に Pod を割り振ります。つまり、raspi003 にできるはずです。\n\n```text\npi@raspi001:~/tmp $ k apply -f sample-pod-affinity-host.yaml\npi@raspi001:~/tmp $  k get pods sample-pod-affinity-host -o wide\nNAME                       READY   STATUS              RESTARTS   AGE   IP       NODE       NOMINATED NODE   READINESS GATES\nsample-pod-affinity-host   0/1     ContainerCreating   0          11s   <none>   raspi003   <none>           <none>\n```\n\n期待通り raspi003 にできています。\nまた、required だけでなく、preferred も設定できます。\n\n```yaml\n## sample-pod-affinity-arch.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-pod-affinity-arch\nspec:\n  affinity:\n    podAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        - labelSelector:\n            matchExpressions:\n              - key: app\n                operator: In\n                values:\n                  - sample-app\n          topologyKey: kubernetes.io/arch\n      preferredDuringSchedulingIgnoredDuringExecution:\n        - weight: 1\n          podAffinityTerm:\n            labelSelector:\n              matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                    - sample-app\n            topologyKey: kubernetes.io/hostname\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n```\n\n必須条件としては、下記のとおりです。\n\n- 「label が app=sample-app である Pod が動いている Node(raspi003)で、kubernetes.io/arch が同じ Node(arm)」\n\nこれは raspi002(arm),raspi003(arm)どちらにも当てはまります。\nそして、優先条件として、下記のとおりです。\n\n- 「label が app=sample-app である Pod が動いている Node(raspi003)で、kubernetes.io/hostname が同じ Node(raspi003)」\n\nこれにより、raspi003 が選ばれるはずです。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-pod-affinity-arch.yaml\npi@raspi001:~/tmp $ k get pods sample-pod-affinity-arch -o wide\nNAME                       READY   STATUS              RESTARTS   AGE   IP       NODE       NOMINATED NODE   READINESS GATES\nsample-pod-affinity-arch   0/1     ContainerCreating   0          13s   <none>   raspi003   <none>           <none>\n```\n\n期待通り raspi003 で動いていますね。\n\n## Inter-Pod Anti-Affinity\n\nInter-Pod Affinity の否定形です。以上。\n\n今まで紹介した Affinity、AntiAffinity,Inter-Pod Affinity, Inter-Pod AntiAffinity は、組み合わせることができます。\n\n## Taints\n\nNode に対して汚れをつけていきます。汚れた Node に対して、許容する Pod のみがスケジューリングできるようになります。\n\n汚れの種類(Effect)は、３つあります。\n\n- PreferNoSchedule\n  - 可能な限りスケジューリングしない\n- NoSchedule\n  - スケジューリングしない（既にスケジューリングされている Pod はそのまま）\n- NoExecute\n  - 実行を許可しない（既にスケジューリングされている Pod は停止される）\n\nそれでは、まず Node を汚しましょう。\n\n```shell\npi@raspi001:~/tmp $ k taint node raspi003 env=prd:NoSchedule\npi@raspi001:~/tmp $ k describe node raspi003 | grep Taints\nTaints:             env=prd:NoSchedule\n```\n\nこれで raspi003 に Pod をスケジューリングできなくなりました。\n\n## Tolerations\n\nさきほど汚した Node に対して、許容(Tolerations)できる Pod を作成しましょう。\n\nkey と value(env=prd)と Effect(NoSchedule)が設定された Pod のみ許容されます。作ってみます。\n\n```yaml\n## sample-tolerations.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-tolerations\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n  tolerations:\n    - key: \"env\"\n      operator: \"Equal\"\n      value: \"prd\"\n      effect: \"NoSchedule\"\n  nodeSelector:\n    disksize: \"300\"\n```\n\n※ nodeSelector で汚れた Node である raspi003 を指定するようにしています。\n\noperator には、2 種類あります。\n\n- Equal\n  - key と value が等しい\n- Exists\n  - key が存在する\n\nでは、適用してみます。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-tolerations.yaml\npi@raspi001:~/tmp $ k get pod sample-tolerations -o=wide\nNAME                 READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\nsample-tolerations   1/1     Running   0          27s   10.244.2.140   raspi003   <none>           <none>\n```\n\n汚れた Node に許容される Pod が適用されましたね。\n許容を一部変えてみる(env=stg)と、もちろん Pending になりました。\n\nもとに戻しておきます。\n\n```shell\npi@raspi001:~/tmp $ k taint node raspi003 env-\n```\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-nodeselector.yaml -f sample-node-affinity.yaml -f sample-pod-affinity-host.yaml -f sample-pod-affinity-arch.yaml -f sample-tolerations.yaml\npi@raspi001:~/tmp $ k label node raspi002 cputype- disksize-\npi@raspi001:~/tmp $ k label node raspi003 cputype- disksize-\n```\n\n## 最後に\n\nPod をどの Node にスケジューリングするのか学習しました。\n汚れ(taint)と許容(tolerations)という考えは面白いなと思いました。\nただ、あまり使いすぎると複雑に陥りやすそうなので、注意が必要ですね。\n次回は、[こちら](./start_the_learning_kubernetes_15)です。","publishedAt":"2019-06-05","slug":"start_the_learning_kubernetes_14","title":"一足遅れて Kubernetes を学び始める - 14. スケジューリング -"},{"body":"大阪から Kubernetes Meetup Tokyo に参加できるとのことで、こちらに参加してきました。\nKubernetes の生みの親である 3 人の内の 1 人の Joe Beda から、**Kubernetes の歴史**の経緯について教えて頂きました。\nその話がとてもわかりやすく、なるほどなと思ったので、ぜひとも共有したいと思います。\n\nhttps://k8sjp-osaka.connpass.com/event/131981/\n\n※ 以降の内容は、私なりの解釈が入っており誤った認識かもしれません。ご了承下さい。\n発表の内容は全て Youtube にありますので、そちらが正しいものです。ご参考下さい。\n\nhttps://www.youtube.com/watch?v=ETHGx8_Q-1k\n\n## Who is Joe Beda\n\n> Joe Beda は、Kubernetes の co-founder（共同創設者/最初に開発した 3 人のうちの 1 人）/ 昨年 VMware に買収された Heptio の CTO / O'Reilly「Kubernetes: Up & Running」 (邦題「入門 Kubernetes」）の共著者で、現在も Kubernetes をリードしている 1 人です。今回は、Kubernetes のこれまでと未来についてお話いただきます。\n\n※ [https://k8sjp.connpass.com/event/126207/](https://k8sjp.connpass.com/event/126207/)\n\nKubernetes の最初のコミッターで、超有名人。\nGoogle で働いていたときは、Kubernetes や Compute Engine を作っていたそうです。\n\nJoe さん曰く、プラットフォームで開発する上でおもしろいことは、下記２点のバランスだと仰っていました。\n\n1. ユーザーが**簡単**に使ってもらえる事\n1. 想定していなかった使われ方があった場合の柔軟性\n\n私なりの解釈で言うと、例えば、GCP というプラットフォームの中で、GKE を使うとします。\nボタンをポチポチするだけでクラスターが作成されますよね。簡単で使ってみたくなります。\n\nただ、簡単だけだと細かい要求を満たせないので、オプションを設定できるようにしたり、\nカスタマイズしやすいものへ改善されていきます。柔軟性ってことでしょうか？\nこの柔軟性をしすぎると複雑になってしまい、ユーザーが使ってくれなくなる恐れがあります（マニアックなユーザーは残るかもしれないけど）。\nそこのバランスが大切なのかなと思いました。\n\nJoe さんの詳細な説明は[こちら](https://www.linkedin.com/in/jbeda)です。\n\n## The origins and future of Kubernetes (en/英語)\n\nJoe さんは英語で話されてました。\nCPCAmerica(?)の田中さんが通訳をされていたのですが、ものすごくわかりやすかったです。感謝です！\nあと、記憶力はんぱねぇ...。\n\nhttps://twitter.com/mumoshu/status/1134438272518635521?s=20\n\n※ 以下、[@‏apstndb](https://twitter.com/apstndb) さんの要約 Tweet を参考にしました。神!!!\n\nhttps://twitter.com/silverbirder/status/1134406467744804864?s=20\n\n## kubernetes の歴史\n\n### Borg の誕生\n\nGoogle では、BigData を処理するための[MapReduce](https://ja.wikipedia.org/wiki/MapReduce)を開発していました。\nMapReduce を扱うために、[GlobalWorkQueue](https://www.slideshare.net/hasanveldstra/the-anatomy-of-the-google-architecture-fina-lv11/34-GWQ_Google_Workqueue_ulliBatch_SubmissionScheduler)(GWQ)というものを開発され、これは主にバッチのために作成されたものでした。そこからバッチだけでなく、リアルタイムに実行したい(検索など)サービスに対応するために生まれたのが Borg だそうです。\nGoogle のような大規模な検索であれば、数％の効率 Up でも大きなコスト削減につながるメリットがあります。\nこれが、Kubernetes の元となりました。\n\n### Kubernetes の誕生\n\nGoogle で Borg を開発を進めていく中で、世の中は仮想マシンを扱うユーザーが多かったそうです。\nBorg はプロプライエタリなソフトウェアだったため、Borg の世界を知ってほしい、開発者を引き込みたいという願いから、\nOSS として Kubernetes が誕生しました。\nまた Kubernetes は、API ドリブンで開発者の生産性を上げるというのが先で、効率やセキュリティは後からついてきたそうです。\n\n### Kubernetes の魅力\n\nKubernetes とは、「コンテナオーケストレーター」と多くの人は知っていると思います。普及した大きなポイントですね。\n他の観点で「１つのデータベースだけでクラスタを管理している設計」が魅力的だという話がありました。\n（勝手な解釈かもしれません。すみません）\n\n![kubernetes overview](https://res.cloudinary.com/silverbirder/image/upload/v1614428761/silver-birder.github.io/blog/google_kubernetes_overview.png)\n\nKubernetes では、クラスタの状態を管理するために分散型 KVS である[etcd](https://github.com/etcd-io/etcd)を使っています(その他の状態管理はキャッシュしているそうです。)。\netcd には、APIServer を経由しなければアクセスできないため、一貫したデータの維持が実現できます。\nその etcd の周りにある、ビジネスロジックを実現するコントローラー([Scheduler, Controller Manager](https://kubernetes.io/docs/concepts/overview/components/))が価値を提供します。\n例えば、Pod を Node にアサインしたり、エンドポイントを提供したり、レプリケーションしたりなどなど...。\n\nkubernetes の control plane である、APIServer, Scheduler, Controller Manager があれば、シングルノードでもマルチノードでも動きます。\nkubernetes を DockerForMac で動かしたときは、そういえばシングルノードでしたね。マルチノードってイメージでしたけど。\n\n![kubernetes jazz Improv](https://res.cloudinary.com/silverbirder/image/upload/v1614428854/silver-birder.github.io/blog/google_kubernetes_jazz_Improv.png)\n\nKubernetes はコンテナオーケストレーションとよく言われますが、事前にすべてがプランされたオーケストレーションではなく、ジャズのように即興で計画して組み立てていくものに近い思想だそうです。\n私は音楽に疎い人なのですが意味は理解しました。（笑）性格的には即興は苦手っす。\n\n### CRD と Operators\n\nPod や Replication,Deployment など様々なリソースがあります。\nただ、Kubernetes が持っていないものを実装するにはどうすればよいのでしょうか。\nそこで、Custom Resource Definitions (CRD)です。\nなんだそれは...?\n\nhttps://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\n\nhttps://qiita.com/cvusk/items/773e222e0971a5391a51\n\n要は、Pod や Deployment のようなリソースを独自に作ることができるのですね。おぉなんだそれ！\n独自に機能を作るためには、Custom Resource と Costom Controller が必要になり、両方をあわせて\nOperators というものが生まれました。\n\n例えば、下記のようなものがあります。\nhttps://github.com/oracle/mysql-operator\n\nhttps://github.com/kubeflow/tf-operator\n\nYahoo では、gimbal という OSS を使って Kubernetes を導入したみたいです。\nhttps://github.com/heptio/gimbal\n\nhttps://techblog.yahoo.co.jp/advent-calendar-2018/oss-gimbal/\n\n詳しくは分かりませんが、こういった拡張しやすい機能があるおかげでドンドン普及するのだなと勉強になりました。\n\n### Q&A\n\n#### Q1. StatefulSets には今回触れられなかったが、どういう扱いなのか\n\nhttps://twitter.com/apstndb/status/1134409892033261569?s=20\n\n#### Q2. スケーラビリティに関して\n\nhttps://twitter.com/apstndb/status/1134410827627487232?s=20\n\n#### Q3. Kubernetes はなぜ etcd を使っているか\n\nhttps://twitter.com/apstndb/status/1134411776009785345?s=20\n\nhttps://twitter.com/apstndb/status/1134412148237512705?s=20\n\nhttps://twitter.com/apstndb/status/1134412317439844352?s=20\n\n#### Q4. Virtual Kubelet とか k3s みたいなエッジで活用する動きがコミュニティでは感じられるが、どう見ている\n\nhttps://twitter.com/apstndb/status/1134413224839745536?s=20\n\nhttps://twitter.com/apstndb/status/1134413431316987904?s=20\n\n#### そのほか\n\n参加者からの質問は、どれも鋭いものばかり。\n適度な質問をしたいなとつぶやきました...。届かなかったけど...。\nhttps://twitter.com/silverbirder/status/1134412867988480000?s=20\n\n## Osaka 会場\n\n会場提供は、株式会社 Aiming さんでした。\n\nhttps://aiming-inc.com/ja/\n\n会場場所は、グランフロント大阪タワー B の 18 階にありました。(高い!)\n今回使わさせて頂いた場所は、会議室でしょうか。\n30,40 人ぐらい入れるスペースで、清潔感がありました。\n\n![kubernetes osaka satelite aiming](https://res.cloudinary.com/silverbirder/image/upload/v1614428802/silver-birder.github.io/blog/kubernetes_osaka_satelite_aiming.jpg)\n\n東京との中継は、ときどき音声が途切れてしまうときもありますが、しっかりと写っていました。\nただ、コンテンツとしては、YouTube にあげらているので、わざわざ Osaka に出席しなくても良いのでは？とも思いました。\n\nしかし、それでも Osaka に出席しても良い面もあるのかなと思います。\n\n- 他の方とのコミュニケーションが取れる\n- 一緒に発表を聞いて議論ができる\n\nまあ、私はコミュ障なので、ほぼなかったですが...。\n\n改善ポイントとしては、**中継地からも質問ができる**ようになってくれたら良いなと期待しています。\n\n## 最後に\n\nKubernetes について、どういった経緯で誕生したのか、また CRD についても勉強になりました。\nまた、Kubernetes とは違うのですが、「**OSS のちから**」というものがエンジニアの世界では大事だと強く感じました。\n普段エンジニアが開発する上で、ほぼ間違いなく OSS を使っています。\nエンジニアにとって、OSS は不可欠な存在であり、利用するばかりです。\n\nGoogle がしたように、「広く使ってほしい、エンジニアを巻き込みたい」という願いから、\nOSS として Kubernetes が広まっていった一要因と思いました。これが有償ならどうだったのでしょうか。\nここまで普及したのでしょうか。\n\nOSS に貢献する企業は、日本にも多く存在します。\n個人でも OSS へ貢献できますし、OSS Gate という初心者向けのものもあります。\nKubernetes のコントリビューターは、ちょっとハードルが高いですが、\n私もエンジニアとして OSS へ貢献し続けていこうと思います。\n\n## そのほか (2)\n\n拙い文章なのに、最後まで読んでいただき、ありがとうございます。\ntwitter をしていますので、フォローしてもらえるとうれしいです。([silverbirder](https://twitter.com/silverbirder))","publishedAt":"2019-06-01","slug":"kubernetes_meetup_tokyo_19_osaka_satellite","title":"【大阪・梅田】Kubernetes Meetup Tokyo 19 大阪サテライト- 2019年5月31日参加レポート"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)では、requests や limit などのリソース制限について学習しました。今回は、ヘルスチェックとコンテナライフサイクルについて学習します。\n\n## ヘルスチェック\n\nKubernetes では、Pod の正常生判断のためのヘルスチェックが 2 種類用意されています。\n\n- Liveness Probe\n  - Pod が正常か判断。異常だった場合、Pod を再起動。\n- Readiness Probe\n  - Pod がサービスインする準備ができているか判断。準備できていなかったら、トラフィックを流さない。\n\nたとえば、Pod 内でメモリリークが発生し応答しなくなった場合に有効です。\nLoadBalancer のサービスは、ICMP による簡易ヘルスチェックがデフォルトで用意されています。\n\nまた、Liveness、Readiness どちらにも３つの方式があります。\n\n- exec\n  - コマンドを実行し、終了コードが 0 でなければ失敗\n- httpGet\n  - HTTP GET リクエストを実行し、statusCode が 200~399 でなければ失敗\n- tcpSocket\n  - TCP セッションが確立できなければ失敗\n\nでは、試してみましょう。\n\n```yaml\n## sample-healthcheck.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-healthcheck\n  labels:\n    app: sample-app\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      ports:\n        - containerPort: 80\n      livenessProbe:\n        httpGet:\n          path: /index.html\n          port: 80\n          scheme: HTTP\n        timeoutSeconds: 1\n        successThreshold: 1\n        failureThreshold: 2\n        initialDelaySeconds: 5\n        periodSeconds: 3\n      readinessProbe:\n        exec:\n          command: [\"ls\", \"/usr/share/nginx/html/50x.html\"]\n        timeoutSeconds: 1\n        successThreshold: 2\n        failureThreshold: 1\n        initialDelaySeconds: 5\n        periodSeconds: 3\n```\n\n- timeoutSeconds\n  - タイムアウトまでの秒数\n- successThreshold\n  - 成功と判断するまでのチェック回数\n- failureThreshold\n  - 失敗と判断するまでのチェック回数\n- initialDelaySeconds\n  - 初回ヘルスチェック開始までの遅延\n- periodSeconds\n  - ヘルスチェックの間隔\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-healthcheck.yaml\npi@raspi001:~/tmp $ k describe pod sample-healthcheck | egrep \"Liveness|Readiness\"\n    Liveness:       http-get http://:80/index.html delay=5s timeout=1s period=3s #success=1 #failure=2\n    Readiness:      exec [ls /usr/share/nginx/html/50x.html] delay=5s timeout=1s period=3s #success=2 #failure=1\n```\n\n設定どおりに動作していますね。では、失敗させましょう。\n\nliveness を失敗させるには index.html を削除すれば良いですね。\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-healthcheck rm /usr/share/nginx/html/index.html\npi@raspi001:~/tmp $ k get pods --watch\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-healthcheck                        1/1     Running   1          9m54s\nsample-healthcheck                        0/1     Running   2          10m\nsample-healthcheck                        1/1     Running   2          10m\n```\n\n一度削除されて、再起動しましたね。\n今度は、readiness を失敗させましょう。こちらは 50x.html を削除すれば良いですね。\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-healthcheck rm /usr/share/nginx/html/50x.html\npi@raspi001:~/tmp $ k get pods --watch\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-healthcheck                        1/1     Running   2          16m\nsample-healthcheck                        0/1     Running   2          16m\npi@raspi001:~/tmp $ k exec -it sample-healthcheck touch /usr/share/nginx/html/50x.html\npi@raspi001:~/tmp $ k get pods --watch\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-healthcheck                        0/1     Running   2          17m\nsample-healthcheck                        1/1     Running   2          17m\n```\n\n期待通り、50x.html を削除すると、READY から外れて、追加すると READY に戻りました。\n\n## コンテナの再起動\n\nコンテナのプロセスが停止、またはヘルスチェックの失敗によってコンテナを再起動するかどうかは、spec.restartPolicy によって決まります。\n種類は下記３つです。\n\n- Always\n  - 常に Pod を再起動させる\n- OnFailure\n  - 終了コード 0 以外の予期せぬ停止の場合、Pod を再起動させる\n- Never\n  - 再起動させない\n\n試してみましょう。\n\n```yaml\n## sample-restart-always.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-restart-always\nspec:\n  restartPolicy: Always\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      command: [\"sh\", \"-c\", \"exit 0\"] # 成功の場合\n##      command: [\"sh\", \"-c\", \"exit 1\"] # 失敗の場合\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-restart-always.yaml\n## 成功の場合\npi@raspi001:~/tmp $ k get pods sample-restart-always --watch\nNAME                    READY   STATUS              RESTARTS   AGE\nsample-restart-always   0/1     ContainerCreating   0          13s\nsample-restart-always   0/1     Completed           0          19s\nsample-restart-always   0/1     Completed           1          27s\nsample-restart-always   0/1     CrashLoopBackOff    1          28s\nsample-restart-always   0/1     Completed           2          37s\n## 失敗の場合\npi@raspi001:~/tmp $ k get pods sample-restart-always --watch\nNAME                    READY   STATUS              RESTARTS   AGE\nsample-restart-always   0/1     ContainerCreating   0          7s\nsample-restart-always   0/1     Error               0          12s\nsample-restart-always   0/1     Error               1          17s\nsample-restart-always   0/1     CrashLoopBackOff    1          18s\nsample-restart-always   0/1     Error               2          37s\n```\n\n成功、失敗どちらも再起動していることがわかります。\n\n```yaml\n## sample-restart-onfailure.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-restart-onfailure\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      command: [\"sh\", \"-c\", \"exit 0\"] # 成功の場合\n##      command: [\"sh\", \"-c\", \"exit 1\"] # 失敗の場合\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-restart-onfailure.yaml\n## 成功の場合\npi@raspi001:~/tmp $ k get pods sample-restart-onfailure --watch\nNAME                       READY   STATUS              RESTARTS   AGE\nsample-restart-onfailure   0/1     ContainerCreating   0          3s\nsample-restart-onfailure   0/1     Completed           0          15s\n## 失敗の場合\npi@raspi001:~/tmp $ k get pods sample-restart-onfailure --watch\nNAME                       READY   STATUS              RESTARTS   AGE\nsample-restart-onfailure   0/1     ContainerCreating   0          4s\nsample-restart-onfailure   0/1     Error               0          22s\nsample-restart-onfailure   0/1     Error               1          28s\nsample-restart-onfailure   0/1     CrashLoopBackOff    1          29s\nsample-restart-onfailure   0/1     Error               2          50s\n```\n\n成功時は、Completed の終了していますね。CrashLoopBackOff していません。失敗時は、Error となり、CrashLoopBackOff しています。\n期待通りですね。\n\n## initContainers\n\nPod のメインとなるコンテナを起動する前に別のコンテナを起動させるための機能です。\nspec.containers がもともとありますが、こちらは同時並列で起動するので、順序が必要な場合には向いていません。\ninitContainers は、spec.initContainers で設定でき、複数指定できます。複数の場合は上から順に起動します。\n\n試してみましょう。\n\n```yaml\n## sample-initcontainer.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-initcontainer\nspec:\n  initContainers:\n    - name: output-1\n      image: nginx:1.12\n      command:\n        [\"sh\", \"-c\", \"sleep 20; echo 1st > /usr/share/nginx/html/index.html\"]\n      volumeMounts:\n        - name: html-volume\n          mountPath: /usr/share/nginx/html/\n    - name: output-2\n      image: nginx:1.12\n      command:\n        [\"sh\", \"-c\", \"sleep 10; echo 2nd >> /usr/share/nginx/html/index.html\"]\n      volumeMounts:\n        - name: html-volume\n          mountPath: /usr/share/nginx/html/\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      volumeMounts:\n        - name: html-volume\n          mountPath: /usr/share/nginx/html/\n  volumes:\n    - name: html-volume\n      emptyDir: {}\n```\n\n```shell\npi@raspi001:~/tmp $ k get pod sample-initcontainer --watch\nNAME                   READY   STATUS     RESTARTS   AGE\nsample-initcontainer   0/1     Init:0/2   0          3s\nsample-initcontainer   0/1     Init:0/2   0          9s\nsample-initcontainer   0/1     Init:1/2   0          30s\nsample-initcontainer   0/1     Init:1/2   0          38s\nsample-initcontainer   0/1     PodInitializing   0          51s\nsample-initcontainer   1/1     Running           0          59s\npi@raspi001:~/tmp $ k exec -it sample-initcontainer cat /usr/share/nginx/html/index.html\n1st\n2nd\n```\n\n確かに、initContainers が順序通り起動できています。ふむふむ。\n\n## 起動時と終了時のコマンド実行(postStart,preStop)\n\nコンテナ起動後に実行するコマンドを postStart,\nコンテナ終了前に実行するコマンドを preStop という機能で実現できます。\n\n```yaml\n## sample-lifecycle.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-lifecycle\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      command: [\"/bin/sh\", \"-c\", \"touch /tmp/started; sleep 3600\"]\n      lifecycle:\n        postStart:\n          exec:\n            command: [\"/bin/sh\", \"-c\", \"sleep 20; touch /tmp/poststart\"]\n        preStop:\n          exec:\n            command: [\"/bin/sh\", \"-c\", \"touch /tmp/prestop; sleep 20\"]\n```\n\n```shell\npi@raspi001:~/tmp $  k apply -f sample-lifecycle.yaml\npi@raspi001:~/tmp $  k exec -it sample-lifecycle ls /tmp\nstarted\n## 数秒後\npi@raspi001:~/tmp $  $ k exec -it sample-lifecycle ls /tmp\npoststart  started\npi@raspi001:~/tmp $ k delete -f sample-lifecycle.yaml\n## すぐ!\npi@raspi001:~/tmp $ k exec -it sample-lifecycle ls /tmp\npoststart  prestop  started\n```\n\nたしかに、postStart, preStop が動いています。\n注意しないといけないのが、postStart は、spec.containers[].command の実行とほぼ同じだそうです。（非同期)\n\n## Pod の安全な停止とタイミング\n\nterminationGracePeriodSeconds に指定した秒数は、pod が削除開始時からの猶予です。\nデフォルトで 30 秒となっています。30 秒の間に preStop+SIGTERM の処理が終わらなければ、\n強制的に SIGKILL されて停止されます。ただし、preStop が終わっていなくて 30 秒たった場合、\nSIGTERM 処理を 2 秒だけ実施できます。\nterminationGracePeriodSeconds の値は、prePost を必ず終える秒数に設定しましょう。\n\n## Node をスケジューリング対象から外す\n\nNode を kubernetes のスケジューリング対象から外す cordon というコマンドがあります。\nNode の状態には、SchedulingEnabled と SchedulingDisabled があり、後者の状態になると、\nkubernetes からのスケジューリング対象外となり、たとえば ReplicaSet の更新などが機能しなくなります。\n\ncordon コマンドを使うと、指定する Node が SchedulingDisabled になります。(uncordon は逆)\nただし、現在動作している Pod はスケジューリング対象になったままで、新たに追加するものが\nスケジューリング対象外になります。現在動作しているものも対象にしたい場合は、drain コマンド\nを使います。\n実際に試してみます。\n\n```shell\npi@raspi001:~/tmp $ k get nodes\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   33d   v1.14.1\nraspi002   Ready    worker   33d   v1.14.1\nraspi003   Ready    worker   32d   v1.14.1\npi@raspi001:~/tmp $ k cordon raspi002\npi@raspi001:~/tmp $ k get nodes\nNAME       STATUS                     ROLES    AGE   VERSION\nraspi001   Ready                      master   33d   v1.14.1\nraspi002   Ready,SchedulingDisabled   worker   33d   v1.14.1\nraspi003   Ready                      worker   32d   v1.14.1\npi@raspi001:~/tmp $ k uncordon raspi002\npi@raspi001:~/tmp $ k get nodes\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   33d   v1.14.1\nraspi002   Ready    worker   33d   v1.14.1\nraspi003   Ready    worker   32d   v1.14.1\npi@raspi001:~/tmp $ k drain raspi002\nnode/raspi002 cordoned\nerror: unable to drain node \"raspi002\", aborting command...\n\nThere are pending nodes to be drained:\n raspi002\nerror: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kube-flannel-ds-arm-7nnbj, kube-system/kube-proxy-wgjdq, metallb-system/speaker-tsxdk\n```\n\ndrain すると、ReplicaSet のように管理した Pod であれば、別 Node に作成されるので良いのですが、\n単体 Pod など管理されていないものは、削除されてしまいます。上記の警告は、DaemonSet で管理されている Pod は、\n削除するしかないけど、良いですか？というものです。\nそのため、drain をすると、いくつか警告されます。警告内容に従って適宜操作する必要があります。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-healthcheck.yaml -f sample-restart-always.yaml -f sample-restart-onfailure.yaml -f sample-initcontainer.yaml -f sample-lifecycle.yaml\n```\n\n## 最後に\n\n今回は、ヘルスチェックの動作と、コンテナを停止するまでのステップを学習しました。\nわざわざヘルスチェックの処理をアプリケーションに用意せずとも、kubernetes に機能として\n存在することに、驚きました。次回は、[こちら](./start_the_learning_kubernetes_14)です。","publishedAt":"2019-05-30","slug":"start_the_learning_kubernetes_13","title":"一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)では、storage について学習しました。\n今回は、リソース制限について学習します。\n\n※ リソースの種類から、次は「Metadata」だったのですが、kubernetes 完全ガイドによると直接説明するのではなく、内容ベースで説明されていましたので、それに準拠します。\n\n## リソース制限\n\nkubernetes で管理するコンテナに対して、リソース制限をかけることができます。主に CPU やメモリに対して制限をかけることができますが、Device Plugins を使うことで GPU にも制限をかけることもできます。\n\n※ CPU の指定方法は、1vCPU を 1000millicores(m)とする単位となります。\n\n## requests と limits\n\nrequest は、使用するリソースの下限値です。\nlimits は、使用するリソースの上限値です。\n\nrequest は、空きノードに指定するリソースがなければスケジューリングされませんが、limits は、関係なくスケジューリングされます。\n\nとにもかくにも、試してみましょう。\n\nまず、現状確認です。\n\n```shell\npi@raspi001:~/tmp $ k get node\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   31d   v1.14.1\nraspi002   Ready    worker   31d   v1.14.1\nraspi003   Ready    worker   30d   v1.14.1\npi@raspi001:~/tmp $ k get nodes -o jsonpath='{.items[?(@.metadata.name!=\"raspi001\")].status.allocatable.memory}'\n847048Ki 847048Ki\npi@raspi001:~/tmp $ k get nodes -o jsonpath='{.items[?(@.metadata.name!=\"raspi001\")].status.allocatable.cpu}'\n4 4\npi@raspi001:~/tmp $ k get nodes -o jsonpath='{.items[?(@.metadata.name!=\"raspi001\")].status.capacity.memory}'\n949448Ki 949448Ki\npi@raspi001:~/tmp $ k get nodes -o jsonpath='{.items[?(@.metadata.name!=\"raspi001\")].status.capacity.cpu}'\n4 4\n\n```\n\njsonpath の使い方は、[こちら](https://kubernetes.io/docs/reference/kubectl/jsonpath/)にあります。\n\nallocatable が Pod に配置できるリソース量で、capacity は Node 全体での配置できるリソース量です。\nこれだけだと、現在使っているリソース量が不明なので個別に調べます。\n\n```shell\npi@raspi001:~/tmp $ k describe node raspi002\n...\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                200m (5%)    200m (5%)\n  memory             150Mi (18%)  150Mi (18%)\n  ephemeral-storage  0 (0%)       0 (0%)\n...\npi@raspi001:~/tmp $ k describe node raspi003\n...\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                400m (10%)   300m (7%)\n  memory             320Mi (38%)  420Mi (50%)\n  ephemeral-storage  0 (0%)       0 (0%)\n...\n```\n\n現状のリソース状況を表にすると下記のとおりです。\n\n| node     | allocatable / (memory/cpu) | capacity / (memory/cpu) | used / (memory/cpu) | remain / (memory/cpu) |\n| -------- | ----------------------------- | -------------------------- | ---------------------- | ------------------------ |\n| raspi002 | 847,048Ki/4000m               | 949,448Ki/4000m            | 150,000Ki/200m         | 697,048Ki/3800m          |\n| raspi003 | 847,048Ki/4000m               | 949,448Ki/4000m            | 320,000Ki/400m         | 527,048Ki/3600m          |\n\nでは、リソース制限を試してみましょう。\n\n```yaml\n## sample-resource.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-resource\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          resources:\n            requests:\n              memory: \"128Mi\"\n              cpu: \"300m\"\n            limits:\n              memory: \"256Mi\"\n              cpu: \"600m\"\n```\n\napply する pod で要求する memory の下限合計は 384Mi(128Mi×3),cpu は 900m(300m×3)です。\nこれだと、pod が run するはずです。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-resource.yaml\npi@raspi001:~/tmp $ k get pods\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-resource-785cd54844-7n89t          1/1     Running   0          108s\nsample-resource-785cd54844-9b5f9          1/1     Running   0          108s\nsample-resource-785cd54844-whj7x          1/1     Running   0          108s\n```\n\n期待通りですね。\n今度はリソース制限になる状態を試してみます。\n\n全 WorkerNode の memory 下限合計は 1,224Mi(697,048Ki+527,048Ki)です。\nこれを超えるように先程のマニフェストを更新します。\nreplica 数を 3 にしましたが、10 にすれば良いですね（1,280Mi)\n\n期待動作として、9 個(128Mi\\*9=1,152Mi)は Running で、1 個(128Mi)は Pending になるはずです。\n\nsample-resource.yaml の replica を 10 に変更したあと ↓\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-resource.yaml\npi@raspi001:~/tmp $ k get pods\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-resource-785cd54844-7n89t          1/1     Running   0          6m19s\nsample-resource-785cd54844-9b5f9          1/1     Running   0          6m19s\nsample-resource-785cd54844-dffsd          1/1     Running   0          61s\nsample-resource-785cd54844-jmkv6          1/1     Running   0          61s\nsample-resource-785cd54844-k9vcb          1/1     Running   0          61s\nsample-resource-785cd54844-l4smf          0/1     Pending   0          60s\nsample-resource-785cd54844-n4hl7          1/1     Running   0          60s\nsample-resource-785cd54844-th4bp          0/1     Pending   0          60s\nsample-resource-785cd54844-whj7x          1/1     Running   0          6m19s\nsample-resource-785cd54844-xclsk          1/1     Running   0          60s\n```\n\nあれ、2 つ Pending になっていますね。もしかして、Node の空きリソースが中途半端にないからですかね。\n確認してみましょう。\n\n```shell\npi@raspi001:~/tmp $ k describe node raspi002\n...\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1700m (42%)  3200m (80%)\n  memory             790Mi (95%)  1430Mi (172%)\n  ephemeral-storage  0 (0%)       0 (0%)\n...\npi@raspi001:~/tmp $ k describe node raspi003\n...\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1300m (32%)  2100m (52%)\n  memory             704Mi (85%)  1188Mi (143%)\n  ephemeral-storage  0 (0%)       0 (0%)\n...\n```\n\nraspi002 は、847Mi 中 790Mi 使っています。１つの Pod を追加するためのリソース（128Mi）はないですね。\nraspi003 は、847Mi 中 704Mi 使っています。こちらは空いている気がするのですが、なぜでしょうか。\n\nここで、memory の`704Mi (85%)`というところに着目すると、100%だった場合は 828Mi ということになります。\n確かに、それだと 704Mi+128Mi=832Mi でオーバーしています。\n\nでは、allocatable で表示されていた 847Mi との違いは何でしょうか。\nallocatable というのは、全ての namespace にある pod も込みのリソース配置可能量だからです。\ndefault だけでなく、kube-system など他の namespace にある pod も、もちろんリソースを消費しています。\n828Mi というのは、default で使えるリソース配置可能量ではないでしょうか。（現在の namespace は default)\n\nちなみに、Limits は、100%を超えていますね...。ひぇ〜...。\n\n## Cluster Autoscaler\n\n需要に応じて Kubernetes Node を自動的に追加されていく機能です。\nこれが動作するタイミングは、Pod が Pending になったときに動作します。\nつまり、先程の例であったように、requests の下限によってスケールします。\n\nそのため、requests が高すぎるために、実際はロードアベレージが低くてもスケールしてしまったり、\nrequests が低すぎるために、実際は高負荷でもスケールしなくなったりします。\nrequests は、パフォーマンステストをしつつ最適化していきましょう。\n\n## LimitRange\n\nさっきの例でもあったように、それぞれに対して requests,limit を設定しても良いのですが、\nもっと便利なものがあります。それが LimitRange です。\nこれは、Namespace に対して CPU やメモリのリソースの最小値や最大値を設定できます。\n設定可能な制限項目として、下記があります。\n\n- default\n  - デフォルトの Limits\n- defaultRequest\n  - デフォルトの Requests\n- max\n  - 最大リソース\n- min\n  - 最小リソース\n- maxLimitRequestRatio\n  - Limits/Requests の割合\n\nまた、制限する対象は、Container,Pod,PersistentVolumeClaim があります。\n実運用する際は、きちんと定義しておきましょう。（プロバイダーによってはデフォルトで設定されているものもあるそうです）\n\n## ResourceQuota\n\nResourceQuota を使うことで、Namespace ごとに「作成可能なリソース数の制限」と「リソース使用量の制限」ができます。\n「作成可能なリソース数の制限」を試そうと思います。\n\n```yaml\n## sample-resourcequota.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: sample-resourcequota\n  namespace: default\nspec:\n  hard:\n    # 作成可能なリソースの数\n    count/pods: 5\n```\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-resource.yaml\npi@raspi001:~/tmp $ k apply -f sample-resourcequota.yaml\npi@raspi001:~/tmp $ k apply -f sample-resource.yaml\npi@raspi001:~/tmp $ k get pods\nNAME                                      READY   STATUS    RESTARTS   AGE\nsample-resource-785cd54844-dll8t          1/1     Running   0          38s\nsample-resource-785cd54844-ljr7q          1/1     Running   0          39s\nsample-resource-785cd54844-r6txh          1/1     Running   0          38s\nsample-resource-785cd54844-sb6sq          1/1     Running   0          38s\nsample-resource-785cd54844-3ffeg          1/1     Running   0          38s\n```\n\nこうすると、pods が 5 個までしか作成できないので、sample-resource.yaml を適用しても 5 個までしか作成されません。\nreplica のような場合は、特に警告がなく単純に作られませんでした。\nconfigmap を 5 個までに制限して、1 つずつ configmap を apply すると、警告がでるそうです。\n\n## HorizontalPodAutoscaler(HPA)\n\nHPA は、Deployment,ReplicaSet で管理する Pod の CPU 負荷などに応じて自動的にスケールするリソースです。\n30 秒に１回の頻度でスケールするかチェックしています。\n\n必要なレプリカ数は、下記の数式で表します。\n\n- 必要なレプリカ数 = ceil(sum(Pod の現在の CPU 使用率)/targetAverageUtilization)\n\n[Kubernetes の Pod と Node の Auto Scaling について](https://qiita.com/sheepland/items/37ea0b77df9a4b4c9d80)で、\n\n> auto scaling は target value に近づくように pod 数が調整されるということ。\n\nという文がわかりやすかったです。つまり、targetAverageUtilization が 50 なら、全体の CPU 使用率が 50%になるよう調整されます。\n今回、試そうと考えたのですが、metrics-server を install していないため、動作確認できませんでした。\nまた今度 install して試してみようと思います。\n\n## VerticalPodAutoscaler(VPA)\n\nVPA は、コンテナに割り当てる CPU やメモリのリソース割当をスケールさせるリソースです。\nこれは、HPA のスケールアウトではなく、Pod のスケールアップを行うものです。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-resource.yaml -f sample-resourcequota.yaml\n```\n\n## 最後に\n\n今回は、Requests や Limits を操作してリソース制限をしてみました。\nどれがいくらリソースを消費しているのか確認する術を学び、\nついでに jsonpath の使い方も知りました。\n次回は、[こちら](./start_the_learning_kubernetes_13)です。","publishedAt":"2019-05-29","slug":"start_the_learning_kubernetes_12","title":"一足遅れて Kubernetes を学び始める - 12. リソース制限 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)では、config について学習しました。\n今回は、storage を学びます。\n\n## Volume と PresistentVolume\n\nVolume は、あらかじめ決められた利用可能なボリュームを指します。こちらは、ボリュームの削除や新規作成ができません。\nPresistentVolume は、外部にある永続ボリュームを指します。こちらは、ボリュームの削除や新規作成ができます。\nDB のようなステートフルなものは PresistentVolume を使います。\n一時的なものなら、Volume を使うのですかね？\n\n※ PresistentVolumeClaim は、PresistentVolume をアサインするためのリソース。\n\n## Volume の種類\n\n書籍（kubernetes 完全ガイド）で紹介されていた Volume の種類は、下記のとおりです。\n\n- emptyDir\n  - 一時的なディスク領域を利用\n  - pod 削除されると、emptyDir も削除\n  - マウント先を指定できない\n- hostPath\n  - emptyDir のマウント先を指定できる版\n- downwardAPI\n  - Pod の情報をファイルとして配置したファイルをマウント\n- projected\n  - secret/configMap/downwardAPI/serviceAccountToken を１つにまとめたディレクトを作成し、マウント\n\n※ [types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)\n\nVolume を残すことができないので、Pod を削除する際は気をつけないとダメですね。\nログをファイルとして保存するなら、一時的に Volume が良いのですかね。\nただ、定期的に外部ストレージに移さないといけないですので、手間です。\n（そもそも、ログはストリームにして外部サービスに流すのがベスト）\n\nプロダクトとしては、あんまり使い道ない...?\n\n## PresistentVolume の種類\n\n外部の永続ボリュームを利用します。例えば、下記の種類があります。\n\n- GCE Persistent Disk\n- AWS Elastic Block Store\n- NFS\n- iSCSI\n- Ceph\n- OpenStack Cinder\n- GlusterFS\n\n[一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)では、NFS を使いましたね。\nPersistentVolume の作成方法は、外部の永続ボリュームによって違うのですが、共通して言えるところもあるみたいなので、\nそこを書いてみます。\n\n- ラベル\n  - PersistentVolume をラベリングすることで、指定しやすくする\n- 容量\n  - Volume で要求する容量。最も小さい容量からアサインされる。\n- アクセスモード\n  - ReadWriteOnce\n    - 単一ノードから Read/Write が可能\n  - ReadOnlyMany\n    - 複数ノードから Read が可能\n  - ReadWriteMany\n    - 複数ノードから Read/Write が可能\n- Reclaim Policy\n  - Volume を使い終わったあと、破棄するか再利用するかのポリシー\n    - Delete\n      - PersistentVolume の実体を削除\n    - Retain\n      - PersistentVolume の実体を残さず保持\n      - 再度マウントされない\n    - Recycle\n      - PersistentVolume のデータを削除し、再利用可能にする\n      - 再度マウントされる\n      - （廃止予定で、DynamicProvisioning を利用すること)\n- StorageClass\n  - 各プロバイザーが提供するストレージの型\n    - 基本的に自動作成されている\n\n## PersistentVolumeClaim\n\n実際に、PresistentVolume を使うためには、PresistentVolumeClaim で要求を出す必要があります。\n必要な項目は、下記です。\n\n- ラベルセレクタ\n  - ラベルでフィルタリング\n- 容量\n  - 求めている容量\n- アクセスモード\n  - PresistentVolume のアクセスモードを参照\n- StorageClass\n  - PresistentVolume の StorageClass を参照\n\n要求を満たした Volume が RetainPolicy だった場合、Claim を削除した時点で「Released」になります。\n\n## 最後に\n\n今回は、書籍をそのまま書いた感じになりました。\n実際に試したのは、[一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)です。\nまあ、あんまり深くはハマらない方が良いのではと思いました。\n次回は、[こちら](./start_the_learning_kubernetes_12)です。","publishedAt":"2019-05-27","slug":"start_the_learning_kubernetes_11","title":"一足遅れて Kubernetes を学び始める - 11. config&storage その2 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)では、様々な service を学習しました。\n今回は、config&storage の config を学びます。\n\n## config&storage\n\nKubernetes には、下記のようにリソースの種類が存在します。\n\n| リソースの分類           | 内容                                                         |\n| :----------------------- | :----------------------------------------------------------- |\n| Workloads リソース       | コンテナの実行に関するリソース                               |\n| Discovery＆LB リソース   | コンテナを外部公開するようなエンドポイントを提供するリソース |\n| Config＆Storage リソース | 設定・機密情報・永続化ボリュームなどに関するリソース         |\n| Cluster リソース         | セキュリティやクォータなどに関するリソース                   |\n| Metadata リソース        | リソースを操作する系統のリソース                             |\n\n※ [Kubernetes の Workloads リソース（その 1）](https://thinkit.co.jp/article/13610)\n\n## 環境変数\n\n静的設定や、Pod やコンテナの情報を設定、シークレットでの設定があるみたいです。\n\n```yaml\n## sample-env.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-env\n  labels:\n    app: sample-app\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n      env:\n        - name: MAX_CONNECTION\n          value: \"100\"\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: LIMITS_CPU\n          valueFrom:\n            resourceFieldRef:\n              containerName: nginx-container\n              resource: limits.cpu\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-env.yaml\npi@raspi001:~/tmp $ k exec -it sample-env env\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n...\nMAX_CONNECTION=100\nPOD_IP=10.244.1.97\nLIMITS_CPU=4\n...\n```\n\nMAX_CONNECTION は、静的に設定できています。\nPod やコンテナの設定は、POD_IP,KIMITS_CPU で設定できています。\nPod やコンテナの情報は、`k get pods sample-env -o yaml`で得ることができます。ふむふむ。\n\n## Secret\n\nパスワードなどの機密情報を Secret で暗号化してくれます。\n手段の種類が下記のようにいくつかあります。\n\n- Generic\n- TLS\n- Docker Repository\n- Service Account\n\nGeneric の場合は、スキーマレスなため、汎用性の高い指定が可能になります。それを使ってみようと思います。(TLS の場合は、tls.crt,tls.key が必要）\n\n使い方して、ファイル参照、envfile 参照、直接指定、マニュフェスト指定の４パターンです。それぞれ試してみます。\n\n## ファイル参照\n\n```shell\npi@raspi001:~/tmp $ echo -n \"root\" > ./username\npi@raspi001:~/tmp $ echo -n \"rootpassword\" > ./password\npi@raspi001:~/tmp $ k create secret generic --save-config sample-db-auth --from-file=./username --from-file=./password\npi@raspi001:~/tmp $ sudo apt-get install jq\npi@raspi001:~/tmp $ k get secrets sample-db-auth -o json | jq .data\n{\n  \"password\": \"cm9vdHBhc3N3b3Jk\",\n  \"username\": \"cm9vdA==\"\n}\n```\n\n## envfile 参照\n\n```text\n## env-secret.txt\nusername=root\npassword=rootpassword\n```\n\n```shell\npi@raspi001:~/tmp $ k create secret generic --save-config sample-db-auth2 --from-env-file ./env-secret.txt\npi@raspi001:~/tmp $ k get secrets sample-db-auth2 -o json | jq .data\n{\n  \"password\": \"cm9vdHBhc3N3b3Jk\",\n  \"username\": \"cm9vdA==\"\n}\n```\n\n## 直接指定\n\n```shell\npi@raspi001:~/tmp $ k create secret generic --save-config sample-db-auth3 --from-literal=username=root --from-literal=password=rootpassword\npi@raspi001:~/tmp $ k get secrets sample-db-auth3 -o json | jq .data\n{\n  \"password\": \"cm9vdHBhc3N3b3Jk\",\n  \"username\": \"cm9vdA==\"\n}\n```\n\n## マニュフェスト指定\n\n```yaml\n## sample-db-auth.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: sample-db-auth4\ntype: Opaque\ndata:\n  username: cm9vdA== # root\n  password: cm9vdHBhc3N3b3Jk # rootpassword\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-db-auth.yaml\npi@raspi001:~/tmp $ k get secrets sample-db-auth4 -o json | jq .data\n{\n  \"password\": \"cm9vdHBhc3N3b3Jk\",\n  \"username\": \"cm9vdA==\"\n}\n```\n\nどれも、正しく動きましたね。プロダクトとしては使わないと思いますが、お試しで確認するには\nGeneric は扱いやすくて良いですね。\n\nでは、設定した値を使ってみましょう。\n\n## Secret の利用\n\n手段として、環境変数か Volume かの 2 つです。\n\n## 環境変数から Secret を使う\n\n```yaml\n## sample-secret-single-env.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-secret-single-env\nspec:\n  containers:\n    - name: secret-container\n      image: nginx:1.12\n      env:\n        - name: DB_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: sample-db-auth\n              key: username\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-secret-single-env.yaml\npi@raspi001:~/tmp $ k exec -it sample-secret-single-env env | grep DB_USERNAME\nDB_USERNAME=root\n```\n\n環境変数から使う場合、値が固定されてしまいます。（静的）\n\n## Volume から Secret を使う\n\n```yaml\n## sample-secret-single-volume.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-secret-single-volume\nspec:\n  containers:\n    - name: secret-container\n      image: nginx:1.12\n      volumeMounts:\n        - name: config-volume\n          mountPath: /config\n  volumes:\n    - name: config-volume\n      secret:\n        secretName: sample-db-auth\n        items:\n          - key: username\n            path: username.txt\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-secret-single-volume.yaml\npi@raspi001:~/tmp $ k exec -it sample-secret-single-volume cat /config/username.txt\nroot\n```\n\nこちらは、動的に書き換えることができるそうです。逐次 Volume を見ているんでしょうね。（環境変数の場合、コンテン起動した時点で固定される）\n\n```shell\npi@raspi001:~/tmp $ cat << EOF | k apply -f -\n> apiVersion: v1\n> kind: Secret\n> metadata:\n>   name: sample-db-auth\n> type: Opaque\n> data:\n>  username: YMRtaW4=\n>  # root > admin\n> EOF\npi@raspi001:~/tmp $ k exec -it sample-secret-single-volume cat /config/username.txt\namin\n```\n\n動的に書き換わっていますね。OK!\n\n※ admin の a が文字化けしていた...\n\n## ConfigMap\n\n設定情報を Key-Value 形式で登録することができます。\nこちらも手段としては、ファイル参照、直接参照、マニフェスト参照があります。\nさっきと同じなので、ファイル参照のみ試してみます。\n\n```text\n## sample.txt\nhogehoge\nfugafuga\n```\n\n```shell\npi@raspi001:~/tmp $ k create configmap --save-config sample-configmap --from-file=./sample.txt\npi@raspi001:~/tmp $ k get configmaps sample-configmap -o json | jq .data\n{\n  \"sample.txt\": \"hogehoge\\nfugafuga\\n\"\n}\n```\n\nsecret と同じ感じですね。これって、どんなファイルでも(1MB まで)保存できちゃうそうです。\nsecret と同様で、設定したデータは環境変数、Volume の２つから参照可能です。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-env.yaml -f sample-db-auth.yaml -f sample-secret-single-env.yaml -f sample-secret-single-volume.yaml\npi@raspi001:~/tmp $ k delete secret sample-db-auth sample-db-auth2 sample-db-auth3\npi@raspi001:~/tmp $ k delete configmap sample-configmap\n```\n\n## 最後に\n\n環境変数の設定方法について、学びました。\n個人開発で、外部サービスをアプリケーションに組み込む際、\nAPI_KEY を環境変数として登録して開発しています。\n今回は、Generic で Secret を保存しましたが、プロダクトでは、\nservice_account を使うのが一般的なのでしょうか？\n\n次回は、Storage について学習します。\n[こちら](./start_the_learning_kubernetes_11)です。","publishedAt":"2019-05-23","slug":"start_the_learning_kubernetes_10","title":"一足遅れて Kubernetes を学び始める - 10. config&storage その1 -"},{"body":"今回、k8s の体験を目的として参加したのですが、意外な収穫があったので、\n共有したく、記事を書くことにしました。hashtag はこちら [#bmxug](https://twitter.com/hashtag/bmxug)\n\nhttps://bmxug.connpass.com/event/117966/\n\n## Watson Discovery\n\n## Watson Discovery とは\n\n簡単に言うと、IBM 製の検索 API になります。\n全文検索システムでおなじみに ElasticSearch とは違った「IBM」ならではの機能が搭載されています。\nまた、無料で使えるとのことで、興味津々になってしまいました。\n\n## どんな特徴があるの\n\nなにかしらの文章データを WatsonDiscovery に渡してあげることで、\n文章にあるコンテキストを種々様々な側面から抽出してくれます。\n特に、大量のドキュメントを検索したいときに使う場合に活躍します。\n\n## メタ情報による検索\n\n登録した文章データから良い感じのメタ情報を抽出してくれます。\nたとえば、下記の属性があるみたいです。\n\n- エンティティ\n- リレーション\n- キーワード\n- カテゴリー\n- コンセプト\n- セマンティックロール\n- センチメント\n- エモーション\n\n例えば、怒っている文章を渡すと WatsonDiscovery では、\n「怒りのエモーション」メタ情報を付与されます。ほえ〜！すごい！\n確かに独自な機能ですよね。  \nこの機能は、日本語ではサポートされていませんでしたが、\n2018 年 8 月ごろにできるようになったそうです！\n\n## 隠れたコンセプトをみつける\n\n文章にあるワードだけでなく、文章にないワードのコンセプトも見出してくれるそうです。\nどうなってるんだ！？\n\n## クローラも提供されている(WebCrewl)\n\n日本語のニュースを定期的にクロールして、ディスカバリーの辞書を更新してくれる機能もあるそうです。\n手段の１つに、URL を指定するだけで勝手にクロールしてくれる方法もあります。簡単だ。。。\nこれを使えば、データを用意しなくて済みますし、お問い合わせ Q&A みたいなのが簡単に作れちゃいます。\n\n## サンプル紹介\n\n例えば、「喜ばれるホワイトデーのプレゼント」で検索してみます。\nまた、メタ情報検索として、センチメンタル「ポジティブ」を指定。\n（データは、WebCrewl で収集済み）\n\n結果を、種々様々な形式のランキングを表示してくれました。\n例えば、「いくらお金をつかうか？」というランキングでは、TOP が**無料**でした。これは面白かった。\n\n## visual insight (ベータ版)\n\nワードの距離を視覚的に見せてくれるそう。wordCloud もありました。\n\n## 最後に\n\nIBM ならではの、独特の全文検索システム API でした。\n無料で使えるそうなので、時間があるときにでも使ってみたいなと思います！","publishedAt":"2019-05-22","slug":"bmxug_kubernetes_watson_discovery","title":"【大阪】BMXUG勉強会 -Kubernates体験＆Watson Discovery入門- 2019年3月27日参加レポート"},{"body":"https://gcpug-osaka.connpass.com/event/128130/\n\nこちらの参加しましたので、ご報告します。hashtag はこちらです。[#next19extended](https://twitter.com/hashtag/next19extended)\n\n## 目的\n\n> 2019/04/09 ～ 04/11 にサンフランシスコで開催された\n> Google Cloud Next '19 San Francisco で発表された\n> Google Cloud の 新サービスに関する解説や振り返りの内容がメインのイベントとなります！\n\n## セッション紹介\n\n## GCPUG Kansai 紹介\n\n```text\nGCPUG Osaka\nGCPUG Kobe\nGCPUG Kyoto\nGCPUG Nara\nGCPUG Shiga\nGCPUG Wakayama\nFJUG Osaka (firebase)\n```\n\n関西には、こんなにも多く GCPUG コミュニティがあるみたいです。すごい、いっぱい！\nOsaka は、継続して参加しようと思います。GCP 大好きですし。\n\n## Cloud Next Recap 1\n\n### 発表者\n\nIan Lewis(Google)\n\n### 内容\n\nGoogle で Kubernetes の担当されているそうです。\nまた、Pycon や、connpass にも携わっているそうです。\n\n#### Anthos\n\n読み方は、アンソスと呼ぶそうです。難しい...。\n\n特徴として、下記が挙げられるそうで...  \n・アプリケーションをモダナイズ  \n・ポリシーオートメーション  \n・一貫したエクスペリエンス\n\nよーわからないので、gg ってみた。\n\nhttps://www.publickey1.jp/blog/19/googleanthoskubernetesgoogle_cloud_next_19.html\n\n> コンテナ化したアプリケーションをオンプレミスとクラウドのどちらでも実行可能にする、ハイブリッドクラウドおよびマルチクラウドのためのプラットフォーム。\n> オンプレミスを含むどのクラウド上にアプリケーションがデプロイされていても、Anthos の管理画面から統合管理可能。\n\nなるほど、Anthos はマルチクラウドを実現するためのプラットフォームなのですね。\nふむふむ、わかりやすい。\n\nまた、Istio をベースとして Anthos が作られたとも発表されていました。\nIstio については、[こちら](https://cloud.google.com/istio/?hl=ja)をご確認下さい。  \nIstio の機能の特徴として下記があるそうです。\n\nhttps://twitter.com/nankouyuukichi/status/1128245474215858176?s=20\n\nk8s では、対象とするクラスタを管理します。規模が拡大するにつれ、\nサービスが複雑になってくるケースがあります。その際 Istio が、そのあたりを\n良い感じに管理してくれると、理解しています。（ざっくり感）  \n※ マルチクラスタは既に実現できていた(?)\n\nAnthos は、その対象範囲をクラウドだけでなく、オンプレ(GKE on Prem)も含めるようにしたと思います。\n\n## CloudRun\n\nこれは、下記で一度試した経験があります。\n\nhttps://silverbirder.github.io/blog/contents/cloud_run_3_step_glang\n\nコンテナとして deploy できるようになります。\n正直、AppEngine, CloudFunction, CoundRun とデプロイサービスが増えてきて、\nどれが何に良いのか分からなくなりそうです...。下記に、まとまっていました。\n\nhttps://docs.google.com/presentation/d/1DCJlrXQKWN63pAz9vtdVNFhMPHceyiKHK0IrFjcwOcU/edit#slide=id.g5693476139_0_155\n\n## CloudRun on GKE\n\nこちらは、k8s に CloudRun を deploy できるみたいです。\n詳しくは分かりません。\n\n## Knative\n\nhttps://cloud.google.com/knative/?hl=ja\n\n> Knative は、オンプレミス、クラウド、サードパーティのデータセンターなど、場所を選ばず実行できるソース中心でコンテナベースの最新アプリケーションを構築する際には不可欠な一連のミドルウェア コンポーネントです。\n\nんー、なんとなくわからなくないですが、他のサイトを見てみます。\n\nhttps://www.apps-gcp.com/knative-overview/\n\n> Knative を使用するためには、Kubernetes がインストールされたクラスタを用意する必要がありますが、Knative は Kubernetes と同様にコンテナをオーケストレーションするためのものである、という点は変わりません。\n> Knative は、クラウドにおける PaaS や FaaS のようなアーキテクチャを、Knative がインストールされていれば(つまり、Kubernetes クラスタであれば)どこでも実現できるものです。\n\nなるほど。要は、クラウドサービスに依存しないコンテナオーケストレーションなんですね。\nGCP を使おうが AWS を使おうが、エンジニアにとって、それは特段大切ではなく、\nアプリケーションのプロダクトコードが重要だと思います。そこで、クラウドサービスを\n意識せずに、k8s を使うことができちゃうということですね。\n\n## gVisor\n\nhttps://www.publickey1.jp/blog/18/gvisorgoogle.html\n従来は、下記のような問題をコンテナは抱えていました。\n\n> コンテナ間で OS のカーネルを共有しているためにコンテナ間の分離レベルは高くなく、同一 OS 上で稼働している別のコンテナの負荷の影響を受けやすかったり、コンテナから OS のシステムコールを直接呼び出せることなどによるセキュリティ上の課題を引き起こしやすくもあります。\n\nそこで、gVisor の出番\n\n> 従来のコンテナの軽量さを保ちつつ、コンテナの分離について新たな実装を提供することよって、準仮想化に近い、より安全な分離を提供するコンテナランタイム\n\nなるほど〜！（ただ、記事を読んだだけｗ）\n\n## Cloud Next Recap 2\n\n### 発表者 (2)\n\n佐藤 一憲(Google)\n\n### 内容 (2)\n\n機械学習について AutoML を紹介されていました。\n私は、そういったものが苦手だったので、よく覚えてないです...\n\n## Cloud Next Recap 3\n\n### 発表者 (3)\n\nKirill Tropin(Google)\n\n### 内容 (3)\n\nスピーキングは英語だったので、よく覚えてないです...\n\n## Cloud Run ネタ\n\n### 発表者 (4)\n\nちまめ@rito\n\n### 発表資料\n\nhttps://speakerdeck.com/chimame/cloud-run-one-step-ahead\n\n### 内容 (4)\n\n2 コマンドで cloudrun できるぐらい、簡単！\nただ、プロダクトとして扱うには、いくつか問題があるそう。\n\n1. docker full build するみたいで遅い\n   → kaniko で、cache が効くそう。  \n   https://github.com/GoogleContainerTools/kaniko\n\n1. memoryStore がまだ未対応(VPC)\n\n## GCP 大阪リージョンとレイテンシ\n\n### 発表者 (5)\n\nsalamander さん\n\n### 内容 (5)\n\n大阪リージョンのレイテンシについて紹介されました。\nhttps://docs.google.com/presentation/d/1dbGgjr3Z9o-bOxmT5SQ5bRHMEI0Jzh0BQUQkXlEGyYE/edit?usp=sharing\n\n## 最後に\n\nGoogle では、もはや当たり前のように Kubernetes のサービスを進めている印象でした。\nクラウド、オンプレを関係なく動かせるプラットフォームである Anthos や、\nどのクラウドサービスでも関係なく動かせるコンテナオーケストレーションである Knative など、\nどこでも kubernetes を動かせるように進めらています。\nこれは、kubernetes を使えるようにならないと！\n下記で、勉強中です！\n\nhttps://silverbirder.github.io/blog/contents/start_the_learning_kubernetes_03","publishedAt":"2019-05-22","slug":"gcpug_kansai_cloud_next_extended","title":"【大阪】GCPUG Kansai 〜 Cloud Next Extended ～ - 2019年5月14日 参加レポート"},{"body":"https://gocon.connpass.com/event/124530/\n\nhttps://gocon.jp/\n\nこちらに参加してきましたので、ご報告します！\n\n```text\n// 場所\nリクルートライフスタイル本社\n東京都千代田区丸の内1-9-2 グラントーキョーサウスタワー\n```\n\n## よかったセッション\n\n## H1 (S): Hacking Go Compiler Internals 2\n\n### 概要\n\n> Since the previous talk at Go Con 2014 Autumn, lots of things in the internals have changed. In this talk, I will try to give an overview of Go compiler internals and update the information as much as possible, along with my new hacks.\n\n### 資料\n\n#### 今回\n\nhttps://speakerdeck.com/moriyoshi/hacking-go-compiler-internals-2nd-season\n\n#### 前回\n\nhttps://www.slideshare.net/moriyoshi/hacking-go-compiler-internals-gocon-2014-autumn\n\n### 感想\n\nこのセッションでは、Golang のソースコードが機械語になるまでのステップ、要はコンパイラの動きを紹介されていました。\n大きく分類して 11 ステップあり、ざっくり要約すると下記のステップです。\n\n１．コードをトークンに分割  \n２．構文木に構築  \n３．型チェック  \n４．インライン化  \n５．中間言語(SSA)の生成  \n６．機械語の生成\n\n正直、高級言語ばかり使っていたので、機械語に近い低級言語の知識が乏しい私ですが、\n今回のお話は、そういった初心者でも分かりやすく説明されていました。\nこの話を聞いて、純粋に疑問に持ったこととして「どこに最も時間がかかるのか」でした。\nちょうど、同じ疑問を持った方が質問されていて、回答として「型チェック」だそうです。\n実際に調べるためのツールが、golang の benchmark があるみたいなので、こちらを使って\nチューニングをすることができます。簡単なコードを書いて、試してみたいなと思いました。\n\n## A4 (S): Design considerations for container-based Go applications\n\n### 概要 (2)\n\nGo 言語でのアプリケーション開発で、特にコンテナを前提とする場合の設計考慮点について話します。 例えば、Go 言語で API を開発する場合、コンテナとして動かすことを前提とするケースが多いと感じます。コンテナベースで動かすことを前提とした場合、コンテナイメージ作成・アプリケーション監視において、考慮すべき点が出てくるでしょう。このトークでは、Go 言語での実装にまで踏み込んだ上で、コンテナベースアプリケーションにおける設計の考慮点について話します。\n\n### 資料 (2)\n\nhttps://speakerdeck.com/hgsgtk/design-considerations-for-container-based-go-application\n\nhttps://www.redhat.com/ja/resources/cloud-native-container-design-whitepaper\n\n### 感想 (2)\n\nGolang の話というより、コンテナで開発する上での Tips の話でした。\nTips は３つ紹介されていて、「Configuration」「Logging」「Monitering」です。\nどれも、資料にあるベストプラクティスに沿った方法で、良い手法だなと勉強になりました。\n\n・Configuration  \n設定情報をソースコードで管理するのではなく、環境変数を使うこと  \n→ 本番/検証等でもソースが変わらない  \n・Logging  \nファイルに出力するのではなく、ストリーミングし外部サービスに流す  \n→ コンテナを使い捨てしやすくなる  \n・Monitering  \nヘルスチェックのエンドポイントを提供する  \n→ 外部サービスと連携しやすくなる\n\n他にもベストプラクティが資料に載ってあるので、時間があるときに読んでみたいなと思います。\n\n## B8 (L): CPU, Memory and Go\n\n### 概要 (3)\n\n基本的な CPU やメモリを簡単に触れ、Go の最適化、コンパイラの最適化、Go で実装したときの CPU やメモリの振る舞いを紹介します。 またこれら最適化の様子やパフォーマンスを実際に Go の標準ツールを使いながら確認していきます。\n\n### 資料 (3)\n\nhttps://speakerdeck.com/sonatard/cpu-memory-and-go\n\n### 感想 (3)\n\nGolang におけるパフォーマンス・チューニングについて勉強になりました。\nGolang だけの話なのかわかりませんが、コーディングする際に気にしたほうが良いと思います。\n\n・動的配列を使うのではなくて、静的配列を使う  \n→ 動的配列だとメモリ確保のコストが高くなるので、遅くなってしまう\n\n・環境変数を使うのではなくて、定数を使うこと  \n→ 実行時にならないと処理が決まらず、コンパイラの最適化がされない\n\n・メモリに割り当てる際は 8byte ずつで割り切れるようにすること(64bit の場合)  \n→ 隙間があった場合、パディングが発生して遅くなる(メモリアライメント)\n\nそもそも低レイヤーについて全くわからない人なので、\nCPU と Memory について知れてよかったです。\n\n## 全体的な感想\n\nGolang のセミナーに初めて参加しました。\nスポンサーの話を聞いていると、Golang を採用した理由は、\nどの企業も「パフォーマンスの良さと、学習コストの低さ」\nという理由が多かった印象があります。\nまた、Docker や Kubernetes が Golang で作られていたりと、\nGolang はドンドンと人気になっていく言語なのかなと期待しています。\n\nまた、スポンサーの中で「既存システムを Golang に再構築した」や\n「Golang の知識を得るために勉強会を開催した」など、各社 Golang へ\n積極的に活動を試みていることをお聞きしました。\n\n## 反省\n\nGoogle Team である Katie Hockman の speaking が英語だったために、ほとんど聞き取ることができませんでした。\n実にもったいないと感じました。\n\n※ 資料まとめ\nhttps://engineer-fumi.hatenablog.com/entry/2019/05/18/172000","publishedAt":"2019-05-21","slug":"go_conference_2019_spring","title":"Go Conference 2019 Spring - 2019年5月18日 参加レポート"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)で Service についての概要を学びました。今回は下記を一気に学びます。\n\n- ExternalIP\n- NodePort\n- LocadBalancer\n- Headless\n- ExternalName\n- None-Selector\n- Ingress\n\n※ ClusterIP を飛ばしたのは、前回使った内容で十分だと思ったため。\n\n## ExternalIP\n\nこちらは、外向けの IP アドレスを割り振ります。\n\n```yaml\n## sample-externalip.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sample-externalip\nspec:\n  type: ClusterIP\n  externalIPs:\n    - 192.168.3.33\n  ports:\n    - name: \"http-port\"\n      protocol: \"TCP\"\n      port: 8080\n      targetPort: 80\n  selector:\n    app: sample-app\n```\n\n私の Node 情報では、下記の状態です。\n\n| host             | ip           |\n| :--------------- | :----------- |\n| raspi001(master) | 192.168.3.32 |\n| raspi002(worker) | 192.168.3.33 |\n| raspi003(worker) | 192.168.3.34 |\n| nfspi(NFS)       | 192.168.3.35 |\n\nここで、spec. externalIPs に、公開したい IP アドレスを上記 Node の IP アドレスより設定します。\n今回は、１つだけ(raspi002:193.168.3.33)にしました。\n\n```yaml\n## sample-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n        - name: redis-container\n          image: redis:3.2\n```\n\n前回同様のファイルを用意します。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-deployment.yaml -f sample-externalip.yaml\npi@raspi001:~/tmp $ k get pod -o=wide\nNAME                                      READY   STATUS    RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\nsample-deployment-9dc487867-7n2sz         2/2     Running   0          16m   10.244.1.73   raspi002   <none>           <none>\nsample-deployment-9dc487867-nnnqm         2/2     Running   0          16m   10.244.1.74   raspi002   <none>           <none>\nsample-deployment-9dc487867-qfdhw         2/2     Running   0          16m   10.244.2.68   raspi003   <none>           <none>\npi@raspi001:~/tmp $ k get service\nNAME                TYPE        CLUSTER-IP       EXTERNAL-IP    PORT(S)    AGE\nsample-externalip   ClusterIP   10.104.170.220   192.168.3.33   8080/TCP   15m\n```\n\nexternalIP が設定されました。\n\n```shell\npi@raspi001:~/tmp $ for PODNAME in `k get pods -l app=sample-app -o jsonpath='{.items[*].metadata.name}'`; do k exec -it ${PODNAME} -- cp /etc/hostname /usr/share/nginx/html/index.html; done\n```\n\nどこの pod かどうかわかりやすいくするため、index.html を書き換えます。\nでは、ブラウザからアクセスしてみます。\n\n![sample_deployment_1](https://res.cloudinary.com/silverbirder/image/upload/v1639816612/silver-birder.github.io/blog/sample_deployment_1.png)\n\n![sample_deployment_2](https://res.cloudinary.com/silverbirder/image/upload/v1639816612/silver-birder.github.io/blog/sample_deployment_2.png)\n\nraspi002 を公開したので、その Node に存在する Pod がランダムに出力されている、つまりロードバランサが動作していることがわかります。\n\n## NodePort\n\nExternalIP のような特定 Node を公開するのと違って、NodePort は、**全て**の Node を公開します。\n\n試してみます。\n\n```yaml\n## sample-nodeport.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sample-nodeport\nspec:\n  type: NodePort\n  ports:\n    - name: \"http-port\"\n      protocol: \"TCP\"\n      port: 8080\n      targetPort: 80\n      nodePort: 30080\n  selector:\n    app: sample-app\n```\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-externalip.yaml #しなくても良い\npi@raspi001:~/tmp $ k apply -f sample-nodeport.yaml\npi@raspi001:~/tmp $ k get service\nNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nsample-nodeport   NodePort    10.96.173.243   <none>        8080:30080/TCP   66s\n```\n\n内向けには、10.96.173.243:8080 でアクセスでき、外向けには、各 Node の IP アドレス:30080 にアクセスします。\nどちらも正常にアクセスできています。もちろん、アクセス先の Pod は、ロードバランシングされます。ロードバランシングさせるのが嫌な場合にも対応できます。アクセスされた Node の先は、その Node 内にある Pod のみにアクセスさせる「spec.externalTrafficPolicy：Local」に設定すれば大丈夫です。\n注意点として、nodePort は、30000~32767 の範囲と決まっています。\n\n## LoadBalancer\n\nExternalIP や NodePort の場合、ロードバランシングするのはクラスタ内の Node になります。そのため、アクセスが集中することで、Node 単一障害が発生しやすいそうです。そこで、LoadBalancer を使うことで、**クラスタ外**にロードバランサを作成します。\n\nただ、クラスタ外にロードバランサを作成する際は、プラットフォームによって対応しているか確認が必要です。私のような raspberryPi 環境では、もちろんそういった機能がないため、準備する必要があります。\n\nmaster(raspi001)に移動\n\n```shell\npi@raspi001:~/tmp $ k apply -f https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml\n```\n\nmetallb と呼ばれるロードバランサを適用します。\n\nhttps://metallb.universe.tf\n\n> MetalLB is a load-balancer implementation for bare metal Kubernetes clusters, using standard routing protocols.\n\n```yaml\n## l2-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 192.168.3.100-192.168.3.200\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f l2-config.yaml\n```\n\nこれで、raspberryPi 環境でも loadBalancer が使えます。さっそくつかってみましょう。\n\n```yaml\n## sample-lb.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sample-lb\nspec:\n  type: LoadBalancer\n  loadBalancerIP: 192.168.3.100\n  ports:\n    - name: \"http-port\"\n      protocol: \"TCP\"\n      port: 8080\n      targetPort: 80\n      nodePort: 30082\n  selector:\n    app: sample-app\n  loadBalancerSourceRanges:\n    - 192.168.3.0/8\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-deployment.yaml\npi@raspi001:~/tmp $ k apply -f sample-lb.yaml\npi@raspi001:~/tmp $ k get services\nNAME         TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\nkubernetes   ClusterIP      10.96.0.1       <none>          443/TCP          16d\nsample-lb    LoadBalancer   10.106.253.65   192.168.3.100   8080:30082/TCP   8m4s\n```\n\nお、192.168.3.100:8080 にアクセス可能みたいです。\n\niMac に移動\n\n```shell\n~ $ curl -s http://192.168.3.100:8080\n<!DOCTYPE html>\n...\n```\n\nOK\n\n## Headless\n\n今までのロードバランスと違い、公開する IP アドレスは提供されません。\nDNS ラウンドロビンによる転送先の Pod の IP アドレスを取得できます。\nつまり、Headless のサービスへ問い合わせすると、spec.selector で登録した Pod の IP アドレスが手に入ります。\nPod の IP アドレスがほしいときには便利です。（Envoy とか?）\n\n```yaml\n## sample-statefulset-headless.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sample-statefulset-headless\nspec:\n  serviceName: sample-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n```\n\n```yaml\n## sample-headless.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sample-headless\nspec:\n  type: ClusterIP\n  clusterIP: None\n  ports:\n    - name: \"http-port\"\n      protocol: \"TCP\"\n      port: 80\n      targetPort: 80\n  selector:\n    app: sample-app\n```\n\nspec.type が ClusterIP であり、spec.clusterIP が None、そして、metadata.name が statefulset の spec.serviceName と同じことで、Headless Service と呼ぶそうです。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-statefulset-headless.yaml\npi@raspi001:~/tmp $ k run --image=centos:7 --restart=Never --rm -i testpod  -- dig sample-headless.default.svc.cluster.local\n...\n;; ANSWER SECTION:\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.1.75\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.2.72\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.2.73\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.1.78\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.1.76\nsample-headless.default.svc.cluster.local. 5 IN A 10.244.2.70\n```\n\nたしかに、headless のサービスに問い合わせると、IP アドレスが返ってきました。\n\n## ExternalName\n\n外部のドメイン宛の CNAME を返すサービスです。\n例えば、Pod から外部の[example.com](http://example.com/)へアクセスする場合、下記のように設定します。\n\n```yaml\n## sample-externalname.yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: sample-externalname\n  namespace: default\nspec:\n  type: ExternalName\n  externalName: example.com\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-externalname.yaml\npi@raspi001:~/tmp $ k run --image=centos:7 --restart=Never --rm -i testpod  -- dig sample-externalname.default.svc.cluster.local\n...\n;; ANSWER SECTION:\nsample-externalname.default.svc.cluster.local. 5 IN CNAME example.com.\nexample.com.  5 IN A 93.184.216.34\n```\n\n確かに、`sample-externalname.default.svc.cluster.local`と問い合わせすることで、外部の[example.com](http://example.com/)への CNAME を取得できます。また、外部のサイトを切り替えたいときは、問い合わせ先は**変わらず**に、sample-externalname.yaml の spec.externalName を変更するだけで済みます。これは切り替えが楽ですね。\n\n## None-Selector\n\n外部のサービスに対してロードバランシングします。\n\n```yaml\n## sample-none-selector.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: sample-none-selector\nspec:\n  type: ClusterIP\n  ports:\n    - protocol: TCP\n      port: 8080\n      targetPort: 80\n---\nkind: Endpoints\napiVersion: v1\nmetadata:\n  name: sample-none-selector\nsubsets:\n  - addresses:\n      - ip: 172.217.31.164\n      - ip: 172.217.31.165\n    ports:\n      - protocol: TCP\n        port: 80\n```\n\n172.217.31.164 と 172.217.31.165 は、どちらも[www.google.com](https://www.google.com/)を指します。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-none-selector.yaml\npi@raspi001:~/tmp $ k get service\nNAME                   TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\nsample-none-selector   ClusterIP      10.102.225.99   <none>          8080/TCP         88s\npi@raspi001:~/tmp $ k describe svc sample-none-selector\nName:              sample-none-selector\n...\nType:              ClusterIP\nIP:                10.102.225.99\nPort:              <unset>  8080/TCP\nTargetPort:        80/TCP\nEndpoints:         172.217.31.164:80,172.217.31.165:80\n...\n```\n\nClusterIP なので、内部で公開されていますね。\n\n```shell\npi@raspi001:~/tmp $ curl 10.102.225.99:8080\n<HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n<TITLE>301 Moved</TITLE></HEAD><BODY>\n<H1>301 Moved</H1>\nThe document has moved\n<A HREF=\"http://www.google.com:8080/\">here</A>.\n</BODY></HTML>\n...\n```\n\n少し結果が不自然だったのですが、確かに google.com へアクセスしました。\n外部サービスへのロードバランシングも容易に実現できます。\n\n※ [172.217.31.164](http://172.217.31.164)へアクセスすると、リダイレクトがかかります。`Status Code:  301`\n\n## Ingress\n\n今までのロードバランサは、l4 レイヤーのロードバランサです。(IP アドレスとポート番号による負荷分散)\nIngress では、l7 レイヤーのロードバランサを提供します。(URL や HTTP ヘッダーで負荷分散が可能)\n\nIngress を置く場所は、クラスタ内、外の２つあります。\nクラスタ外の場合は、使うプラットフォームによります。\nクラスタ内の場合は、Nginx Ingress を使うことができます。\n\nraspberryPi 環境では、Ingress-Nginx-Controller を使うことで、Ingress を使えるそうです。\n[NGINX Ingress Controller - Installation Guide](https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal)\nを参考にして進めたのですが、arm64 環境では動きませんでした。\n\nそこで、下記の yaml を発見し、試してみると動作します。ぜひ、お試しあれ。\n[hectcastro/mandatory.yaml](https://gist.github.com/hectcastro/097ba8e9759689b6b29dd164cd116eeb)\n\n※ namespace を削除できない場合は、[こちら](https://www.ibm.com/support/knowledgecenter/en/SSBS6K_3.1.1/troubleshoot/ns_terminating.html)を参考下さい。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-externalip.yaml -f sample-deployment.yaml -f sample-nodeport.yaml -f sample-lb.yaml -f sample-statefulset-headless.yaml -f sample-headless.yaml -f sample-none-selector.yaml -f sample-externalname.yaml\n```\n\n## 最後に\n\nService について学びました。\n様々な用途に応じて、エンドポイントを公開する手段を学びました。\n手を動かして確認してみると、理解が深まりました。\n本番で k8s を使った経験はありませんが、今後必要に迫られた際に、こちらの記事を思い返そうと思います。\n\n次回は[こちら](./start_the_learning_kubernetes_10)です。","publishedAt":"2019-05-15","slug":"start_the_learning_kubernetes_09","title":"一足遅れて Kubernetes を学び始める - 09. discovery&LB その2 -"},{"body":"https://algolia.connpass.com/event/128524/\n\nこちらに参加しましたので、ご報告までに記事を書こうと思います。\n\n## Algolia って\n\n## 百聞は一見にしかず\n\nまずは下記サイトで、色々検索してみて下さい！\n\n- Algolia Community Sample\n  - [https://community.algolia.com/instantsearch.js/v2/examples/e-commerce/](https://community.algolia.com/instantsearch.js/v2/examples/e-commerce/)\n  - [https://community.algolia.com/instantsearch.js/v2/examples/tourism/](https://community.algolia.com/instantsearch.js/v2/examples/tourism/)\n  - [https://community.algolia.com/instantsearch.js/v2/examples/media/](https://community.algolia.com/instantsearch.js/v2/examples/media/)\n- 実際に Product として使われているサイト\n  - [https://www.bringmeister.de/](https://www.bringmeister.de/)\n  - [https://8tracks.com/explore/all](https://8tracks.com/explore/all)\n\nどれも**爆速**に結果が返ってきませんか !?\nこれ、 実は**SaaS**で動いているんですよ ?\n\n## 概要\n\nhttps://www.algolia.com/\n\n> Products to accelerate search and discovery experiences across any device and platform.\n\nAlgolia は、全文検索を提供してくれる SaaS です。\n全文検索を使う場合、一般的には Elastic Search や Solr といったものをサーバに乗せて管理することが多いかと思います。\n使い始めると、「カテゴリ選択、ファセット絞り込み、ハイライト」等の機能がほしくなり、独自開発することもあると思います。\nAloglia では、そういった全文検索に関わる機能を SaaS として提供してくれます。\n\n使われているところでは、ブログサービスである[medium](https://medium.com/)や、オンライン決算処理である[Stripe のドキュメント](https://stripe.com/docs/api)がメジャーでしょうか。\nエンジニア向けとしては、[Docker Hub](https://hub.docker.com/)にも使われています。また、Firebase の公式でも使用事例として紹介されています。これは驚きですね。\n\nhttps://firebase.google.com/docs/firestore/solutions/search?hl=ja\n\nAlgolia の会社としては、フランスから 2012 年よりスタートしました。\nベンチャー企業であり、日本人のエンジニア募集もあるそうです。\n\nSaaS コミュニティ用のイベントがあるそうで、こちらに Algolia さんも登壇されています。\n\nhttps://www.saastr.com/\n\nhttps://www.saastr.com/watch-the-saastr-masterclass-from-0-to-10m-in-arr-from-algolia-in-paris-video/\n\n## どんな機能があるの\n\nお話を Algolia の Solution Architect である[@shinodogg](https://twitter.com/shinodogg)から説明があったものとして、下記のような機能があるそうです。\n\n- 検索時の表記ゆれ\n- タイプミス補助\n- カテゴリ、ファセットによる絞り込み\n- 検索キーワードのハイライト\n- パーソナライゼーション\n- A/B テスト\n- GEO 検索\n- 画像検索\n- 音声検索\n\n他にも「安い」と検索すると設定次第で「500 円以下の商品」を表示させるような\nこともできるそうです。あとは、チャットボットにも使えるとのことです。\n\n※ ただ、まだ日本語には対応していないみたいで、現在開発中とのこと。\n\n## どうやって使うの\n\nhttps://github.com/algolia\nOSS としてライブラリを提供されています。\n手っ取り早く使いたいときは、instantsearch.js でしょうか。\n\nhttps://community.algolia.com\n\nこちらも参考になるかと思います。\n\n## Algolia は知っていたの\n\n知っていました。\nAlgolia を知ったきっかけは、大学時代の友人(id:castaneai)からでした。\nAlgolia は、全文検索システムを構築せずとも、お手軽に使えて、しかも高機能な SaaS ということで、\n個人開発をする私にとって興味を持ち始めました。\n\nその後、下記の記事で書いた通り OSS Gate の対象にもさせてもらいました。\n\nhttps://tech-blog.monotaro.com/entry/2018/10/17/115442\n\nまた、作りたいものリストに溜まっていたアプリを作る時間があったので、\n最近では、下記のような書籍管理を作りました。検索は Algolia を使っています。\n\nhttps://github.com/silverbirder/book-store-vue\n\n## なぜ会場が、はてな株式会社なの\n\nはてなの社長である id:chris4403 さんが、[@shinodogg](https://twitter.com/shinodogg)と前職での知り合いだったからだそうです。\n\nhttps://mackerel.io/ja/\n\nはてなも、サーバー監視サービスである mackerel（鯖）を SaaS として提供しています。\nこのお二方が、前職を離れてからも、同様の事業に携わっているということに、不思議な縁だな〜と思いました。\n\n会場では、ピザを提供して頂きました。美味しかったです！ごちそうさまでした！\n\nhttps://twitter.com/silverbirder/status/1126841269097865216?s=20\n\n## 最後に\n\nSaaS は、その専門の技術を持ってサービス提供をされています。\n独自に開発するよりも、そういった専門の SaaS を駆使することで、\n開発コストや運用コストの削減につながります。\nそもそも、そういった専門技術を持っていない環境は、独自開発することとなり、\n学習コストもかかりますし、非機能要件を考えないといけないので大変です。\n\n「かけるべき部分に時間を割いて、それ以外は SaaS に移す」というのは今の時代の効率良い開発スタイルだなと思います。","publishedAt":"2019-05-11","slug":"algolia_community_party_in_kyoto","title":"Algolia Community Party in 京都 - 2019年5月10日 参加レポート"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)でようやく workloads が終了しました。今回は、discovery&LB を進めようと思います。\n\n## discovery&LB\n\nKubernetes には、下記のようにリソースの種類が存在します。\n今回は、discovery&LB を学習します。\n\n| リソースの分類           | 内容                                                         |\n| :----------------------- | :----------------------------------------------------------- |\n| Workloads リソース       | コンテナの実行に関するリソース                               |\n| Discovery＆LB リソース   | コンテナを外部公開するようなエンドポイントを提供するリソース |\n| Config＆Storage リソース | 設定・機密情報・永続化ボリュームなどに関するリソース         |\n| Cluster リソース         | セキュリティやクォータなどに関するリソース                   |\n| Metadata リソース        | リソースを操作する系統のリソース                             |\n\n※ [Kubernetes の Workloads リソース（その 1）](https://thinkit.co.jp/article/13610)\n\ndiscovery&LB をには、下記 8 つの種類があります。\n\n- Service\n  - ClusterIP\n  - ExternalIP\n  - NodePort\n  - LoadBalancer\n  - Headless (None)\n  - ExternalName\n  - None-Selector\n- Ingress\n\nService の概要について学びます。\n\n## Kubernetes とネットワーク\n\nKubernetes では、Pod 毎に IP アドレスが割り振られています。\nそのため、異なる Pod 間で通信する際は、Pod の IP アドレスが必要になります。逆に同一の Pod 内なら localhost で通信できます。\n\n説明するために、準備します。\n\n```yaml\n## sample-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n        - name: redis-container\n          image: redis:3.2\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-deployment.yaml\npi@raspi001:~/tmp $ k get pods -l app=sample-app -o custom-columns=\"NAME:{metadata.name}, IP:{status.podIP},NODE:{spec.nodeName}\"\nNAME                                 IP           NODE\nsample-deployment-9dc487867-h7lww   10.244.1.72   raspi002\nsample-deployment-9dc487867-n8x5w   10.244.2.66   raspi003\nsample-deployment-9dc487867-nxbxc   10.244.2.67   raspi003\n```\n\n![pod ip adress](https://res.cloudinary.com/silverbirder/image/upload/v1639816788/silver-birder.github.io/blog/pod_ip_adress_kubernetes.png)\n\nこのような状況下で、`sample-deployment-9dc487867-n8x5w:redis`を中心に見ていきます。\n\n※ nginx は 80 ポートで開放されています。\n\n## 前準備\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-deployment-9dc487867-n8x5w -c redis-container /bin/bash\nroot@sample-deployment-9dc487867-n8x5w:/data# apt-get update && apt-get install curl -y\nroot@sample-deployment-9dc487867-n8x5w:/data# exit\n```\n\ncurl がないのでインストールします。\n\n## 同一 Node,同一 Pod 内のコンテナへ通信\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-deployment-9dc487867-n8x5w -c redis-container /bin/bash\nroot@sample-deployment-9dc487867-n8x5w:/data# curl localhost:80\n<!DOCTYPE html>\n...\n```\n\nOK\n\n## 同一 Node,異なる Pod のコンテナへ通信\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-deployment-9dc487867-n8x5w -c redis-container /bin/bash\nroot@sample-deployment-9dc487867-n8x5w:/data# curl 10.244.2.66:80\n<!DOCTYPE html>\n...\nroot@sample-deployment-9dc487867-n8x5w:/data# curl 10.244.2.67:80\n<!DOCTYPE html>\n...\n```\n\nOK\n\n## 異なる Node,異なる Pod のコンテナへ通信\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-deployment-9dc487867-n8x5w -c redis-container /bin/bash\nroot@sample-deployment-9dc487867-n8x5w:/data# curl 10.244.1.72:80\n<!DOCTYPE html>\n...\n```\n\nOK\n\n## MasterNode から各 Pod へ通信\n\n```shell\npi@raspi001:~/tmp $ curl 10.244.1.72:80\n<!DOCTYPE html>\n...\npi@raspi001:~/tmp $ curl 10.244.2.66:80\n<!DOCTYPE html>\n...\npi@raspi001:~/tmp $ curl 10.244.2.67:80\n<!DOCTYPE html>\n...\n```\n\nOK\n\nここから分かるように、Pod 内部の通信、Pod 間の通信、さらに Node 間の通信までも、Kubernetes によってネットワークが構築されています。\n\n## Service\n\nService は、下記の２つの大きな機能が存在します。\n\n- pod 宛トラフィックのロードバランシング\n- サービスディスカバリとクラスタ内 DNS\n\n## pod 宛トラフィックのロードバランシング\n\n先程の例で、Pod 間を通信することは可能です。しかし、pod を作り直すたびに IP アドレスが変わってしまうため、\n自作すると、少し大変です。そこで、Service の出番です。\nサービスは、複数存在する Pod に対して**自動的にロードバランスしてくれる**のと、合わせて**外向けの IP アドレス**(ExternalIP)や、**内向けの IP アドレス**(ClusterIP)も提供してくれます。\n\nさっそく、試してみます。\n\n```yaml\n## sample-clusterip.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sample-clusterip\nspec:\n  type: ClusterIP\n  ports:\n    - name: \"http-port\"\n      protocol: \"TCP\"\n      port: 8080\n      targetPort: 80\n  selector:\n    app: sample-app\n```\n\nこれは、`app=sample-app`にマッチする Pod に対してロードバランスしてくれます。外から 8080 ポートで待ち受けて、80 ポートでコンテナへ通信します。\nspec.type が ClusterIP なので、内向けの IP アドレスが提供されています。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-clusterip.yaml\npi@raspi001:~/tmp $ k get service sample-clusterip\nNAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\nsample-clusterip   ClusterIP   10.111.197.69   <none>        8080/TCP   30s\npi@raspi001:~/tmp $ k describe service sample-clusterip\nName:              sample-clusterip\n...\nSelector:          app=sample-app\nType:              ClusterIP\nIP:                10.111.197.69\nPort:              http-port  8080/TCP\nTargetPort:        80/TCP\nEndpoints:         10.244.1.72:80,10.244.2.66:80,10.244.2.67:80\n...\n```\n\n内向けに 10.111.197.69 の IP アドレスが振られました。また、ロードバランスする対象 Pod は、先にあげた Pod の IP アドレスです。\nEndpints に`:80`とあるように、port 毎にサービス(clusterIP)を作ることもできます。(service の spec.ports は配列指定）\n\nアクセスできるのか、試します。\nせっかくなので、pod 毎に index.html の内容を変化させましょう。\n\n```shell\npi@raspi001:~/tmp $ for PODNAME in `k get pods -l app=sample-app -o jsonpath='{.items[*].metadata.name}'`; do\n> k exec -it ${PODNAME} -- cp /etc/hostname /usr/share/nginx/html/index.html;\n> done\npi@raspi001:~/tmp $ curl 10.111.197.69:8080\nsample-deployment-9dc487867-nxbxc\npi@raspi001:~/tmp $ curl 10.111.197.69:8080\nsample-deployment-9dc487867-n8x5w\npi@raspi001:~/tmp $ curl 10.111.197.69:8080\nsample-deployment-9dc487867-h7lww\n```\n\n確かに、ロードバランシングによって pod に適度なランダム具合でアクセスできています。\nもちろん、外からはアクセスできません。\n\niMac へ移動\n\n```shell\n~ $ curl 10.111.197.69:8080\n## 返答なし\n```\n\n## サービスディスカバリとクラスタ内 DNS\n\nサービスディスカバリとは、「問題においての解決策」を指しています。\nKubernetes における問題とは、動的にサービスが生成され続けていることによるサービスを特定することが難しくなる問題です。\nそのサービスディスカバリが、Service にあります。\nその方法について下記があります。\n\n- 環境変数を利用したサービスディスカバリ\n  - Pod に IP アドレスや port,protocol が設定されている。\n- DNS A レコードを利用したサービスディスカバリ\n  - Kubernetes 内のクラスタ内 DNS によって、ドメイン名によるアクセスができる。(ドメイン名の命名規則に従う)\n- DNS SRV レコードを利用したサービスディスカバリ\n  - IP アドレスからドメイン名を取得する逆引きもできる。\n\ndnsPolicy による明示的な設定がない限り、Pod 生成時にクラスタ内 DNS へレコード追加されます。\nクラスタ内 DNS で名前解決できなかった場合は、クラスタ外 DNS に問い合わせします。\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-deployment.yaml -f sample-clusterip.yaml\n```\n\n## 最後に\n\n今回は、Service についての概要を学びました。Kubernetes の世界では、自動的にネットワーク構築されているため、特段意識することはありませんでした。\nもう少し理解が進めれば、ネットワークがどのように構築されているのか、クラスタ内 DNS がどのように動いているのか知りたいと思います。\n次回は、[こちら](./start_the_learning_kubernetes_09)です。\n\n※ お絵かきしてアウトプットすると、理解が深まるのでおすすめです。","publishedAt":"2019-05-07","slug":"start_the_learning_kubernetes_08","title":"一足遅れて Kubernetes を学び始める - 08. discovery&LB その1 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)にて、DaemonSet と StatefulSet(一部）を学習しました。今回は、StatefulSet の続きと Job,CronJob を学習します。\n\n## StatefulSet\n\n```yaml\n## sample-statefulset.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sample-statefulset\nspec:\n  serviceName: sample-statefulset\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n          volumeMounts:\n            - name: www\n              mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n    - metadata:\n        name: www\n      spec:\n        accessModes:\n          - ReadWriteMany\n        storageClassName: managed-nfs-storage\n        resources:\n          requests:\n            storage: 1Gi\n```\n\n永続的にデータが保存されるかどうか確認します。\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k exec -it sample-statefulset-0 -- df -h\nFilesystem  Size  Used Avail Use% Mounted on\n...\n192.168.3.35:/home/data/default-www-sample-statefulset-0-pvc-*   15G  1.1G   13G   8% /usr/share/nginx/html\n...\npi@raspi001:~/tmp $ k exec -it sample-statefulset-0 touch /usr/share/nginx/html/sample.html\n```\n\nsample.html というファイルを作りました。こちらが消えるかどうか確認します。\n\n```shell\npi@raspi001:~/tmp $ k delete pod sample-statefulset-0\npi@raspi001:~/tmp $ k exec -it sample-statefulset-0 ls /usr/share/nginx/html/sample.html\n/usr/share/nginx/html/sample.html\n```\n\npod を消してセルフヒーリングで復活した後、確認すると、sample.html 残っています。\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k exec -it sample-statefulset-0 ls /usr/share/nginx/html/sample.html\n/usr/share/nginx/html/sample.html\n```\n\nこちらも残っていますね。OK です。\n\n## スケーリング\n\nStatefulSet では、スケールアウトするときは、インデックスが小さいものから増えていきます。\n逆にスケールインするときは、インデックスが大きいものから削除されていきます。\nまた、１つずつ増減します。そのため、一番始めに作られる Pod は、一番最後に削除されることになります。\n試してみます。\n\n```shell\npi@raspi001:~ $ k get pod | grep sample-statefulset\nsample-statefulset-0                      1/1     Running   1          10h\nsample-statefulset-1                      1/1     Running   1          10h\nsample-statefulset-2                      1/1     Running   1          10h\npi@raspi001:~/tmp $ vim sample-statefulset.yaml # replica:3→4\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k get pod | grep sample-statefulset\nsample-statefulset-0                      1/1     Running             1          10h\nsample-statefulset-1                      1/1     Running             1          10h\nsample-statefulset-2                      1/1     Running             1          10h\nsample-statefulset-3                      0/1     ContainerCreating   0          6s\npi@raspi001:~/tmp $ vim sample-statefulset.yaml # replica:4→2\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k get pod | grep sample-statefulset\nsample-statefulset-0                      1/1     Running       1          10h\nsample-statefulset-1                      1/1     Running       1          10h\nsample-statefulset-2                      1/1     Running       1          10h\nsample-statefulset-3                      0/1     Terminating   0          2m4s\npi@raspi001:~/tmp $ k get pod | grep sample-statefulset\nsample-statefulset-0                      1/1     Running       1          10h\nsample-statefulset-1                      1/1     Running       1          10h\nsample-statefulset-2                      0/1     Terminating   0          10h\n```\n\n期待通りですね。１つずつではなく、並列して作成したい場合は、spec.podManagementPolicy を parallel にすれば実現できます。\n\n## アップデート戦略\n\n戦略は２通りあり、OnDelete と RollingUpdate があります。前者は、削除された（マニュフェスト更新ではなく、delete）タイミングに更新され、後者は、即時更新します。StatefulSet の更新では、アップデート中の過不足分の調整(maxUnavailable, maxSurge)は一切できません。また、partition というフィールドのによって、どのインデックス以降を更新するかを調整することもできます。これは、ステートフルならではの機能です。\nDeployment では試してませんでしたが、こちらで試してみようと思います。\n\nデフォルトの戦略は RollingUpdate です。これは何度も動作して確認できているので、OnDelete を試そうと思います。(partition は置いとく）\n\n```yaml\n## sample-statefulset.yaml\n---\nspec:\n  updateStrategy:\n    type: OnDelete\n---\ntemplate:\n  spec:\n    containers:\n      - name: nginx-container\n        image: nginx:1.13\n```\n\nアップデート戦略を OnDelete にし、nginx イメージを 1.12 から 1.13 に更新しました。\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k describe pod sample-statefulset-0 | grep \"Image:\"\n    Image:          nginx:1.12\npi@raspi001:~/tmp $ k delete pod sample-statefulset-0\npi@raspi001:~/tmp $ k get pod | grep sample-statefulset\nsample-statefulset-0                      0/1     ContainerCreating   0          5s\nsample-statefulset-1                      1/1     Running             0          2m59s\npi@raspi001:~/tmp $ k describe pod sample-statefulset-0 | grep \"Image:\"\n    Image:          nginx:1.13\n```\n\n期待通りですね。明示的に pod を削除すれば nginx が更新されました。\n\n## Job\n\n一度限りの処理を実行させるリソース。\nreplicaSet のように複製ができる。\nバッチ処理に向いている。\n\n10 秒 sleep するだけの job を実行してみます。\n\n```yaml\n## sample-job.yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: sample-job\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 10\n  template:\n    spec:\n      containers:\n        - name: sleep-container\n          image: nginx:1.12\n          command: [\"sleep\"]\n          args: [\"10\"]\n      restartPolicy: Never\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-job.yaml\npi@raspi001:~/tmp $ k get pod\nNAME                                      READY   STATUS      RESTARTS   AGE\nsample-job-d7465                          0/1     Completed   0          3m17s\npi@raspi001:~/tmp $ k get job\nNAME         COMPLETIONS   DURATION   AGE\nsample-job   1/1           27s        4m8s\n```\n\njob の実行が終わると、pod が消えていますね。そして、job の COMPLETIONS が 1/1 になっているので正常終了したみたいです。逆に正常終了しなかった場合、restartPolicy に沿って再実行することになります。種類として Never と OnFailure があります。Never は、新規に Pod を作って再実行、OnFailure は、既存 Pod を使って再実行するそうです。ただし、データ自体は消失することになるので、ご注意下さい。\n\ncompletions は目標成功数で、parallelism は並列数、backoffLimit は失敗許容値です。\n目的に合う設定にすれば良いですね。\nまた、completions を未指定にすると job を止めるまでずっと動き続けます。backoffLimit を未指定にすると 6 回までとなります。\n\nんー、特に興味が惹かれることもなく、終わります。笑\n\n## CronJob\n\nJob をスケジュールされた時間で実行するリソース。\nDeployment と ReplicaSet の関係と似ていて、Cronjob が job を管理する。\n\n1 分毎に 50%の確率で成功する job を用意して、試してみます。\n\n```yaml\n## sample-cronjob.yaml\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: sample-cronjob\nspec:\n  schedule: \"*/1 * * * *\"\n  concurrencyPolicy: Allow\n  startingDeadlineSeconds: 30\n  successfulJobsHistoryLimit: 5\n  failedJobsHistoryLimit: 3\n  suspend: false\n  jobTemplate:\n    spec:\n      completions: 1\n      parallelism: 1\n      backoffLimit: 1\n      template:\n        spec:\n          containers:\n            - name: sleep-container\n              image: nginx:1.12\n              command:\n                - \"sh\"\n                - \"-c\"\n              args:\n                # 約50%の確率で成功するコマンド\n                - \"sleep 40; date +'%N' | cut -c 9 | egrep '[1|3|5|7|9]'\"\n          restartPolicy: Never\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-cronjob.yaml\npi@raspi001:~/tmp $ k get all\nNAME                           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE\ncronjob.batch/sample-cronjob   */1 * * * *   False     0        <none>          9s\n```\n\n時間がくるまで、job,pod は作成されないようです。\n数分待ってみました。\n\n```shell\npi@raspi001:~/tmp $ k get all\nNAME                                          READY   STATUS      RESTARTS   AGE\npod/sample-cronjob-1557115320-dsdvg           0/1     Error       0          2m18s\npod/sample-cronjob-1557115320-qkgtp           0/1     Completed   0          87s\npod/sample-cronjob-1557115380-r57sw           0/1     Completed   0          78s\npod/sample-cronjob-1557115440-2phzb           1/1     Running     0          17s\n\nNAME                                  COMPLETIONS   DURATION   AGE\njob.batch/sample-cronjob-1557115320   1/1           105s       2m18s\njob.batch/sample-cronjob-1557115380   1/1           52s        78s\njob.batch/sample-cronjob-1557115440   0/1           17s        17s\n\nNAME                           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE\ncronjob.batch/sample-cronjob   */1 * * * *   False     1        20s             3m12s\n```\n\n名前の命名ルールがあるので、どう関連しているのか一目瞭然ですね。\nPod が残っているのは、failedJobsHistoryLimit と successfulJobsHistoryLimit の値の影響ですね。\nlog で確認できるように残しておくそうですが、ログ収集基盤に集約した方が良いとも言われています。\n\n途中で止めたいときは、spec.suspend を true にすることで実現可能になります。\n同時実行する制限として、concurrencyPolicy があり、Allow,Forbid,Replace があります。\nAllow は、特に制限しない。\nForbid は、前の job が終わらない限り実行しない。\nReplace は、前の job を削除し、job を実行する。\n\n遅延がどのぐらい許容できるかは、startingDeadlineSeconds で指定します。\n\nこちらも、特に何事もなく終わりました。笑\n\n## お片付け\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-statefulset.yaml -f sample-job.yaml -f sample-cronjob.yaml\npi@raspi001:~/tmp $ k delete pvc www-sample-statefulset-{0,1,2,3}\n```\n\n## 終わりに\n\nようやく、workloads が終わりました。最後はざっくり進めてしまった感がありました。\n次回は[こちら](./start_the_learning_kubernetes_08)です。","publishedAt":"2019-05-06","slug":"start_the_learning_kubernetes_07","title":"一足遅れて Kubernetes を学び始める - 07. workloads その3 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)では、Pod,ReplicaSet,Deployment の３つを学習しました。今回は DaemonSet,StatefulSet(一部)を学びます。\n\n## DaemonSet\n\nReplicaSet とほぼ同じ機能のリソース。\nReplicaSet との違いは、各ノードに 1 つずつ配置するのが DaemonSet,バラバラなのが ReplicaSet。\n用途として、モニタリングツールやログ収集の Pod に使うそうです。\n\nさっそく、試してみます。\n\n```yaml\n## sample-ds.yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sample-ds\nspec:\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --all --prune\ndaemonset.apps/sample-ds created\npi@raspi001:~/tmp $ k get all -o=wide\nNAME                  READY   STATUS    RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\npod/sample-ds-wxzbw   1/1     Running   0          60s   10.244.2.24   raspi003   <none>           <none>\npod/sample-ds-xjjtp   1/1     Running   0          60s   10.244.1.37   raspi002   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE    SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d1h   <none>\n\nNAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS        IMAGES       SELECTOR\ndaemonset.apps/sample-ds   2         2         2       2            2           <none>          60s   nginx-container   nginx:1.12   app=sample-app\n```\n\nReplicaSet と大きく違いはありません。\nまた、各ノードに対して pod が作られていることがわかります。\n\nDeployment と似ているアップデート戦略があり、OnDelete と RollingUpdate(デフォルト)があります。前者は、pod を明示的に削除した(`k delete`)際に更新する戦略です。DaemonSet は、死活監視やログ収集に使うので、手動でのタイミングが効く OnDelete が好まれます。後者は、Deployment と同じ動きで、即時更新していく戦略です。\n\nReplicaSet と似ているようで、機能的には Deployment に近い感じですね。ReplicaSet は pod が削除されたら複製されますけど、アップデートされません。DaemonSet は pod が削除されたら複製するし、アップデートもされます。試してみます。\n\n```yaml\n## sample-ds.yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sample-ds\nspec:\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.13\n          ports:\n            - containerPort: 80\n```\n\nnginx のバージョンを 1.12 から 1.13 に変更しました。\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --all --prune\ndaemonset.apps/sample-ds configured\npi@raspi001:~/tmp $ k get all -o=wide\nNAME                  READY   STATUS              RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\npod/sample-ds-sx4mv   0/1     ContainerCreating   0          5s    <none>        raspi003   <none>           <none>\npod/sample-ds-xjjtp   1/1     Running             0          12m   10.244.1.37   raspi002   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE    SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d2h   <none>\n\nNAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS        IMAGES       SELECTOR\ndaemonset.apps/sample-ds   2         2         1       1            1           <none>          12m   nginx-container   nginx:1.13   app=sample-app\n```\n\napply してみると、一台ずつ update されています(containerCreating)。Deployment と違うのは、最大 pod 数が１のために、一時的に pod が機能しなくなるタイミングが生まれます(超過分の設定不可)。\n\n```shell\npi@raspi001:~/tmp $ k delete pod sample-ds-sx4mv\npod \"sample-ds-sx4mv\" deleted\npi@raspi001:~/tmp $ k get all -o=wide\nNAME                  READY   STATUS              RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\npod/sample-ds-hgvtv   0/1     ContainerCreating   0          6s      <none>        raspi003   <none>           <none>\npod/sample-ds-k8cfx   1/1     Running             0          4m38s   10.244.1.38   raspi002   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE    SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d2h   <none>\n\nNAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS        IMAGES       SELECTOR\ndaemonset.apps/sample-ds   2         2         1       2            1           <none>          17m   nginx-container   nginx:1.13   app=sample-app\n```\n\npod を削除しても、セルフヒーリングで復活します。\n\n## StatefulSet\n\nステートレスな pod ではなく、DB のようなステートフルな pod 向けのリソース。\npod を削除しても、データを永続的に保存する仕組みが存在。\n動作自体は、replicaSet と似ています。\n\nさっそく、試してみます。\n\n```yaml\n## sample-statefulset.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sample-statefulset\nspec:\n  serviceName: sample-statefulset\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n          volumeMounts:\n            - name: www\n              mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n    - metadata:\n        name: www\n      spec:\n        accessModes:\n          - ReadWriteOnce\n        resources:\n          requests:\n            storage: 1G\n```\n\nmountPath で指定したマウントしたいパスを、volumeClaimTemplates でマウントしてくれます。 どこに？\nStorage に関しては別で学習することにします。\nひとまず、apply します。\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --all --prune\ndaemonset.apps/sample-ds unchanged\nstatefulset.apps/sample-statefulset created\npi@raspi001:~/tmp $ k get pod\nNAME                   READY   STATUS    RESTARTS   AGE\nsample-ds-hgvtv        1/1     Running   0          54m\nsample-ds-k8cfx        1/1     Running   0          58m\nsample-statefulset-0   0/1     Pending   0          5m19s\npi@raspi001:~/tmp $ k describe pod sample-statefulset-0\n...\nEvents:\n  Type     Reason            Age                  From               Message\n  ----     ------            ----                 ----               -------\n  Warning  FailedScheduling  70s (x3 over 2m28s)  default-scheduler  pod has unbound immediate PersistentVolumeClaims (repeated 2 times)\n```\n\nおや、Pending になってしまいました。 `pod has unbound immediate PersistentVolumeClaims`\n\n## PersistentVolume と PersistentVolumeClaims\n\nPersistentVolume(永続的ボリューム)は、名前の通りで、データを永続的に保存しておく場所のリソースです。\nマネージドサービスを利用すると、デフォルトで PresistentVolume が用意されているそうです。\n私の環境は、マネージドサービスではなく、自作環境であるので、PresistentVolume を用意する必要があります。\n\nPersistentVolumeClaims(永続的ボリューム要求)は、これも名前の通りで、「PresistentVolume を使わせて」というリソースです。\nこのリソースで、PresistentVolume の name を指定し、apply することで、初めてマウントができます。\n例えば、Pod から PersistentVolumeClaims の名前を指定してあげると、その Pod は Claim した PersistentVolume をマウントすることができます。\nvolumeClaimTemplates というのは、「わざわざ PersistentVolumeClaims を定義しなくてもテンプレートに沿って書けば Claims できるよ」というものです。\n\n## で、何が問題だったの\n\n`pod has unbound immediate PersistentVolumeClaims`のとおりで、「PersistentVolume の要求をしたけど、Volume 割当できなかったよ」とのことです。\n\nPersistentVolume(pv)があるのか確認してみます。\n\n```shell\npi@raspi001:~/tmp $ k get pv\nNo resources found.\n```\n\nたしかにないです。PersistentVolume を用意しないといけないのですが、どうしましょう。\n解決手段として考えたのは 3 点です。\n\n1. GCP や AWS,Azure のサービスを使う\n1. LocalVolume を使う\n1. NFS を使う\n\n※ [types-of-persistent-volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes)\n\n1 は、書いておいてなんですが、却下です。理由は、せっかく raspberryPi で構築したのでクラウドサービスを利用したくないからです。\n\n2 は、[Kubernetes: Local Volume の検証](https://qiita.com/ysakashita/items/67a452e76260b1211920)の参考にして**試した**のですが、 記事にも書いてあるとおり「Local Volume は他の Pod から共有で利用することができない」ため、statefulset が`replica:1`でなければ動きません。それはそれで動くので学習になり良いのですが、せっかくなら replica の制限なしにしたいです(ReadWriteMany にしたい)。\n\n3 は、もう一台 raspberryPi を用意して、それを NFS と見立てて PersistentVolume にしてみる方法です。\n\n3 を進めようと思います。\n\n## NFS 導入\n\n### サーバ設定\n\nNFS 用の新たな raspberryPi を用意します。設定手順は[こちら](./start_the_learning_kubernetes_03)を参考にしました。\nその後の続きは下記です。\n\nNFS のホスト名は`nfspi`とします。\n\n```shell\n~ $ slogin pi@nfspi.local\npi@nfspi:~ $ sudo apt-get install nfs-kernel-server\npi@nfspi:~ $ sudo vim /etc/exports\n```\n\n```shell\n/home/data/ 192.168.3.0/255.255.255.0(rw,sync,no_subtree_check,fsid=0)\n```\n\n意味としては、「指定範囲の IP アドレスからのマウントを許可する」。オプションは、[こちら](https://linuxjm.osdn.jp/html/nfs-utils/man5/exports.5.html)を参照。\n\n| host             | ip           |\n| ---------------- | ------------ |\n| iMac             | 192.168.3.3  |\n| raspi001(master) | 192.168.3.32 |\n| raspi002(worker) | 192.168.3.33 |\n| raspi003(worker) | 192.168.3.34 |\n| nfspi(NFS)       | 192.168.3.35 |\n\n```shell\npi@nfspi:~ $ sudo mkdir -p /home/data\npi@nfspi:~ $ sudo chmod 755 /home/data\npi@nfspi:~ $ sudo chown pi:pi /home/data\npi@nfspi:~ $ sudo /etc/init.d/nfs-kernel-server restart\npi@nfspi:~ $ service rpcbind status\npi@nfspi:~ $ systemctl status nfs-server.service\n```\n\n正しく設定されたか、iMac から確認してみます。\n\n```shell\n~ $ mkdir share\n~ $ sudo mount_nfs -P nfspi.local:/home/data ./share/\n~ $ sudo umount share\n```\n\nOK\n\n### クライアント設定\n\n各ノードに対して下記を実行します。\n\n```shell\npi@raspi001:~ $ sudo apt-get install nfs-common\n```\n\n## nfs-client 導入\n\nraspberryPi 環境では、真っ白な状態なので、一から PersistentVolume を用意する必要があります。それには Volume となる Storage の型を用意する必要もあるのですが、[Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner)を見る限り、NFS 用の型は標準で存在しません。そこで、[nfs-client](https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client)を使って NFS 用の StorageClass を作成します。\n\n```shell\npi@raspi001:~ $ git clone https://github.com/kubernetes-incubator/external-storage.git && cd cd external-storage/nfs-client/\npi@raspi001:~/external-storage/nfs-client $ NS=$(kubectl config get-contexts|grep -e \"^\\*\" |awk '{print $5}')\npi@raspi001:~/external-storage/nfs-client $ NAMESPACE=${NS:-default}\npi@raspi001:~/external-storage/nfs-client $ sed -i'' \"s/namespace:.*/namespace: $NAMESPACE/g\" ./deploy/rbac.yaml\npi@raspi001:~/external-storage/nfs-client $ k apply -f deploy/rbac.yaml\n```\n\nrbac.yaml にある namespace を現在動かしている環境の namespace に置換して、apply しています。\n\n```shell\npi@raspi001:~/external-storage/nfs-client $ k apply -f deploy/deployment-arm.yaml\npi@raspi001:~/external-storage/nfs-client $ k apply -f deploy/class.yaml\n```\n\ndeployment-arm.yaml では、NFS サーバの IP アドレス(192.168.3.35)とマウントパス(/home/data)を設定しました。\nclass.yaml が、今回欲していた NFS の storageClass(managed-nfs-storage)になります。\n\n※ raspberryPi のイメージは Raspbian を使っているので、arm 用の deployment-arm.yaml を使います。[Wiki](https://ja.wikipedia.org/wiki/Raspbian)\nこれに随分とハマってしまいました...\n\n```shell\npi@raspi001:~/external-storage/nfs-client $ k apply -f deploy/test-claim.yaml -f deploy/test-pod.yaml\n```\n\n試しにマウント先にファイルが作成できているのかテストしています。確認します。\n\nnfspi に移動\n\n```shell\npi@nfspi:~ $ ls /home/data\n```\n\nあれば成功です。あれば、下記で片付けます。\n\n```shell\npi@raspi001:~/external-storage/nfs-client $ k delete -f deploy/test-pod.yaml -f deploy/test-claim.yaml\n```\n\n## statefulset をリトライ\n\n以上で、StorageClass を用意できました。よって後は、PersistentVolume 作って、PersistentVolumeClaim 作って...となる予定でした。\nしかし、[nfs-client](https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client)には、**dynamic provisioning**という機能が備わっており、PersistentVolume を作らなくても、PersistentVolumeClaim するだけで良くなります。この件については、storage を学習する際に書きます。\n\nraspi001 に移動して、sample-statefulset.yaml をもう一度 apply します。\n(storageClassName: managed-nfs-storage を追加, ReadWriteOnce→ReadWriteMany に変更)\n\n```yaml\n## sample-statefulset.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sample-statefulset\nspec:\n  serviceName: sample-statefulset\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n          volumeMounts:\n            - name: www\n              mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n    - metadata:\n        name: www\n      spec:\n        accessModes:\n          - ReadWriteMany\n        storageClassName: managed-nfs-storage\n        resources:\n          requests:\n            storage: 1Gi\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f sample-statefulset.yaml\n```\n\nnfapi に移動して、あるか確認。\n\n```shell\npi@nfspi:~ $ ls -la /home/data\ntotal 20\ndrwxrwxrwx 5 pi     pi      4096 May  5 17:18 .\ndrwxr-xr-x 4 root   root    4096 May  4 15:50 ..\ndrwxrwxrwx 2 nobody nogroup 4096 May  5 17:17 default-www-sample-statefulset-0-pvc-5911505b-6f51-11e9-bb47-b827eb8ccd80\ndrwxrwxrwx 2 nobody nogroup 4096 May  5 17:18 default-www-sample-statefulset-1-pvc-5f2fd68e-6f51-11e9-bb47-b827eb8ccd80\ndrwxrwxrwx 2 nobody nogroup 4096 May  5 17:18 default-www-sample-statefulset-2-pvc-69bee568-6f51-11e9-bb47-b827eb8ccd80\n```\n\nありました！ マウントできています！\n\n## お片付け\n\n`--prune`でも良いのですが、下記のほうが使いやすかったです。\n\n```shell\npi@raspi001:~/tmp $ k delete -f sample-ds.yaml -f sample-statefulset.yaml\npi@raspi001:~/tmp $ k delete pvc www-sample-statefulset-{0,1,2}\n```\n\n※ `k get pv`と`k get pvc`を試して頂き、今回作ったリソースがありましたら削除お願いします。\n\n## おわりに\n\nStatefulSet を使える状態にするまでに記事が大きくなってしまいました。次回に詳しく学んでいこうと思います。笑\nあと、[nfs-client](https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client)を見て思ったのが、kubernetes のパッケージマネージャである helm を導入した方が、遥かに便利だと思いつつ、手動設定しました。。。\n次回は、[こちら](./start_the_learning_kubernetes_07)です。","publishedAt":"2019-05-05","slug":"start_the_learning_kubernetes_06","title":"一足遅れて Kubernetes を学び始める - 06. workloads その2 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)では、kubenetes の CLI ツール kubectl を学習しました。\n今回は、目玉機能である workloads について学習します。\n\n## workloads\n\nKubernetes には、下記のようにリソースの種類が存在します。\n今回は、Workloads を学習します。\n\n| リソースの分類           | 内容                                                         |\n| :----------------------- | :----------------------------------------------------------- |\n| Workloads リソース       | コンテナの実行に関するリソース                               |\n| Discovery＆LB リソース   | コンテナを外部公開するようなエンドポイントを提供するリソース |\n| Config＆Storage リソース | 設定・機密情報・永続化ボリュームなどに関するリソース         |\n| Cluster リソース         | セキュリティやクォータなどに関するリソース                   |\n| Metadata リソース        | リソースを操作する系統のリソース                             |\n\n※ [Kubernetes の Workloads リソース（その 1）](https://thinkit.co.jp/article/13610)\n\nWorkloads には、下記 8 つの種類があります。\n\n- Pod\n- ReplicationController\n- ReplicaSet\n- Deployment\n- DaemonSet\n- StatefulSet\n- Job\n- CronJob\n\nPod,ReplicationController,ReplicaSet,Deployment までを見ていきます。\n\n## Pod\n\nコンテナを 1 つ以上含めた最小単位のリソース。\nPod 毎に IP アドレスが振られる。ボリュームは共有。\n基本的に、Pod にコンテナを詰め込めるのではなく、「分離できるなら、分離する」方針がマイクロサービスとして良いそうです。\nさっそく、動かしてみます。\n\n※ `alias k=kubectl`\n\n```yaml\n## sample-2pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sample-2pod\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:1.12\n    - name: redis-container\n      image: redis:3.2\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --prune --all\npod/sample-2pod created\npi@raspi001:~/tmp $ k get pod sample-2pod\nNAME          READY   STATUS    RESTARTS   AGE\nsample-2pod   2/2     Running   0          101s\n```\n\n期待通り複数のコンテナが動いていますね。(READY 2/2)\nexec で中に入る場合、どうなるのでしょうか。\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-2pod /bin/sh\nDefaulting container name to nginx-container.\nUse 'kubectl describe pod/sample-2pod -n default' to see all of the containers in this pod.\n#\n```\n\nなるほど、デフォルトのコンテナ（spec.containers の先頭)に入るみたいです。\nredis-container に入る場合は、\n\n```shell\npi@raspi001:~/tmp $ k exec -it sample-2pod -c redis-container /bin/sh\n## redis-cli\n127.0.0.1:6379> exit\n#\n```\n\n`-c`でコンテナを指定するだけみたいです。\n他にも説明したいことがありますが、長くなりそうなので切り上げます。\n\n## ReplicaSet, ReplicationController\n\nレプリカという名前だけあって、Pod を複製するリソース。\n過去の経緯から ReplicationController から ReplicaSet へ名前変更があったため、ReplicaSet を使うことが推奨\n\nさっそく、動かしてみます。\n\n```yaml\n## sample-rs.yaml\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: sample-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n        - name: redis-container\n          image: redis:3.2\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --prune --all\nreplicaset.apps/sample-rs created\npod/sample-2pod unchanged\npi@raspi001:~/tmp $ k get pods\nNAME              READY   STATUS              RESTARTS   AGE\nsample-2pod       2/2     Running             0          20m\nsample-rs-ghkcc   2/2     Running             0          103s\nsample-rs-nsc5b   0/2     ContainerCreating   0          103s\nsample-rs-wk7vl   0/2     ContainerCreating   0          103s\n```\n\n確かに、replica3 つ(sample-rs)で、それぞれコンテナが２つ(READY 2/2)作れていますね。\n書いて気になるのは、 pod の apiVersion は、`v1`に対して、replicaSet の apiVersion は、 `apps/v1`というのが気になりましたので、調べてみたところ、[Kubernetes の apiVersion に何を書けばいいか](https://qiita.com/soymsk/items/69aeaa7945fe1f875822)という記事を見つけました。\nCore となる機能は、`v1`で良いみたいです。\n\nKubernetes の目玉機能であるオーケストレーションの機能であるセルフヒーリングを試してみます。\n\n```shell\npi@raspi001:~/tmp $ k get pods\nNAME              READY   STATUS    RESTARTS   AGE\nsample-2pod       2/2     Running   0          29m\nsample-rs-ghkcc   2/2     Running   0          11m\nsample-rs-nsc5b   2/2     Running   0          11m\nsample-rs-wk7vl   2/2     Running   0          11m\npi@raspi001:~/tmp $ k delete pod sample-rs-wk7vl\npod \"sample-rs-wk7vl\" deleted\npi@raspi001:~/tmp $ k get pods\nNAME              READY   STATUS              RESTARTS   AGE\nsample-2pod       2/2     Running             0          30m\nsample-rs-ghkcc   2/2     Running             0          11m\nsample-rs-gq2hs   0/2     ContainerCreating   0          13s\nsample-rs-nsc5b   2/2     Running             0          11m\n```\n\nおー、ContainerCreating されています。良いですね〜。\nちなみに、気になったのは node 自体が故障してダウンした場合は、どうなるのでしょうか。試してみます。\n\n```shell\npi@raspi001:~/tmp $ k get pods -o=wide\nNAME              READY   STATUS    RESTARTS   AGE    IP            NODE       NOMINATED NODE   READINESS GATES\nsample-2pod       2/2     Running   0          32m    10.244.1.25   raspi002   <none>           <none>\nsample-rs-ghkcc   2/2     Running   0          13m    10.244.1.26   raspi002   <none>           <none>\nsample-rs-gq2hs   2/2     Running   0          114s   10.244.1.27   raspi002   <none>           <none>\nsample-rs-nsc5b   2/2     Running   0          13m    10.244.2.15   raspi003   <none>           <none>\n```\n\nraspi003 の電源を落としてみます。\n\nworker(raspi003)に移動\n\n```shell\n~ $ slogin pi@raspi003.local\npi@raspi003.local's password:\npi@raspi003:~ $ sudo shutdown now\nsudo: unable to resolve host raspi003\nConnection to raspi003.local closed by remote host.\nConnection to raspi003.local closed.\n~ $\n```\n\nmaster(raspi001)に移動\n\n```shell\npi@raspi001:~/tmp $ k get nodes\nNAME       STATUS     ROLES    AGE     VERSION\nraspi001   Ready      master   5d16h   v1.14.1\nraspi002   Ready      worker   5d16h   v1.14.1\nraspi003   NotReady   worker   4d21h   v1.14.1\npi@raspi001:~/tmp $ k get pods -o=wide\nNAME              READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\nsample-2pod       2/2     Running   0          35m     10.244.1.25   raspi002   <none>           <none>\nsample-rs-ghkcc   2/2     Running   0          17m     10.244.1.26   raspi002   <none>           <none>\nsample-rs-gq2hs   2/2     Running   0          5m38s   10.244.1.27   raspi002   <none>           <none>\nsample-rs-nsc5b   2/2     Running   0          17m     10.244.2.15   raspi003   <none>           <none>\n```\n\nん？ raspi003 で動いている？ 数十秒後...\n\n```shell\npi@raspi001:~/kubernetes-perfect-guide/samples/chapter05/tmp $ k get pods -o=wide\nNAME              READY   STATUS        RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\nsample-2pod       2/2     Running       0          40m   10.244.1.25   raspi002   <none>           <none>\nsample-rs-ghkcc   2/2     Running       0          22m   10.244.1.26   raspi002   <none>           <none>\nsample-rs-gq2hs   2/2     Running       0          10m   10.244.1.27   raspi002   <none>           <none>\nsample-rs-nsc5b   2/2     Terminating   0          22m   10.244.2.15   raspi003   <none>           <none>\nsample-rs-p2jsc   2/2     Running       0          53s   10.244.1.28   raspi002   <none>           <none>\n```\n\nおー、期待通り raspi003 にある pod が消えて、raspi002 に作り直されました。sample-rs-nsc5b は node が落ちちゃっているので、消すこともできず残り続けます。\n\n## 少し待ち時間が長いような\n\n[Kubernetes はクラスタで障害があったとき、どういう動きをするのか](http://dr-asa.hatenablog.com/entry/2018/04/02/174006)という記事によれば、kube-controller-manager が検知して、kube-scheduler が正しい数に揃えているみたいです。**数十秒待たされた**のは、検知の間隔のせいでしょうか。\n\n[kube-controller-manager](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/)のオプションで、`--attach-detach-reconcile-sync-period duration Default: 1m0s`とあります。**1 分間隔**なのですかね。\n\n## Pod を特定の Node で動かさないようにしたい\n\nみたいな要望を叶えれるのでしょうか。\n\n[Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)によると、nodeSelector フィールドでアサインされる node を指定できるそうです。（除外ではなく、指定）\nただし、[Editing nodeSelector doesn't rearrange pods in ReplicaSet](https://stackoverflow.com/questions/48640806/editing-nodeselector-doesnt-rearrange-pods-in-replicaset)によると、それは replicaSet ではなく、deployment で行うべきとのことです。replicaSet で動くかどうか、念の為試してみます。\n\nまず、先程落とした raspi003 を電源を入れ直して起動させます。\nその後、master(raspi001)に移動。\n\n```shell\npi@raspi001:~/tmp $ k label nodes raspi002 type=AWS\nnode/raspi002 labeled\npi@raspi001:~/tmp $ k label nodes raspi003 type=GCP\nnode/raspi003 labeled\npi@raspi001:~/tmp $ k get nodes -L type\nNAME       STATUS   ROLES    AGE     VERSION   TYPE\nraspi001   Ready    master   5d17h   v1.14.1\nraspi002   Ready    worker   5d17h   v1.14.1   AWS\nraspi003   Ready    worker   4d21h   v1.14.1   GCP\npi@raspi001:~/tmp $ k get pods -o=wide\nNAME              READY   STATUS    RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\nsample-2pod       2/2     Running   0          75m   10.244.1.25   raspi002   <none>           <none>\nsample-rs-ghkcc   2/2     Running   0          56m   10.244.1.26   raspi002   <none>           <none>\nsample-rs-gq2hs   2/2     Running   0          44m   10.244.1.27   raspi002   <none>           <none>\nsample-rs-p2jsc   2/2     Running   0          35m   10.244.1.28   raspi002   <none>           <none>\n```\n\nnode にラベルを貼って、nodeSelector しやすいようにしました。\nsample-rs は、全て raspi002 で動いているので、下記を試してみます。\n\n1. sample-rs は raspi002 でのみ動くよう設定\n1. raspi002 をシャットダウン\n\nその結果、「sample-rs は raspi002 が動いていないので、セルフヒーリングしない」ことを期待します。\n\n```yaml\n## sample-rs.yaml\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: sample-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n        - name: redis-container\n          image: redis:3.2\n      nodeSelector:\n        type: AWS\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --prune --all\nreplicaset.apps/sample-rs configured\npod/sample-2pod unchanged\n```\n\nnodeSelector を追加しました。\n今回は単純な指定なのでこれで良いですが、より柔軟に指定したい場合は nodeAffinity を使うそうです。\n\nworker(raspi002)に移動\n\n```shell\n~ $ slogin pi@raspi002.local\npi@raspi002.local's password:\npi@raspi002:~ $ sudo shutdown now\nsudo: unable to resolve host raspi002\nConnection to raspi002.local closed by remote host.\nConnection to raspi002.local closed.\n~ $\n```\n\n数十秒待つ...\n結果は...!\n\nmaster(raspi001)に移動\n\n```shell\npi@raspi001:~/tmp $ k get nodes -L type\nNAME       STATUS     ROLES    AGE     VERSION   TYPE\nraspi001   Ready      master   5d17h   v1.14.1\nraspi002   NotReady   worker   5d17h   v1.14.1   AWS\nraspi003   Ready      worker   4d22h   v1.14.1   GCP\npi@raspi001:~/tmp $ k get pods -o=wide\nNAME              READY   STATUS        RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES\nsample-2pod       2/2     Terminating   0          89m   10.244.1.25   raspi002   <none>           <none>\nsample-rs-4srpp   0/2     Pending       0          36s   <none>        <none>     <none>           <none>\nsample-rs-6mgcr   0/2     Pending       0          37s   <none>        <none>     <none>           <none>\nsample-rs-ghkcc   2/2     Terminating   0          71m   10.244.1.26   raspi002   <none>           <none>\nsample-rs-gq2hs   2/2     Terminating   0          59m   10.244.1.27   raspi002   <none>           <none>\nsample-rs-lc225   0/2     Pending       0          36s   <none>        <none>     <none>           <none>\nsample-rs-p2jsc   2/2     Terminating   0          49m   10.244.1.28   raspi002   <none>           <none>\n```\n\n期待通りでした。つまり、sample-rs は raspi002 以外で作り直せないので、Pending,Terminating 状態です。\nまた、単純な pod である sample-2pod は replicaSet ではないので、セルフヒーリングされずに Terminating になっています。\n面白いですね。これ。\n\n## Deployment\n\n複数の ReplicaSet を管理。\nReplicaSet にない「ローリングアップデート、ロールバック」機能が存在。\nPod や ReplicaSet ではなく、Deployment が最も推奨されるリソース種類。\n\nReplicaSet では、指定したコンテナイメージを更新した場合(アップデート)、どうなるのでしょうか。すべて更新されるのか、一部だけなのでしょうか。試してみます。\n\nsample-2pod-replica.yaml の nginx イメージを 1.12 から 1.13 に更新しました。\n\n```shell\npi@raspi001:~/tmp $ k get all\nNAME                  READY   STATUS    RESTARTS   AGE\npod/sample-rs-4srpp   2/2     Running   0          7h14m\npod/sample-rs-6mgcr   2/2     Running   0          7h14m\npod/sample-rs-lc225   2/2     Running   0          7h14m\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d\n\nNAME                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/sample-rs   3         3         3       8h\npi@raspi001:~/tmp $ k apply -f . --prune --all\nreplicaset.apps/sample-rs configured\npod/sample-2pod created\npi@raspi001:~/tmp $ k describe replicaset sample-rs\nName:         sample-rs\n...\n  Containers:\n   nginx-container:\n    Image:        nginx:1.13\n...\n```\n\nreplicaset のマニュフェストは更新されました。\n\n```shell\npi@raspi001:~/tmp $ k describe pod sample-rs-4srpp\nName:               sample-rs-4srpp\n...\n  nginx-container:\n    Container ID:   docker://9160f550ee9d9bbcd1a5c990ca95389b2b39aff6688bcd933c99fe93b1968b99\n    Image:          nginx:1.12\n...\n```\n\npod は変化なしのようです。\nでは、Deployment を使ってみます。\n\n```yaml\n## sample-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.12\n          ports:\n            - containerPort: 80\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --prune --all --record\nreplicaset.apps/sample-rs configured\npod/sample-2pod configured\ndeployment.apps/sample-deployment created\n```\n\n`--record`をつけることで、履歴を保持することができます。ロールバックに使います。\n\n```shell\npi@raspi001:~/tmp $ k get all\nNAME                                    READY   STATUS    RESTARTS   AGE\npod/sample-2pod                         2/2     Running   0          12m\npod/sample-deployment-6cd85bd5f-4whgn   1/1     Running   0          119s\npod/sample-deployment-6cd85bd5f-js2sw   1/1     Running   0          119s\npod/sample-deployment-6cd85bd5f-mjt77   1/1     Running   0          119s\npod/sample-rs-4srpp                     2/2     Running   0          7h28m\npod/sample-rs-6mgcr                     2/2     Running   0          7h28m\npod/sample-rs-lc225                     2/2     Running   0          7h28m\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d1h\n\nNAME                                READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/sample-deployment   3/3     3            3           2m\n\nNAME                                          DESIRED   CURRENT   READY   AGE\nreplicaset.apps/sample-deployment-6cd85bd5f   3         3         3       2m\nreplicaset.apps/sample-rs                     3         3         3       8h\n```\n\nsample-deployment が、deployment,replicaset,pod を作成しました。\n\nでは、sample-deployment の nginx コンテナを 1.12 から 1.13 に更新してみます。\n\n```yaml\n## sample-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      labels:\n        app: sample-app\n    spec:\n      containers:\n        - name: nginx-container\n          image: nginx:1.13\n          ports:\n            - containerPort: 80\n```\n\n```shell\npi@raspi001:~/tmp $ k apply -f . --prune --all --record\nreplicaset.apps/sample-rs unchanged\npod/sample-2pod unchanged\ndeployment.apps/sample-deployment configured\npi@raspi001:~/tmp $ k get pod\nNAME                                 READY   STATUS              RESTARTS   AGE\nsample-2pod                          2/2     Running             0          15m\nsample-deployment-6cd85bd5f-js2sw    1/1     Running             0          4m53s\nsample-deployment-6cd85bd5f-mjt77    1/1     Running             0          4m53s\nsample-deployment-7dfb996c6b-gh2cg   0/1     ContainerCreating   0          21s\nsample-deployment-7dfb996c6b-m4wrd   1/1     Running             0          38s\nsample-rs-4srpp                      2/2     Running             0          7h31m\nsample-rs-6mgcr                      2/2     Running             0          7h31m\nsample-rs-lc225                      2/2     Running             0          7h31m\n```\n\nおー、deployment の pod が作り変わっていっています。これが**ローリングアップデート**です。\nローリングアップデートは、spec.template 以下が更新されると変化したとみなすそうです。\nまた、ロールバックは、rollout コマンドで実施できますし、revision 指定で戻すこともできます。\nしかし、基本的にはマニュフェストを戻して apply すべきです。\n\nアップデート戦略というものがあり、デフォルトは RollingUpdate です。過不足分の Pod 考慮した更新戦略になります。\nアップデート中に許容される不足分と超過分を設定できます。(maxUnavailable, maxSurge)\n他の戦略として、Recreate 戦略があります。こちらは、全て同時に作り直しになります。ですので、一時的にアクセス不可になってしまいます。\n\n１つ不安に感じたものとして、「フロントエンドのバージョンを１から２にアップデートしたら、バージョン 1 のコンテナにアクセスしたユーザがバージョン 2 のコンテナに遷移したら大丈夫なのかな」と思いました。しかし、これはローリングアップデートに限った話ではないので、それは考えないこととしました。ちゃんと設計すれば良い話ですね。\n\nちなみに、マニュフェストを書かずに deployment ができます。`k run sample-deployment-cli --image nginx:1.12 --replicas 3 --port 80`です。お試しなら、便利ですね。\n\n## お片付け\n\n試しに、prune で削除しています。\n\n```shell\npi@raspi001:~/tmp $ ls\nsample-2pod-replica.yaml  sample-2pod.yaml  sample-deployment.yaml\npi@raspi001:~/tmp $ mv sample-2pod-replica.yaml sample-2pod-replica.yaml.org\npi@raspi001:~/tmp $ mv sample-deployment.yaml sample-deployment.yaml.org\npi@raspi001:~/tmp $ k apply -f . --all --prune\npod/sample-2pod configured\ndeployment.apps/sample-deployment pruned\nreplicaset.apps/sample-rs pruned\npi@raspi001:~/tmp $ k get all\nNAME              READY   STATUS    RESTARTS   AGE\npod/sample-2pod   2/2     Running   0          30m\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6d1h\n```\n\nんー、こうすると消せるのですが、どうしても１ファイル残してしまいます...。\nすべて org にすると、`k apply -f .`が失敗しますし...。\n\n```shell\npi@raspi001:~/tmp $ k delete pod sample-2pod\npod \"sample-2pod\" deleted\n```\n\n結局、こうしました...。\n\n```shell\npi@raspi001:~/tmp $ k label node raspi002 type-\npi@raspi001:~/tmp $ k label node raspi003 type-\n```\n\n## おわりに\n\n思った以上に、ReplicaSet にハマってしまいました。\n次は、残りの workloads を試します。\n次回は[こちら](./start_the_learning_kubernetes_06)です。","publishedAt":"2019-05-03","slug":"start_the_learning_kubernetes_05","title":"一足遅れて Kubernetes を学び始める - 05. workloads その1 -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)では、RaspberryPi の環境に Kubernetes を導入しました。無事、動作確認ができたので、さっそく学習していきたいです。\n\n## 参考\n\n「[Kubernetes 完全ガイド](https://www.amazon.co.jp/Kubernetes%E5%AE%8C%E5%85%A8%E3%82%AC%E3%82%A4%E3%83%89-impress-top-gear-%E9%9D%92%E5%B1%B1/dp/4295004804/)」を読んで進めてみます。ソースコードは[こちら](https://github.com/MasayaAoyama/kubernetes-perfect-guide)。\n\n以前の投稿では、[入門 Kubernetes](https://www.amazon.co.jp/%E5%85%A5%E9%96%80-Kubernetes-Kelsey-Hightower/dp/4873118409/)を参考にしていましたが、Kubernetes 完全ガイドの方が網羅的に学べて良かったで、そちらを使いました。\n\n## kubectl\n\n> Kubectl is a command line interface for running commands against Kubernetes clusters\n\n※ https://kubernetes.io/docs/reference/kubectl/overview/\n\nkubernetes を操作するための CLI です。\n\nよく使うものを私なりに整理し、入門時に最小限覚えておけば良いものをまとめました。\n\n## 1. apply\n\n```shell\npi@raspi001:~ $ cat << EOF > sample-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n name: sample-pod\nspec:\n containers:\n   - name: nginx-container\n     image: nginx:1.12\nEOF\npi@raspi001:~ $ kubectl apply -f sample-pod.yaml\npod/sample-pod created\n```\n\nKubernetes では、基本的にはマニフェストファイルを作成し、`apply`で適用するのが一般的のようです。それは、新規作成だけでなく、更新や削除も同様です。`create`や`replace`,`delete`といった CLI もありますが、`apply`でも同様の操作ができるため、使い分ける必要はあまりありません。`apply`で登録したマニュフェストファイルは履歴として保存されています。\n\n※ [Kubernetes: kubectl apply の動作](https://qiita.com/tkusumi/items/0bf5417c865ef716b221)\n\n## 2. set, get\n\n```shell\npi@raspi001:~ $ kubectl set image pod sample-pod nginx-container=nginx:1.13\npod/sample-pod image updated\npi@raspi001:~ $ kubectl get pod sample-pod\nNAME         READY   STATUS    RESTARTS   AGE\nsample-pod   1/1     Running   1          13m\n```\n\nkubectl では、どのリソース種類（`pod`,`service`,etc）で、どのリソース名なのかを教えてあげる必要があります。\nまた、フィルタリングする機能として`label`があります。\n\n```yaml\n## sample-pod-label.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n name: sample-pod\n  labels:\n   env: prod\n   app: sample\nspec:\n containers:\n   - name: nginx-container\n     image: nginx:1.12\n```\n\n```shell\npi@raspi001:~ $ kubectl get pod -l env=prod\nNo resources found.\npi@raspi001:~ $ kubectl apply -f sample-pod-label.yaml\npod/sample-pod configured\npi@raspi001:~ $ kubectl get pod -l env=prod\nNAME         READY   STATUS    RESTARTS   AGE\nsample-pod   1/1     Running   0          7m23s\n```\n\n更に詳細の情報が必要な場合は、`describe`を使います。\n\n```shell\npi@raspi001:~ $ kubectl describe pod sample-pod\nName:               sample-pod\n...\n```\n\n※ `edit`という直接編集する方法もありますが、一時的な対応のみに利用するべきとのことです。\nせっかくの宣言的ファイルが意味ないですよね。\n\n余談ですが、`service`を`svc`という風に省略できたりします。\n※ [（備忘）kubectl コマンドでの短縮リソース名](https://qiita.com/nagase/items/3b8f905f432abba15b5a)\n\n## 3. debug\n\n```shell\npi@raspi001:~ $ kubectl exec -it sample-pod /bin/sh\n## exit\npi@raspi001:~ $ kubectl logs sample-pod\npi@raspi001:~ $ kubectl cp sample-pod.yaml sample-pod:/var/sample-pod.yaml\npi@raspi001:~ $ kubectl port-forward sample-pod 8888:80\nForwarding from 127.0.0.1:8888 -> 80\nForwarding from [::1]:8888 -> 80\n```\n\nどれも`pod`に対する操作なためリソース種類の指定はありません。どれも開発時に必要が迫られれば使う感じですね。\n\n## 99. top\n\nこちら、どうしても動作できませんでした... 😥😥\n今はそこまで必要としないので、一旦見送ります。\n`calico`だか`flannel`とかが関係しているっぽいのですが、理解が浅いため未解決です。\n\n## お片付け\n\n```shell\npi@raspi001:~ $ kubectl delete pod sample-pod\npod \"sample-pod\" deleted\n```\n\n複数の pod を扱っているなら、`delete`よりも`apply --prune`の方が良いですが、今回は単体 pod なので、直接`delete`しました。\n\n## おわりに\n\n入門当初は、どれほど覚えなくてはいけないのかと不安になっていたのですが、\n蓋を開けてみると、そこまで多くはありませんでした。（まだ知らないものは多いと思いますが）\n規則性として、 リソース種類とリソース名を指定する習慣にも徐々に慣れてきました。\n面倒なときは、`kubectl get all`で全部出すという荒業も覚えました。（笑）\n\n次回は[こちら](./start_the_learning_kubernetes_05)です。","publishedAt":"2019-05-02","slug":"start_the_learning_kubernetes_04","title":"一足遅れて Kubernetes を学び始める - 04. kubectl -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)では、Mac で Kubernetes を軽く動かしてみました。DockerForMac では、Node が Master のみだったため、Kubernetes を学習するには、ものたりない感がありました。そこで、RaspberryPi を使っておうち Kubernetes を構築することになりました。\n\n参考サイト\n\n- [ラズパイで Kubernetes クラスタを構築する](https://qiita.com/sotoiwa/items/e350579d4c81c4a65260)\n- [おうち Kubernetes 構築でハマったところ - ニッチ編 -](https://qiita.com/shnmorimoto/items/7ce3c3ef8e962f8e5c59)\n- [おうち kubernetes でデータを永続化する](https://qiita.com/inajob/items/7b61904586d0816dfe5f)\n- [kubernetes のラズパイ包みが美味しそうだったので、kubeadm を使って作ってみた](https://qiita.com/shirot61/items/2321b70cd9c93f8f5cf0)\n- [Raspberry PI と kubeadm で自宅 Kubernetes クラスタを構築する](https://qiita.com/hatotaka/items/48a88ecb190e1f5e03c3)\n- [3 日間クッキング【Kubernetes のラズペリーパイ包み “サイバーエージェント風”】](https://developers.cyberagent.co.jp/blog/archives/14721/)\n- [33 時間クッキング【Kubernetes のラズベリーパイ包み〜ウエパ風〜】](https://engineers.weddingpark.co.jp/?p=1993)\n\n## レシピ\n\n| 商品名                                                                                                     | 個数 | 用途                                   |\n| ---------------------------------------------------------------------------------------------------------- | ---- | -------------------------------------- |\n| [Raspberry Pi 3 Model B](https://www.amazon.co.jp/gp/product/B01NAHBSUD/)                                  | 3 つ | MasterNode1 台 / WorkerNode2 台     |\n| [microSDHC カード 16GB](https://www.amazon.co.jp/gp/product/B079H6PDCK/)                                   | 3 枚 | RaspberryPi の image 書き込み先        |\n| [LAN ケーブル](https://www.amazon.co.jp/gp/product/B00JEUSAR2)                                             | 1 本 | RaspberryPi とネットワーク接続         |\n| [USB 充電器](https://www.amazon.co.jp/gp/product/B01AVSNEFS/)                                              | 1 台 | RaspberryPi の電源                     |\n| [Micro USB ケーブル](https://www.amazon.co.jp/gp/product/B07K3WGLV7/)                                      | 4 本 | RaspberryPi と USB 充電器をつなげる    |\n| [for Raspberry Pi ケース 専用 4 段](https://www.amazon.co.jp/gp/product/B01JONA3U0/)  /  ヒートシンク付 | 1 台 | 4 段 / (3:RaspberryPi,1:USB 充電器) |\n\nRaspberryPi は世代 3 の ModelB なら WiFi 接続できるので、自宅の WiFi につなげることにしました。自宅では SoftbankAir を使っています。\n（ただし、初回のみ LAN ケーブルでネットワーク接続します)\n\nまた、私の環境は下記のとおりです。\n\n```text\niMac (21.5-inch, 2017)\n```\n\n## 構築（物理）\n\n[Raspberry Pi でおうち Kubernetes 構築【物理編】](https://qiita.com/go_vargo/items/d1271ab60f2bba375dcc)で十分な情報があります。こちらを参考にして組み立てします。\nできたものがこちらです。\n\n![kubernetes_raspberrypi.png](https://res.cloudinary.com/silverbirder/image/upload/v1639816691/silver-birder.github.io/blog/kubernetes_raspberrypi.png)\n\nWiFi を使うために、LAN ケーブルや WiFi 親機などがなくなり、スッキリしました。\n電源を確保できるところであれば、家の中なら、どこでも持ち運びできます。 ✨\n\n## 構築（論理）\n\n[Raspbian Stretch Lite](https://www.raspberrypi.org/downloads/raspbian/)をダウンロードしておきます。\n\nStep の 1 から 3 までの手順を**RaspberryPi 一台ずつ** 、下記の手続きを踏んでいきます。\n\n## 1. 初期設定\n\nmicroSD カードを Mac につなげた後に、下記を実施します。\n\n```shell\ndiskutil list\nsudo diskutil umount /dev/disk3s1\nsudo dd bs=1m if=2019-04-08-raspbian-stretch-lite.img of=/dev/rdisk3 conv=sync\ncd /Volumes/boot\ntouch ssh\nvim cmdline.txt\n## 下記を末尾に追記\ncgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1\n```\n\nイメージを書き込み際、**r** をつける (rdisk3)と、高速になるそうです。\n\n## 2. RaspberryPi に接続\n\nMicroSD カードを RaspbeeryPi に挿入し、電源をつけたら、下記を実施します。\nLAN ケーブルは、自宅の WiFi に直接つなげます。(私の場合は SoftBankAir)\n\nhostname は、お好みの名前にします。（私は、`Master:raspi001, Worker:raspi002,raspi003`としました。)\n\n```shell\nslogin pi@raspberrypi.local\n## 初回password「raspberry」\npi@raspbeerypi:~ $ sudo passwd pi\npi@raspbeerypi:~ $ sudo apt-get update && sudo apt-get -y upgrade && sudo apt-get install -y vim\npi@raspbeerypi:~ $ sudo vim /etc/hostname\npi@raspbeerypi:~ $ sudo sh -c 'wpa_passphrase <SSID> <PASSWORD> >> /etc/wpa_supplicant/wpa_supplicant.conf'\npi@raspbeerypi:~ $ sudo shutdown -r now\n```\n\n※ 2 回目以降は、`ssh-keygen -R raspberrypi.local`をしましょう。\n\n電源を落として、LAN ケーブルを外します。再度電源をつけて数分待ってから、下記を実施します。\n\n```shell\nslogin pi@raspi001.local\npi@raspi001:~ $\n```\n\n接続できたら成功です。\n\n## 3. 各種インストール\n\nおまじないをします。\n\n```shell\npi@raspi001:~ $ sudo dphys-swapfile swapoff && sudo dphys-swapfile uninstall && sudo update-rc.d dphys-swapfile remove\n```\n\nDocker をインストールします。\n\n```shell\npi@raspi001:~ $ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common -y\npi@raspi001:~ $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -\npi@raspi001:~ $ echo \"deb [arch=armhf] https://download.docker.com/linux/$(. /etc/os-release; echo \"$ID\") \\\n     $(lsb_release -cs) stable\" | \\\n    sudo tee /etc/apt/sources.list.d/docker.list\npi@raspi001:~ $ sudo apt-get update -y\npi@raspi001:~ $ sudo apt-get install docker-ce -y\n```\n\nKubernetes をインストールします。\n\n```shell\npi@raspi001:~ $ curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg|sudo apt-key add -\npi@raspi001:~ $ echo \"deb http://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kube.list\npi@raspi001:~ $ sudo apt-get update -y && sudo apt-get install kubelet kubeadm kubectl -y\n```\n\n## 4. MasterNode の設定\n\nMasterNode にする RaspberryPi に対して下記を実施します。\n\n```shell\npi@raspi001:~ $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16\npi@raspi001:~ $ mkdir -p $HOME/.kube\npi@raspi001:~ $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\npi@raspi001:~ $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n出力される join メッセージをメモしておき、WorkerNode の構築時に使います。\n\n[こちら](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network)に従い下記を実行します。\n\n```shell\npi@raspi001:~ $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml\npi@raspi001:~ $ kubectl get pods --all-namespaces\nNAMESPACE     NAME                               READY   STATUS              RESTARTS   AGE\nkube-system   coredns-fb8b8dccf-lglcr            0/1     ContainerCreating   0          4d16h\nkube-system   coredns-fb8b8dccf-snt7d            0/1     ContainerCreating   0          4d16h\n...\n```\n\n## 5. WorkerNode の設定\n\nMasterNode から出力された join コマンドを実施します。\n\n```shell\npi@raspi002 $ kubeadm join 192.168.3.32:6443 --token X \\\n    --discovery-token-ca-cert-hash sha256:X\n```\n\n## 6. MasterNode から確認\n\nNode が増えているか確認します。\n\n```shell\npi@raspi001:~ $ kubectl get nodes\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   65m   v1.14.1\nraspi002   Ready    <none>   18m   v1.14.1\nraspi002   Ready    <none>   18m   v1.14.1\npi@raspi001:~ $ kubectl label node raspi002 node-role.kubernetes.io/worker=worker\npi@raspi001:~ $ kubectl label node raspi003 node-role.kubernetes.io/worker=worker\npi@raspi001:~ $ kubectl get nodes\nNAME       STATUS   ROLES    AGE   VERSION\nraspi001   Ready    master   65m   v1.14.1\nraspi002   Ready    worker   37m   v1.14.1\nraspi003   Ready    worker   37m   v1.14.1\n```\n\n## 7. ブラウザから確認\n\n試しにデプロイ → サービス公開 → ブラウザ確認までを、さっと通してみます。\n\n```shell\npi@raspi001:~ $ kubectl run nginx --image=nginx --replicas=1 --port=80\npi@raspi001:~ $ kubectl expose deployment nginx --port 80 --target-port 80 --type NodePort\npi@raspi001:~ $ kubectl get svc nginx\nNAME    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nnginx   NodePort   10.99.227.194   <none>        80:30783/TCP   17m\n```\n\nサービス公開までしたので、アクセスしてみます。\n\n内部\n\n```shell\npi@raspi001:~ $ curl http://10.99.227.194:80\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href=\"http://nginx.org/\">nginx.org</a>.<br/>\nCommercial support is available at\n<a href=\"http://nginx.com/\">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n```\n\n外部\n\n```shell\npi@raspi001:~ $ ifconfig\n...\nwlan0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 192.168.3.32  netmask 255.255.255.0  broadcast 192.168.3.255\n```\n\n`http://192.168.3.32:30783`にアクセス\n\n![nginx](https://res.cloudinary.com/silverbirder/image/upload/v1639816718/silver-birder.github.io/blog/kubernetes_nginx.png)\n\nOK!\n\n## お片付け\n\n```shell\npi@raspi001:~ $ kubectl delete deployments nginx\ndeployment.extensions \"nginx\" deleted\npi@raspi001:~ $ kubectl  delete service nginx\nservice \"nginx\" deleted\n```\n\n## 完成\n\nすんなりと構築することができました。これは先人たちの記事がたくさんあるので、\nサクサクと進めることができました。これで、Kubernetes を使いまくります!! 💪💪\n次回は[こちら](./start_the_learning_kubernetes_04)です。","publishedAt":"2019-04-28","slug":"start_the_learning_kubernetes_03","title":"一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 前回\n\n[一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)にて、Kubernetes を学ぶ環境を考えてみました。いきなり GKE を使うんじゃなくて、お手軽に試せる DockerForMac を使おうとなりました。\n\n## Docker For Mac を試す\n\n## 環境\n\n```text\n## Machine\niMac (21.5-inch, 2017)\n```\n\n```text\n## Docker\nDocker Community Edition:\n  Version: 18.06.1-ce-mac73 (26764)\nDocker Engine:\n  Version: 18.06.1-ce\nKubernetes:\n  Version: v1.10.3\n```\n\n## 実践\n\nさっそく、使ってみます。 ([入門 Kubernetes](https://www.oreilly.co.jp/books/9784873118406/)参考)\n\n```shell\n~ $ kubectl get componentstatuses\nNAME                 STATUS    MESSAGE              ERROR\ncontroller-manager   Healthy   ok\nscheduler            Healthy   ok\netcd-0               Healthy   {\"health\": \"true\"}\n```\n\nKubernetes では、MasterNode と WorkerNode の 2 種類の Node が存在しており、\nそのうちの MasterNode にあるコンポーネントの一覧が上記よりわかります。詳細については、[こちら](https://qiita.com/tkusumi/items/c2a92cd52bfdb9edd613)にあります。\n要は、`kubectl apply -f nginx.yaml` とすると\n\n1. etcd にマニュフェスト(nginx.yaml)を登録\n1. controller-manager が etcd にあるマニュフェストと既存 pod を比べて pod が少ないことを検知\n1. scheduler が適切な数の pod に調整\n\nという理解になりました。また、全てのやり取りは、api-server を経由しているそうです。\n\n私なりの理解をアウトプットしたものが下記になります。\n(ほとんど真似した感じです。しかし、アウトプットするだけで理解が深まるため実施。 **アウトプット大事！** )\n\n![Kubernetes_learning.png](https://res.cloudinary.com/silverbirder/image/upload/v1639816747/silver-birder.github.io/blog/Kubernetes_learning.png)\n\n```shell\n~ $ kubectl get nodes\nNAME                 STATUS    ROLES     AGE       VERSION\ndocker-for-desktop   Ready     master    120d      v1.10.3\n~ $ kubectl get pods\nNo resources found.\n```\n\n使い始めたばかりだと、pod が１つもない状態ですね。\nまた、DockerForMac では、もちろん動かしているマシンは一台（VM とか使えば増やせますが）なので、\nMasterNode と WorkerNode が同一になっているはずです。試してみます。\n\n```yaml\n## nginx.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n    - name: nginx\n      image: nginx\n      ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n```\n\n```shell\n~ $ kubectl apply -f nginx.yaml\npod \"nginx\" created\n~ $ kubectl get pod -o wide\nNAME      READY     STATUS    RESTARTS   AGE       IP           NODE\nnginx     1/1       Running   0          3m        10.1.0.157   docker-for-desktop\n```\n\nWorkerNode に Pod が作られていますね。んー、これだとある程度の学習には繋がりそう（Pod の動き）ですが、\n後の学ぶ ReplicaSet や Daemonset など Node 横断した機能を経験したい場合には不向きのようですね。\nまあ、簡単に使えるので良いっちゃ良いのですが...\n\n次は、いくつかのコマンド(cp,exec, port-forward)を試してみます。\n\n```shell\n~ $ touch memo.txt\n~ $ ls\nnginx.yaml memo.txt\n~ $ kubectl cp memo.txt nginx:/memo.txt\n~ $ rm memo.txt\n~ $ ls\nnginx.yaml\n~ $ kubectl cp nginx:/memo.txt ./memo.txt\n~ $ ls\nnginx.yaml memo.txt\n~ $ kubectl exec -it nginx bash\nroot@nginx:/# exit\nexit\n~ $\n```\n\nローカルと Pod との双方向コピー、仮想的なターミナルを体験していました。\n「ふ〜ん、で？」ってなっちゃいました。(笑)\n\n## お片付け\n\n```shell\n~ $ kubectl delete -f nginx.yaml\npod \"nginx\" deleted\n```\n\n## ものたりない\n\nやっぱり Node 増やしたい！！\n[Raspberry Pi でおうち Kubernetes 構築【論理編】](https://qiita.com/go_vargo/items/29f6d832ea0a289b4778)を見て、これをやるっきゃない！\nすごく今更だけど、試してみようと思います。\n次回は[こちら](./start_the_learning_kubernetes_03)です。","publishedAt":"2019-04-27","slug":"start_the_learning_kubernetes_02","title":"一足遅れて Kubernetes を学び始める - 02. Docker For Mac -"},{"body":"## ストーリー\n\n1. [一足遅れて Kubernetes を学び始める - 01. 環境選択編 -](./start_the_learning_kubernetes_01)\n1. [一足遅れて Kubernetes を学び始める - 02. Docker For Mac -](./start_the_learning_kubernetes_02)\n1. [一足遅れて Kubernetes を学び始める - 03. Raspberry Pi -](./start_the_learning_kubernetes_03)\n1. [一足遅れて Kubernetes を学び始める - 04. kubectl -](./start_the_learning_kubernetes_04)\n1. [一足遅れて Kubernetes を学び始める - 05. workloads その 1 -](./start_the_learning_kubernetes_05)\n1. [一足遅れて Kubernetes を学び始める - 06. workloads その 2 -](./start_the_learning_kubernetes_06)\n1. [一足遅れて Kubernetes を学び始める - 07. workloads その 3 -](./start_the_learning_kubernetes_07)\n1. [一足遅れて Kubernetes を学び始める - 08. discovery&LB その 1 -](./start_the_learning_kubernetes_08)\n1. [一足遅れて Kubernetes を学び始める - 09. discovery&LB その 2 -](./start_the_learning_kubernetes_09)\n1. [一足遅れて Kubernetes を学び始める - 10. config&storage その 1 -](./start_the_learning_kubernetes_10)\n1. [一足遅れて Kubernetes を学び始める - 11. config&storage その 2 -](./start_the_learning_kubernetes_11)\n1. [一足遅れて Kubernetes を学び始める - 12. リソース制限 -](./start_the_learning_kubernetes_12)\n1. [一足遅れて Kubernetes を学び始める - 13. ヘルスチェックとコンテナライフサイクル -](./start_the_learning_kubernetes_13)\n1. [一足遅れて Kubernetes を学び始める - 14. スケジューリング -](./start_the_learning_kubernetes_14)\n1. [一足遅れて Kubernetes を学び始める - 15. セキュリティ -](./start_the_learning_kubernetes_15)\n1. [一足遅れて Kubernetes を学び始める - 16. コンポーネント -](./start_the_learning_kubernetes_16)\n\n## 経緯\n\nKubernetes を使えるようになりたいな〜（定義不明）\nけど、他にやりたいこと（アプリ開発）あるから後回しにしちゃえ〜！！\nと、今までずっと、ちゃんと学ばなかった Kubernetes を、本腰入れて使ってみようと思います。✨\n\n## 環境\n\n```text\niMac (21.5-inch, 2017)\n```\n\n私の知識レベルは、\n「Kubernetes はコンテナオーケストレーションしてくれるやつでしょ」というざっくり認識で、関連用語は耳にしたことがあるだけで、よく理解できていません。\n\n## 最初、何から始めよう\n\nマネージドサービスの GKE 使ったほうが、最初は楽で簡単だから、そっちを使ったほうが良いみたいです。 😍\n\n## GKE SetUp\n\n![GKE 標準クラスタ テンプレート 1](https://res.cloudinary.com/silverbirder/image/upload/v1639816542/silver-birder.github.io/blog/GKE_template_1.png)\n\nノードってのは、ポッド（コンテナ）を入れるマシンなんだっけな。 ([Pod と Node](https://nownabe.github.io/kubernetes-doc/tutorials/kubernetes_basics/3_explore_your_app.html))\n\n![GKE 標準クラスタ テンプレート 2](https://res.cloudinary.com/silverbirder/image/upload/v1639816542/silver-birder.github.io/blog/GKE_template_2.png)\n\nまあ、デフォルトで良いよね 🤔\n\n![GKE 標準クラスタ テンプレート 3](https://res.cloudinary.com/silverbirder/image/upload/v1639816542/silver-birder.github.io/blog/GKE_template_3.png)\n\n単語がどれも分からなさすぎる...(Istio?自動プロビジョニング?垂直ポッド自動スケーリング？) 🤔🤔🤔\n\n## Mac で Kubernetes 試せるから、そっちで学んでいこう\n\nちょっと意味がわからない状態で、GKE 動かしたらお金がかかる上に、何してるのか分からないから、もったいない。\nDocker For Mac に Kubernetes 使えるみたいだから、まずはそっちを使って学んでいこうかな。。。 💪\n\n次回は[こちら](./start_the_learning_kubernetes_02)です。","publishedAt":"2019-04-18","slug":"start_the_learning_kubernetes_01","title":"一足遅れて Kubernetes を学び始める  - 01. 環境選択編 -"},{"body":"## Cloud Run とは\n\n> Cloud Run is a managed compute platform that enables you to run stateless containers that are invocable via HTTP requests. Cloud Run is serverless\n\n※ [https://cloud.google.com/run/](https://cloud.google.com/run/)\n\n詳しくは割愛するが、Cloud Functions や App Engine と同じようなサーバーレスで動作するもの。\nコンテナを deploy するため、GKE から制御することもできる。\n\n[![Cloud Run Deploy](https://res.cloudinary.com/silverbirder/image/upload/v1693376921/silver-birder.github.io/blog/190410-abrigednews-02-google-devops-with-serverless.png)](https://japan.zdnet.com/article/35135525/)\n\n## デプロイしてみた\n\n[https://cloud.google.com/run/docs/quickstarts/build-and-deploy](https://cloud.google.com/run/docs/quickstarts/build-and-deploy)\n\nを参考に進めていく。\n\nちなみに、動作環境は下記コンテナ内に行う。\n\n[https://hub.docker.com/r/google/cloud-sdk](https://hub.docker.com/r/google/cloud-sdk)\n\n## step1. gcloud の各種設定\n\n```shell\ngcloud components update\ngcloud components install beta\ngcloud config set run/region us-central1\n```\n\n※ 2019/04/11 時点では、Cloud Run は beta.\n\n## step2. アプリケーションコードの作成\n\n```shell\nmkdir helloworld-go && cd helloworld-go\ntouch helloworld.go Dockerfile\n```\n\n```go\npackage main\n\nimport (\n        \"fmt\"\n        \"log\"\n        \"net/http\"\n        \"os\"\n)\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n        log.Print(\"Hello world received a request.\")\n        target := os.Getenv(\"TARGET\")\n        if target == \"\" {\n                target = \"World\"\n        }\n        fmt.Fprintf(w, \"Hello %s!\\n\", target)\n}\n\nfunc main() {\n        log.Print(\"Hello world sample started.\")\n\n        http.HandleFunc(\"/\", handler)\n\n        port := os.Getenv(\"PORT\")\n        if port == \"\" {\n                port = \"8080\"\n        }\n\n        log.Fatal(http.ListenAndServe(fmt.Sprintf(\":%s\", port), nil))\n}\n```\n\n```Dockerfile\n## Use the offical Golang image to create a build artifact.\n## This is based on Debian and sets the GOPATH to /go.\n## https://hub.docker.com/_/golang\nFROM golang:1.12 as builder\n\n## Copy local code to the container image.\nWORKDIR /go/src/github.com/knative/docs/helloworld\nCOPY . .\n\n## Build the command inside the container.\n## (You may fetch or manage dependencies here,\n## either manually or with a tool like \"godep\".)\nRUN CGO_ENABLED=0 GOOS=linux go build -v -o helloworld\n\n## Use a Docker multi-stage build to create a lean production image.\n## https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds\nFROM alpine\n\n## Copy the binary to the production image from the builder stage.\nCOPY --from=builder /go/src/github.com/knative/docs/helloworld/helloworld /helloworld\n\n## Run the web service on container startup.\nCMD [\"/helloworld\"]\n```\n\n## step3. 登録&デプロイ\n\n```shell\ngcloud builds submit --tag gcr.io/[PROJECT-ID]/helloworld\ngcloud beta run deploy --image gcr.io/[PROJECT-ID]/helloworld\n```\n\n![result](https://res.cloudinary.com/silverbirder/image/upload/v1613818551/silver-birder.github.io/blog/D34Fl0ZU4AA-dhU.png)\n\n## 感想\n\n普段私は、個人開発をしているときによくつかっている [now.sh](https://zeit.co/now)という Serverless Deployments を使っている。こちらは、v1 のときは docker コンテナを使えていたのだが、v2 になると使えなくなってしまった。ただ、無料で簡単にデプロイできるものを選んでいると、こちらのサービスが最善だと感じていた。\n\nしかし、今回の GoogleCloudNext19 の発表で、CloudRun というものを Beta 版でリリースされたことを知り、早速使ってみた。\n何事もなく、今回の手順を進めて一切失敗することなく、3 分以内にデプロイまで進めることができた。\nこれは、なんて楽で便利なんだと感心してしまった。\nまた、[価格テーブル](https://cloud.google.com/run/pricing)を見ると、CloudFunctions のようなリクエストによる従量課金制で、月 2 百万リクエストまで無料だ。個人開発においては、AppEngine のようなインスタンス起動時間による料金設定よりも、こちらの方が断然オトク。\nこれはもう now.sh をやめて、こっちに乗り換えるっきゃない!!","publishedAt":"2019-04-11","slug":"cloud_run_3_step_glang","title":"Cloud Runをたった3ステップでデプロイしてみた (golang)"},{"body":"「鍵どこいったっけ？」という悩みから、おさらば！\n\n## SESAME(セサミ)って なに\n\nhttps://jp.candyhouse.co/\n\n> あなたは家を出る時、何を持って出ますか？\n> 鍵、財布、そしてスマホ…？\n> もう鍵は必要ありません。\n> スマホがあなたの鍵になります。\n\nスマートフォンから家の扉にある鍵を開けれるようになります。\n\n## Q. 危なくないの\n\n公式ページでは、次のようにアナウンスされています。\n\n結論としては、しっかりと考慮されているそうなので、そこまで神経質にならなくて良いかもです。\n\n## 長いバッテリー寿命\n\n> 電池の持ちは約 500 日。残量が少なくなったらスマホに通知が来るから安心。\n\n## 従来の鍵も使用可能\n\n> セサミは従来の鍵でも今まで通り使用可能です。スマホに慣れていない家族や、スマホの電池が切れてしまった場合でも安心です。\n\n## 通知機能\n\n> 誰かがドアを開閉した際に、あなたのスマホへ通知します。\n\n## セキュリティは某国軍事レベル\n\n> セサミは悪い人を寄せ付けません。セサミは AES-256-GCM と TLS 1.2 を採用しています。\n\n## Q. どんな機能があるの\n\n- 自動アンロック & ロック\n  - SEMAME とスマートフォンが一定距離に近づく・離れたら、鍵を開く・閉じるようになっています。\n- ノック機能（iOS のみ対応)\n  - アプリをバックグラウンドで起動している状態で、スマートフォンをノックすると、SEMAME が解錠してくれます。\n- 鍵のシェア\n  - 特定の人に鍵をシェアすることができます。\n\n## 使ってみるまでの過程\n\nまず、私の家の扉はつぎの画像の感じです。ここの下の鍵に SESAME を取り付けたいなと考えていました。\n\n![私の家の扉](https://res.cloudinary.com/silverbirder/image/upload/v1639791386/silver-birder.github.io/blog/my_house_door.png)\n\nただ、試してみると、私の家の扉では SESAME が設置できませんでした…\n\n![ミスマッチ！](https://res.cloudinary.com/silverbirder/image/upload/v1614345846/silver-birder.github.io/blog/miss_match_sesame_size.png)\n\n何がダメかというと、SESAME は両面テープでくっつけるため、壁と設置する必要があります。ただ、私の家の扉には、段差があるため、SESAME をくっつけることができませんでした…。\n\n![鍵と扉に奥行きがある](https://res.cloudinary.com/silverbirder/image/upload/v1614345933/silver-birder.github.io/blog/lock_and_door_have_depth_sesame.png)\n\nそこで、カスタマーサポートに連絡したところ、超親切にフォローして頂き、アダプター作成をしてもらえました。（送料無料、ただしアマゾンレビューをする）\n\n![SESAMEと私のやりとり。ほぼ１日程度に返事がくる](https://res.cloudinary.com/silverbirder/image/upload/v1614346016/silver-birder.github.io/blog/SESAME_and_my_correspondence_get_a_response_almost_every_day_or_so.png)\n\n返事がとてつもなく早く、本当に素晴らしいと感動しました。\nこちらが提供した情報は、扉の各必要な長さを提供したぐらいです。\n\n![それぞれの長さを提供 1](https://res.cloudinary.com/silverbirder/image/upload/v1614381654/silver-birder.github.io/blog/provide_the_length_of_each_door_1.png)\n\n![それぞれの長さを提供 2](https://res.cloudinary.com/silverbirder/image/upload/v1614381654/silver-birder.github.io/blog/provide_the_length_of_each_door_2.png)\n\n![それぞれの長さを提供 3](https://res.cloudinary.com/silverbirder/image/upload/v1614381657/silver-birder.github.io/blog/provide_the_length_of_each_door_3.png)\n\n![それぞれの長さを提供 4](https://res.cloudinary.com/silverbirder/image/upload/v1614381657/silver-birder.github.io/blog/provide_the_length_of_each_door_4.png)\n\nそれぞれの長さを提供すると、つぎのようなアダプターが完成したとのことで連絡をもらいました。（おそらく 3D プリンターで作成されたのかな)\n\n![アダプター完成図](https://res.cloudinary.com/silverbirder/image/upload/v1614382012/silver-birder.github.io/blog/SESAME_adapter_complete_diagram.png)\n\nこちらを私の家の扉に設定してみると、ぴったしハマり、無事両面テープが貼れました！ぱちぱち！\n\n![アダプターを噛ませて設置 1](https://res.cloudinary.com/silverbirder/image/upload/v1614382084/silver-birder.github.io/blog/Installation_by_engaging_the_SESAME_adapter_1.png)\n\n![アダプターを噛ませて設置 2](https://res.cloudinary.com/silverbirder/image/upload/v1614382086/silver-birder.github.io/blog/Installation_by_engaging_the_SESAME_adapter_2.png)\n\n当初、白色のアダプターが来るのかと思ったのですが、黒色がきました。良いね！\n\nhttps://youtu.be/6Bn8uYl0ans\n\n家の扉前から SESAME を使ってみた Bluetooth が繋がっている状態だと、スムーズにロック解除ができました ！わーい！\n\n## 残念ポイント…\n\nSESAME とスマートフォンが Bluetooth に繋がって**初めて**、鍵の解除ができます。ですので、Bluetooth まで繋がるまでは、何もできません。\n\nそこを待つのが長くて数十秒かかってしまうので、ちょっと待ってしまいます。また、オートロックは、１０歩程度離れると発動するのですが、オートアンロックは、ほとんど動作しませんでした。（近づいたら鍵が解除すること）。ノック機能も同様で、Bluetooth 接続されて初めてノックが有効になります。しかも、Bluetooth 接続した状態でも、ノックの失敗率が高く、あんまり使い物にはなりません…。改善の余地ありですね。\n\n## まとめ\n\nカスタマーサポートのフォローには、アマゾンレビュー星５つぐらいの好感を持てました。機能に関しては、残念ポイントで伝えたとおり、目玉機能がちょっと残念な結果になってしまいました。しかし、当初の目的だった「鍵を探す手間」は、なくなりました。家の扉に近づくころに、アプリを起動すれば、Bluetooth 接続がすんなり通るため、タップ１つで鍵が開きます。要は使い所を工夫すれば、全然メリットの方が大きいのかなと個人的にはそう思います。\n\n是非、みなさんも購入を検討してみてください。本体だと今、１つで 14,800 円です！扉を取替するよりかは断然安い！\n\n※ ちなみに、私は WiFi アクセスポイントなしの本体のみを購入しました。","publishedAt":"2019-04-08","slug":"Introduce_SESAME","title":"SESAME(セサミ) が届いたよ！"},{"body":"私が実際に使ってみて便利だと感じたオススメ商品を３つ紹介します！\n\n## スマート家電？なにそれ\n\nハマる前までは、スマート家電という言葉自体よくわかっておらず、「なんだか賢い家電なんでしょ（適当）」と興味ありませんでした。\n\nとある職場での会話をきっかけにして、その**便利さ**にドンドンとスマート家電にハマっていき、「**これはもっとはやくに知っておきたった！**」と後悔すら感じるほどでした。以降では、以下３つのスマート家電を紹介します！\n\n- [Nature Remo](https://nature.global/jp/top)\n- [Switch Bot](https://www.switchbot.jp/)\n- [Google Home Mini](https://store.google.com/jp/magazine/compare_nest_speakers_displays?hl=ja-JP&srp=/jp/product/google_home_mini)\n\n決して回し者ではないです（笑）\n\n## オススメ１： Nature Remo\n\n赤外線送信している媒体に対して、nature remo が代わりに送信してくれます。ですので、例えば照明にリモコンでポチポチ ON/OFF していたことを、代わりに nature remo がしてくれます。\n\nこれのよいところは、つぎのとおりです。\n\n- スマートフォンから ON/OFF できるので、わざわざリモコンを探さなくてすむ。\n- タイマー機能と一連の動作を設定できるので、「朝 7 時に電気とエアコンとテレビをつける」ということが自動的にしてくれる。\n- Google Home や Alexa などのスマートスピーカーと連動できるので、音声による制御もできる。（ok google, ただいま〜 → 電気エアコンテレビがつく）\n- （つかってないけど）湿度、温度、照明の明るさ、スマートフォンとの距離をトリガーにできる\n\n↓ スマートフォンから nature remo 経由で電気をつけてみます。\n\nhttps://www.youtube.com/watch?v=_j-qXrxtsyU\n\n## オススメ２： Switch Bot\n\n物理的に押すボタンに対して switch bot が代わりに押してくれます。\nnature remo では制御できなかった物理ボタンに対応しています。\n\nこれのよいところは、つぎのとおりです。\n\n- スマートフォンから物理ボタンを押したり引いたりできる。\n- タイマーやスケジューリングも可能。\n- 両面テープでしっかり固定されるので、どこでも使える。\n\nこれを使えば、帰宅中に、お風呂のお湯沸かしボタンを押せるので、\n帰宅したらすぐにお風呂に入れます！\n\n※ [SwitchBot Hub](https://www.switchbot.jp/hub-plus)というものを経由しないと自宅外から制御できないのが難点。\n\n↓ スマートフォンから switch bot 経由でボタンを押しています。\n\nhttps://www.youtube.com/watch?v=wkrPf-FuXFU\n\n## オススメ３： Google Home Mini\n\nこれは無知な僕でも知っていた商品です。音声で google アシスタントにサポートしてくれるすぐれものですよね。\n\nまた、\n\nさきほど紹介した Nature Remo や Switch Bot とも連携できるので、\n「スマートフォンからの操作」から「音声から操作」できるようになります。これはすごく便利で、「スマートフォンを開く → アプリをタップ → 操作」という流れを google home mini に「電気をつけて」って言うだけで済みます。\n\nまた、一連の操作を登録できる「ルーティン」があるので、「電気をつける、エアコンをつける、テレビをつける」→「ただいま」と登録すると「ok google, ただいま」というだけで３つの家電がつきます。\n\nこの「nature remo + switchbot + google home mini」の組み合わせは、僕の生活スタイルにピッタリで、とても楽になりました。\n\n↓ google home mini から「ただいま」を言ってみる\n\nhttps://www.youtube.com/watch?v=_XGMBIXC3pU\n\n## おわりに\n\nとある友達にこのことを伝えると「自分でやれば良いじゃん（笑）」と言われてしまいました。しかし、どっぷりハマった僕には、もう引き返せません。朝起きて、電気をつけて、エアコンをつけて、テレビをつけてる生活なんて…。\n\nむしろ、「ほかにも便利なものないのか！？」と amazon で調べまくってます。（笑）\n\nぜひとも、スマート家電のよさを知って頂ければ幸いです。\n\n## 近況\n\n近々、セサミというスマートロックが自宅に届きます。こちらは、家の扉にある鍵をスマート化します。\nこちらが届きましたら、また記事を書いてみようかなと思います。","publishedAt":"2019-03-26","slug":"Good_Smart_Gadget","title":"スマート家電のよさをしってほしい"}]